diff --git a/Documentation/devicetree/bindings/display/xlnx/amd,mmi-dc.yaml b/Documentation/devicetree/bindings/display/xlnx/amd,mmi-dc.yaml
new file mode 100644
index 000000000..442f4a872
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/amd,mmi-dc.yaml
@@ -0,0 +1,337 @@
+# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
+%YAML 1.2
+---
+$id: http://devicetree.org/schemas/display/xlnx/amd,mmi-dc.yaml#
+$schema: http://devicetree.org/meta-schemas/core.yaml#
+
+title: AMD Multimedia Integrated Display Controller.
+
+description:
+  The AMD Multimedia Integrated Display Controller IP block implements the
+  AV pipelines in the Versal Gen 2 family of devices.
+
+  The Display Controller works in 2 modes Functional and Bypass.
+
+  In Bypass mode, up to 4 video streams (including audio and SDP data) from the PL
+  can be passed on directly to the UDH Display Port Tx IP. Max resolution supported
+  in this case is 8kp30 (quad pixel per clock).
+
+  In functional mode, 2 video streams are blended and passed on to the UDH DP Tx
+  and to the PL out / feedback path. Here there can be only one of the video streams
+  can have an audio stream. The video streams can come from non live / memory path
+  or from the PL fabric input. There are 3 modes here namely -
+  1. Non-live - Both video streams, one audio stream and one cursor / SDP stream
+  are from memory. The pixel clock comes from internal clock.
+  2. Live mode - Both video streams, audio stream originate from PL
+  3. Mixed mode - One video stream is from memory and another is from PL.
+  The video clock in this case comes from the PL fabric video.
+  Max resolution supported is 4kp60.
+
+maintainers:
+  - Vishal Sagar <vishal.sagar@amd.com>
+
+properties:
+  compatible:
+    const: amd,mmi-dc-1.0
+
+  reg:
+    items:
+      - description: dp registers
+      - description: blending registers
+      - description: audio video buff mgr registers
+      - description: misc registers
+      - description: interrupt registers
+
+  reg-names:
+    items:
+      - const: dp
+      - const: blend
+      - const: avbuf
+      - const: misc
+      - const: irq
+
+  interrupts:
+    items:
+      - description: DC Misc event
+
+  dmas:
+    items:
+      - description: Video 0, plane 0
+      - description: Video 0, plane 1
+      - description: Video 0, plane 2
+      - description: Video 1, plane 0
+      - description: Video 1, plane 1
+      - description: Video 1, plane 2
+      - description: Audio
+      - description: Cursor
+
+  dma-names:
+    items:
+      - const: vid.0.0
+      - const: vid.0.1
+      - const: vid.0.2
+      - const: vid.1.0
+      - const: vid.1.1
+      - const: vid.1.2
+      - const: aud
+      - const: cur
+
+  power-domains:
+    maxItems: 1
+
+  resets:
+    maxItems: 1
+
+  clocks:
+    minItems: 1
+    items:
+      - description: PS Pixel clock from mmi_aux0_ref_clk or ps_mmi_dc_t10mode_clk
+      - description: PS Audio clock from mmi_aux1_ref_clk or ps_mmi_dc_t10mode_i2s_clk
+      - description: PL Pixel clock from pl_mmi_dc_2x_clk for DMA mode
+      - description: PL Pixel clock from pl_mmi_dc_1x_clk for Bypass mode
+      - description: PL Audio clock from pl_mmi_i2s_s0_clk
+      - description: APB Clock
+      - description: 27 MHz clock for System Timestamp Counter
+
+  clock-names:
+    minItems: 1
+    items:
+      - const: ps_vid_clk
+      - const: ps_aud_clk
+      - const: pl_vid_func_clk
+      - const: pl_vid_bypass_clk
+      - const: pl_aud_clk
+      - const: apb_clk
+      - const: stc_ref_clk
+
+  xlnx,dc-operating-mode:
+    description: Blending of 2 streams happens in functional mode.
+    enum: [DC_Functional, DC_Bypass]
+
+  xlnx,dc-presentation-mode:
+    description:
+      Non Live mode video streams come from memory.
+      Live mode video stream comes from fabric.
+      Mixed mode when 1 stream comes from fabric and other from memory.
+    enum: [Non_Live, Live, Mixed]
+
+  xlnx,dc-live-video-select:
+    description:
+      Live video input from either the first port (V01) or second port (V02)
+      or both is / are selected.
+    enum: [Both, V01, V02]
+
+  xlnx,dc-live-video01-mode:
+    description:
+      Whether V01 stream contains video only or audio and video.
+    enum: [Audio_&_Video, Video_only]
+
+  xlnx,dc-live-video02-mode:
+    description: V02 stream will always be video only
+    const: Video_only
+
+  xlnx,dc-live-video-alpha-en:
+    type: boolean
+    description: boolean present when alpha is present in video 01
+
+  xlnx,dc-live-video-sdp-en:
+    type: boolean
+    description: boolean present when SDP packets are to be sent with video 01
+
+  xlnx,dc-streams:
+    description: number of input streams to DC
+    $ref: /schemas/types.yaml#/definitions/uint32
+    enum: [1, 2, 4]
+
+  xlnx,dc-stream0-mode:
+    description:
+      In Bypass mode whether stream 0 from fabric contains
+      video only or audio and video.
+    enum: [Audio_&_Video, Video_only]
+
+  xlnx,dc-stream0-pixel-mode:
+    description: pixels per clock of Stream 0
+    $ref: /schemas/types.yaml#/definitions/uint32
+    enum: [1, 2, 4]
+
+  xlnx,dc-stream0-sdp-en:
+    type: boolean
+    description: boolean present when SDP interface is needed for stream 0.
+
+  xlnx,dc-stream1-mode:
+    description:
+      In Bypass mode whether stream 1 from fabric contains
+      video only or audio and video.
+    enum: [Audio_&_Video, Video_only]
+
+  xlnx,dc-stream1-pixel-mode:
+    description: pixels per clock of Stream 1
+    $ref: /schemas/types.yaml#/definitions/uint32
+    enum: [1, 2]
+
+  xlnx,dc-stream1-sdp-en:
+    type: boolean
+    description: boolean present when SDP interface is needed for stream 1.
+
+  xlnx,dc-stream2-mode:
+    description:
+      In Bypass mode whether stream 2 from fabric contains
+      video only or audio and video.
+    enum: [Audio_&_Video, Video_only]
+
+  xlnx,dc-stream2-pixel-mode:
+    description: pixels per clock of Stream 2
+    $ref: /schemas/types.yaml#/definitions/uint32
+    const: 1
+
+  xlnx,dc-stream2-sdp-en:
+    type: boolean
+    description: boolean present when SDP interface is needed for stream 2.
+
+  xlnx,dc-stream3-mode:
+    description:
+      In Bypass mode whether stream 3 from fabric contains
+      video only or audio and video.
+    enum: [Audio_&_Video, Video_only]
+
+  xlnx,dc-stream3-pixel-mode:
+    description: pixels per clock of Stream 3
+    $ref: /schemas/types.yaml#/definitions/uint32
+    const: 1
+
+  xlnx,dc-stream3-sdp-en:
+    type: boolean
+    description: boolean present when SDP interface is needed for stream 3.
+
+  ports:
+    type: object
+    description:
+      Connections to the programmable logic and the DisplayPort. Each port
+      shall have a single endpoint. Initial 12 are input ports.
+      Next 4 are output ports connected to DP Tx. Last 3 are output ports
+      to the PL / Feedback path for video, audio and SDP in case of functional mode.
+
+    properties:
+      "#address-cells":
+        const: 1
+
+      "#size-cells":
+        const: 0
+
+    patternProperties:
+      "^port@([0-9a-f]|1[0-2])$":
+        type: object
+        description:
+          port 0x0-0x3 represent live Video 0-3 inputs.
+          Live 0/1 are inputs in functional mode only.
+          port 0x4-0x7 represent the corresponding Audio stream inputs for live video inputs.
+          port 0x8-0xB represent the corresponding SDP stream inputs for live video inputs.
+          port 0xC-0xF represent the outputs connected to DisplayPort Tx input ports.
+          port 0xC carries the blended video output to DisplayPort Tx
+          port 0xD-0xf are connected in bypass / MST mode only.
+          port 0x10-0x12 is blended video/audio/SDP 0 output to PL feedback path
+
+        properties:
+          reg:
+            items:
+              minimum: 0
+              maximum: 18
+
+          endpoint:
+            type: object
+
+            properties:
+              remote-endpoint: true
+
+            required:
+              - remote-endpoint
+
+            additionalProperties: false
+
+        required:
+          - reg
+          - endpoint
+
+        additionalProperties: false
+
+    required:
+      - "#address-cells"
+      - "#size-cells"
+      - port@c
+
+    additionalProperties: false
+
+required:
+  - compatible
+  - reg
+  - reg-names
+  - interrupts
+  - resets
+  - clocks
+  - clock-names
+  - ports
+
+additionalProperties: false
+
+examples:
+  - |
+    axi {
+        #address-cells = <2>;
+        #size-cells = <2>;
+
+        mmi_dc@edd00000 {
+            compatible = "amd,mmi-dc-1.0";
+            reg = <0x0 0xedd00000 0x0 0x1000>, <0x0 0xedd0a000 0x0 0x1000>, <0x0 0xedd0b000 0x0 0x1000>,
+                  <0x0 0xedd0c000 0x0 0x1000>, <0x0 0xedd0d000 0x0 0x1000>;
+            reg-names = "dp", "blend", "avbuf", "misc", "irq";
+            interrupts = <0 179 4>;
+            resets = <&versal2_reset 0xc104119>;
+            clocks = <&mmi_aux0_ref_clk>, <&mmi_aux1_ref_clk>, <&pl_mmi_dc_2x_clk>,
+                     <&pl_mmi_dc_1x_clk>, <&pl_mmi_i2s_s0_clk>, <&mmi_dc_apb_clk>, <&stc_clk>;
+            clock-names = "ps_vid_clk", "ps_aud_clk", "pl_vid_func_clk",
+                          "pl_vid_bypass_clk", "pl_aud_clk", "apb_clk", "stc_ref_clk";
+            dma-names = "vid.0.0", "vid.0.1", "vid.0.2", "vid.1.0", "vid.1.1", "vid.1.2", "aud", "cur";
+            dmas = <&mmi_dcdma 0>, <&mmi_dcdma 1>, <&mmi_dcdma 2>, <&mmi_dcdma 3>, <&mmi_dcdma 4>,
+                   <&mmi_dcdma 5>, <&mmi_dcdma 6>, <&mmi_dcdma 7>;
+
+            xlnx,dc-operating-mode = "DC_Functional";
+            xlnx,dc-presentation-mode = "Non_Live";
+
+            ports {
+                #address-cells = <1>;
+                #size-cells = <0>;
+
+                port@c {
+                    reg = <12>;
+                    dc_out_0: endpoint {
+                        remote-endpoint = <&dptx_in_0>;
+                    };
+                };
+                port@d {
+                    reg = <13>;
+                    dc_out_1: endpoint {
+                        remote-endpoint = <&dptx_in_1>;
+                    };
+                };
+                port@e {
+                    reg = <14>;
+                    dc_out_2: endpoint {
+                        remote-endpoint = <&dptx_in_2>;
+                    };
+                };
+                port@f {
+                    reg = <15>;
+                    dc_out_3: endpoint {
+                        remote-endpoint = <&dptx_in_3>;
+                    };
+                };
+                port@10 {
+                    reg = <16>;
+                    dc_fb_vid_out: endpoint {
+                        remote-endpoint = <&pl_fb_rd>;
+                    };
+                };
+            };
+        };
+    };
+...
diff --git a/Documentation/devicetree/bindings/display/xlnx/bridge.txt b/Documentation/devicetree/bindings/display/xlnx/bridge.txt
new file mode 100644
index 000000000..c5f7c0a1d
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/bridge.txt
@@ -0,0 +1,29 @@
+Xilinx DRM bridge
+-----------------
+
+The Xilinx DRM provides the interface layer called Xilinx bridge to bridge
+multiple components with a series of functions. It models a simple
+unidirectional communication, single client -> single bridge. The client
+is not limited to DRM compatible drivers, but can be any subsystem driver,
+but the client driver should call the bridge functions explicitly.
+
+Provider
+--------
+
+The bridge provider should assign a corresponding of_node to struct xlnx_bridge.
+For example, if its own node is used,
+
+	provider_node: provider_node {
+	};
+
+	bridge.of_node = provider_device->of_node;
+
+Client
+------
+
+The bridge client should have a phandle to the bridge device node. The bridge
+device node should be passed to get a bridge instance,
+
+       client_node {
+	       xlnx,bridge = <&provider_node>;
+       };
diff --git a/Documentation/devicetree/bindings/display/xlnx/xlnx,dp-tx.yaml b/Documentation/devicetree/bindings/display/xlnx/xlnx,dp-tx.yaml
new file mode 100644
index 000000000..ae88d8808
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/xlnx,dp-tx.yaml
@@ -0,0 +1,227 @@
+# SPDX-License-Identifier: GPL-2.0
+%YAML 1.2
+---
+$id: http://devicetree.org/schemas/display/xlnx/xlnx,dp-tx.yaml#
+$schema: http://devicetree.org/meta-schemas/core.yaml#
+
+title: Xilinx DisplayPort Transmitter Subsystem
+
+maintainers:
+  - Rajesh Gugulothu <gugulothu.rajesh@xilinx.com>
+
+description: |
+  The Xilinx DisplayPort Tx Subsystem contains several subcores to implement
+  a DisplayPort Transmitter and outputs video data using DisplayPort protocol.
+  For more details, please refer to PG199 at
+  https://www.xilinx.com/support/documentation/ip_documentation/dp_tx_subsystem/v2_1/pg199-displayport-tx-subsystem.pdf
+
+properties:
+  compatible:
+    enum:
+      - xlnx,v-dp-txss-3.0
+      - xlnx,v-dp-txss-3.1
+
+  reg:
+    maxItems: 2
+    description: DisplayPort Transmitter Subsystem registers
+
+  reg-names:
+    items:
+      - const: dp_base
+      - const: gt_quad_base
+
+  interrupts:
+    minItems: 1
+    maxItems: 4
+
+  interrupt-names:
+    description: Only dptxss_dp_irq is mandatory. Others are optional.
+                 dptxss_timer_irq will be present when HDCP 1x or 2x is selected.
+                 dptxss_hdcp_irq will be present when HDCP 1x is selected.
+                 dptxss_hdcp22_cipher_irq will be present when HDCP 2x is selected.
+    items:
+      - const: dptxss_dp_irq
+      - const: dptxss_timer_irq
+      - const: dptxss_hdcp_irq
+      - const: dptxss_hdcp22_cipher_irq
+
+  clocks:
+    description: List of clock specifiers
+    items:
+      - description: AXI Lite clock
+      - description: Video clock
+
+  clock-names:
+    items:
+      - const: s_axi_aclk
+      - const: tx_vid_clk
+
+  phys:
+    description: This denotes phandles for phy lanes registered
+                 for DP protocol.DisplayPort always require 4 lanes
+
+  phy-names:
+    items:
+      - const: dp-phy0
+      - const: dp-phy1
+      - const: dp-phy2
+      - const: dp-phy3
+
+  xlnx,vtc-offset:
+    description: This denotes register offset address of VTC sub-core of
+                 DisplayPort Transmitter Subsystem.
+    allOf:
+      - $ref: /schemas/types.yaml#/definitions/uint32
+
+  xlnx,max-lanes:
+    description: Max number of lanes that IP configured with.
+                 Possible values are 1, 2, 4.
+    allOf:
+      - $ref: /schemas/types.yaml#/definitions/uint32
+      - enum: [1, 2, 4]
+
+  xlnx,max-link-rate:
+    description: |
+      Max link rate that IP configured with.Possible values are as below -
+      162000 - 1.6 Gb/s
+      270000 - 2.7 Gb/s
+      540000 - 5.4 Gb/s
+      810000 - 8.1 Gb/s
+    allOf:
+      - $ref: /schemas/types.yaml#/definitions/uint32
+      - enum: [162000, 270000, 540000, 810000]
+
+  xlnx,bpc:
+    description: |
+      Max BPC value that IP configured with. For example if IP is configured
+      with 10 BPC means it supports (6, 8, 10) up to 10bpc.
+      Possible values are 6, 8, 10, 12, 16.
+    allOf:
+      - $ref: /schemas/types.yaml#/definitions/uint32
+      - enum: [6, 8, 10, 12, 16]
+
+  xlnx,audio-channels:
+    description: |
+      This denotes number of audio channels enabled in the IP
+      configuration. Possible values are 2, 3, 4, 5, 6, 7, 8.
+    allOf:
+      - $ref: /schemas/types.yaml#/definitions/uint32
+      - enum: [2, 3, 4, 5, 6, 7, 8]
+
+  xlnx,hdcp22-enable:
+    type: boolean
+    description: |
+      Present when HDCP2.2 is present in design.
+
+  xlnx,hdcp-enable:
+    type: boolean
+    description: |
+      Present when HDCP1.4 is present in design.
+
+  xlnx,versal-gt:
+    type: boolean
+    description: |
+      Boolean property present when versal GT is present in design.
+
+  xlnx,xilinx-vfmc:
+    description: phandle of xilinx video FMC node
+    $ref: /schemas/types.yaml#/definitions/phandle
+
+  ports:
+    type: object
+    $ref: /schemas/graph.yaml#/properties/ports
+
+    properties:
+      port@0:
+        type: object
+        description: |
+          Output / source port node, endpoint describing modules
+          connected the DisplayPort transmitter
+
+        properties:
+          reg:
+            const: 0
+
+          endpoint:
+            type: object
+
+            properties:
+
+              remote-endpoint: true
+
+            required:
+              - remote-endpoint
+
+            additionalProperties: false
+
+        additionalProperties: false
+    unevaluatedProperties: false
+
+required:
+  - compatible
+  - reg
+  - reg-names
+  - interrupts
+  - clocks
+  - clock-names
+  - xlnx,max-link-rate
+  - xlnx,bpc
+  - xlnx,max-lanes
+  - phy-names
+  - phys
+  - ports
+
+additionalProperties: false
+
+if:
+  properties:
+    compatible:
+      contains:
+        const: xlnx,v-dp-txss-3.1
+
+then:
+  required:
+    - xlnx,vtc-offset
+
+examples:
+  - |
+   bus {
+       #address-cells = <2>;
+       #size-cells = <2>;
+
+       v_dp_txss1@a0100000 {
+           compatible = "xlnx,v-dp-txss-3.1";
+           reg = <0x0 0xa0100000 0x0 0x40000>, <0x0 0xa4080000 0x0 0x10000>;
+           reg-names = "dp_base", "gt_quad_base";
+           clock-names = "s_axi_aclk", "tx_vid_clk";
+           clocks = <&zynqmp_clk 71>, <&si570_1>;
+           interrupt-names = "dptxss_dp_irq", "dptxss_timer_irq", "dptxss_hdcp_irq",
+                              "dptxss_hdcp22_cipher_irq";
+           interrupts = <0 92 4>, <0 108 4>, <0 111 4>, <0 109 4>;
+           xlnx,vtc-offset = <0x8000>;
+           xlnx,max-lanes = <4>;
+           xlnx,max-link-rate = <810000>;
+           xlnx,bpc = <8>;
+           xlnx,audio-channels = <2>;
+           xlnx,hdcp22-enable;
+           xlnx,hdcp-enable;
+           xlnx,versal-gt;
+           xlnx,xilinx-vfmc = <&xfmc>;
+           phy-names = "dp-phy0", "dp-phy1", "dp-phy2", "dp-phy3";
+           phys = <&vphy_lane0 0 1 1 0>, <&vphy_lane1 0 1 1 0>,
+                  <&vphy_lane2 0 1 1 0>, <&vphy_lane3 0 1 1 0>;
+
+           ports {
+               #address-cells = <1>;
+               #size-cells = <0>;
+
+               port@0 {
+                   reg = <0>;
+                   dp_transmitter: endpoint {
+                       remote-endpoint = <&display_controller>;
+                   };
+               };
+           };
+       };
+   };
+...
diff --git a/Documentation/devicetree/bindings/display/xlnx/xlnx,dsi.txt b/Documentation/devicetree/bindings/display/xlnx/xlnx,dsi.txt
new file mode 100644
index 000000000..a545a0d81
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/xlnx,dsi.txt
@@ -0,0 +1,74 @@
+Device-Tree bindings for Xilinx MIPI DSI Tx IP core
+
+The IP core supports transmission of video data in MIPI DSI protocol.
+
+Required properties:
+ - compatible: Should be "xlnx,dsi".
+
+ - reg: Base address and size of the IP core.
+
+ - xlnx,dsi-datatype: Color format. The value should be one of "MIPI_DSI_FMT_RGB888",
+  "MIPI_DSI_FMT_RGB666", "MIPI_DSI_FMT_RGB666_PACKED" or "MIPI_DSI_FMT_RGB565".
+
+ - simple_panel: The subnode for connected panel. This represents the
+   DSI peripheral connected to the DSI host node. Please refer to
+   Documentation/devicetree/bindings/display/mipi-dsi-bus.txt. The
+   simple-panel driver has auo,b101uan01 panel timing parameters added along
+   with other existing panels. DSI driver derive the required Tx IP controller
+   timing values from the panel timing parameters.
+
+ - port: Logical block can be used / connected independently with
+   external device. In the display controller port nodes, topology
+   for entire pipeline should be described using the DT bindings defined in
+   Documentation/devicetree/bindings/graph.txt.
+
+ - xlnx,dsi-num-lanes: Possible number of DSI lanes for the Tx controller.
+   The values should be 1, 2, 3 or 4. Based on xlnx,dsi-num-lanes and
+   line rate for the MIPI D-PHY core in Mbps, the AXI4-stream received by
+   Xilinx MIPI DSI Tx IP core adds markers as per DSI protocol and the packet
+   thus framed is convered to serial data by MIPI D-PHY core. Please refer
+   Xilinx pg238 for more details. This value should be equal to the number
+   of lanes supported by the connected DSI panel. Panel has to support this
+   value or has to be programmed to the same value that DSI Tx controller is
+   configured to.
+
+ - clocks: List of phandles to Video and 200Mhz DPHY clocks.
+
+ - clock-names: Must contain "s_axis_aclk" and "dphy_clk_200M" in same order as
+   clocks listed in clocks property.
+
+Required simple_panel properties:
+ - compatible: Value should be one of the panel names in
+   Documentation/devicetree/bindings/display/panel/. e.g. "auo,b101uan01".
+   For available panel compatible strings, please refer to bindings in
+   Documentation/devicetree/bindings/display/panel/
+
+Optional properties:
+ - xlnx,vpss: vpss phandle
+   This handle is required only when VPSS is connected to DSI as bridge.
+ - xlnx,dsi-cmd-mode: denotes command mode enable.
+
+Example:
+
+#include <dt-bindings/drm/mipi-dsi.h>
+	mipi_dsi_tx_subsystem@80000000 {
+		compatible = "xlnx,dsi";
+		reg = <0x0 0x80000000 0x0 0x10000>;
+		xlnx,dsi-num-lanes = <4>;
+		xlnx,dsi-data-type = <MIPI_DSI_FMT_RGB888>;
+		#address-cells = <1>;
+		#size-cells = <0>;
+		xlnx,vpss = <&v_proc_ss_0>;
+		clock-names = "dphy_clk_200M", "s_axis_aclk";
+		clocks = <&misc_clk_0>, <&misc_clk_1>;
+		encoder_dsi_port: port@0 {
+			reg = <0>;
+			dsi_encoder: endpoint {
+				remote-endpoint = <&xyz_port>;
+			};
+		};
+		simple_panel: simple-panel@0 {
+			compatible = "auo,b101uan01";
+			reg = <0>;
+			};
+		};
diff --git a/Documentation/devicetree/bindings/display/xlnx/xlnx,mixer.txt b/Documentation/devicetree/bindings/display/xlnx/xlnx,mixer.txt
new file mode 100644
index 000000000..22eddebb8
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/xlnx,mixer.txt
@@ -0,0 +1,215 @@
+Device-Tree bindings for Xilinx Video Mixer IP core
+
+The IP core provides a flexible video processing block for alpha blending
+and compositing multiple video and/or graphics layers.
+Support for up to sixteen layers based on IP version, with an optional logo
+layer, using a combination of video inputs from either frame buffer or
+streaming video cores (through AXI4-Stream interfaces) is provided.
+The Video Mixer always has one streaming input layer, known as master layer.
+
+Required properties:
+ - compatible: Must contain atleast one of
+	"xlnx,v-mix-5.3" (MIXER 5.3 version)
+	"xlnx,mixer-5.0" (MIXER 5.0 version)
+	"xlnx,mixer-4.0" (MIXER 4.0 version)
+	"xlnx,mixer-3.0" (MIXER 3.0 version)
+ - reg: Base address and size of the IP core.
+ - interrupts: Interrupt number.
+ - interrupts-parent: phandle for interrupt controller.
+ - reset-gpio: gpio to reset the mixer IP
+ - xlnx,enable-csc-coefficient-register: denotes colorimetry
+   coefficients can be programmed, valid for mixer 5.0 version only.
+ - xlnx,dma-addr-width: dma address width, valid values are 32 and 64
+ - xlnx,bpc: bits per component for mixer
+ - xlnx,ppc: pixel per clock for mixer
+ - xlnx,num-layers: Total number of layers (excluding logo)
+   Value ranges from 1-9 for compatible string xlnx,mixer-3.0 and
+   Value ranges from 1-17 for comptaible string xlnx,mixer-4.0 and above
+ - layer_[x]: node for [x] layer
+ - xlnx,layer-id: layer identifier number
+ - xlnx,vformat: video format for layer. See list of supported formats below.
+ - xlnx,layer-max-width: max layer width, mandatory for master layer
+   for overlay layers if scaling is alowed then this is mandatory otherwise
+   not required for overlay layers. Valid range is 64 to 8192
+ - xlnx,layer-max-height: max layer height, mandatory for master layer
+   Not required for overlay layers. Valid range is 64 to 4320
+ - xlnx,layer-primary: denotes the primary layer, should be mentioned in node
+   of layer which is expected to be constructing the primary plane
+
+Optional properties:
+ - dmas: dma attach to layer, mandatory for master layer
+   for rest other layers its optional
+ - dma-names: Should be "dma0", for more details on DMA identifier string
+   refer Documentation/devicetree/bindings/dma/dma.txt
+ - xlnx,layer-streaming: denotes layer can be streaming,
+   mandatory for master layer. Streaming layers need external dma, where
+   as non streaming layers read directly from memory.
+ - xlnx,layer-alpha: denotes layer can do alpha compositing
+ - xlnx,layer-scale: denotes layer can be scale to 2x and 4x
+ - xlnx,logo-layer: denotes logo layer is enable
+ - logo: logo layer
+ - xlnx,bridge: phandle to bridge node.
+   This handle is required only when VTC is connected as bridge.
+ - memory-region: phandle to /reserved-memory node.
+   If memory is reserved for special use by mixer then this node
+   can be used to refer and use from this reserved memory region.
+
+Supported Formats:
+	Mixer IP Format		Driver supported Format String
+	 BGR888			"RG24"
+	 RGB888			"BG24"
+	 XBGR2101010		"XB30"
+	 XRGB8888		"XR24"
+	 RGBA8888		"RA24"
+	 ABGR8888		"AB24"
+	 ARGB8888		"AR24"
+	 XBGR8888		"XB24"
+	 YUYV			"YUYV"
+	 UYVY			"UYVY"
+	 AYUV			"AYUV"
+	 NV12			"NV12"
+	 NV16			"NV16"
+	 Y8			"GREY"
+	 Y10			"Y10 " (Note: Space included)
+	 XVUY2101010		"XV30"
+	 VUY888			"VU24"
+	 XVUY8888		"XV24"
+	 XV15			"XV15"
+	 XV20			"XV20"
+	 Y_U_V8			"y_u_v8"
+	 Y_U_V10		"y_u_v10"
+	 Y_U_V12		"y_u_v12"
+Note : Format strings are case sensitive.
+
+Example:
+	v_mix_0: v_mix@80100000 {
+		compatible = "xlnx,mixer-3.0";
+		interrupt-parent = <&gic>;
+		interrupts = <0 93 4>;
+		reg = <0x0 0x80100000 0x0 0x80000>;
+
+		xlnx,dma-addr-width=<32>;
+		reset-gpios = <&gpio 1 1>;
+
+		xlnx,bpc = <8>;
+		xlnx,ppc = <2>;
+		xlnx,num-layers = <8>;
+		xlnx,logo-layer;
+		xlnx,bridge = <&v_tc_0>;
+
+		mixer_port: mixer_port@0 {
+			reg = <0>;
+			mixer_crtc: endpoint {
+				remote-endpoint = <&sdi_encoder>;
+			};
+		};
+		xv_mix_master: layer_0 {
+			xlnx,layer-id = <0>;
+			xlnx,vformat = "YUYV";
+			xlnx,layer-max-width = <4096>;
+			xlnx,layer-height = <2160>;
+			dmas = <&axi_vdma_0 0>;
+			dma-names = "dma0";
+			xlnx,layer-streaming;
+			xlnx,layer-primary;
+		};
+		xv_mix_overlay_1: layer_1 {
+			xlnx,layer-id = <1>;
+			xlnx,vformat = "NV16";
+			xlnx,layer-alpha;
+			xlnx,layer-scale;
+			xlnx,layer-max-width=<1920>;
+		};
+		xv_mix_overlay_2: layer_2 {
+			xlnx,layer-id = <2>;
+			xlnx,vformat = "YUYV";
+			xlnx,layer-alpha;
+			xlnx,layer-scale;
+			xlnx,layer-max-width=<1920>;
+		};
+		xv_mix_overlay_3: layer_3 {
+			xlnx,layer-id = <3>;
+			xlnx,vformat = "AYUV";
+			xlnx,layer-alpha;
+			xlnx,layer-scale;
+			xlnx,layer-max-width=<1920>;
+		};
+		xv_mix_overlay_4: layer_4 {
+			xlnx,layer-id = <4>;
+			xlnx,vformat = "GREY";
+			dmas = <&scaler_v_frmbuf_rd_0 0>;
+			dma-names = "dma0";
+			xlnx,layer-streaming;
+			xlnx,layer-alpha;
+			xlnx,layer-scale;
+			xlnx,layer-max-width=<1920>;
+		};
+		xv_mix_overlay_5: layer_5 {
+			xlnx,layer-id = <5>;
+			xlnx,vformat = "AB24";
+			xlnx,layer-alpha;
+			xlnx,layer-scale;
+			xlnx,layer-max-width=<1920>;
+		};
+		xv_mix_overlay_6: layer_6 {
+			xlnx,layer-id = <6>;
+			xlnx,vformat = "XB24";
+			xlnx,layer-alpha;
+			xlnx,layer-scale;
+			xlnx,layer-max-width=<1920>;
+			};
+		xv_mix_overlay_7: layer_7 {
+			xlnx,layer-id = <7>;
+			xlnx,vformat = "BG24";
+			xlnx,layer-alpha;
+			xlnx,layer-scale;
+			xlnx,layer-max-width=<1920>;
+		};
+		xv_mix_logo: logo {
+			xlnx,layer-id = <8>;
+			xlnx,logo-height = <64>;
+			xlnx,logo-width = <64>;
+		};
+	};
+Example using reserved memory:
+Reserving from 32bit Shared CMA pool of 512MiB using System RAM:
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+/ {
+	reserved-memory {
+		#address-cells = <0x2>;
+		#size-cells = <0x2>;
+		ranges;
+		psmem_multimedia: multimedia_cma_mem_region {
+			compatible = "shared-dma-pool";
+			reg = <0x00 0x40000000 0x00 0x20000000>;
+			reusable;
+		};
+	};
+};
+...
+	v_mix_0: v_mix@80100000 {
+		/* ... */
+		memory-region = <&psmem_multimedia>;
+	};
+
+Reserving from 64bit Shared DMA pool of 1792 MiB using external PL based
+DDR memory:
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+/ {
+	reserved-memory {
+		#address-cells = <0x2>;
+		#size-cells = <0x2>;
+		ranges;
+		plmem_multimedia: multimedia_dma_mem_region {
+			compatible = "shared-dma-pool";
+			no-map;
+			reg = <0x48 0x0 0x0 0x70000000>;
+		};
+	};
+
+};
+...
+	v_mix_0: v_mix@80100000 {
+		/* ... */
+		memory-region = <&plmem_multimedia>;
+	}
diff --git a/Documentation/devicetree/bindings/display/xlnx/xlnx,pl-disp.txt b/Documentation/devicetree/bindings/display/xlnx/xlnx,pl-disp.txt
new file mode 100644
index 000000000..229bde36b
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/xlnx,pl-disp.txt
@@ -0,0 +1,86 @@
+Xilinx PL Display driver
+------------------------
+
+Pl_Display is a logical device to provide completeness to xilinx display
+pipeline. This is a software driver for providing drm components crtc
+and plane for various IPs using xilinx display pipelines.
+
+A linear pipeline with multiple blocks:
+DMA --> PL_Display --> SDI
+
+Required properties:
+
+- compatible: Must be "xlnx,pl-disp"
+- dmas: dma attach to pipeline
+- dma-names: names for dma
+- memory-region: phandle to /reserved-memory node.
+  If memory is reserved for special use by PL display then this node
+  can be used to refer and use from this reserved memory region.
+- xlnx,vformat: video format for layer
+- port: Logical block can be used / connected independently with
+  external device. In the display controller port nodes, topology
+  for entire pipeline should be described using the DT bindings defined in
+  Documentation/devicetree/bindings/graph.txt.
+- reg: Base address and size of device
+
+Optional properties:
+ - xlnx,bridge: bridge phandle
+   This handle is required only when VTC is connected as bridge.
+
+Example:
+
+	drm-pl-disp-drv {
+		compatible = "xlnx,pl-disp";
+		dmas = <&axi_vdma_0 0>;
+		dma-names = "dma0";
+		xlnx,vformat = "YUYV";
+		xlnx,bridge = <&v_tc_0>;
+		pl_disp_port@0 {
+			reg = <0>;
+			endpoint {
+				remote-endpoint = <&sdi_port>;
+			};
+		};
+	};
+Example using reserved memory:
+Reserving from 32bit Shared CMA pool of 512MiB using System RAM:
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+/ {
+	reserved-memory {
+		#address-cells = <0x2>;
+		#size-cells = <0x2>;
+		ranges;
+		psmem_multimedia: multimedia_cma_mem_region {
+			compatible = "shared-dma-pool";
+			reg = <0x00 0x40000000 0x00 0x20000000>;
+			reusable;
+		};
+	};
+};
+...
+	drm-pl-disp-drv {
+		/* ... */
+		memory-region = <&psmem_multimedia>;
+	};
+
+Reserving from 64bit Shared DMA pool of 1792 MiB using external PL based
+DDR memory:
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+/ {
+	reserved-memory {
+		#address-cells = <0x2>;
+		#size-cells = <0x2>;
+		ranges;
+		plmem_multimedia: multimedia_dma_mem_region {
+			compatible = "shared-dma-pool";
+			no-map;
+			reg = <0x500 0x00 0x00 0x70000000>;
+		};
+	};
+
+};
+...
+	drm-pl-disp-drv {
+		/* ... */
+		memory-region = <&plmem_multimedia>;
+	}
diff --git a/Documentation/devicetree/bindings/display/xlnx/xlnx,sdi-tx.yaml b/Documentation/devicetree/bindings/display/xlnx/xlnx,sdi-tx.yaml
new file mode 100644
index 000000000..1cc604d37
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/xlnx,sdi-tx.yaml
@@ -0,0 +1,137 @@
+# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
+%YAML 1.2
+---
+$id: http://devicetree.org/schemas/display/xlnx/xlnx,sdi-tx.yaml#
+$schema: http://devicetree.org/meta-schemas/core.yaml#
+
+title: Xilinx SDI Transmitter Subsystem
+
+maintainers:
+  - Katta Dhanunjanrao <katta.dhanunjanrao@amd.com>
+
+description:
+  The AMD SDI Tx Subsystem conatins several subcores to implement
+  a SDI Transmitter and outputs video data using SDI protocol.
+  For more details refer to PG289 SMPTE UHD-SDI transmitter subsystems.
+
+properties:
+  compatible:
+    const: xlnx,sdi-tx
+
+  reg:
+    maxItems: 1
+
+  interrupts:
+    maxItems: 1
+
+  clocks:
+    description: List of phandles to AXI Lite, Video and SDI Tx Clock.
+    items:
+      - description: AXI4-Lite CPU clock.
+      - description: Video input clock.
+      - description: SMPTE UHD-SDI Tx core clock.
+
+  clock-names:
+    items:
+      - const: s_axi_aclk
+      - const: video_in_clk
+      - const: sdi_tx_clk
+
+  phy-reset-gpios:
+    description: Specifier for a GPIO that asserts GT phy.
+
+  xlnx,picxo-enabled:
+    description: This property is present when PICXO is present in design.
+    type: boolean
+
+  xlnx,qpll1-enabled:
+    description: The property is present when the QPLL1 drives GT clock
+                 absent with QPLL0 drives GT clock.
+    type: boolean
+
+  xlnx,tx-insert-c-str-st352:
+    description: Insert ST352 payload id in chroma stream.
+    type: boolean
+
+  xlnx,vpss:
+    description: This is required only when VPSS is connected to SDI as bridge.
+    $ref: /schemas/types.yaml#/definitions/phandle
+
+  ports:
+    type: object
+    properties:
+      "#address-cells":
+        const: 1
+
+      "#size-cells":
+        const: 0
+
+    patternProperties:
+      "^port@[0-1]$":
+        type: object
+        description: port@0 is output. port@1 is input.
+
+        properties:
+          reg:
+            enum: [0, 1]
+
+          endpoint:
+            type: object
+
+            properties:
+              remote-endpoint: true
+
+            required:
+              - remote-endpoint
+
+            additionalProperties: false
+
+        required:
+          - reg
+          - endpoint
+
+        additionalProperties: false
+
+    required:
+      - "#address-cells"
+      - "#size-cells"
+      - port@0
+      - port@1
+
+    additionalProperties: false
+
+required:
+  - reg
+  - clocks
+  - clock-names
+  - interrupts
+  - ports
+
+additionalProperties: false
+
+examples:
+  - |
+    sdi-tx-subsystem@80000000 {
+        compatible = "xlnx,sdi-tx";
+        reg = <0x80000000 0x10000>;
+        clocks = <&misc_clk_0>, <&misc_clk_1>, <&misc_clk_2>;
+        clock-names = "s_axi_aclk", "video_in_clk", "sdi_tx_clk";
+        interrupts = <0 90 4>;
+        ports {
+            #address-cells = <1>;
+            #size-cells = <0>;
+            port@0 {
+                reg = <0>;
+                endpoint {
+                    remote-endpoint = <&pl_disp_crtc>;
+                };
+            };
+            port@1 {
+                reg = <1>;
+                endpoint {
+                    remote-endpoint = <&sditx_audio_embed_src_port>;
+                };
+            };
+        };
+    };
+...
diff --git a/Documentation/devicetree/bindings/display/xlnx/xlnx,v-hdmi-txss1.yaml b/Documentation/devicetree/bindings/display/xlnx/xlnx,v-hdmi-txss1.yaml
new file mode 100644
index 000000000..82228e611
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/xlnx,v-hdmi-txss1.yaml
@@ -0,0 +1,216 @@
+# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
+%YAML 1.2
+---
+$id: http://devicetree.org/schemas/display/xlnx/xlnx,v-hdmi-txss1.yaml#
+$schema: http://devicetree.org/meta-schemas/core.yaml#
+
+title: Xilinx HDMI Transmitter Subsystem
+
+maintainers:
+  - Venkateshwar Rao Gannavarapu <venkateshwar.rao.gannavarapu@xilinx.com>
+
+description: |
+  The Xilinx HDMI Tx Subsystem contains several subcores to implement
+  a HDMI Transmitter and outputs video data using HDMI protocol.
+  For more details refer to PG350 Xilinx HDMI-2.1 Tx Subsystem.
+
+properties:
+  compatible:
+    items:
+      - enum:
+          - xlnx,v-hdmi-txss1-1.1
+          - xlnx,v-hdmi-txss1-1.2
+
+  reg:
+    maxItems: 1
+
+  interrupts:
+    minItems: 1
+    maxItems: 4
+
+  interrupt-names:
+    description: Only hdmitx interrupt is mandatory. Others are optional.
+                 hdcp14 and hdcp14timer will be present when HDCP 1x
+                 is selected.
+                 hdcp22timer will be present when HDCP 2x is selected.
+    items:
+      - const: hdmitx
+      - const: hdcp14
+      - const: hdcp14timer
+      - const: hdcp22timer
+
+  clocks:
+    description: List of clock specifiers
+    items:
+      - description: AXI Lite CPU clock
+      - description: Link clock
+      - description: Video clock
+      - description: Fixed Rate Link clock
+      - description: AXI4-Stream Video clock
+
+  clock-names:
+    items:
+      - const: s_axi_cpu_aclk
+      - const: link_clk
+      - const: video_clk
+      - const: frl_clk
+      - const: s_axis_video_aclk
+
+  phys:
+    description: This denotes phandles for phy lanes registered
+                 for HDMI protocol. HDMI always require 4 lanes
+
+  phy-names:
+    items:
+      - const: hdmi-phy0
+      - const: hdmi-phy1
+      - const: hdmi-phy2
+      - const: hdmi-phy3
+
+  xlnx,input-pixels-per-clock:
+    description: Configurable samples per clock.
+                 Possible values are 4, 8.
+    allOf:
+      - $ref: /schemas/types.yaml#/definitions/uint32
+      - enum: [4, 8]
+
+  xlnx,max-bits-per-component:
+    description: |
+      Max BPC value that IP configured with. For example if IP is configured
+      with 12 BPC means it supports (8, 10, 12) up to 12bpc.
+      Possible values are 8, 10, 12, 16.
+    allOf:
+      - $ref: /schemas/types.yaml#/definitions/uint32
+      - enum: [8, 10, 12, 16]
+
+  xlnx,vid-interface:
+    description: Supported video interface.
+                 Possible values are 0 for AXI4-Stream,
+                 1 for Native and 2 for Native-IDE interface.
+    allOf:
+      - $ref: /schemas/types.yaml#/definitions/uint32
+      - enum: [0, 1, 2]
+
+  xlnx,max-frl-rate:
+    description: Maximum FRL Rate.
+                 Possible values are 0 for TMDS mode,
+                 1 to 6 for FRL mode of operation.
+    allOf:
+      - $ref: /schemas/types.yaml#/definitions/uint32
+      - enum: [0, 1, 2, 3, 4, 5, 6]
+
+  xlnx,include-hdcp-1-4:
+    type: boolean
+    $ref: /schemas/types.yaml#/definitions/flag
+    description: |
+      Present when HDCP1.4 is present in design.
+
+  xlnx,include-hdcp-2-2:
+    type: boolean
+    $ref: /schemas/types.yaml#/definitions/flag
+    description: |
+      Present when HDCP2.2 is present in design.
+
+  xlnx,hdcp1x-keymgmt:
+    description:
+      A phandle to a syscon device, used to access
+      hdcp1x keymgmt registers.
+    $ref: /schemas/types.yaml#/definitions/phandle
+
+  ports:
+    type: object
+
+    properties:
+      "#address-cells":
+        const: 1
+
+      "#size-cells":
+        const: 0
+
+      port@0:
+        type: object
+        description: |
+          Output / source port node, endpoint describing modules
+          connected the HDMI transmitter
+
+        properties:
+          reg:
+            const: 0
+
+          endpoint:
+            type: object
+
+            properties:
+
+              remote-endpoint: true
+
+            required:
+              - remote-endpoint
+
+            additionalProperties: false
+
+        additionalProperties: false
+
+    additionalProperties: false
+
+required:
+  - compatible
+  - reg
+  - interrupts
+  - clocks
+  - clock-names
+  - phys
+  - phy-names
+  - xlnx,input-pixels-per-clock
+  - xlnx,max-bits-per-component
+  - xlnx,vid-interface
+  - xlnx,max-frl-rate
+  - ports
+
+additionalProperties: false
+
+dependencies:
+  xlnx,include-hdcp-1-4: [ 'xlnx,hdcp1x-keymgmt' ]
+  xlnx,hdcp1x-keymgmt: [ 'xlnx,include-hdcp-1-4' ]
+
+examples:
+  - |
+    #include <dt-bindings/interrupt-controller/arm-gic.h>
+
+    v_hdmi_txss1@80020000 {
+        compatible = "xlnx,v-hdmi-txss1-1.1";
+        reg = <0x80020000 0x20000>;
+        interrupt-names = "hdmitx", "hdcp14", "hdcp14timer",
+                          "hdcp22timer";
+        interrupts = <GIC_SPI 91 IRQ_TYPE_LEVEL_HIGH>, <GIC_SPI 106 IRQ_TYPE_LEVEL_HIGH>,
+                     <GIC_SPI 107 IRQ_TYPE_LEVEL_HIGH>, <GIC_SPI 111 IRQ_TYPE_LEVEL_HIGH>;
+        clock-names = "s_axi_cpu_aclk", "link_clk", "video_clk", "frl_clk", "s_axis_video_aclk";
+        clocks = <&zynqmp_clk 71>, <&misc_clk_1>, <&misc_clk_3>, <&misc_clk_4>, <&misc_clk_5>;
+        xlnx,input-pixels-per-clock = <4>;
+        xlnx,max-bits-per-component = <0x8>;
+        xlnx,vid-interface = <0>;
+        xlnx,max-frl-rate = <0x6>;
+        xlnx,include-hdcp-1-4;
+        xlnx,include-hdcp-2-2;
+        xlnx,hdcp1x-keymgmt = <&hdcp_keymngmt_blk_0>;
+        phy-names = "hdmi-phy0", "hdmi-phy1", "hdmi-phy2", "hdmi-phy3";
+        phys = <&hdmiphy_lane0 0 1 1 1>, <&hdmiphy_lane1 0 1 1 1>,
+               <&hdmiphy_lane2 0 1 1 1>, <&hdmiphy_lane3 0 1 1 1>;
+        ports {
+            #address-cells = <1>;
+            #size-cells = <0>;
+
+            port@0 {
+                reg = <0>;
+                hdmi_encoder: endpoint {
+                    remote-endpoint = <&dmaengine_crtc>;
+                };
+            };
+        };
+    };
+
+    hdcp_keymngmt_blk_0: hdcp_keymngmt_blk@80030000 {
+        compatible = "xlnx,hdcp-keymngmt-blk-1.0", "syscon";
+        reg = <0x80030000 0x10000>;
+    };
+...
diff --git a/Documentation/devicetree/bindings/display/xlnx/xlnx,vpss-csc.yaml b/Documentation/devicetree/bindings/display/xlnx/xlnx,vpss-csc.yaml
new file mode 100644
index 000000000..59dcbb176
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/xlnx,vpss-csc.yaml
@@ -0,0 +1,68 @@
+# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
+%YAML 1.2
+---
+$id: http://devicetree.org/schemas/display/xlnx/xlnx,vpss-csc.yaml#
+$schema: http://devicetree.org/meta-schemas/core.yaml#
+
+title: Xilinx VPROC_SS IP.
+
+maintainers:
+  - Kunal Rane <kunal.rane@amd.com>
+
+description:
+  The Xilinx VPSS Color Space Converter is a Video IP that supports
+  color space conversion from RGB to YUV 444/422/420 and vice versa.
+
+properties:
+  compatible:
+    const: xlnx,vpss-csc
+
+  reg:
+    maxItems: 1
+
+  clocks:
+    description: Reference to video core clock.
+    maxItems: 1
+
+  reset-gpios:
+    description: Should contain GPIO reset phandle
+    maxItems: 1
+
+  xlnx,max-height:
+    description: Maximum number of lines.
+    $ref: /schemas/types.yaml#/definitions/uint32
+    minimum: 64
+    maximum: 4320
+
+  xlnx,max-width:
+    description: Maximum number of pixels in a line.
+    $ref: /schemas/types.yaml#/definitions/uint32
+    minimum: 64
+    maximum: 8192
+
+  xlnx,video-width:
+    description: Video width set for the IP.
+    $ref: /schemas/types.yaml#/definitions/uint32
+    enum: [8, 10, 12, 16]
+
+required:
+  - reg
+  - clocks
+  - reset-gpios
+  - xlnx,max-width
+  - xlnx,max-height
+  - xlnx,video-width
+
+additionalProperties: false
+
+examples:
+  - |
+    csc@a0040000 {
+        compatible = "xlnx,vpss-csc";
+        reg = <0xa0040000 0x10000>;
+        clocks = <&misc_clk_0>;
+        reset-gpios = <&gpio 0 1>;
+        xlnx,max-height = <2160>;
+        xlnx,max-width = <3840>;
+        xlnx,video-width = <8>;
+    };
diff --git a/Documentation/devicetree/bindings/display/xlnx/xlnx,vpss-scaler.yaml b/Documentation/devicetree/bindings/display/xlnx/xlnx,vpss-scaler.yaml
new file mode 100644
index 000000000..146d705b1
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/xlnx,vpss-scaler.yaml
@@ -0,0 +1,98 @@
+# SPDX-License-Identifier: (GPL-2.0-only OR BSD-2-Clause)
+%YAML 1.2
+---
+$id: http://devicetree.org/schemas/display/xlnx/xlnx,vpss-scaler.yaml#
+$schema: http://devicetree.org/meta-schemas/core.yaml#
+
+title: Xilinx VPROC_SS IP.
+
+maintainers:
+  - Kunal Rane <kunal.rane@amd.com>
+
+description:
+  The Xilinx VPSS Scaler is a Video IP that supports up scaling,
+  down scaling and no scaling functionailty. This supports custom
+  resolution values between 0 to 4096.
+
+properties:
+  compatible:
+    const: xlnx,vpss-scaler
+
+  reg:
+    maxItems: 1
+
+  clock-names:
+    items:
+      - const: aclk_ctrl
+      - const: aclk_axis
+
+  clocks:
+    description: List of clock specifiers.
+    items:
+      - description: AXI Lite CPU clock
+      - description: Video clock
+
+  reset-gpios:
+    description: Should contain GPIO reset phandle
+    maxItems: 1
+
+  xlnx,num-hori-taps:
+    description: The number of horizontal taps for scaling filter.
+      A value of 2 represents bilinear filters.
+      A value of 4 represents bicubic. Values 6, 8, 10, 12 represent
+      polyphase filters.
+    $ref: /schemas/types.yaml#/definitions/uint32
+    enum: [2, 4, 6, 8, 10, 12]
+
+  xlnx,num-vert-taps:
+    description: The number of vertical taps for scaling filter.
+      A value of 2 represents bilinear filters.
+      A value of 4 represents bicubic. Values 6, 8, 10, 12 represent
+      polyphase filters.
+    $ref: /schemas/types.yaml#/definitions/uint32
+    enum: [2, 4, 6, 8, 10, 12]
+
+  xlnx,max-height:
+    description: Maximum number of lines.
+    $ref: /schemas/types.yaml#/definitions/uint32
+    minimum: 64
+    maximum: 4320
+
+  xlnx,max-width:
+    description: Maximum number of pixels in a line.
+    $ref: /schemas/types.yaml#/definitions/uint32
+    minimum: 64
+    maximum: 8192
+
+  xlnx,pix-per-clk:
+    description: The pixels per clock property of the IP.
+    $ref: /schemas/types.yaml#/definitions/uint32
+    enum: [1, 2, 4, 8]
+
+required:
+  - reg
+  - clock-names
+  - clocks
+  - reset-gpios
+  - xlnx,num-hori-taps
+  - xlnx,num-vert-taps
+  - xlnx,max-height
+  - xlnx,max-width
+  - xlnx,pix-per-clk
+
+additionalProperties: false
+
+examples:
+  - |
+    scaler@a0040000 {
+        compatible = "xlnx,vpss-scaler";
+        reg = <0xa0000000 0x40000>;
+        clock-names = "aclk_ctrl", "aclk_axis";
+        clocks = <&misc_clk_0>, <&misc_clk_1>;
+        reset-gpios = <&gpio 0 1>;
+        xlnx,num-hori-taps = <8>;
+        xlnx,num-vert-taps = <8>;
+        xlnx,max-height = <2160>;
+        xlnx,max-width = <3840>;
+        xlnx,pix-per-clk = <2>;
+    };
diff --git a/Documentation/devicetree/bindings/display/xlnx/xlnx,vtc.txt b/Documentation/devicetree/bindings/display/xlnx/xlnx,vtc.txt
new file mode 100644
index 000000000..6a4d5bcc5
--- /dev/null
+++ b/Documentation/devicetree/bindings/display/xlnx/xlnx,vtc.txt
@@ -0,0 +1,32 @@
+Device-Tree bindings for Xilinx Video Timing Controller(VTC)
+
+Xilinx VTC is a general purpose video timing generator and detector.
+The input side of this core automatically detects horizontal and
+vertical synchronization, pulses, polarity, blanking timing and active pixels.
+While on the output, it generates the horizontal and vertical blanking and
+synchronization pulses used with a standard video system including support
+for programmable pulse polarity.
+
+The core is commonly used with Video in to AXI4-Stream core to detect the
+format and timing of incoming video data or with AXI4-Stream to Video out core
+to generate outgoing video timing for downstream sinks like a video monitor.
+
+For details please refer to
+https://www.xilinx.com/support/documentation/ip_documentation/v_tc/v6_1/pg016_v_tc.pdf
+
+Required properties:
+ - compatible: value should be "xlnx,bridge-v-tc-6.1"
+ - reg: base address and size of the VTC IP
+ - xlnx,pixels-per-clock: Pixels per clock of the stream. Can be 1, 2 or 4.
+ - clocks: List of phandles for AXI Lite and Video Clock
+ - clock-names: Must contain "s_axi_aclk" and "clk" in same order as clocks listed
+   in clocks property.
+
+Example:
+	v_tc_0: v_tc@80030000 {
+			compatible = "xlnx,bridge-v-tc-6.1";
+			reg = <0x0 0x80030000 0x0 0x10000>;
+			xlnx,pixels-per-clock = <2>;
+			clock-names = "s_axi_aclk", "clk";
+			clocks = <&misc_clk_0>, <&misc_clk_1>;
+	};
diff --git a/Documentation/devicetree/bindings/display/xlnx/xlnx,zynqmp-dpsub.yaml b/Documentation/devicetree/bindings/display/xlnx/xlnx,zynqmp-dpsub.yaml
index 554f9d580..6b754d4f2 100644
--- a/Documentation/devicetree/bindings/display/xlnx/xlnx,zynqmp-dpsub.yaml
+++ b/Documentation/devicetree/bindings/display/xlnx/xlnx,zynqmp-dpsub.yaml
@@ -100,12 +100,16 @@ properties:
       - description: Video layer, plane 1 (U/V or U)
       - description: Video layer, plane 2 (V)
       - description: Graphics layer
+      - description: Audio channel 0
+      - description: Audio channel 1
   dma-names:
     items:
       - const: vid0
       - const: vid1
       - const: vid2
       - const: gfx0
+      - const: aud0
+      - const: aud1
 
   phys:
     description: PHYs for the DP data lanes
@@ -194,11 +198,13 @@ examples:
         power-domains = <&pd_dp>;
         resets = <&reset ZYNQMP_RESET_DP>;
 
-        dma-names = "vid0", "vid1", "vid2", "gfx0";
+        dma-names = "vid0", "vid1", "vid2", "gfx0", "aud0", "aud1";
         dmas = <&xlnx_dpdma 0>,
                <&xlnx_dpdma 1>,
                <&xlnx_dpdma 2>,
-               <&xlnx_dpdma 3>;
+               <&xlnx_dpdma 3>,
+               <&xlnx_dpdma 4>,
+               <&xlnx_dpdma 5>;
 
         phys = <&psgtr 1 PHY_TYPE_DP 0 3>,
                <&psgtr 0 PHY_TYPE_DP 1 3>;
diff --git a/Documentation/gpu/drivers.rst b/Documentation/gpu/drivers.rst
index b899cbc5c..187201aed 100644
--- a/Documentation/gpu/drivers.rst
+++ b/Documentation/gpu/drivers.rst
@@ -22,6 +22,7 @@ GPU Driver Documentation
    afbc
    komeda-kms
    panfrost
+   zynqmp
 
 .. only::  subproject and html
 
diff --git a/Documentation/gpu/zynqmp.rst b/Documentation/gpu/zynqmp.rst
new file mode 100644
index 000000000..1a6f9193d
--- /dev/null
+++ b/Documentation/gpu/zynqmp.rst
@@ -0,0 +1,147 @@
+.. SPDX-License-Identifier: GPL-2.0+
+
+===============================================
+Xilinx ZynqMP Ultrascale+ DisplayPort Subsystem
+===============================================
+
+This subsystem handles DisplayPort video and audio output on the ZynqMP. It
+supports in-memory framebuffers with the DisplayPort DMA controller
+(xilinx-dpdma), as well as "live" video and audio from the programmable logic
+(PL). This subsystem can perform several transformations, including color space
+conversion, alpha blending, and audio mixing, although not all features are
+currently supported.
+
+debugfs
+-------
+
+To support debugging and compliance testing, several test modes can be enabled
+though debugfs. The following files in /sys/kernel/debug/dri/X/DP-1/test/
+control the DisplayPort test modes:
+
+active:
+        Writing a 1 to this file will activate test mode, and writing a 0 will
+        deactivate test mode. Writing a 1 or 0 when the test mode is already
+        active/inactive will re-activate/re-deactivate test mode. When test
+        mode is inactive, changes made to other files will have no (immediate)
+        effect, although the settings will be saved for when test mode is
+        activated. When test mode is active, changes made to other files will
+        apply immediately.
+
+custom:
+        Custom test pattern value
+
+downspread:
+        Enable/disable clock downspreading (spread-spectrum clocking) by
+        writing 1/0
+
+enhanced:
+        Enable/disable enhanced framing
+
+ignore_aux_errors:
+        Ignore AUX errors when set to 1. Writes to this file take effect
+        immediately (regardless of whether test mode is active) and affect all
+        AUX transfers.
+
+ignore_hpd:
+        Ignore hotplug events (such as cable removals or monitor link
+        retraining requests) when set to 1. Writes to this file take effect
+        immediately (regardless of whether test mode is active).
+
+laneX_preemphasis:
+        Preemphasis from 0 (lowest) to 2 (highest) for lane X
+
+laneX_swing:
+        Voltage swing from 0 (lowest) to 3 (highest) for lane X
+
+lanes:
+        Number of lanes to use (1, 2, or 4)
+
+pattern:
+        Test pattern. May be one of:
+
+                video
+                        Use regular video input
+
+                symbol-error
+                        Symbol error measurement pattern
+
+                prbs7
+                        Output of the PRBS7 (x^7 + x^6 + 1) polynomial
+
+                80bit-custom
+                        A custom 80-bit pattern
+
+                cp2520
+                        HBR2 compliance eye pattern
+
+                tps1
+                        Link training symbol pattern TPS1 (/D10.2/)
+
+                tps2
+                        Link training symbol pattern TPS2
+
+                tps3
+                        Link training symbol pattern TPS3 (for HBR2)
+
+rate:
+        Rate in hertz. One of
+
+                * 5400000000 (HBR2)
+                * 2700000000 (HBR)
+                * 1620000000 (RBR)
+
+You can dump the displayport test settings with the following command::
+
+        for prop in /sys/kernel/debug/dri/1/DP-1/test/*; do
+                printf '%-17s ' ${prop##*/}
+                if [ ${prop##*/} = custom ]; then
+                        hexdump -C $prop | head -1
+                else
+                        cat $prop
+                fi
+        done
+
+The output could look something like::
+
+        active            1
+        custom            00000000  00 00 00 00 00 00 00 00  00 00                    |..........|
+        downspread        0
+        enhanced          1
+        ignore_aux_errors 1
+        ignore_hpd        1
+        lane0_preemphasis 0
+        lane0_swing       3
+        lane1_preemphasis 0
+        lane1_swing       3
+        lanes             2
+        pattern           prbs7
+        rate              1620000000
+
+The recommended test procedure is to connect the board to a monitor,
+configure test mode, activate test mode, and then disconnect the cable
+and connect it to your test equipment of choice. For example, one
+sequence of commands could be::
+
+        echo 1 > /sys/kernel/debug/dri/1/DP-1/test/enhanced
+        echo tps1 > /sys/kernel/debug/dri/1/DP-1/test/pattern
+        echo 1620000000 > /sys/kernel/debug/dri/1/DP-1/test/rate
+        echo 1 > /sys/kernel/debug/dri/1/DP-1/test/ignore_aux_errors
+        echo 1 > /sys/kernel/debug/dri/1/DP-1/test/ignore_hpd
+        echo 1 > /sys/kernel/debug/dri/1/DP-1/test/active
+
+at which point the cable could be disconnected from the monitor.
+
+Internals
+---------
+
+.. kernel-doc:: drivers/gpu/drm/xlnx/zynqmp_disp.h
+
+.. kernel-doc:: drivers/gpu/drm/xlnx/zynqmp_dpsub.h
+
+.. kernel-doc:: drivers/gpu/drm/xlnx/zynqmp_kms.h
+
+.. kernel-doc:: drivers/gpu/drm/xlnx/zynqmp_disp.c
+
+.. kernel-doc:: drivers/gpu/drm/xlnx/zynqmp_dp.c
+
+.. kernel-doc:: drivers/gpu/drm/xlnx/zynqmp_kms.c
diff --git a/drivers/gpu/drm/display/drm_hdmi_helper.c b/drivers/gpu/drm/display/drm_hdmi_helper.c
index 74dd4d01d..4da56bb6d 100644
--- a/drivers/gpu/drm/display/drm_hdmi_helper.c
+++ b/drivers/gpu/drm/display/drm_hdmi_helper.c
@@ -78,6 +78,81 @@ int drm_hdmi_infoframe_set_hdr_metadata(struct hdmi_drm_infoframe *frame,
 }
 EXPORT_SYMBOL(drm_hdmi_infoframe_set_hdr_metadata);
 
+
+/**
+ * drm_hdmi_infoframe_set_gen_hdr_metadata() - fill an HDMI DRM infoframe with
+ *                                             HDR metadata from userspace
+ * @frame: HDMI DRM infoframe
+ * @conn_state: Connector state containing HDR metadata
+ *
+ * Return: 0 on success or a negative error code on failure.
+ */
+int
+drm_hdmi_infoframe_set_gen_hdr_metadata(struct hdmi_drm_infoframe *frame,
+					const struct drm_connector_state *conn_state)
+{
+	struct drm_connector *connector;
+	struct gen_hdr_output_metadata *gen_hdr_metadata;
+	struct hdr_metadata_infoframe *hdr_infoframe;
+	int err;
+
+	if (!frame || !conn_state)
+		return -EINVAL;
+
+	connector = conn_state->connector;
+
+	if (!conn_state->gen_hdr_output_metadata)
+		return -EINVAL;
+
+	gen_hdr_metadata = conn_state->gen_hdr_output_metadata->data;
+
+	if (!gen_hdr_metadata || !connector)
+		return -EINVAL;
+
+	if (gen_hdr_metadata->metadata_type == DRM_HDR_TYPE_HDR10) {
+		hdr_infoframe = (struct hdr_metadata_infoframe *)
+			gen_hdr_metadata->payload;
+
+		/* Sink EOTF is Bit map while infoframe is absolute values */
+		if (!is_eotf_supported(hdr_infoframe->eotf,
+		    connector->hdr_sink_metadata.hdmi_type1.eotf)) {
+			DRM_DEBUG_KMS("EOTF Not Supported\n");
+			return -EINVAL;
+		}
+
+		err = hdmi_drm_infoframe_init(frame);
+		if (err < 0)
+			return err;
+
+		frame->eotf = hdr_infoframe->eotf;
+		frame->metadata_type = hdr_infoframe->metadata_type;
+
+		BUILD_BUG_ON(sizeof(frame->display_primaries) !=
+			     sizeof(hdr_infoframe->display_primaries));
+		BUILD_BUG_ON(sizeof(frame->white_point) !=
+			     sizeof(hdr_infoframe->white_point));
+
+		memcpy(&frame->display_primaries,
+		       &hdr_infoframe->display_primaries,
+		       sizeof(frame->display_primaries));
+
+		memcpy(&frame->white_point,
+		       &hdr_infoframe->white_point,
+		       sizeof(frame->white_point));
+
+		frame->max_display_mastering_luminance =
+			hdr_infoframe->max_display_mastering_luminance;
+		frame->min_display_mastering_luminance =
+			hdr_infoframe->min_display_mastering_luminance;
+		frame->max_fall = hdr_infoframe->max_fall;
+		frame->max_cll = hdr_infoframe->max_cll;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(drm_hdmi_infoframe_set_gen_hdr_metadata);
+
+
 /* HDMI Colorspace Spec Definitions */
 #define FULL_COLORIMETRY_MASK		0x1FF
 #define NORMAL_COLORIMETRY_MASK		0x3
diff --git a/drivers/gpu/drm/drm_atomic_state_helper.c b/drivers/gpu/drm/drm_atomic_state_helper.c
index 519228eb1..dda7ac573 100644
--- a/drivers/gpu/drm/drm_atomic_state_helper.c
+++ b/drivers/gpu/drm/drm_atomic_state_helper.c
@@ -640,6 +640,9 @@ __drm_atomic_helper_connector_duplicate_state(struct drm_connector *connector,
 	if (state->hdr_output_metadata)
 		drm_property_blob_get(state->hdr_output_metadata);
 
+	if (state->gen_hdr_output_metadata)
+		drm_property_blob_get(state->gen_hdr_output_metadata);
+
 	/* Don't copy over a writeback job, they are used only once */
 	state->writeback_job = NULL;
 }
@@ -689,6 +692,7 @@ __drm_atomic_helper_connector_destroy_state(struct drm_connector_state *state)
 		drm_writeback_cleanup_job(state->writeback_job);
 
 	drm_property_blob_put(state->hdr_output_metadata);
+	drm_property_blob_put(state->gen_hdr_output_metadata);
 }
 EXPORT_SYMBOL(__drm_atomic_helper_connector_destroy_state);
 
diff --git a/drivers/gpu/drm/drm_atomic_uapi.c b/drivers/gpu/drm/drm_atomic_uapi.c
index fd36b8fd5..57e4626aa 100644
--- a/drivers/gpu/drm/drm_atomic_uapi.c
+++ b/drivers/gpu/drm/drm_atomic_uapi.c
@@ -742,6 +742,13 @@ static int drm_atomic_connector_set_property(struct drm_connector *connector,
 				sizeof(struct hdr_output_metadata), -1,
 				&replaced);
 		return ret;
+	} else if (property == config->gen_hdr_output_metadata_property) {
+		ret = drm_property_replace_blob_from_id(dev,
+				&state->gen_hdr_output_metadata,
+				val,
+				sizeof(struct gen_hdr_output_metadata), -1,
+				&replaced);
+		return ret;
 	} else if (property == config->aspect_ratio_property) {
 		state->picture_aspect_ratio = val;
 	} else if (property == config->content_type_property) {
@@ -848,6 +855,9 @@ drm_atomic_connector_get_property(struct drm_connector *connector,
 	} else if (property == config->hdr_output_metadata_property) {
 		*val = state->hdr_output_metadata ?
 			state->hdr_output_metadata->base.id : 0;
+	} else if (property == config->gen_hdr_output_metadata_property) {
+		*val = state->gen_hdr_output_metadata ?
+			state->gen_hdr_output_metadata->base.id : 0;
 	} else if (property == config->content_protection_property) {
 		*val = state->content_protection;
 	} else if (property == config->hdcp_content_type_property) {
diff --git a/drivers/gpu/drm/drm_connector.c b/drivers/gpu/drm/drm_connector.c
index 994afa5a0..dc5241bb4 100644
--- a/drivers/gpu/drm/drm_connector.c
+++ b/drivers/gpu/drm/drm_connector.c
@@ -1531,6 +1531,14 @@ EXPORT_SYMBOL(drm_hdmi_connector_get_output_format_name);
  *	hdmi_drm_infoframe_pack() to pack the infoframe as per spec, in case of
  *	HDMI encoder.
  *
+ * GEN_HDR_OUTPUT_METADATA:
+ *  This connector property is functionally the same as HDR_OUTPUT_METADATA.
+ *  However, the existing structures for HDR_OUTPUT_METADATA are not flexible
+ *  enough for dynamic HDR or other connectivity devices like SDI. So, this
+ *  property was created to utilize more generic structures that would be
+ *  scalable in the future. This is currently experimental and may possibly
+ *  be merged with the original HDR_OUTPUT_METADATA property in the future.
+ *
  * max bpc:
  *	This range property is used by userspace to limit the bit depth. When
  *	used the driver would limit the bpc in accordance with the valid range
@@ -1695,6 +1703,12 @@ int drm_connector_create_standard_properties(struct drm_device *dev)
 		return -ENOMEM;
 	dev->mode_config.hdr_output_metadata_property = prop;
 
+	prop = drm_property_create(dev, DRM_MODE_PROP_BLOB,
+				   "GEN_HDR_OUTPUT_METADATA", 0);
+	if (!prop)
+		return -ENOMEM;
+	dev->mode_config.gen_hdr_output_metadata_property = prop;
+
 	return 0;
 }
 
diff --git a/drivers/gpu/drm/drm_edid.c b/drivers/gpu/drm/drm_edid.c
index 13bc4c290..9c2211a9b 100644
--- a/drivers/gpu/drm/drm_edid.c
+++ b/drivers/gpu/drm/drm_edid.c
@@ -3008,6 +3008,57 @@ mode_is_rb(const struct drm_display_mode *mode)
 	       (mode->vsync_start - mode->vdisplay == 3);
 }
 
+/**
+ * drm_mode_find_cea - Create a copy of a mode if present in CEA
+ * @dev: Device to duplicate against
+ * @hsize: Mode width
+ * @vsize: Mode height
+ * @fresh: Mode refresh rate
+ * @interlaced: Mode interlace support
+ *
+ * Walk the CEA mode list looking for a match for the given parameters.
+ *
+ * Return: A newly allocated copy of the mode, or NULL if not found.
+ */
+struct drm_display_mode *drm_mode_find_cea(struct drm_device *dev, int hsize,
+					   int vsize, int fresh, bool interlaced)
+{
+	unsigned int i;
+
+	for (i = 0; i < ARRAY_SIZE(edid_cea_modes_1); i++) {
+		const struct drm_display_mode *ptr = &edid_cea_modes_1[i];
+
+		if (hsize != ptr->hdisplay)
+			continue;
+		if (vsize != ptr->vdisplay)
+			continue;
+		if (fresh != drm_mode_vrefresh(ptr))
+			continue;
+		if (interlaced != (ptr->flags & DRM_MODE_FLAG_INTERLACE))
+			continue;
+
+		return drm_mode_duplicate(dev, ptr);
+	}
+
+	for (i = 0; i < ARRAY_SIZE(edid_cea_modes_193); i++) {
+		const struct drm_display_mode *ptr = &edid_cea_modes_193[i];
+
+		if (hsize != ptr->hdisplay)
+			continue;
+		if (vsize != ptr->vdisplay)
+			continue;
+		if (fresh != drm_mode_vrefresh(ptr))
+			continue;
+		if (interlaced != (ptr->flags & DRM_MODE_FLAG_INTERLACE))
+			continue;
+
+		return drm_mode_duplicate(dev, ptr);
+	}
+
+	return NULL;
+}
+EXPORT_SYMBOL(drm_mode_find_cea);
+
 /*
  * drm_mode_find_dmt - Create a copy of a mode if present in DMT
  * @dev: Device to duplicate against
diff --git a/drivers/gpu/drm/drm_fb_dma_helper.c b/drivers/gpu/drm/drm_fb_dma_helper.c
index e1d61a652..9d00bb193 100644
--- a/drivers/gpu/drm/drm_fb_dma_helper.c
+++ b/drivers/gpu/drm/drm_fb_dma_helper.c
@@ -77,7 +77,6 @@ dma_addr_t drm_fb_dma_get_gem_addr(struct drm_framebuffer *fb,
 	u8 h_div = 1, v_div = 1;
 	u32 block_w = drm_format_info_block_width(fb->format, plane);
 	u32 block_h = drm_format_info_block_height(fb->format, plane);
-	u32 block_size = fb->format->char_per_block[plane];
 	u32 sample_x;
 	u32 sample_y;
 	u32 block_start_y;
@@ -100,7 +99,7 @@ dma_addr_t drm_fb_dma_get_gem_addr(struct drm_framebuffer *fb,
 	num_hblocks = sample_x / block_w;
 
 	dma_addr += fb->pitches[plane] * block_start_y;
-	dma_addr += block_size * num_hblocks;
+	dma_addr += drm_format_plane_width_bytes(fb->format, plane, num_hblocks);
 
 	return dma_addr;
 }
diff --git a/drivers/gpu/drm/drm_fbdev_dma.c b/drivers/gpu/drm/drm_fbdev_dma.c
index 51c2d742d..ea14fc3d6 100644
--- a/drivers/gpu/drm/drm_fbdev_dma.c
+++ b/drivers/gpu/drm/drm_fbdev_dma.c
@@ -170,10 +170,8 @@ static int drm_fbdev_dma_helper_fb_probe(struct drm_fb_helper *fb_helper,
 		info->flags |= FBINFO_READS_FAST; /* signal caching */
 	info->screen_size = sizes->surface_height * fb->pitches[0];
 	info->screen_buffer = map.vaddr;
-	if (!(info->flags & FBINFO_HIDE_SMEM_START)) {
-		if (!drm_WARN_ON(dev, is_vmalloc_addr(info->screen_buffer)))
-			info->fix.smem_start = page_to_phys(virt_to_page(info->screen_buffer));
-	}
+	if (!(info->flags & FBINFO_HIDE_SMEM_START))
+		info->fix.smem_start = dma_obj->dma_addr;
 	info->fix.smem_len = info->screen_size;
 
 	/*
diff --git a/drivers/gpu/drm/drm_fourcc.c b/drivers/gpu/drm/drm_fourcc.c
index 3a94ca211..c7a47694e 100644
--- a/drivers/gpu/drm/drm_fourcc.c
+++ b/drivers/gpu/drm/drm_fourcc.c
@@ -29,6 +29,7 @@
 
 #include <drm/drm_device.h>
 #include <drm/drm_fourcc.h>
+#include <drm/drm_print.h>
 
 /**
  * drm_mode_legacy_fb_format - compute drm fourcc code from legacy description
@@ -267,6 +268,7 @@ const struct drm_format_info *__drm_format_info(u32 format)
 		{ .format = DRM_FORMAT_YVU422,		.depth = 0,  .num_planes = 3, .cpp = { 1, 1, 1 }, .hsub = 2, .vsub = 1, .is_yuv = true },
 		{ .format = DRM_FORMAT_YUV444,		.depth = 0,  .num_planes = 3, .cpp = { 1, 1, 1 }, .hsub = 1, .vsub = 1, .is_yuv = true },
 		{ .format = DRM_FORMAT_YVU444,		.depth = 0,  .num_planes = 3, .cpp = { 1, 1, 1 }, .hsub = 1, .vsub = 1, .is_yuv = true },
+		{ .format = DRM_FORMAT_Y8,		.depth = 8,  .num_planes = 1, .cpp = { 1, 0, 0 }, .hsub = 1, .vsub = 1, .is_yuv = true },
 		{ .format = DRM_FORMAT_NV12,		.depth = 0,  .num_planes = 2, .cpp = { 1, 2, 0 }, .hsub = 2, .vsub = 2, .is_yuv = true },
 		{ .format = DRM_FORMAT_NV21,		.depth = 0,  .num_planes = 2, .cpp = { 1, 2, 0 }, .hsub = 2, .vsub = 2, .is_yuv = true },
 		{ .format = DRM_FORMAT_NV16,		.depth = 0,  .num_planes = 2, .cpp = { 1, 2, 0 }, .hsub = 2, .vsub = 1, .is_yuv = true },
@@ -346,6 +348,31 @@ const struct drm_format_info *__drm_format_info(u32 format)
 		{ .format = DRM_FORMAT_P030,            .depth = 0,  .num_planes = 2,
 		  .char_per_block = { 4, 8, 0 }, .block_w = { 3, 3, 0 }, .block_h = { 1, 1, 0 },
 		  .hsub = 2, .vsub = 2, .is_yuv = true},
+		{ .format = DRM_FORMAT_AVUY,		.depth = 0,  .num_planes = 1, .cpp = { 4, 0, 0 }, .hsub = 1, .vsub = 1, .has_alpha = true },
+		{ .format = DRM_FORMAT_XVUY8888,	.depth = 0,  .num_planes = 1, .cpp = { 4, 0, 0 }, .hsub = 1, .vsub = 1 },
+		{ .format = DRM_FORMAT_XVUY2101010,	.depth = 0,  .num_planes = 1, .cpp = { 4, 0, 0 }, .hsub = 1, .vsub = 1 },
+		{ .format = DRM_FORMAT_Y8,		.depth = 0,  .num_planes = 1, .cpp = { 1, 0, 0 }, .hsub = 1, .vsub = 1 },
+		{ .format = DRM_FORMAT_Y10,		.depth = 0,  .num_planes = 1, .pixels_per_macropixel =  { 3, 0, 0 }, .bytes_per_macropixel = { 4, 0, 0 }, .hsub = 1, .vsub = 1 },
+		{ .format = DRM_FORMAT_XV15,		.depth = 0,
+		  .num_planes = 2, .char_per_block = { 4, 8, 0 },
+		  .block_w = { 3, 3, 0 }, .block_h = { 1, 1, 0 }, .hsub = 2,
+		  .vsub = 2, .is_yuv = true },
+		{ .format = DRM_FORMAT_XV20,		.depth = 0,
+		  .num_planes = 2, .char_per_block = { 4, 8, 0 },
+		  .block_w = { 3, 3, 0 }, .block_h = { 1, 1, 0 }, .hsub = 2,
+		  .vsub = 1, .is_yuv = true },
+		{ .format = DRM_FORMAT_Y10_LE32,        .depth = 0,
+		  .num_planes = 1, .char_per_block =  { 4, 0, 0 },
+		  .block_w = { 3, 0, 0 }, .block_h = { 1, 0, 0 }, .hsub = 1,
+		  .vsub = 1, .is_yuv = true },
+		{ .format = DRM_FORMAT_X403,		.depth = 0,
+		  .num_planes = 3, .char_per_block =  { 4, 4, 4 },
+		  .block_w = { 3, 3, 3 }, .block_h = { 1, 1, 1 },
+		  .hsub = 1, .vsub = 1, .is_yuv = true },
+		{ .format = DRM_FORMAT_X423,		.depth = 0,
+		  .num_planes = 3, .char_per_block = { 3, 3, 3 },
+		  .block_w = { 2, 2, 2 }, .block_h = { 1, 1, 1 }, .hsub = 1,
+		  .vsub = 1, .is_yuv = true, },
 	};
 
 	unsigned int i;
@@ -457,6 +484,13 @@ unsigned int drm_format_info_bpp(const struct drm_format_info *info, int plane)
 	if (!info || plane < 0 || plane >= info->num_planes)
 		return 0;
 
+	if (info->char_per_block[plane] * 8 %
+	    (drm_format_info_block_width(info, plane) *
+	     drm_format_info_block_height(info, plane))) {
+		pr_warn("unable to return an integer bpp\n");
+		return 0;
+	}
+
 	return info->char_per_block[plane] * 8 /
 	       (drm_format_info_block_width(info, plane) *
 		drm_format_info_block_height(info, plane));
@@ -484,3 +518,36 @@ uint64_t drm_format_info_min_pitch(const struct drm_format_info *info,
 			    drm_format_info_block_height(info, plane));
 }
 EXPORT_SYMBOL(drm_format_info_min_pitch);
+
+/**
+ * drm_format_plane_width_bytes - bytes of the given width of the plane
+ * @info: DRM format information
+ * @plane: plane index
+ * @width: width to get the number of bytes
+ *
+ * This returns the number of bytes for given @width and @plane.
+ * The @char_per_block or macro pixel information should be valid.
+ *
+ * Returns:
+ * The bytes of @width of @plane. 0 for invalid format info.
+ */
+uint64_t drm_format_plane_width_bytes(const struct drm_format_info *info,
+				 int plane, unsigned int width)
+{
+	if (!info || plane >= info->num_planes)
+		return 0;
+
+	if (info->char_per_block[plane])
+		return drm_format_info_min_pitch(info, plane, width);
+
+	if (WARN_ON(!info->bytes_per_macropixel[plane] ||
+		    !info->pixels_per_macropixel[plane])) {
+		DRM_WARN("Either cpp or macro-pixel info should be valid: %p4cc\n",
+			 &info->format);
+		return 0;
+	}
+
+	return DIV_ROUND_UP(width * info->bytes_per_macropixel[plane],
+			    info->pixels_per_macropixel[plane]);
+}
+EXPORT_SYMBOL(drm_format_plane_width_bytes);
diff --git a/drivers/gpu/drm/drm_framebuffer.c b/drivers/gpu/drm/drm_framebuffer.c
index 888aadb6a..33ab0f540 100644
--- a/drivers/gpu/drm/drm_framebuffer.c
+++ b/drivers/gpu/drm/drm_framebuffer.c
@@ -180,7 +180,8 @@ static int framebuffer_check(struct drm_device *dev,
 	for (i = 0; i < info->num_planes; i++) {
 		unsigned int width = drm_format_info_plane_width(info, r->width, i);
 		unsigned int height = drm_format_info_plane_height(info, r->height, i);
-		unsigned int block_size = info->char_per_block[i];
+		unsigned int block_size = info->char_per_block[i] ||
+					  info->bytes_per_macropixel[i];
 		u64 min_pitch = drm_format_info_min_pitch(info, i, width);
 
 		if (!block_size && (r->modifier[i] == DRM_FORMAT_MOD_LINEAR)) {
@@ -274,7 +275,8 @@ drm_internal_framebuffer_create(struct drm_device *dev,
 	struct drm_framebuffer *fb;
 	int ret;
 
-	if (r->flags & ~(DRM_MODE_FB_INTERLACED | DRM_MODE_FB_MODIFIERS)) {
+	if (r->flags & ~(DRM_MODE_FB_INTERLACED | DRM_MODE_FB_MODIFIERS |
+	    DRM_MODE_FB_ALTERNATE_TOP | DRM_MODE_FB_ALTERNATE_BOTTOM)) {
 		drm_dbg_kms(dev, "bad framebuffer flags 0x%08x\n", r->flags);
 		return ERR_PTR(-EINVAL);
 	}
diff --git a/drivers/gpu/drm/panel/panel-simple.c b/drivers/gpu/drm/panel/panel-simple.c
index 06381c628..f336c2e57 100644
--- a/drivers/gpu/drm/panel/panel-simple.c
+++ b/drivers/gpu/drm/panel/panel-simple.c
@@ -5160,6 +5160,33 @@ static const struct panel_desc_dsi auo_b080uan01 = {
 	.lanes = 4,
 };
 
+static const struct drm_display_mode auo_b101uan01_mode = {
+	.clock = 154500,
+	.hdisplay = 1920,
+	.hsync_start = 1920 + 185,
+	.hsync_end = 1920 + 185,
+	.htotal = 1920 + 185 + 925,
+	.vdisplay = 1200,
+	.vsync_start = 1200 + 3,
+	.vsync_end = 1200 + 3 + 5,
+	.vtotal = 1200 + 3 + 5 + 4,
+};
+
+static const struct panel_desc_dsi auo_b101uan01 = {
+	.desc = {
+		.modes = &auo_b101uan01_mode,
+		.num_modes = 1,
+		.bpc = 8,
+		.size = {
+			.width = 108,
+			.height = 272,
+		},
+	},
+	.flags = MIPI_DSI_MODE_VIDEO | MIPI_DSI_MODE_VIDEO_SYNC_PULSE,
+	.format = MIPI_DSI_FMT_RGB888,
+	.lanes = 4,
+};
+
 static const struct drm_display_mode boe_tv080wum_nl0_mode = {
 	.clock = 160000,
 	.hdisplay = 1200,
@@ -5338,6 +5365,9 @@ static const struct of_device_id dsi_of_match[] = {
 	{
 		.compatible = "auo,b080uan01",
 		.data = &auo_b080uan01
+	}, {
+		.compatible = "auo,b101uan01",
+		.data = &auo_b101uan01
 	}, {
 		.compatible = "boe,tv080wum-nl0",
 		.data = &boe_tv080wum_nl0
diff --git a/drivers/gpu/drm/xlnx/Kconfig b/drivers/gpu/drm/xlnx/Kconfig
index 626e5ac4c..71eae3fa8 100644
--- a/drivers/gpu/drm/xlnx/Kconfig
+++ b/drivers/gpu/drm/xlnx/Kconfig
@@ -1,3 +1,19 @@
+config DRM_AMD_MMI_DC
+	tristate "Multimedia Integrated Display Controller Driver"
+	depends on DRM && OF
+	depends on DMADEVICES
+	select AMD_MMI_DCDMA
+	select DRM_DISPLAY_DP_HELPER
+	select DRM_DISPLAY_HELPER
+	select DRM_BRIDGE_CONNECTOR
+	select DRM_GEM_DMA_HELPER
+	select DRM_KMS_HELPER
+	help
+	  This is the DRM/KMS CRTC driver for AMD Versal Gen2 Multimedia
+	  Integrated Display Controller. Choose this option if you have
+	  the AMD Versal Gen 2 SoC with DisplayPort subsystem and planning to
+	  use DisplayPort output.
+
 config DRM_ZYNQMP_DPSUB
 	tristate "ZynqMP DisplayPort Controller Driver"
 	depends on ARCH_ZYNQMP || COMPILE_TEST
@@ -16,3 +32,147 @@ config DRM_ZYNQMP_DPSUB
 	  This is a DRM/KMS driver for ZynqMP DisplayPort controller. Choose
 	  this option if you have a Xilinx ZynqMP SoC with DisplayPort
 	  subsystem.
+
+config DRM_ZYNQMP_DPSUB_AUDIO
+	bool "ZynqMP DisplayPort Audio Support"
+	depends on DRM_ZYNQMP_DPSUB
+	depends on SND && SND_SOC
+	select SND_SOC_GENERIC_DMAENGINE_PCM
+	help
+	  Choose this option to enable DisplayPort audio support in the ZynqMP
+	  DisplayPort driver.
+
+config DRM_XLNX
+	tristate "Xilinx DRM KMS Driver"
+	depends on DRM && OF && SND
+	select DRM_KMS_HELPER
+	select DRM_KMS_DMA_HELPER
+	select DRM_GEM_DMA_HELPER
+	select SND_PCM_ELD
+	help
+	  Xilinx DRM KMS driver. Choose this option if you have
+	  a Xilinx SoCs with hardened display pipeline or soft
+	  display pipeline using Xilinx IPs in FPGA. This module
+	  provides the kernel mode setting functionalities
+	  for Xilinx display drivers.
+
+config DRM_XLNX_BRIDGE
+	tristate "Xilinx DRM KMS bridge"
+	depends on DRM_XLNX
+	help
+	  Xilinx DRM KMS bridge. This module provides some interfaces
+	  to enable inter-module communication. Choose this option
+	  from the provider driver when the Xilinx bridge interface is
+	  needed.
+
+config DRM_XLNX_BRIDGE_DEBUG_FS
+	bool "Xilinx DRM KMS bridge debugfs"
+	depends on DEBUG_FS && DRM_XLNX_BRIDGE
+	help
+	  Enable the debugfs code for Xilinx bridge. The debugfs code
+	  enables debugging or testing related features. It exposes some
+	  low level controls to the user space to help testing automation,
+	  as well as can enable additional diagnostic or statistical
+	  information.
+
+config DRM_XLNX_DPTX
+	tristate "Xilinx DRM DisplayPort Subsystem Driver"
+	depends on DRM_XLNX
+	select DRM_DISPLAY_HELPER
+	select DRM_DISPLAY_HDMI_HELPER
+	select DRM_DISPLAY_DP_HELPER
+	select DRM_XLNX_HDCP
+	select PHY_XILINX_DPGTQUAD
+	select MFD_SYSCON
+	help
+	  DRM driver for Xilinx DisplayPort Tx Subsystem for FPGA. Choose
+	  this option if you have a FPGA display pipeline that includes
+	  the Xilinx DisplayPort Tx Subsystem IP. The driver provides
+	  the kernel mode setting functionalities for the IP.
+
+config DRM_XLNX_DSI
+	tristate "Xilinx DRM DSI Subsystem Driver"
+	depends on DRM_XLNX
+	select DRM_MIPI_DSI
+	select DRM_PANEL
+	select BACKLIGHT_LCD_SUPPORT
+	select BACKLIGHT_CLASS_DEVICE
+	help
+	  DRM driver for Xilinx MIPI-DSI.
+
+config DRM_XLNX_HDMITX
+	tristate "Xilinx DRM HDMI Subsystem Driver"
+	depends on DRM_XLNX
+	select DRM_XLNX_HDCP
+	select MFD_SYSCON
+	help
+	  DRM driver for Xilinx HDMI Tx Subsystem for FPGA. Choose
+	  this option if you have a FPGA display pipeline that includes
+	  the Xilinx HDMI Tx Subsystem IP. The driver provides
+	  the kernel mode setting functionalities for the IP.
+
+config DRM_XLNX_MIXER
+	tristate "Xilinx DRM Mixer Driver"
+	depends on DRM_XLNX
+	select VIDEOMODE_HELPERS
+	help
+	  DRM driver for Xilinx Mixer driver.
+
+config DRM_XLNX_PL_DISP
+	tristate "Xilinx DRM PL display driver"
+	depends on DRM_XLNX && XILINX_FRMBUF
+	select VIDEOMODE_HELPERS
+	help
+	  DRM driver for Xilinx PL display driver, provides drm
+	  crtc and plane object to display pipeline. You need to
+	  choose this option if your display pipeline needs one
+	  crtc and plane object with single DMA connected.
+
+config DRM_XLNX_SDI
+	tristate "Xilinx DRM SDI Subsystem Driver"
+	depends on DRM_XLNX
+	select DRM_DISPLAY_HELPER
+	select DRM_DISPLAY_HDMI_HELPER
+	select DRM_DISPLAY_DP_HELPER
+	help
+	  DRM driver for Xilinx SDI Tx Subsystem.
+
+config DRM_XLNX_BRIDGE_CSC
+	tristate "Xilinx DRM CSC Driver"
+	depends on DRM_XLNX_BRIDGE
+	help
+	  DRM brige driver for color space converter of VPSS. Choose
+	  this option if color space converter is connected to an encoder.
+	  The driver provides set/get resolution and color format
+	  functionality through bridge layer.
+
+config DRM_XLNX_BRIDGE_SCALER
+	tristate "Xilinx DRM Scaler Driver"
+	depends on DRM_XLNX_BRIDGE
+	help
+	  DRM brige driver for scaler of VPSS. Choose this option
+	  if scaler is connected to an encoder. The driver provides
+	  upscaling, down scaling and no scaling functionality through
+	  bridge layer.
+
+config DRM_XLNX_BRIDGE_VTC
+	tristate "Xilinx DRM VTC Driver"
+	depends on DRM_XLNX_BRIDGE
+	help
+	  DRM brige driver for Xilinx Video Timing Controller. Choose
+	  this option to make VTC a part of the CRTC in display pipeline.
+	  Currently the support is added to the Xilinx Video Mixer and
+	  Xilinx PL display CRTC drivers. This driver provides ability
+	  to generate timings through the bridge layer.
+
+config DRM_XLNX_HDCP
+	bool "Xilinx DRM HDCP Driver"
+	depends on DRM_XLNX_DPTX || DRM_XLNX_HDMITX
+	select XILINX_HDCP_COMMON
+	select CRYPTO_AES
+	help
+	  Enables the Functionality of HDCP Encryption/Decryption for
+	  Xilinx display drivers. It handles the HDCP authentication.
+	  Choose this option if you have a FPGA display pipeline using
+	  Xilinx FPGA's in IP. This driver provides the kernel mode
+	  setting functionalities for the IP.
diff --git a/drivers/gpu/drm/xlnx/Makefile b/drivers/gpu/drm/xlnx/Makefile
index ea1422a39..f23f4123f 100644
--- a/drivers/gpu/drm/xlnx/Makefile
+++ b/drivers/gpu/drm/xlnx/Makefile
@@ -1,2 +1,19 @@
+mmi-dc-y := mmi_dc_plane.o mmi_dc.o mmi_dc_kms.o
+obj-$(CONFIG_DRM_AMD_MMI_DC) += mmi-dc.o
 zynqmp-dpsub-y := zynqmp_disp.o zynqmp_dpsub.o zynqmp_dp.o zynqmp_kms.o
+zynqmp-dpsub-$(CONFIG_DRM_ZYNQMP_DPSUB_AUDIO) += zynqmp_dp_audio.o
 obj-$(CONFIG_DRM_ZYNQMP_DPSUB) += zynqmp-dpsub.o
+xlnx_drm-objs += xlnx_crtc.o xlnx_drv.o xlnx_fb.o xlnx_gem.o
+xlnx_drm-$(CONFIG_DRM_XLNX_BRIDGE) += xlnx_bridge.o
+obj-$(CONFIG_DRM_XLNX) += xlnx_drm.o
+obj-$(CONFIG_DRM_XLNX_BRIDGE_CSC) += xlnx_csc.o
+obj-$(CONFIG_DRM_XLNX_BRIDGE_SCALER) += xlnx_scaler.o
+obj-$(CONFIG_DRM_XLNX_BRIDGE_VTC) += xlnx_vtc.o
+obj-$(CONFIG_DRM_XLNX_DPTX) += xlnx_dptx.o
+obj-$(CONFIG_DRM_XLNX_DSI) += xlnx_dsi.o
+obj-$(CONFIG_DRM_XLNX_HDMITX) += xlnx_hdmi.o
+obj-$(CONFIG_DRM_XLNX_MIXER) += xlnx_mixer.o
+obj-$(CONFIG_DRM_XLNX_PL_DISP) += xlnx_pl_disp.o
+xlnx-sdi-objs += xlnx_sdi.o xlnx_sdi_timing.o
+obj-$(CONFIG_DRM_XLNX_SDI) += xlnx-sdi.o
+obj-$(CONFIG_DRM_XLNX_HDCP) += hdcp/
diff --git a/drivers/gpu/drm/xlnx/hdcp/Makefile b/drivers/gpu/drm/xlnx/hdcp/Makefile
new file mode 100644
index 000000000..28cb1fdf9
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/Makefile
@@ -0,0 +1,7 @@
+obj-$(CONFIG_DRM_XLNX_HDCP) += xhdcp2x_tx.o \
+				xhdcp1x_tx.o \
+				xlnx_hdcp1x_keymngt.o \
+				xlnx_hdcp1x_tx.o \
+				xlnx_hdcp2x_tx.o \
+				xlnx_hdcp_sha1.o \
+				xlnx_hdcp2x_crypt.o xlnx_hdcp_tx.o
diff --git a/drivers/gpu/drm/xlnx/hdcp/xhdcp1x_tx.c b/drivers/gpu/drm/xlnx/hdcp/xhdcp1x_tx.c
new file mode 100644
index 000000000..9e7aab70f
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xhdcp1x_tx.c
@@ -0,0 +1,182 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx HDCP1X Protocol Driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Katta Dhanunjanrao <katta.dhanunjanrao@amd.com>
+ *
+ * This driver provides standard HDCP1X protocol specific functionalites.
+ * It consists of:
+ * - A state machine which handles the states as specified in the HDCP
+ *	specification.
+ * This driver still have Xilinx specific functionalities as it is not upstreamed now,
+ * it will be updated as more generic and standardized driver in the next upstream version.
+ *
+ * Reference :
+ * https://www.digital-cp.com/sites/default/files/specifications/HDCP%20on%20DisplayPort%20Specification%20Rev1_1.pdf
+ *
+ */
+#include <linux/dev_printk.h>
+#include "xhdcp1x_tx.h"
+#include "xlnx_hdcp1x_tx.h"
+
+static enum hdcp1x_tx_state hdcp1x_run_unautheticated_state(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	hdcp1x->state_helper = 0;
+	return H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED;
+}
+
+static enum hdcp1x_tx_state hdcp1x_tx_runread_ksv_list_state_A7(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	if (xlnx_hdcp1x_tx_read_ksv_list(hdcp1x))
+		return A4_HDCP1X_TX_STATE_AUTHENTICATED;
+	else
+		return REPTR_HDCP1X_TX_STATE_UNAUTHENTICATED;
+}
+
+static enum hdcp1x_tx_state hdcp1x_tx_runwait_for_ready_state_A6(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	return xlnx_hdcp1x_tx_wait_for_ready(hdcp1x);
+}
+
+static enum hdcp1x_tx_state
+	    hdcp1x_tx_run_testfor_repeater_state_A5(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	if (xlnx_hdcp1x_tx_test_for_repeater(hdcp1x)) {
+		xlnx_hdcp1x_tx_start_timer(hdcp1x, 100, 0);
+		return A6_HDCP1X_TX_STATE_WAIT_FOR_READY;
+	}
+
+	return A4_HDCP1X_TX_STATE_AUTHENTICATED;
+}
+
+static enum hdcp1x_tx_state hdcp1x_tx_run_authenticated_state_A4(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	hdcp1x->state_helper = 0;
+
+	if (hdcp1x->prev_state != A4_HDCP1X_TX_STATE_AUTHENTICATED) {
+		xlnx_hdcp1x_tx_start_timer(hdcp1x, 2000, 0);
+		hdcp1x->stats.auth_passed++;
+
+		return A4_HDCP1X_TX_STATE_AUTHENTICATED;
+	}
+	if (hdcp1x->xhdcp1x_internal_timer.timer_expired) {
+		hdcp1x->xhdcp1x_internal_timer.timer_expired = 0;
+		xlnx_hdcp_tmrcntr_stop(&hdcp1x->xhdcp1x_internal_timer.tmr_ctr, 0);
+		xhdcp1x_tx_set_check_linkstate(hdcp1x, 1);
+
+		return A4_HDCP1X_TX_STATE_AUTHENTICATED;
+	}
+
+	if (hdcp1x->is_riupdate) {
+		xlnx_hdcp_tmrcntr_stop(&hdcp1x->xhdcp1x_internal_timer.tmr_ctr, 0);
+
+		return A8_XHDCP1X_TX_STATE_LINK_INTEGRITY_CHECK;
+	}
+
+	return A4_HDCP1X_TX_STATE_AUTHENTICATED;
+}
+
+static enum hdcp1x_tx_state hdcp1x_tx_check_link_integrity(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	if (xlnx_hdcp1x_check_link_integrity(hdcp1x))
+		return A4_HDCP1X_TX_STATE_AUTHENTICATED;
+
+	return A0_HDCP1X_TX_STATE_DETERMINE_RX_CAPABLE;
+}
+
+static enum hdcp1x_tx_state hdcp1x_tx_run_validaterx_state_A3(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	if (xlnx_hdcp1x_tx_validaterxstate(hdcp1x)) {
+		xlnx_hdcp1x_tx_enable_encryption(hdcp1x);
+		return A5_HDCP1X_TX_STATE_TEST_FOR_REPEATER;
+	}
+
+	return  H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED;
+}
+
+static enum hdcp1x_tx_state hdcp1x_tx_run_computations_state_A2(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	if (xlnx_hdcp1x_computationsstate(hdcp1x))
+		return A3_HDCP1X_TX_STATE_VALIDATE_RX;
+	else
+		return A2_HDCP1X_TX_STATE_COMPUTATIONS;
+}
+
+static enum hdcp1x_tx_state hdcp1x_tx_run_exchange_ksv_state_A1(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	if (xlnx_hdcp1x_exchangeksvs(hdcp1x))
+		return A2_HDCP1X_TX_STATE_COMPUTATIONS;
+	else
+		return H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED;
+}
+
+static enum hdcp1x_tx_state
+	    hdcp1x_tx_run_determine_rx_capable_state_A0(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	if (xlnx_hdcp1x_tx_check_rxcapable(hdcp1x))
+		return A1_HDCP1X_TX_STATE_EXCHANGE_KSVS;
+	else
+		return H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED;
+}
+
+static enum hdcp1x_tx_state hdcp1x_tx_run_disablestate(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	hdcp1x->pending_events = 0;
+
+	return A0_HDCP1X_TX_STATE_DETERMINE_RX_CAPABLE;
+}
+
+/*
+ * HDCP Transmitter State Diagram available in
+ * HDCP1.1 specification. Section 2.3
+ * https://www.digital-cp.com/sites/default/files/
+ * specifications/HDCP%20on%20DisplayPort%20Specification%20Rev1_1.pdf
+ */
+int hdcp1x_tx_protocol_authenticate_sm(struct xlnx_hdcp1x_config *hdcp1x)
+{
+	int status = H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED;
+	enum hdcp1x_tx_state hdcp1x_state = hdcp1x->curr_state;
+
+	switch (hdcp1x_state) {
+	case H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED:
+		status = hdcp1x_tx_run_disablestate(hdcp1x);
+		break;
+	case A0_HDCP1X_TX_STATE_DETERMINE_RX_CAPABLE:
+		status = hdcp1x_tx_run_determine_rx_capable_state_A0(hdcp1x);
+		break;
+	case A1_HDCP1X_TX_STATE_EXCHANGE_KSVS:
+		status = hdcp1x_tx_run_exchange_ksv_state_A1(hdcp1x);
+		break;
+	case A2_HDCP1X_TX_STATE_COMPUTATIONS:
+		status = hdcp1x_tx_run_computations_state_A2(hdcp1x);
+		break;
+	case A3_HDCP1X_TX_STATE_VALIDATE_RX:
+		status = hdcp1x_tx_run_validaterx_state_A3(hdcp1x);
+		break;
+	case A4_HDCP1X_TX_STATE_AUTHENTICATED:
+		status = hdcp1x_tx_run_authenticated_state_A4(hdcp1x);
+		break;
+	case A8_XHDCP1X_TX_STATE_LINK_INTEGRITY_CHECK:
+		status = hdcp1x_tx_check_link_integrity(hdcp1x);
+		break;
+	case A5_HDCP1X_TX_STATE_TEST_FOR_REPEATER:
+		status = hdcp1x_tx_run_testfor_repeater_state_A5(hdcp1x);
+		break;
+	case A6_HDCP1X_TX_STATE_WAIT_FOR_READY:
+		status = hdcp1x_tx_runwait_for_ready_state_A6(hdcp1x);
+		break;
+	case A7_HDCP1X_TX_STATE_READ_KSV_LIST:
+		status = hdcp1x_tx_runread_ksv_list_state_A7(hdcp1x);
+		break;
+	case REPTR_HDCP1X_TX_STATE_UNAUTHENTICATED:
+		status = hdcp1x_run_unautheticated_state(hdcp1x);
+		break;
+	default:
+		status = hdcp1x_state;
+		dev_dbg(hdcp1x->dev, "Invalid HDCP1x State");
+		break;
+	}
+	return status;
+}
diff --git a/drivers/gpu/drm/xlnx/hdcp/xhdcp1x_tx.h b/drivers/gpu/drm/xlnx/hdcp/xhdcp1x_tx.h
new file mode 100644
index 000000000..f6bc26fb9
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xhdcp1x_tx.h
@@ -0,0 +1,39 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx HDCP1X Protocol Driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved
+ * .
+ * Author: katta Dhanunjanrao <katta.dhanunjanrao@amd.com>
+ *
+ */
+#ifndef HDCP1X_TX_H_
+#define HDCP1X_TX_H_
+
+#include <drm/display/drm_hdcp.h>
+#include <linux/types.h>
+/*
+ * hdcp1x_tx_state: The enum structure has the HDCP state machine states.
+ * @H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED: HDCP state H0
+ * @A0_HDCP1X_TX_STATE_DETERMINE_RX_CAPABLE: HDCP state A0
+ * @A1_HDCP1X_TX_STATE_EXCHANGE_KSVS: HDCP state A1
+ * @A2_HDCP1X_TX_STATE_COMPUTATIONS: HDCP state A2
+ * @A3_HDCP1X_TX_STATE_VALIDATE_RX: HDCP state A3
+ * @A4_HDCP1X_TX_STATE_AUTHENTICATED: HDCP state A4
+ * @A5_HDCP1X_TX_STATE_TESTFORREPEATER: HDCP state A5
+ * @REPTR_HDCP1X_TX_STATE_UNAUTHENTICATED: Repeater state checking
+ */
+enum hdcp1x_tx_state {
+	H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED = 0,
+	A0_HDCP1X_TX_STATE_DETERMINE_RX_CAPABLE,
+	A1_HDCP1X_TX_STATE_EXCHANGE_KSVS,
+	A2_HDCP1X_TX_STATE_COMPUTATIONS,
+	A3_HDCP1X_TX_STATE_VALIDATE_RX,
+	A4_HDCP1X_TX_STATE_AUTHENTICATED,
+	A8_XHDCP1X_TX_STATE_LINK_INTEGRITY_CHECK,
+	A5_HDCP1X_TX_STATE_TEST_FOR_REPEATER,
+	A6_HDCP1X_TX_STATE_WAIT_FOR_READY,
+	A7_HDCP1X_TX_STATE_READ_KSV_LIST,
+	REPTR_HDCP1X_TX_STATE_UNAUTHENTICATED
+};
+#endif
diff --git a/drivers/gpu/drm/xlnx/hdcp/xhdcp2x_tx.c b/drivers/gpu/drm/xlnx/hdcp/xhdcp2x_tx.c
new file mode 100644
index 000000000..7950508ba
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xhdcp2x_tx.c
@@ -0,0 +1,851 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx HDCP2X Protocol Driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Lakshmi Prasanna Eachuri <lakshmi.prasanna.eachuri@amd.com>
+ *
+ * This driver provides standard HDCP2X protocol specific functionalites.
+ * It consists of:
+ * - A state machine which handles the states as specified in the HDCP
+ *	specification.
+ * This driver still have Xilinx specific functionalities as it is not upstreamed now,
+ * it will be updated as more generic and standardized driver in the next upstream version.
+ *
+ * Reference :
+ * https://www.digital-cp.com/sites/default/files/HDCP%20on%20DisplayPort%20Specification%20Rev2_3.pdf
+ */
+
+#include <linux/xlnx/xlnx_hdcp2x_cipher.h>
+#include <linux/xlnx/xlnx_hdcp_common.h>
+#include <linux/xlnx/xlnx_hdcp_rng.h>
+#include <linux/xlnx/xlnx_timer.h>
+#include "xhdcp2x_tx.h"
+#include "xlnx_hdcp2x_tx.h"
+
+static int hdcp2x_tx_receive_message(struct xlnx_hdcp2x_config *xhdcp2x_tx, u8 msg_id)
+{
+	return xlnx_hdcp2x_tx_read_msg(xhdcp2x_tx, msg_id);
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_verify_mprime(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+	int result;
+
+	/*
+	 * Wait for the receiver to respond within 100 msecs.
+	 * If the receiver has timed out we go to state A9 for a retry.
+	 * If the receiver is busy, we stay in this state (return from polling).
+	 * If the receiver has finished, but the message was not handled yet,
+	 * we handle the message.
+	 */
+	result = xlnx_hdcp2x_tx_wait_for_receiver(xhdcp2x_tx,
+						  HDCP2X_TX_REPEATERAUTH_STREAM_READY_SIZE,
+						  0);
+	if (result < 0)
+		return A9_HDCP2X_TX_STREAM_MANAGE;
+
+	if (!xhdcp2x_tx->xhdcp2x_info.msg_available)
+		return A9_HDCP2X_TX_VERIFY_MPRIME;
+
+	if (xhdcp2x_tx->xhdcp2x_info.content_strm_mng_chk_cntr)
+		dev_dbg(xhdcp2x_tx->dev, "content stream manage message");
+
+	result = hdcp2x_tx_receive_message(xhdcp2x_tx,
+					   HDCP_2_2_REP_STREAM_READY);
+	if (result < 0)
+		return A9_HDCP2X_TX_STREAM_MANAGE;
+
+	if (memcmp(tx_msg->msg_type.rpt_auth_stream_rdy.m_prime,
+		   xhdcp2x_tx->xhdcp2x_info.M,
+		   HDCP_2_2_MPRIME_LEN))
+		return A9_HDCP2X_TX_STREAM_MANAGE;
+
+	xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP2X_TX_WAIT_FOR_ENCRYPTION_TIMEOUT,
+				   XHDCP2X_TX_TS_WAIT_FOR_CIPHER);
+
+	xhdcp2x_tx->xhdcp2x_info.is_content_stream_type_set = 1;
+
+	return A5_HDCP2X_TX_AUTHENTICATED;
+}
+
+static enum  hdcp2x_tx_state hdcp2x_tx_process_stream_manage(struct xlnx_hdcp2x_config
+							     *xhdcp2x_tx)
+{
+	struct xhdcp2x_tx_internal_info *hdcp2x_tx_internal_info =
+				&xhdcp2x_tx->xhdcp2x_info;
+	int result;
+
+	if (!xhdcp2x_tx->xhdcp2x_internal_timer.timer_expired)
+		return A9_HDCP2X_TX_STREAM_MANAGE;
+
+	xlnx_hdcp2x_tx_read_rxstatus(xhdcp2x_tx);
+	if ((hdcp2x_tx_internal_info->dp_rx_status &
+			XHDCP2X_TX_RXSTATUS_REAUTH_REQ_MASK) ==
+		XHDCP2X_TX_RXSTATUS_REAUTH_REQ_MASK) {
+		xlnx_hdcp2x_handle_reauth_request(xhdcp2x_tx);
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	if (!hdcp2x_tx_internal_info->is_content_stream_type_set) {
+		xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP2X_TX_WAIT_FOR_STREAM_TYPE_TIMEOUT,
+					   XHDCP2X_TX_TS_WAIT_FOR_STREAM_TYPE);
+		return A9_HDCP2X_TX_STREAM_MANAGE;
+	}
+
+	if (!hdcp2x_tx_internal_info->content_strm_mng_chk_cntr)
+		dev_dbg(xhdcp2x_tx->dev, "verify receiver-id");
+
+	if (hdcp2x_tx_internal_info->content_strm_mng_chk_cntr >=
+			XHDCP2X_TX_MAX_ALLOWED_STREAM_MANAGE_CHECKS) {
+		dev_err(xhdcp2x_tx->dev,
+			"content stream manage check counter fail");
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	if (hdcp2x_tx_internal_info->seq_num_m <
+			hdcp2x_tx_internal_info->prev_seq_num_m) {
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	hdcp2x_tx_internal_info->prev_seq_num_m = hdcp2x_tx_internal_info->seq_num_m;
+
+	result = xlnx_hdcp2x_tx_rptr_auth_stream_mng(xhdcp2x_tx);
+	if (result < 0) {
+		dev_dbg(xhdcp2x_tx->dev, "write message fail: stream manage");
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP_2_2_STREAM_READY_TIMEOUT_MS,
+				   HDCP_2_2_REP_STREAM_READY);
+
+	hdcp2x_tx_internal_info->content_strm_mng_chk_cntr++;
+
+	return A9_HDCP2X_TX_VERIFY_MPRIME;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_process_rcvid(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	dev_dbg(xhdcp2x_tx->dev, "receiver id sent ack");
+
+	return A0_HDCP2X_TX_AKE_INIT;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_wait_for_rcvid(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct hdcp2x_tx_pairing_info *hdcp2x_tx_pairing_info =
+		(struct hdcp2x_tx_pairing_info *)xhdcp2x_tx->xhdcp2x_info.state_context;
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+	u8 V[HDCP2X_TX_V_SIZE];
+	u32 seq_num_v;
+	int i, result;
+	u8 device_count;
+
+	/*
+	 * Wait for the receiver to respond within 3 secs.
+	 * If the receiver has timed out we go to state A0.
+	 * If the receiver is busy, we stay in this state (return from polling).
+	 * If the receiver has finished, but the message was not handled yet,
+	 * we handle the message.
+	 */
+	result = xlnx_hdcp2x_tx_wait_for_receiver(xhdcp2x_tx, 0, 1);
+	if (result < 0)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	if (!xhdcp2x_tx->xhdcp2x_info.msg_available)
+		return A6_HDCP2X_TX_WAIT_FOR_RCVID;
+
+	dev_dbg(xhdcp2x_tx->dev, "wait for receiver id");
+
+	result = hdcp2x_tx_receive_message(xhdcp2x_tx,
+					   HDCP_2_2_REP_SEND_RECVID_LIST);
+	if (result < 0)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	device_count = (HDCP_2_2_DEV_COUNT_HI(tx_msg->msg_type.rpt_auth_send_rcvid.rxinfo[0]) << 4 |
+			HDCP_2_2_DEV_COUNT_LO(tx_msg->msg_type.rpt_auth_send_rcvid.rxinfo[1]));
+
+	xhdcp2x_tx->xhdcp2x_topology.devicecount = device_count + 1;
+	xhdcp2x_tx->xhdcp2x_topology.depth =
+		HDCP_2_2_DEPTH(tx_msg->msg_type.rpt_auth_send_rcvid.rxinfo[0]);
+	xhdcp2x_tx->xhdcp2x_topology.max_dev_exceeded =
+		HDCP_2_2_MAX_DEVS_EXCEEDED(tx_msg->msg_type.rpt_auth_send_rcvid.rxinfo[1]);
+	xhdcp2x_tx->xhdcp2x_topology.max_cascaded_exceeded =
+		HDCP_2_2_MAX_CASCADE_EXCEEDED(tx_msg->msg_type.rpt_auth_send_rcvid.rxinfo[1]);
+	xhdcp2x_tx->xhdcp2x_topology.hdcp2x_legacy_ds =
+	HDCP2X_TX_LEGACY2X_DEVICE_DOWNSTREAM(tx_msg->msg_type.rpt_auth_send_rcvid.rxinfo[1]);
+	xhdcp2x_tx->xhdcp2x_topology.hdcp1x_legacy_ds =
+	HDCP2X_TX_LEGACY1X_DEVICE_DOWNSTREAM(tx_msg->msg_type.rpt_auth_send_rcvid.rxinfo[1]);
+
+	if (xhdcp2x_tx->xhdcp2x_topology.max_dev_exceeded ||
+	    xhdcp2x_tx->xhdcp2x_topology.max_cascaded_exceeded) {
+		dev_err(xhdcp2x_tx->dev, "Failed with topology errors");
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	dev_dbg(xhdcp2x_tx->dev, "start compute V-hash");
+
+	xlnx_hdcp2x_tx_compute_v(xhdcp2x_tx->xhdcp2x_info.rn,
+				 xhdcp2x_tx->xhdcp2x_info.r_rx,
+				 tx_msg->msg_type.rpt_auth_send_rcvid.rxinfo,
+				 xhdcp2x_tx->xhdcp2x_info.r_tx,
+				 (u8 *)tx_msg->msg_type.rpt_auth_send_rcvid.rcvids,
+				 device_count,
+				 tx_msg->msg_type.rpt_auth_send_rcvid.seq_num_v,
+				 hdcp2x_tx_pairing_info->km, V);
+
+	dev_dbg(xhdcp2x_tx->dev, "start compute V-hash done");
+
+	if (memcmp(tx_msg->msg_type.rpt_auth_send_rcvid.vprime, V,
+		   HDCP_2_2_V_PRIME_HALF_LEN)) {
+		dev_err(xhdcp2x_tx->dev, "v-prime compare fail");
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	for (i = 0; i < device_count; i++) {
+		memcpy(&xhdcp2x_tx->xhdcp2x_topology.rcvid[i + 1],
+		       &tx_msg->msg_type.rpt_auth_send_rcvid.rcvids[i],
+			   HDCP_2_2_RECEIVER_ID_LEN);
+		if (xhdcp2x_tx->xhdcp2x_hw.tx_mode == XHDCP2X_TX_TRANSMITTER) {
+			u8 *rcv_id = tx_msg->msg_type.rpt_auth_send_rcvid.rcvids[i];
+
+			if (xlnx_hdcp2x_tx_is_device_revoked(xhdcp2x_tx, rcv_id)) {
+				xhdcp2x_tx->xhdcp2x_info.is_device_revoked = 1;
+				xhdcp2x_tx->xhdcp2x_info.auth_status =
+						XHDCP2X_TX_DEVICE_IS_REVOKED;
+				return A0_HDCP2X_TX_AKE_INIT;
+			}
+		}
+	}
+
+	seq_num_v = drm_hdcp_be24_to_cpu(tx_msg->msg_type.rpt_auth_send_rcvid.seq_num_v);
+	if (seq_num_v < xhdcp2x_tx->xhdcp2x_info.seq_num_v)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	xhdcp2x_tx->xhdcp2x_info.seq_num_v = seq_num_v;
+
+	result = xlnx_hdcp2x_tx_write_rptr_auth_send_ack(xhdcp2x_tx,
+							 &V[HDCP_2_2_V_PRIME_HALF_LEN]);
+	if (result < 0) {
+		dev_err(xhdcp2x_tx->dev, "write message fail - V prime");
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	return A9_HDCP2X_TX_STREAM_MANAGE;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_authenticated(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	if (!xhdcp2x_tx->xhdcp2x_internal_timer.timer_expired)
+		return A5_HDCP2X_TX_AUTHENTICATED;
+
+	if (xhdcp2x_tx->xhdcp2x_info.auth_status
+				!= XHDCP2X_TX_AUTHENTICATED)
+		dev_dbg(xhdcp2x_tx->dev, "HDCP 2X Authenticated");
+
+	if (xhdcp2x_tx->xhdcp2x_internal_timer.reason_id ==
+			XHDCP2X_TX_TS_WAIT_FOR_CIPHER) {
+		u8 handle_reauth_request = 0;
+
+		if (xhdcp2x_tx->xhdcp2x_hw.protocol == XHDCP2X_TX_DP) {
+			if ((xhdcp2x_tx->xhdcp2x_info.dp_rx_status &
+				(XHDCP2X_RX_STATUS_REAUTH_REQ |
+				 XHDCP2X_RX_STATUS_LINK_INTEGRITY_FAIL))) {
+				xhdcp2x_tx->xhdcp2x_info.dp_rx_status &=
+					~(XHDCP2X_RX_STATUS_REAUTH_REQ |
+					XHDCP2X_RX_STATUS_LINK_INTEGRITY_FAIL);
+				handle_reauth_request = 1;
+			}
+		} else {
+			if (xhdcp2x_tx->xhdcp2x_info.rx_status &
+					XHDCP2X_TX_RXSTATUS_REAUTH_REQ_MASK)
+				handle_reauth_request = 1;
+		}
+
+		if (handle_reauth_request) {
+			xlnx_hdcp2x_handle_reauth_request(xhdcp2x_tx);
+			return A0_HDCP2X_TX_AKE_INIT;
+		}
+
+		xhdcp2x_tx->xhdcp2x_info.auth_status =
+				XHDCP2X_TX_AUTHENTICATED;
+
+		xlnx_hdcp2x_tx_enable_encryption(xhdcp2x_tx);
+		xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP2X_TX_WAIT_REAUTH_CHECK_TIMEOUT,
+					   XHDCP2X_TX_TS_RX_REAUTH_CHECK);
+
+		dev_info(xhdcp2x_tx->dev, "HDCP 2X Authenticated");
+
+		return A5_HDCP2X_TX_AUTHENTICATED;
+	}
+
+	if (xhdcp2x_tx->xhdcp2x_internal_timer.reason_id ==
+			XHDCP2X_TX_TS_RX_REAUTH_CHECK) {
+		u8 handle_reauth_request = 0;
+		u8 handle_repeater_rdy = 0;
+
+		dev_dbg(xhdcp2x_tx->dev, "check for re-authentication");
+
+		if (xhdcp2x_tx->xhdcp2x_hw.protocol == XHDCP2X_TX_DP) {
+			if ((xhdcp2x_tx->xhdcp2x_info.dp_rx_status &
+				(XHDCP2X_RX_STATUS_REAUTH_REQ |
+				 XHDCP2X_RX_STATUS_LINK_INTEGRITY_FAIL))) {
+				xhdcp2x_tx->xhdcp2x_info.dp_rx_status &=
+					~(XHDCP2X_RX_STATUS_REAUTH_REQ |
+					XHDCP2X_RX_STATUS_LINK_INTEGRITY_FAIL);
+				handle_reauth_request = 1;
+			}
+
+			if ((xhdcp2x_tx->xhdcp2x_info.dp_rx_status &
+					XHDCP2X_RX_STATUS_RPTR_RDY) ==
+							XHDCP2X_RX_STATUS_RPTR_RDY)
+				handle_repeater_rdy = 1;
+		} else {
+			if (xhdcp2x_tx->xhdcp2x_info.rx_status &
+					XHDCP2X_TX_RXSTATUS_REAUTH_REQ_MASK)
+				handle_reauth_request = 1;
+
+			if (xhdcp2x_tx->xhdcp2x_info.rx_status &
+					XHDCP2X_TX_RXSTATUS_READY_MASK)
+				handle_repeater_rdy = 1;
+		}
+
+		if (handle_reauth_request) {
+			xlnx_hdcp2x_handle_reauth_request(xhdcp2x_tx);
+			return A0_HDCP2X_TX_AKE_INIT;
+		}
+		if (handle_repeater_rdy) {
+			/* The downstream topology has changed */
+			return A6_HDCP2X_TX_WAIT_FOR_RCVID;
+		}
+
+		xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP2X_TX_WAIT_REAUTH_CHECK_TIMEOUT,
+					   XHDCP2X_TX_TS_RX_REAUTH_CHECK);
+	}
+
+	return A5_HDCP2X_TX_AUTHENTICATED;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_rptr_check(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	if (xhdcp2x_tx->xhdcp2x_info.is_rcvr_repeater) {
+		xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP_2_2_RECVID_LIST_TIMEOUT_MS,
+					   HDCP_2_2_REP_SEND_RECVID_LIST);
+		return A6_HDCP2X_TX_WAIT_FOR_RCVID;
+	}
+
+	xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP2X_TX_WAIT_FOR_ENCRYPTION_TIMEOUT,
+				   XHDCP2X_TX_TS_WAIT_FOR_CIPHER);
+
+	return A5_HDCP2X_TX_AUTHENTICATED;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_exchange_ks(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct hdcp2x_tx_pairing_info *hdcp2x_tx_pairing_info =	(struct hdcp2x_tx_pairing_info *)
+					xhdcp2x_tx->xhdcp2x_info.state_context;
+	u8 riv[HDCP_2_2_RIV_LEN];
+	u8 ks[HDCP2X_TX_KS_SIZE];
+	u8 edkeys_ks[HDCP_2_2_E_DKEY_KS_LEN];
+	int result;
+
+	dev_dbg(xhdcp2x_tx->dev, "tx exchange ks");
+
+	xlnx_hdcp2x_rng_get_random_number(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_rng,
+					  riv, HDCP_2_2_RIV_LEN, HDCP_2_2_RIV_LEN);
+	xlnx_hdcp2x_cipher_set_keys(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher,
+				    riv, XHDCP2X_CIPHER_REG_RIV_1_OFFSET, HDCP_2_2_RIV_LEN);
+	xlnx_hdcp2x_rng_get_random_number(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_rng, ks,
+					  HDCP2X_TX_KS_SIZE,
+					  HDCP2X_TX_KS_SIZE);
+	xlnx_hdcp2x_cipher_set_keys(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher,
+				    ks, XHDCP2X_CIPHER_REG_KS_1_OFFSET, HDCP2X_TX_KS_SIZE);
+	xlnx_hdcp2x_tx_compute_edkey_ks(xhdcp2x_tx->xhdcp2x_info.rn,
+					hdcp2x_tx_pairing_info->km, ks,
+					xhdcp2x_tx->xhdcp2x_info.r_rx,
+					xhdcp2x_tx->xhdcp2x_info.r_tx,
+					edkeys_ks);
+
+	result = xlnx_hdcp2x_tx_write_ske_send_eks(xhdcp2x_tx, edkeys_ks, riv);
+	if (result < 0) {
+		dev_err(xhdcp2x_tx->dev, "ske send eks write fail");
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	result = xlnx_hdcp2x_tx_write_type_value(xhdcp2x_tx);
+	if (result < 0) {
+		dev_err(xhdcp2x_tx->dev, "SKE send ES write fail");
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	return A4_HDCP2X_TX_REPEATER_CHECK;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_verify_lprime_msg(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+	struct hdcp2x_tx_pairing_info *hdcp2x_tx_pairing_info =
+		(struct hdcp2x_tx_pairing_info *)xhdcp2x_tx->xhdcp2x_info.state_context;
+	u8 lprime[HDCP_2_2_L_PRIME_LEN];
+	int result = 0;
+
+	/*
+	 * Wait for the receiver to respond within 20 msecs.
+	 * If the receiver has timed out we go to state A2 for a retry.
+	 * If the receiver is busy, we stay in this state (return from polling).
+	 * If the receiver has finished, but the message was not handled yet,
+	 * we handle the message.
+	 */
+	result = xlnx_hdcp2x_tx_wait_for_receiver(xhdcp2x_tx,
+						  sizeof(struct hdcp2x_tx_lc_send_lc_prime),
+						  0);
+	if (result < 0)
+		return A2_HDCP2X_TX_LC_CHECK;
+
+	if (!xhdcp2x_tx->xhdcp2x_info.msg_available)
+		return A2_HDCP2X_TX_VERIFY_LPRIME;
+
+	result = hdcp2x_tx_receive_message(xhdcp2x_tx, HDCP_2_2_LC_SEND_LPRIME);
+	if (result < 0)
+		return A2_HDCP2X_TX_LC_CHECK;
+
+	xlnx_hdcp2x_tx_compute_lprime(xhdcp2x_tx->xhdcp2x_info.rn,
+				      hdcp2x_tx_pairing_info->km,
+				      xhdcp2x_tx->xhdcp2x_info.r_rx,
+				      xhdcp2x_tx->xhdcp2x_info.r_tx,
+				      lprime);
+
+	if (memcmp(tx_msg->msg_type.lcsend_lcprime.lprime,
+		   lprime, sizeof(lprime))) {
+		dev_err(xhdcp2x_tx->dev, "compare L fail");
+		return A2_HDCP2X_TX_LC_CHECK;
+	}
+
+	dev_dbg(xhdcp2x_tx->dev, "locality check counter=%d\n",
+		(u16)xhdcp2x_tx->xhdcp2x_info.lc_counter);
+
+	return A3_HDCP2X_TX_EXCHANGE_KS;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_lc_check(struct xlnx_hdcp2x_config
+		*xhdcp2x_tx)
+{
+	int result;
+
+	xhdcp2x_tx->xhdcp2x_info.lc_counter++;
+
+	if (xhdcp2x_tx->xhdcp2x_info.lc_counter >
+			HDCP2X_TX_MAX_ALLOWED_LOCALITY_CHECKS) {
+		dev_dbg(xhdcp2x_tx->dev, "lc_counter = %d/n",
+			(u16)xhdcp2x_tx->xhdcp2x_info.lc_counter - 1);
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	xlnx_hdcp2x_rng_get_random_number(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_rng,
+					  xhdcp2x_tx->xhdcp2x_info.rn,
+					  HDCP_2_2_RN_LEN,
+					  HDCP_2_2_RN_LEN);
+	result = xlnx_hdcp2x_tx_write_lcinit(xhdcp2x_tx,
+					     xhdcp2x_tx->xhdcp2x_info.rn);
+	if (result < 0) {
+		dev_err(xhdcp2x_tx->dev, "write lc-init message fail");
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP_2_2_DP_LPRIME_TIMEOUT_MS,
+				   HDCP_2_2_LC_SEND_LPRIME);
+
+	return A2_HDCP2X_TX_VERIFY_LPRIME;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_compute_hprime(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct hdcp2x_tx_pairing_info *hdcp2x_tx_pairing_info =
+	(struct hdcp2x_tx_pairing_info *)xhdcp2x_tx->xhdcp2x_info.state_context;
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+	u8 h_prime[HDCP_2_2_H_PRIME_LEN];
+	int result = 0;
+
+	/*
+	 * Wait for the receiver to respond within 1 second.
+	 * If the receiver has timed out we go to state A0.
+	 * If the receiver is busy, we stay in this state (return from polling).
+	 * If the receiver has finished, but the message was not handled yet,
+	 * we handle the message.
+	 */
+	result = xlnx_hdcp2x_tx_wait_for_receiver(xhdcp2x_tx,
+						  sizeof(struct hdcp2x_tx_ake_sendprime),
+						  0);
+	if (result < 0)
+		return A0_HDCP2X_TX_AKE_INIT;
+	if (!xhdcp2x_tx->xhdcp2x_info.msg_available)
+		return A1_HDCP2X_TX_VERIFY_HPRIME;
+
+	result = hdcp2x_tx_receive_message(xhdcp2x_tx, HDCP_2_2_AKE_SEND_HPRIME);
+	if (result < 0)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	xlnx_hdcp2x_tx_compute_hprime(xhdcp2x_tx->xhdcp2x_info.r_rx,
+				      hdcp2x_tx_pairing_info->rxcaps,
+				      xhdcp2x_tx->xhdcp2x_info.r_tx,
+				      xhdcp2x_tx->xhdcp2x_info.txcaps,
+				      hdcp2x_tx_pairing_info->km, h_prime);
+
+	if (memcmp(tx_msg->msg_type.ake_send_prime.h_prime, h_prime,
+		   sizeof(h_prime))) {
+		dev_err(xhdcp2x_tx->dev, "compare H' fail");
+		xlnx_hdcp2x_tx_invalidate_paring_info(xhdcp2x_tx,
+						      hdcp2x_tx_pairing_info->rcvid);
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	return A2_HDCP2X_TX_LC_CHECK;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_wait_for_pairing_info(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct hdcp2x_tx_pairing_info *hdcp2x_tx_pairing_info = &xhdcp2x_tx->xhdcp2x_pairing_info;
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+	int result = 0;
+
+	result = xlnx_hdcp2x_tx_wait_for_receiver(xhdcp2x_tx,
+						  sizeof(struct hdcp2x_tx_ake_send_pairing_info),
+						  0);
+	if (result < 0) {
+		xlnx_hdcp2x_tx_invalidate_paring_info(xhdcp2x_tx, hdcp2x_tx_pairing_info->rcvid);
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+	if (!xhdcp2x_tx->xhdcp2x_info.msg_available)
+		return A1_HDCP2X_TX_WAIT_FOR_PAIRING;
+
+	dev_dbg(xhdcp2x_tx->dev, "wait for pairing to be done");
+	result = hdcp2x_tx_receive_message(xhdcp2x_tx,
+					   HDCP_2_2_AKE_SEND_PAIRING_INFO);
+	if (result < 0) {
+		xlnx_hdcp2x_tx_invalidate_paring_info(xhdcp2x_tx, hdcp2x_tx_pairing_info->rcvid);
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	memcpy(hdcp2x_tx_pairing_info->ekh_km,
+	       tx_msg->msg_type.ake_send_pairing_info.ekh_km,
+	       sizeof(hdcp2x_tx_pairing_info->ekh_km));
+
+	hdcp2x_tx_pairing_info = xlnx_hdcp2x_tx_update_pairinginfo(xhdcp2x_tx,
+								   hdcp2x_tx_pairing_info, 1);
+
+	return A2_HDCP2X_TX_LC_CHECK;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_wait_for_hprime_msg(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct hdcp2x_tx_pairing_info *hdcp2x_tx_pairing_info =
+				(struct hdcp2x_tx_pairing_info *)
+				xhdcp2x_tx->xhdcp2x_info.state_context;
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+	u8 h_prime[HDCP_2_2_H_PRIME_LEN];
+	int result = 0;
+
+	/*
+	 * Wait for the receiver to respond within 1 second.
+	 * If the receiver has timed out we go to state A0.
+	 * If the receiver is busy, we stay in this state (return from polling).
+	 * If the receiver has finished, but the message was not handled yet,
+	 * we handle the message.
+	 */
+	result = xlnx_hdcp2x_tx_wait_for_receiver(xhdcp2x_tx,
+						  sizeof(struct hdcp2x_tx_ake_sendprime), 0);
+	if (result < 0) {
+		xlnx_hdcp2x_tx_invalidate_paring_info(xhdcp2x_tx,
+						      hdcp2x_tx_pairing_info->rcvid);
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+	if (!xhdcp2x_tx->xhdcp2x_info.msg_available)
+		return A1_HDCP2X_TX_WAIT_FOR_HPRIME;
+
+	dev_dbg(xhdcp2x_tx->dev, "wait for H-Prime");
+
+	result = hdcp2x_tx_receive_message(xhdcp2x_tx,
+					   HDCP_2_2_AKE_SEND_HPRIME);
+	if (result < 0) {
+		xlnx_hdcp2x_tx_invalidate_paring_info(xhdcp2x_tx,
+						      hdcp2x_tx_pairing_info->rcvid);
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	xlnx_hdcp2x_tx_compute_hprime(hdcp2x_tx_pairing_info->rrx,
+				      hdcp2x_tx_pairing_info->rxcaps,
+				      hdcp2x_tx_pairing_info->rtx,
+				      xhdcp2x_tx->xhdcp2x_info.txcaps,
+				      hdcp2x_tx_pairing_info->km, h_prime);
+	dev_dbg(xhdcp2x_tx->dev, "Compute H' done");
+
+	if (memcmp(tx_msg->msg_type.ake_send_prime.h_prime, h_prime, sizeof(h_prime))) {
+		dev_dbg(xhdcp2x_tx->dev, "compare H' fail");
+
+		xlnx_hdcp2x_tx_invalidate_paring_info(xhdcp2x_tx,
+						      hdcp2x_tx_pairing_info->rcvid);
+		return A0_HDCP2X_TX_AKE_INIT;
+	}
+
+	xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP_2_2_PAIRING_TIMEOUT_MS,
+				   HDCP_2_2_AKE_SEND_PAIRING_INFO);
+
+	return A1_HDCP2X_TX_WAIT_FOR_PAIRING;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_wait_for_ack(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct xhdcp2x_tx_msg *xhdcp2x_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+	struct hdcp2x_tx_pairing_info  *xhdcp2x_pairing_info = NULL;
+	struct hdcp2x_tx_pairing_info xhdcp2x_new_pairing_info;
+	const u8 *kpubdpcptr = NULL;
+	int result;
+
+	result = xlnx_hdcp2x_tx_wait_for_receiver(xhdcp2x_tx,
+						  sizeof(struct hdcp2x_tx_ake_sendcert), 0);
+	if (result < 0)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	if (!xhdcp2x_tx->xhdcp2x_info.msg_available)
+		return A1_HDCP2X_TX_WAIT_FOR_ACK;
+
+	result = hdcp2x_tx_receive_message(xhdcp2x_tx, HDCP_2_2_AKE_SEND_CERT);
+
+	if (result < 0)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	kpubdpcptr = xlnx_hdcp2x_tx_get_publickey(xhdcp2x_tx);
+
+	if (!kpubdpcptr)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	result = xlnx_hdcp2x_tx_verify_certificate(&xhdcp2x_msg->msg_type.ake_send_cert.cert_rx,
+						   kpubdpcptr, HDCP2X_TX_KPUB_DCP_LLC_N_SIZE,
+						   &kpubdpcptr[HDCP2X_TX_KPUB_DCP_LLC_N_SIZE],
+						   HDCP2X_TX_KPUB_DCP_LLC_E_SIZE);
+	if (result < 0)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	if (xhdcp2x_tx->xhdcp2x_hw.tx_mode == XHDCP2X_TX_TRANSMITTER) {
+		u8 *rcv_id = xhdcp2x_msg->msg_type.ake_send_cert.cert_rx.rcvid;
+
+		if (xlnx_hdcp2x_tx_is_device_revoked(xhdcp2x_tx, rcv_id)) {
+			xhdcp2x_tx->xhdcp2x_info.is_device_revoked = 1;
+			xhdcp2x_tx->xhdcp2x_info.auth_status =
+					XHDCP2X_TX_DEVICE_IS_REVOKED;
+			return A0_HDCP2X_TX_AKE_INIT;
+		}
+		xhdcp2x_tx->xhdcp2x_info.is_device_revoked  = 0;
+	}
+	memcpy(&xhdcp2x_tx->xhdcp2x_topology.rcvid[0],
+	       xhdcp2x_msg->msg_type.ake_send_cert.cert_rx.rcvid,
+		   HDCP_2_2_RECEIVER_ID_LEN);
+	xhdcp2x_tx->xhdcp2x_topology.devicecount = 1;
+
+	if (xhdcp2x_msg->msg_type.ake_send_cert.rxcaps[2] & 0x1)
+		xhdcp2x_tx->xhdcp2x_info.is_rcvr_repeater = 1;
+	else
+		xhdcp2x_tx->xhdcp2x_info.is_rcvr_repeater = 0;
+
+	memcpy(xhdcp2x_tx->xhdcp2x_info.r_rx,
+	       xhdcp2x_msg->msg_type.ake_send_cert.r_rx,
+	       sizeof(xhdcp2x_tx->xhdcp2x_info.r_rx));
+
+	xhdcp2x_pairing_info =
+		xlnx_hdcp2x_tx_get_pairing_info(xhdcp2x_tx,
+						xhdcp2x_msg->msg_type.ake_send_cert.cert_rx.rcvid);
+	if (xhdcp2x_pairing_info) {
+		if (xhdcp2x_pairing_info->ready) {
+			memcpy(xhdcp2x_pairing_info->rxcaps,
+			       xhdcp2x_msg->msg_type.ake_send_cert.rxcaps,
+			       sizeof(xhdcp2x_pairing_info->rxcaps));
+
+			result = xlnx_hdcp2x_tx_write_ake_storedkm(xhdcp2x_tx,
+								   xhdcp2x_pairing_info);
+			if (result < 0)
+				return A0_HDCP2X_TX_AKE_INIT;
+
+			xhdcp2x_tx->xhdcp2x_info.state_context =
+					xhdcp2x_pairing_info;
+
+			xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP_2_2_PAIRING_TIMEOUT_MS,
+						   HDCP_2_2_AKE_SEND_HPRIME);
+			return A1_HDCP2X_TX_VERIFY_HPRIME;
+		}
+	}
+	memcpy(xhdcp2x_new_pairing_info.rrx, xhdcp2x_tx->xhdcp2x_info.r_rx,
+	       sizeof(xhdcp2x_new_pairing_info.rrx));
+	memcpy(xhdcp2x_new_pairing_info.rtx, xhdcp2x_tx->xhdcp2x_info.r_tx,
+	       sizeof(xhdcp2x_new_pairing_info.rtx));
+	memcpy(xhdcp2x_new_pairing_info.rxcaps, xhdcp2x_msg->msg_type.ake_send_cert.rxcaps,
+	       sizeof(xhdcp2x_new_pairing_info.rxcaps));
+	memcpy(xhdcp2x_new_pairing_info.rcvid, xhdcp2x_msg->msg_type.ake_send_cert.cert_rx.rcvid,
+	       sizeof(xhdcp2x_new_pairing_info.rcvid));
+
+	xlnx_hdcp2x_tx_generatekm(xhdcp2x_tx, xhdcp2x_new_pairing_info.km);
+
+	xhdcp2x_pairing_info =
+			xlnx_hdcp2x_tx_update_pairinginfo(xhdcp2x_tx,
+							  &xhdcp2x_new_pairing_info,
+							  0);
+	if (!xhdcp2x_pairing_info)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	xhdcp2x_tx->xhdcp2x_info.state_context =  (void *)xhdcp2x_pairing_info;
+
+	result = xlnx_hdcp2x_tx_write_akenostored_km(xhdcp2x_tx,
+						     &xhdcp2x_new_pairing_info,
+						     &xhdcp2x_msg->msg_type.ake_send_cert.cert_rx);
+	if (result < 0)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP_2_2_HPRIME_NO_PAIRED_TIMEOUT_MS,
+				   HDCP_2_2_AKE_SEND_HPRIME);
+
+	return A1_HDCP2X_TX_WAIT_FOR_HPRIME;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_write_ake_init(struct xlnx_hdcp2x_config
+						     *xhdcp2x_tx)
+{
+	if (!xhdcp2x_tx->xhdcp2x_info.is_enabled)
+		return H1_HDCP2X_TX_WAIT_FOR_TX_ENABLE;
+
+	if (!xhdcp2x_tx->xhdcp2x_info.is_rcvr_hdcp2x_capable) {
+		xhdcp2x_tx->xhdcp2x_info.auth_status =
+		XHDCP2X_TX_INCOMPATIBLE_RX;
+		return H1_HDCP2X_TX_WAIT_FOR_TX_ENABLE;
+	}
+
+	xhdcp2x_tx->xhdcp2x_info.auth_status =
+			XHDCP2X_TX_AUTHENTICATION_BUSY;
+
+	xlnx_hdcp2x_tx_disable_encryption(xhdcp2x_tx);
+	xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP_2_2_CERT_TIMEOUT_MS, A0_HDCP2X_TX_AKE_INIT);
+
+	return A1_HDCP2X_TX_EXCHANGE_KM;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_exchange_km_process(struct xlnx_hdcp2x_config
+							  *xhdcp2x_tx)
+{
+	int result;
+
+	if (!xhdcp2x_tx->xhdcp2x_internal_timer.timer_expired)
+		return A1_HDCP2X_TX_EXCHANGE_KM;
+
+	result = xlnx_hdcp2x_tx_write_ake_init(xhdcp2x_tx);
+	if (result < 0)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	xlnx_hdcp2x_tx_start_timer(xhdcp2x_tx, HDCP_2_2_CERT_TIMEOUT_MS, HDCP_2_2_AKE_SEND_CERT);
+
+	memset(&xhdcp2x_tx->xhdcp2x_topology, 0, sizeof(xhdcp2x_tx->xhdcp2x_topology));
+
+	xhdcp2x_tx->xhdcp2x_info.seq_num_v  = 0;
+	xhdcp2x_tx->xhdcp2x_info.seq_num_m = 0;
+	xhdcp2x_tx->xhdcp2x_info.content_strm_mng_chk_cntr  = 0;
+	xhdcp2x_tx->xhdcp2x_info.lc_counter = 0;
+	xhdcp2x_tx->xhdcp2x_info.prev_seq_num_m = 0;
+
+	return A1_HDCP2X_TX_WAIT_FOR_ACK;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_wait_for_tx_state(struct xlnx_hdcp2x_config
+		*xhdcp2x_tx)
+{
+	if (xhdcp2x_tx->xhdcp2x_info.auth_status !=
+			XHDCP2X_TX_AUTHENTICATION_BUSY)
+		return H1_HDCP2X_TX_WAIT_FOR_TX_ENABLE;
+
+	xhdcp2x_tx->xhdcp2x_info.is_rcvr_hdcp2x_capable =
+			xlnx_hdcp2x_downstream_capbility(xhdcp2x_tx);
+
+	if (xhdcp2x_tx->xhdcp2x_info.is_rcvr_hdcp2x_capable)
+		return A0_HDCP2X_TX_AKE_INIT;
+
+	xhdcp2x_tx->xhdcp2x_info.auth_status =
+			XHDCP2X_TX_INCOMPATIBLE_RX;
+
+	return H1_HDCP2X_TX_WAIT_FOR_TX_ENABLE;
+}
+
+static enum hdcp2x_tx_state hdcp2x_tx_idle_state(struct xlnx_hdcp2x_config
+		*xhdcp2x_tx)
+{
+	return H1_HDCP2X_TX_WAIT_FOR_TX_ENABLE;
+}
+
+/*
+ * HDCP Transmitter State Diagram available in
+ * HDCP2.3 specification. Section 2.8
+ * https://www.digital-cp.com/sites/default/files/
+ * HDCP%20Interface%20Independent%20Adaptation%20Specification%20Rev2_3.pdf
+ */
+int hdcp2x_tx_protocol_authenticate_sm(struct xlnx_hdcp2x_config *hdcp2x_tx)
+{
+	int status = H0_HDCP2X_TX_NO_RX_ATTACHED;
+	enum hdcp2x_tx_state hdcp_state = hdcp2x_tx->xhdcp2x_info.curr_state;
+
+	switch (hdcp_state) {
+	case H0_HDCP2X_TX_NO_RX_ATTACHED:
+		status = hdcp2x_tx_idle_state(hdcp2x_tx);
+		break;
+	case H1_HDCP2X_TX_WAIT_FOR_TX_ENABLE:
+		status = hdcp2x_tx_wait_for_tx_state(hdcp2x_tx);
+		break;
+	case A0_HDCP2X_TX_AKE_INIT:
+		status = hdcp2x_tx_write_ake_init(hdcp2x_tx);
+		break;
+	case A1_HDCP2X_TX_EXCHANGE_KM:
+		status = hdcp2x_tx_exchange_km_process(hdcp2x_tx);
+		break;
+	case A1_HDCP2X_TX_WAIT_FOR_ACK:
+		status = hdcp2x_tx_wait_for_ack(hdcp2x_tx);
+		break;
+	case A1_HDCP2X_TX_WAIT_FOR_HPRIME:
+		status = hdcp2x_tx_wait_for_hprime_msg(hdcp2x_tx);
+		break;
+	case A1_HDCP2X_TX_WAIT_FOR_PAIRING:
+		status = hdcp2x_tx_wait_for_pairing_info(hdcp2x_tx);
+		break;
+	case A1_HDCP2X_TX_VERIFY_HPRIME:
+		status = hdcp2x_tx_compute_hprime(hdcp2x_tx);
+		break;
+	case A2_HDCP2X_TX_LC_CHECK:
+		status = hdcp2x_tx_lc_check(hdcp2x_tx);
+		break;
+	case A2_HDCP2X_TX_VERIFY_LPRIME:
+		status = hdcp2x_tx_verify_lprime_msg(hdcp2x_tx);
+		break;
+	case A3_HDCP2X_TX_EXCHANGE_KS:
+		status = hdcp2x_tx_exchange_ks(hdcp2x_tx);
+		break;
+	case A4_HDCP2X_TX_REPEATER_CHECK:
+		status = hdcp2x_tx_rptr_check(hdcp2x_tx);
+		break;
+	case A5_HDCP2X_TX_AUTHENTICATED:
+		status = hdcp2x_tx_authenticated(hdcp2x_tx);
+		break;
+	case A6_HDCP2X_TX_WAIT_FOR_RCVID:
+		status = hdcp2x_tx_wait_for_rcvid(hdcp2x_tx);
+		break;
+	case A7_HDCP2X_TX_VERIFY_RCVID:
+		status = hdcp2x_tx_process_rcvid(hdcp2x_tx);
+		break;
+	case A9_HDCP2X_TX_STREAM_MANAGE:
+		status = hdcp2x_tx_process_stream_manage(hdcp2x_tx);
+		break;
+	case A9_HDCP2X_TX_VERIFY_MPRIME:
+		status = hdcp2x_tx_verify_mprime(hdcp2x_tx);
+		break;
+	default:
+		status = hdcp_state;
+		dev_dbg(hdcp2x_tx->dev, "Invalid HDCP State");
+		break;
+	}
+
+	return status;
+}
diff --git a/drivers/gpu/drm/xlnx/hdcp/xhdcp2x_tx.h b/drivers/gpu/drm/xlnx/hdcp/xhdcp2x_tx.h
new file mode 100644
index 000000000..d4fbaf093
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xhdcp2x_tx.h
@@ -0,0 +1,296 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx HDCP2X Protocol Driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Lakshmi Prasanna Eachuri <lakshmi.prasanna.eachuri@amd.com>
+ */
+
+#ifndef _XHDCP2X_TX_H_
+#define _XHDCP2X_TX_H_
+
+#include <drm/display/drm_hdcp.h>
+#include <linux/types.h>
+
+#define HDCP2X_TX_SRM_ID			0x91
+#define HDCP2X_TX_REPEATERAUTH_STREAM_READY_SIZE	33
+
+#define HDCP2X_TX_V_SIZE			32
+#define HDCP2X_TX_MAX_DEV_COUNT			32
+#define HDCP2X_TX_K_SIZE			2
+#define HDCP2X_TX_STREAMID_TYPE_SIZE		2
+#define HDCP2X_TX_SHA256_HASH_SIZE		32
+#define HDCP2X_TX_AES128_SIZE			16
+#define HDCP2X_TX_KM_SIZE			HDCP2X_TX_AES128_SIZE
+#define HDCP2X_TX_KM_MSK_SEED_SIZE		HDCP2X_TX_SHA256_HASH_SIZE
+#define HDCP2X_TX_KS_SIZE			16
+
+#define HDCP2X_TX_CERT_PUB_KEY_N_SIZE		128
+#define HDCP2X_TX_CERT_PUB_KEY_E_SIZE		3
+#define HDCP2X_TX_CERT_RSVD_SIZE		2
+#define HDCP2X_TX_CERT_RSA_PARAMETER_SIZE		384
+#define HDCP2X_TX_CERT_SIGNATURE_SIZE		384
+#define HDCP2X_TX_CERT_PADDING_BYTES		330
+#define HDCP2X_TX_CERT_PADDING_END_DELIMITER	332
+#define HDCP2X_TX_CERT_PADDING_TI_IDENTIFIER	333
+#define HDCP2X_TX_CERT_PADDING_T_HASH		352
+#define HDCP2X_TX_SRM_SIGNATURE_SIZE		384
+#define HDCP2X_TX_CERT_TI_IDENTIFIER_SIZE 19
+#define HDCP2X_TX_CERT_T_HASH_SIZE 19
+#define HDCP2X_TX_CERT_SIZE		(HDCP_2_2_RECEIVER_ID_LEN +	\
+					 HDCP2X_TX_CERT_PUB_KEY_N_SIZE +	\
+					 HDCP2X_TX_CERT_PUB_KEY_E_SIZE +	\
+					 HDCP2X_TX_CERT_RSVD_SIZE +	\
+					 HDCP2X_TX_CERT_SIGNATURE_SIZE)
+#define HDCP2X_TX_CERT_PUBLIC_EXPONENT_E	4
+#define HDCP2X_TX_DKEY				15
+#define HDCP2X_TX_DKEY_CTR1			1
+#define HDCP2X_TX_DKEY_CTR2			2
+#define HDCP2X_TX_DKEY_SIZE			2
+
+#define HDCP2X_TX_TXCAPS_SIZE			3
+#define HDCP2X_TX_KPUB_DCP_LLC_N_SIZE		384
+#define HDCP2X_TX_KPUB_DCP_LLC_E_SIZE		1
+
+#define HDCP2X_TX_HDCPPORT_E_KPUB_KM_SIZE	128
+#define HDCP2X_TX_HDCPPORT_CERT_RX_SIZE		522
+#define HDCP2X_TX_HDCPPORT_K_SIZE		2
+#define HDCP2X_TX_HDCPPORT_TYPE_VALUE_SIZE	1
+
+#define XDPTX_HDCP2X_DPCD_OFFSET			0x69000
+#define HDCP2X_TX_HDCPPORT_M_OFFSET			(0x2B0 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_R_TX_OFFSET			(0x000 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_TX_CAPS_OFFSET		(0x008 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_CERT_RX_OFFSET		(0x00B + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_R_RX_OFFSET			(0x215 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_RX_CAPS_OFFSET		(0x21D + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_E_KPUB_KM_OFFSET		(0x220 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_E_KH_KM_OFFSET		(0x2A0 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_H_PRIME_OFFSET		(0x2C0 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_E_KH_KM_PAIRING_OFFSET	(0x2E0 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_R_N_OFFSET			(0x2F0 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_L_PRIME_OFFSET		(0x2F8 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_E_DKEY_KS_OFFSET		(0x318 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_R_IV_OFFSET			(0x328 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_RX_INFO_OFFSET		(0x330 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_SEQ_NUM_V_OFFSET		(0x332 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_V_PRIME_OFFSET		(0x335 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_RCVR_ID_LST_OFFSET		(0x345 + XDPTX_HDCP2X_DPCD_OFFSET)
+
+#define HDCP2X_TX_HDCPPORT_RCVR_ID_LST_MAX_SIZE		155
+#define HDCP2X_TX_HDCPPORT_V_OFFSET			(GENMASK(9, 5) + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_SEQ_NUM_M_OFFSET		(GENMASK(9, 4) + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_K_OFFSET			(0x3F3 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_STREAM_ID_TYPE_OFFSET	(0x3F5 + XDPTX_HDCP2X_DPCD_OFFSET)
+
+#define HDCP2X_TX_HDCPPORT_STREAM_ID_TYPE_SIZE		2
+#define HDCP2X_TX_HDCPPORT_M_PRIME_OFFSET		(0x473 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_RX_STATUS_OFFSET		(0x493 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_TYPE_VALUE_OFFSET		(0x494 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_VERSION_OFFSET		(0x50 + XDPTX_HDCP2X_DPCD_OFFSET)
+#define HDCP2X_TX_HDCPPORT_RX_CAPS_OFFSET		(0x21D + XDPTX_HDCP2X_DPCD_OFFSET)
+
+#define HDCP2X_TX_HDCPPORT_WRITE_MSG_OFFSET		BIT(5)
+#define HDCP2X_TX_HDCPPORT_RXSTATUS_OFFSET		BIT(6)
+#define HDCP2X_TX_HDCPPORT_READ_MSG_OFFSET		BIT(7)
+
+#define HDCP2x_TX_REPEATER_MAX_CASCADE_DEPTH		4
+#define HDCP2X_TX_REVOCATION_LIST_MAX_DEVICES		944
+#define HDCP2X_TX_MAX_ALLOWED_LOCALITY_CHECKS		8
+#define HDCP2X_TX_TYPE_VALUE				18
+
+#define HDCP2X_TX_WAIT_REAUTH_CHECK_TIMEOUT		1000
+#define HDCP2X_TX_WAIT_FOR_ENCRYPTION_TIMEOUT		200
+#define HDCP2X_TX_WAIT_FOR_STREAM_TYPE_TIMEOUT		50
+
+#define HDCP2X_TX_LEGACY2X_DEVICE_DOWNSTREAM(x)	((x) & BIT(1))
+#define HDCP2X_TX_LEGACY1X_DEVICE_DOWNSTREAM(x)	((x) & BIT(0))
+
+/*
+ * HDCP Authentication Protocol messages in
+ * HDCP2.3 specification. Section 4.1
+ * https://www.digital-cp.com/sites/default/files/
+ * HDCP%20Interface%20Independent%20Adaptation%20Specification%20Rev2_3.pdf
+ */
+struct hdcp2x_tx_ake_init {
+	u8 msg_id;
+	u8 r_tx[HDCP_2_2_RTX_LEN];
+	u8 txcaps[HDCP2X_TX_TXCAPS_SIZE];
+} __packed;
+
+struct hdcp2x_tx_ake_no_stored_km {
+	u8 msg_id;
+	u8 ek_pubkm[HDCP_2_2_E_KPUB_KM_LEN];
+} __packed;
+
+struct hdcp2x_tx_ake_stored_km {
+	u8 msg_id;
+	u8 ekh_km[HDCP_2_2_E_KH_KM_LEN];
+	u8 r_tx[HDCP_2_2_RTX_LEN];
+	u8 r_rx[HDCP_2_2_RRX_LEN];
+} __packed;
+
+struct hdcp2x_tx_lc_init {
+	u8 msg_id;
+	u8 rn[HDCP_2_2_RN_LEN];
+} __packed;
+
+struct hdcp2x_tx_ske_send_eks {
+	u8 msg_id;
+	u8 edkeys_ks[HDCP_2_2_E_DKEY_KS_LEN];
+	u8 riv[HDCP_2_2_RIV_LEN];
+} __packed;
+
+struct hdcp2x_tx_rpt_auth_send_ack {
+	u8 msg_id;
+	u8 V[HDCP_2_2_V_PRIME_HALF_LEN];
+} __packed;
+
+struct hdcp2x_tx_rpt_auth_stream_manage {
+	u8 msg_id;
+	u8 seq_num_m[HDCP_2_2_SEQ_NUM_LEN];
+	u8 K[HDCP2X_TX_K_SIZE];
+	u8 streamid_type[HDCP2X_TX_STREAMID_TYPE_SIZE];
+} __packed;
+
+struct hdcp2x_tx_cert_rx {
+	u8 rcvid[HDCP_2_2_RECEIVER_ID_LEN];
+	u8 N[HDCP2X_TX_CERT_PUB_KEY_N_SIZE];
+	u8 e[HDCP2X_TX_CERT_PUB_KEY_E_SIZE];
+	u8 reserved[HDCP2X_TX_CERT_RSVD_SIZE];
+	u8 signature[HDCP2X_TX_CERT_SIGNATURE_SIZE];
+} __packed;
+
+struct hdcp2x_tx_ake_sendcert {
+	u8 msg_id;
+	struct hdcp2x_tx_cert_rx  cert_rx;
+	u8 r_rx[HDCP_2_2_RRX_LEN];
+	u8 rxcaps[HDCP_2_2_RXCAPS_LEN];
+} __packed;
+
+struct hdcp2x_tx_ake_send_pairing_info {
+	u8 msg_id;
+	u8 ekh_km[HDCP_2_2_E_KH_KM_LEN];
+} __packed;
+
+struct hdcp2x_tx_lc_send_lc_prime {
+	u8 msg_id;
+	u8 lprime[HDCP_2_2_L_PRIME_LEN];
+} __packed;
+
+struct hdcp2x_tx_rpt_auth_send_rcvid_list {
+	u8 msg_id;
+	u8 rxinfo[HDCP_2_2_RXINFO_LEN];
+	u8 seq_num_v[HDCP_2_2_SEQ_NUM_LEN];
+	u8 vprime[HDCP_2_2_V_PRIME_HALF_LEN];
+	u8 rcvids[HDCP_2_2_MAX_DEVICE_COUNT][HDCP_2_2_RECEIVER_ID_LEN];
+} __packed;
+
+struct hdcp2x_tx_rpt_auth_stream_ready {
+	u8 msg_id;
+	u8 m_prime[HDCP_2_2_MPRIME_LEN];
+} __packed;
+
+struct hdcp2x_tx_ake_sendprime {
+	u8 msg_id;
+	u8 h_prime[HDCP_2_2_H_PRIME_LEN];
+} __packed;
+
+struct hdcp2x_tx_certrx {
+	u8 rcvid[HDCP_2_2_RECEIVER_ID_LEN];
+	u8 N[HDCP2X_TX_CERT_PUB_KEY_N_SIZE];
+	u8 e[HDCP2X_TX_CERT_PUB_KEY_E_SIZE];
+	u8 rsvd[HDCP2X_TX_CERT_RSVD_SIZE];
+	u8 signature[HDCP2X_TX_CERT_SIGNATURE_SIZE];
+} __packed;
+
+struct hdcp2x_tx_pairing_info {
+	u8 rcvid[HDCP_2_2_RECEIVER_ID_LEN];
+	u8 rxcaps[HDCP_2_2_RXCAPS_LEN];
+	u8 rtx[HDCP_2_2_RTX_LEN];
+	u8 rrx[HDCP_2_2_RRX_LEN];
+	u8 km[HDCP_2_2_E_KH_KM_LEN];
+	u8 ekh_km[HDCP_2_2_E_KH_KM_LEN];
+	u8 ready;
+} __packed;
+
+struct hdcp2x_tx_revoclist {
+	u8  rcvid[HDCP2X_TX_REVOCATION_LIST_MAX_DEVICES][HDCP_2_2_RECEIVER_ID_LEN];
+	u32 num_of_devices;
+} __packed;
+
+struct hdcp2x_tx_topology {
+	u8  rcvid[HDCP2X_TX_MAX_DEV_COUNT][HDCP_2_2_RECEIVER_ID_LEN];
+	u8  depth;
+	u8  devicecount;
+	u8  max_dev_exceeded;
+	u8  max_cascaded_exceeded;
+	u8  hdcp2x_legacy_ds;
+	u8  hdcp1x_legacy_ds;
+} __packed;
+
+/**
+ * union hdcp2x_tx_msg_type - HDCP 2X authentication protocol message buffers
+ * @ake_send_cert: Reads CertRx message
+ * @ake_send_prime: Reads HPrime message
+ * @ake_send_pairing_info: Reads Ekh_km message
+ * @lcsend_lcprime: Reads L` prime message
+ * @rpt_auth_send_rcvid: Reads receiver-id list message
+ * @rpt_auth_stream_rdy: Reads M` message
+ * @ake_int: Writes Txcaps and RTx message
+ * @ake_nostored_km: Writes Ekubkm message
+ * @ake_stored_km: Writes Ekh_km message
+ * @lcinit: Writes Rn message
+ * @ske_send_eks: Writes Edkey(ks) and riv message
+ * @rpt_auth_send_ack: Writes acknowledgment to the rcv-id list message
+ * @rpt_auth_stream_mng: Writes content type value to the HDCP receiver
+ * @msg_id: Identification id for messages
+ */
+union hdcp2x_tx_msg_type {
+	u8 msg_id;
+	struct hdcp2x_tx_ake_sendcert		ake_send_cert;
+	struct hdcp2x_tx_ake_sendprime		ake_send_prime;
+	struct hdcp2x_tx_ake_send_pairing_info	ake_send_pairing_info;
+	struct hdcp2x_tx_lc_send_lc_prime	lcsend_lcprime;
+	struct hdcp2x_tx_rpt_auth_send_rcvid_list	rpt_auth_send_rcvid;
+	struct hdcp2x_tx_rpt_auth_stream_ready	rpt_auth_stream_rdy;
+	struct hdcp2x_tx_ake_init		ake_int;
+	struct hdcp2x_tx_ake_no_stored_km	ake_nostored_km;
+	struct hdcp2x_tx_ake_stored_km		ake_stored_km;
+	struct hdcp2x_tx_lc_init		lcinit;
+	struct hdcp2x_tx_ske_send_eks		ske_send_eks;
+	struct hdcp2x_tx_rpt_auth_send_ack	rpt_auth_send_ack;
+	struct hdcp2x_tx_rpt_auth_stream_manage	rpt_auth_stream_mng;
+};
+
+/*
+ * HDCP Transmitter State Diagram available in
+ * HDCP2.3 specification. Section 2.8
+ * https://www.digital-cp.com/sites/default/files/
+ * HDCP%20Interface%20Independent%20Adaptation%20Specification%20Rev2_3.pdf
+ */
+/* HDCP 2X authentication protocol states */
+enum hdcp2x_tx_state {
+	H0_HDCP2X_TX_NO_RX_ATTACHED	= 0x00,
+	H1_HDCP2X_TX_WAIT_FOR_TX_ENABLE	= 0x01,
+	A0_HDCP2X_TX_AKE_INIT		= 0x02,
+	A1_HDCP2X_TX_EXCHANGE_KM	= 0x03,
+	A1_HDCP2X_TX_WAIT_FOR_ACK	= 0x04,
+	A1_HDCP2X_TX_WAIT_FOR_HPRIME	= 0x05,
+	A1_HDCP2X_TX_WAIT_FOR_PAIRING	= 0x06,
+	A1_HDCP2X_TX_VERIFY_HPRIME	= 0x07,
+	A2_HDCP2X_TX_LC_CHECK		= 0x08,
+	A2_HDCP2X_TX_VERIFY_LPRIME	= 0x09,
+	A3_HDCP2X_TX_EXCHANGE_KS	= 0x0A,
+	A4_HDCP2X_TX_REPEATER_CHECK	= 0x0B,
+	A5_HDCP2X_TX_AUTHENTICATED	= 0x0C,
+	A6_HDCP2X_TX_WAIT_FOR_RCVID	= 0x0D,
+	A7_HDCP2X_TX_VERIFY_RCVID	= 0x0E,
+	A8_HDCP2X_TX_SEND_RCVID_ACK	= 0x0F,
+	A9_HDCP2X_TX_STREAM_MANAGE	= 0x10,
+	A9_HDCP2X_TX_VERIFY_MPRIME	= 0x11,
+	HDCP2X_TX_NUM_STATES		= 0x12
+};
+
+#endif
diff --git a/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp1x_keymngt.c b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp1x_keymngt.c
new file mode 100644
index 000000000..235f6b536
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp1x_keymngt.c
@@ -0,0 +1,337 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx Specific HDCP1x driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Katta Dhanunjanrao <katta.dhanunjanrao@amd.com>
+ *
+ */
+
+#include <linux/types.h>
+#include <linux/uaccess.h>
+
+#include "xlnx_hdcp_tx.h"
+#include "xhdcp1x_tx.h"
+#include "xlnx_hdcp1x_tx.h"
+#include "xlnx_hdcp2x_tx.h"
+
+/* DEBUG CONSTANTS */
+#define HDCP1X_KEYMGMT_REG_VERSION		0x0000
+#define HDCP1X_KEYMGMT_REG_TYPE			0x0004
+#define HDCP1X_KEYMGMT_REG_CTRL			0x000C
+#define HDCP1X_KEYMGMT_REG_TBL_CTRL		0x0020
+#define HDCP1X_KEYMGMT_REG_TBL_STATUS		0x0024
+#define HDCP1X_KEYMGMT_REG_TBL_ADDR		0x0028
+#define HDCP1X_KEYMGMT_REG_TBL_DAT_H		0x002C
+#define HDCP1X_KEYMGMT_REG_TBL_DAT_L		0x0030
+
+#define HDCP1X_KEYMGMT_REG_CTRL_RST_MASK	BIT(31)
+#define HDCP1X_KEYMGMT_REG_CTRL_DISABLE_MASK	GENMASK(31, 1)
+#define HDCP1X_KEYMGMT_REG_CTRL_ENABLE_MASK	BIT(0)
+#define HDCP1X_KEYMGMT_REG_TBL_STATUS_RETRY	0x400
+#define HDCP1X_KEYMGMT_TBLID_0			0
+#define HDCP1X_KEYMGMT_REG_TBL_CTRL_WR_MASK	BIT(0)
+#define HDCP1X_KEYMGMT_REG_TBL_CTRL_RD_MASK	BIT(1)
+#define HDCP1X_KEYMGMT_REG_TBL_CTRL_EN_MASK	BIT(31)
+#define HDCP1X_KEYMGMT_REG_TBL_STATUS_DONE_MASK	BIT(0)
+#define HDCP1X_KEYMGMT_MAX_TBLS			8
+#define HDCP1X_KEYS_SIZE			336
+#define HDCP1X_KEYMGMT_MAX_ROWS_PER_TBL		41
+
+union hdcp1x_key_table {
+	u8 data_u8[HDCP1X_KEYS_SIZE];
+	u64 data_u64[HDCP1X_KEYS_SIZE / (sizeof(u64))];
+};
+
+/* Register related operations */
+static inline void xdptx_hdcp1x_keymgmt_reset(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u32 data;
+
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_CTRL, &data))
+		return;
+	data |= HDCP1X_KEYMGMT_REG_CTRL_RST_MASK;
+	if (regmap_update_bits(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			       HDCP1X_KEYMGMT_REG_CTRL, HDCP1X_KEYMGMT_REG_CTRL_RST_MASK,
+			       data))
+		return;
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_CTRL, &data))
+		return;
+	data &= ~HDCP1X_KEYMGMT_REG_CTRL_RST_MASK;
+	regmap_update_bits(xhdcp1x_tx->hdcp1x_keymgmt_base, HDCP1X_KEYMGMT_REG_CTRL,
+			   HDCP1X_KEYMGMT_REG_CTRL_RST_MASK, data);
+}
+
+static inline void xdptx_hdcp1x_keymgmt_enable(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u32 data;
+
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_CTRL, &data))
+		return;
+	data |= HDCP1X_KEYMGMT_REG_CTRL_ENABLE_MASK;
+	if (regmap_update_bits(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			       HDCP1X_KEYMGMT_REG_CTRL, HDCP1X_KEYMGMT_REG_CTRL_ENABLE_MASK,
+			       data))
+		return;
+
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_TBL_CTRL, &data))
+		return;
+	data |= HDCP1X_KEYMGMT_REG_TBL_CTRL_EN_MASK;
+	regmap_update_bits(xhdcp1x_tx->hdcp1x_keymgmt_base, HDCP1X_KEYMGMT_REG_TBL_CTRL,
+			   HDCP1X_KEYMGMT_REG_TBL_CTRL_EN_MASK, data);
+}
+
+static inline void xdptx_hdcp1x_keymgmt_disable(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u32 data;
+
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_CTRL, &data))
+		return;
+	data &= HDCP1X_KEYMGMT_REG_CTRL_DISABLE_MASK;
+	regmap_update_bits(xhdcp1x_tx->hdcp1x_keymgmt_base, HDCP1X_KEYMGMT_REG_CTRL,
+			   HDCP1X_KEYMGMT_REG_CTRL_DISABLE_MASK, data);
+}
+
+static int xdptx_hdcp1x_keymgmt_is_table_config_done(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	int retry = HDCP1X_KEYMGMT_REG_TBL_STATUS_RETRY;
+	u32 data;
+
+	while (retry) {
+		if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+				HDCP1X_KEYMGMT_REG_TBL_STATUS, &data))
+			return 0;
+		if (!(data & HDCP1X_KEYMGMT_REG_TBL_STATUS_DONE_MASK))
+			break;
+		retry--;
+		usleep_range(50, 100);
+	}
+
+	return retry;
+}
+
+static int xdptx_hdcp1x_keymgmt_table_read(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+					   u8 table_id, u8 row_id, u64 *read_val)
+{
+	u64 temp;
+	u32 addr, data;
+
+	addr = table_id;
+	addr <<= BITS_PER_BYTE;
+	addr |= row_id;
+
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_TBL_CTRL, &data))
+		return -EIO;
+	data &= ~HDCP1X_KEYMGMT_REG_TBL_CTRL_WR_MASK;
+	data |= HDCP1X_KEYMGMT_REG_TBL_CTRL_RD_MASK;
+	if (regmap_write(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			 HDCP1X_KEYMGMT_REG_TBL_CTRL, data))
+		return -EIO;
+	if (regmap_write(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			 HDCP1X_KEYMGMT_REG_TBL_ADDR, addr))
+		return -EIO;
+	if (!xdptx_hdcp1x_keymgmt_is_table_config_done(xhdcp1x_tx))
+		return -EIO;
+
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_TBL_DAT_H, &data))
+		return -EIO;
+	temp = data;
+	temp <<= BITS_PER_BYTE * sizeof(u32);
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_TBL_DAT_L, &data))
+		return -EIO;
+	temp |= data;
+	*read_val = temp;
+
+	return 0;
+}
+
+static int xdptx_hdcp1x_keymgmt_table_write(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+					    u8 table_id, u8 row_id, u64 write_val)
+{
+	u32 addr, data;
+
+	if (regmap_write(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			 HDCP1X_KEYMGMT_REG_TBL_DAT_L,
+			 lower_32_bits(write_val)))
+		return -EIO;
+	if (regmap_write(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			 HDCP1X_KEYMGMT_REG_TBL_DAT_H,
+			 upper_32_bits(write_val)))
+		return -EIO;
+
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_TBL_CTRL, &data))
+		return -EIO;
+	data &= ~HDCP1X_KEYMGMT_REG_TBL_CTRL_RD_MASK;
+	data |= HDCP1X_KEYMGMT_REG_TBL_CTRL_WR_MASK;
+	if (regmap_write(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			 HDCP1X_KEYMGMT_REG_TBL_CTRL, data))
+		return -EIO;
+
+	addr = table_id;
+	addr <<= BITS_PER_BYTE;
+	addr |= row_id;
+	if (regmap_write(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			 HDCP1X_KEYMGMT_REG_TBL_ADDR, addr))
+		return -EIO;
+	if (!xdptx_hdcp1x_keymgmt_is_table_config_done(xhdcp1x_tx))
+		return -EIO;
+
+	return 0;
+}
+
+static void xdptx_hdcp1x_keymgmt_get_num_of_tables_rows(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+							u8 *num_tables, u8 *num_rows_per_table)
+{
+	u32 data;
+
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_TYPE, &data))
+		return;
+
+	if (data) {
+		*num_tables = (data >> 8) & 0xFF;
+		*num_rows_per_table = data & 0xFF;
+	} else {
+		*num_tables = HDCP1X_KEYMGMT_MAX_TBLS;
+		*num_rows_per_table = HDCP1X_KEYMGMT_MAX_ROWS_PER_TBL;
+	}
+}
+
+static int xdptx_hdcp1x_keymgmt_init_tables(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	int ret = 0;
+	u8 num_tables = 0, num_rows_per_table = 0, table_id, row_id;
+
+	xdptx_hdcp1x_keymgmt_get_num_of_tables_rows(xhdcp1x_tx, &num_tables,
+						    &num_rows_per_table);
+	for (table_id = 0; table_id < num_tables; table_id++)
+		for (row_id = 0; row_id < num_rows_per_table; row_id++)
+			if (xdptx_hdcp1x_keymgmt_table_write(xhdcp1x_tx, table_id,
+							     row_id, 0))
+				return -EIO;
+	return ret;
+}
+
+static int xdptx_hdcp1x_keymgmt_load_keys(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+					  union hdcp1x_key_table *key_table,
+					  u32 key_table_size)
+{
+	int ret = 0;
+	u8 row_id;
+
+	for (row_id = 0; row_id < (key_table_size / sizeof(u64)); row_id++)
+		if (xdptx_hdcp1x_keymgmt_table_write(xhdcp1x_tx, HDCP1X_KEYMGMT_TBLID_0,
+						     row_id, key_table->data_u64[row_id]))
+			ret = -EIO;
+
+	return ret;
+}
+
+static int xdptx_hdcp1x_keymgmt_verify_keys(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+					    union hdcp1x_key_table *key_table,
+					    u32 key_table_size)
+{
+	u64 data;
+	int ret = 0;
+	u8 row_id;
+
+	for (row_id = 0; row_id < (key_table_size / sizeof(u64)); row_id++) {
+		data = 0;
+		xdptx_hdcp1x_keymgmt_table_read(xhdcp1x_tx, HDCP1X_KEYMGMT_TBLID_0,
+						row_id, &data);
+		if (data != key_table->data_u64[row_id])
+			ret = -EIO;
+	}
+
+	return ret;
+}
+
+static int xdptx_hdcp1x_keymgmt_set_key(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	union hdcp1x_key_table key_table;
+	int ret = 0;
+	u32 version, type;
+	u8 index;
+
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_VERSION, &version))
+		return -EIO;
+	if (regmap_read(xhdcp1x_tx->hdcp1x_keymgmt_base,
+			HDCP1X_KEYMGMT_REG_TYPE, &type))
+		return -EIO;
+	if (!version && !type) {
+		dev_err(xhdcp1x_tx->dev, "hdcp1x keymgmt core is not present\n");
+		return -ENODEV;
+	}
+
+	xdptx_hdcp1x_keymgmt_reset(xhdcp1x_tx);
+	ret = xdptx_hdcp1x_keymgmt_init_tables(xhdcp1x_tx);
+	if (ret)
+		return ret;
+	xdptx_hdcp1x_keymgmt_disable(xhdcp1x_tx);
+	memcpy(key_table.data_u8, xhdcp1x_tx->hdcp1x_key, HDCP1X_KEYS_SIZE);
+	/* adjust the endian-ness to host order */
+	for (index = 0; index < HDCP1X_KEYS_SIZE / sizeof(u64); index++)
+		key_table.data_u64[index] =
+			be64_to_cpu(*((__be64 *)&key_table.data_u64[index]));
+
+	ret = xdptx_hdcp1x_keymgmt_load_keys(xhdcp1x_tx, &key_table,
+					     HDCP1X_KEYS_SIZE);
+	if (ret)
+		return ret;
+	ret = xdptx_hdcp1x_keymgmt_verify_keys(xhdcp1x_tx, &key_table,
+					       HDCP1X_KEYS_SIZE);
+	if (ret)
+		return ret;
+	xdptx_hdcp1x_keymgmt_enable(xhdcp1x_tx);
+
+	return ret;
+}
+
+static int xdptx_hdcp1x_key_write(struct xlnx_hdcp1x_config *xhdcp1x_tx, u8 *data)
+{
+	int ret = 0;
+
+	xhdcp1x_tx->hdcp1x_key = devm_kzalloc(xhdcp1x_tx->dev, HDCP1X_KEYS_SIZE,
+					      GFP_KERNEL);
+	if (!xhdcp1x_tx->hdcp1x_key)
+		return -ENOMEM;
+
+	memcpy(xhdcp1x_tx->hdcp1x_key, data, HDCP1X_KEYS_SIZE);
+	xhdcp1x_tx->hdcp1x_key_available = true;
+	ret = xdptx_hdcp1x_keymgmt_set_key(xhdcp1x_tx);
+
+	if (ret < 0)
+		return ret;
+
+	xhdcp1x_tx_set_keyselect(xhdcp1x_tx, 0);
+	xhdcp1x_tx_load_aksv(xhdcp1x_tx);
+	//msleep(5);
+
+	return ret;
+}
+
+int xlnx_hdcp1x_keymngt_init(struct xlnx_hdcp1x_config *xhdcp1x_tx, u8 *data)
+{
+	int ret = 0;
+
+	if (!(xhdcp1x_tx->keyinit)) {
+		/* Key Management Initialize */
+		ret = xdptx_hdcp1x_key_write(xhdcp1x_tx, data);
+		if (ret < 0)
+			return ret;
+		xhdcp1x_tx->keyinit = true;
+	}
+
+	return ret;
+}
diff --git a/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp1x_tx.c b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp1x_tx.c
new file mode 100644
index 000000000..582951f42
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp1x_tx.c
@@ -0,0 +1,1282 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx HDCP1X Protocol Driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Katta Dhanunjanrao <katta.dhanunjanrao@amd.com>
+ *
+ * This driver provides standard HDCP1X protocol specific functionalites.
+ * It consists of:
+ * - A state machine which handles the states as specified in the HDCP
+ *	specification.
+ * This driver still have Xilinx specific functionalities as it is not upstreamed now,
+ * it will be updated as more generic and standardized driver in the next upstream version.
+ *
+ * Reference :
+ * https://www.digital-cp.com/sites/default/files/specifications/HDCP%20on%20DisplayPort%20Specification%20Rev1_1.pdf
+ *
+ */
+
+#include <linux/xlnx/xilinx-hdcp1x-cipher.h>
+#include <linux/xlnx/xlnx_timer.h>
+#include <linux/xlnx/xlnx_hdcp_common.h>
+#include "xlnx_hdcp_tx.h"
+#include "xlnx_hdcp_sha1.h"
+#include "xlnx_hdcp1x_tx.h"
+#include "xhdcp1x_tx.h"
+
+#define XHDCP1X_WRITE_CHUNK_SZ	8
+#define XHDCP1X_WRITE_ADDRESS_OFFSET 0x100
+
+/**
+ * xlnx_hdcp1x_tx_enble: This function enables the cipher block for An,Aksv generation.
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ *
+ * @return: true means sucessfull set or othervalue
+ */
+static bool xlnx_hdcp1x_tx_enble(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	xhdcp1x_tx->is_enabled = XHDCP1X_ENABLE;
+	xhdcp1x_tx->is_cipher = xhdcp1x_cipher_enable(xhdcp1x_tx->cipher);
+
+	if (xhdcp1x_tx->is_cipher)
+		return -EINVAL;
+
+	xlnx_hdcp_tmrcntr_stop(&xhdcp1x_tx->xhdcp1x_internal_timer.tmr_ctr,
+			       XTC_TIMER_0);
+
+	return true;
+}
+
+/**
+ * xlnx_hdcp1x_tx_start_authenticate: This function sets the initial states for HDCP state machine
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ *
+ * @return: true means sucessfull set or othervalue
+ */
+static bool xlnx_hdcp1x_tx_start_authenticate(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	if (!(xhdcp1x_tx->is_enabled))
+		return -EINVAL;
+
+	xhdcp1x_tx->auth_status = XHDCP1X_TX_AUTHENTICATION_BUSY;
+	xhdcp1x_tx->curr_state = H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED;
+	xhdcp1x_tx->prev_state = H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED;
+	return true;
+}
+
+/**
+ * xlnx_hdcp1x_tx_process_ri_event: This function provides an indication
+ * whether RI updation is done in hardware or not
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ *
+ * @return: none
+ */
+void xlnx_hdcp1x_tx_process_ri_event(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	xhdcp1x_tx->is_riupdate = true;
+}
+
+/**
+ * xlnx_start_hdcp1x_engine: This function calls necessary functions for HDCP state machine.
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ *
+ * @return: nothing
+ */
+void xlnx_start_hdcp1x_engine(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	xlnx_hdcp1x_tx_enble(xhdcp1x_tx);
+	xlnx_hdcp1x_tx_start_authenticate(xhdcp1x_tx);
+}
+
+/**
+ * xlnx_hdcp1x_tx_init: This function initilizes cipher and set defaults.
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ * @is_repeater: the downstream is repeater or monitor.
+ *
+ * @return: true means init sucessfull or flase/other value
+ */
+bool xlnx_hdcp1x_tx_init(struct xlnx_hdcp1x_config *xhdcp1x_tx, bool is_repeater)
+{
+	/* Default Configuration */
+	xhdcp1x_tx->pending_events = XHDCP1X_DEFAULT_INIT;
+	xhdcp1x_tx->curr_state = XHDCP1X_DEFAULT_INIT;
+	xhdcp1x_tx->prev_state = XHDCP1X_DEFAULT_INIT;
+	xhdcp1x_tx->is_encryption_en = XHDCP1X_DEFAULT_INIT;
+	xhdcp1x_tx->encryption_map = XHDCP1X_DEFAULT_INIT;
+	xhdcp1x_tx->is_enabled = XHDCP1X_ENABLE;
+	if (is_repeater) {
+		dev_info(xhdcp1x_tx->dev, "Hdcp1x Repeater Functionality is not supported\n");
+		return false;
+	}
+	/* initialize the Cipher core */
+	xhdcp1x_tx->cipher = xhdcp1x_cipher_init(xhdcp1x_tx->dev,
+						 xhdcp1x_tx->interface_base);
+	if (IS_ERR(xhdcp1x_tx->cipher))
+		return -EINVAL;
+
+	return true;
+}
+
+/**
+ * xlnx_hdcp1x_task_monitor: This function monitors the HDCP states.
+ * @xhdcp1x_tx: reference to the HDCP config structure
+ *
+ * @return: it return the HDCP state
+ */
+int xlnx_hdcp1x_task_monitor(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	enum hdcp1x_tx_state new_state;
+
+	new_state = hdcp1x_tx_protocol_authenticate_sm(xhdcp1x_tx);
+	xhdcp1x_tx->prev_state = xhdcp1x_tx->curr_state;
+	xhdcp1x_tx->curr_state = new_state;
+
+	return xhdcp1x_tx->stats.auth_status;
+}
+
+static int xlnx_hdcp1x_tx_writedata(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+				    u8 offset,
+				    const void *buf, u32 buf_size)
+{
+	u8 slave = DRM_HDCP_DDC_ADDR;
+	u8 tx_buf[XHDCP1X_WRITE_CHUNK_SZ + 1];
+	int num_written = 0;
+	u32 this_time = 0;
+	const u8 *write_buf = buf;
+
+	if ((buf_size + offset) > XHDCP1X_WRITE_ADDRESS_OFFSET)
+		buf_size = (XHDCP1X_WRITE_ADDRESS_OFFSET - offset);
+	do {
+		this_time = XHDCP1X_WRITE_CHUNK_SZ;
+		if (this_time > buf_size)
+			this_time = buf_size;
+		tx_buf[0] = offset;
+		memcpy(&tx_buf[1], write_buf, this_time);
+		if (xhdcp1x_tx->handlers.wr_handler(xhdcp1x_tx->interface_ref,
+						    slave,
+						    tx_buf,
+						    (this_time + 1)) < 0) {
+			num_written = -1;
+			break;
+		}
+		num_written += this_time;
+		write_buf += this_time;
+		buf_size -= this_time;
+	} while ((buf_size != 0) && (num_written > 0));
+
+	return num_written;
+}
+
+/**
+ * xlnx_hdcp1x_downstream_capbility: This function queries the downstream device to check
+ * if the downstream device is HDCP capable.
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ *
+ * @return: true indicates HDCP capable or not (false)
+ */
+bool xlnx_hdcp1x_downstream_capbility(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u8 value[XHDMI_HDCP1X_PORT_SIZE_BSTATUS] = {0};
+	u8 rxcaps = 0;
+
+	if (xhdcp1x_tx->protocol == XHDCP1X_TX_HDMI) {
+		xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						XHDMI_HDCP1X_PORT_OFFSET_BCAPS,
+						value, 2);
+		if (value[0] & 0x80) {
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDMI_HDCP1X_PORT_OFFSET_BSTATUS,
+							value, XHDMI_HDCP1X_PORT_SIZE_BSTATUS);
+			return 1;
+		}
+
+		return 0;
+	}
+	xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+					XHDCP1X_PORT_OFFSET_BCAPS,
+					(void *)&rxcaps,
+					XHDCP1X_REMOTE_INFO_BCAPS_VAL);
+
+	return (rxcaps & XHDCP1X_PORT_BIT_BCAPS_HDCP_CAPABLE);
+}
+
+/**
+ * xlnx_hdcp1x_tx_check_rxcapable: This function ensure that remote end is HDCP capable.
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ *
+ * @return: true indicates HDCP capable remote end or not (false)
+ */
+bool xlnx_hdcp1x_tx_check_rxcapable(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u8 value = 0;
+
+	xlnx_hdcp1x_tx_disable_encryption(xhdcp1x_tx, XHDCP1X_STREAM_MAP);
+	xhdcp1x_tx->is_encryption_en = XHDCP1X_DEFAULT_INIT;
+
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP) {
+		if ((xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						     XHDMI_HDCP1X_PORT_OFFSET_BCAPS,
+						     &value,
+						     XHDMI_HDCP1X_PORT_SIZE_BCAPS)) > 0) {
+			if ((value & 0x80)) {
+				xlnx_hdcp_tmrcntr_stop(&xhdcp1x_tx->xhdcp1x_internal_timer.tmr_ctr,
+						       XTC_TIMER_0);
+				return true;
+			}
+		}
+	}
+	/* Check the Rx HDCP Capable or Not */
+	if (xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+					    XHDCP1X_PORT_OFFSET_BCAPS,
+					    &value, XHDCP1X_REMOTE_INFO_BCAPS_VAL)) {
+		if (value & XHDCP1X_PORT_BIT_BCAPS_HDCP_CAPABLE)
+			return true;
+	}
+	dev_dbg(xhdcp1x_tx->dev, "HDCP1x RX Not Capable");
+
+	return false;
+}
+
+/**
+ * xlnx_hdcp1x_read_bksv_from_remote: This function reads the bksv from the remote.
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ * @offset: the remote HDCP bksv offset
+ * @buf: the remote bksv value stored in buffer
+ * @buf_size: the size of the bskv
+ *
+ * @return: true indicates read sucessfull or not (false)
+ */
+bool xlnx_hdcp1x_read_bksv_from_remote(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+				       u32 offset, void *buf, u32 buf_size)
+{
+	if ((buf_size + (offset - XDPTX_HDCP1X_DPCD_OFFSET)) > XHDCP1X_BUF_OFFSET_LEN)
+		buf_size = (XHDCP1X_BUF_OFFSET_LEN - offset);
+
+	xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+					offset,
+					buf, buf_size);
+
+	return true;
+}
+
+static void xlnx_hdcp1x_uint_to_buf(u8 *buf, u64 resval, u32 size)
+{
+	int byte;
+
+	if ((size) > 0) {
+		for (byte = 0; byte <= (int)(((size) - 1) >> 3); byte++) {
+			buf[byte] = (uint8_t)(resval & 0xFFu);
+			resval >>= XHDCP1X_BYTE_IN_BITS;
+		}
+	}
+}
+
+static u64 xlnx_hdcp1x_buf_to_unit(u8 *buf, u32 size)
+{
+	u64 remoteksv = 0;
+	int byte;
+
+	if ((size) > 0) {
+		for (byte = (((size) - 1) >> 3); byte >= 0; byte--) {
+			remoteksv <<= XHDCP1X_BYTE_IN_BITS;
+			remoteksv  |= buf[byte];
+		}
+	}
+	return remoteksv;
+}
+
+/**
+ * xlnx_hdcp1x_tx_test_for_repeater: This function checks the remote end to see if its a repeater.
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ *
+ * @return: true indicates sucessfull or not (false)
+ */
+int xlnx_hdcp1x_tx_test_for_repeater(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u8 value = 0, ret = 0;
+
+	/* Check For Repeater */
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP) {
+		ret = xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						      XHDMI_HDCP1X_PORT_OFFSET_BCAPS,
+						      &value,
+						      XHDMI_HDCP1X_PORT_SIZE_BCAPS);
+		if (ret != XHDMI_HDCP1X_PORT_SIZE_BCAPS)
+			return false;
+		if (value & XHDMI_HDCP1X_PORT_BIT_BCAPS_REPEATER) {
+			xhdcp1x_tx->is_repeater = 1;
+			return true;
+		}
+
+	} else {
+		ret = xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						      XHDCP1X_PORT_OFFSET_BCAPS,
+						      &value,
+						      XHDMI_HDCP1X_PORT_SIZE_BCAPS);
+		if (ret != XHDCP1X_PORT_SIZE_BCAPS)
+			return false;
+		if (value & XHDCP1X_PORT_BIT_BCAPS_REPEATER) {
+			xhdcp1x_tx->is_repeater = 1;
+			return true;
+		}
+	}
+
+	return false;
+}
+
+/**
+ * xlnx_hdcp1x_set_keys: This function loads the key to key management block
+ * @xhdcp1x_tx: It points to the HDCP1x config structre
+ * @data: Key information received from sysfs
+ *
+ * @return: return 1 indicates success or 0 for failure
+ */
+
+int xlnx_hdcp1x_set_keys(struct xlnx_hdcp1x_config *xhdcp1x_tx, u8 *data)
+{
+	int ret = 0;
+
+	ret = xlnx_hdcp1x_keymngt_init(xhdcp1x_tx, data);
+	return ret;
+}
+
+/**
+ * xlnx_hdcp1x_exchangeksvs: This function exchanges the ksvs between the two ends of the link.
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ *
+ * @return: true indicates keys exchange sucessfull or not (false)
+ */
+bool xlnx_hdcp1x_exchangeksvs(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	/* Reading the Downstream Capabilities */
+	u8 buf[XHDCP1X_BYTE_IN_BITS] = {XHDCP1X_DEFAULT_INIT};
+	u64 remoteksv = XHDCP1X_DEFAULT_INIT;
+	u64 localksv = XHDCP1X_DEFAULT_INIT, an = XHDCP1X_DEFAULT_INIT;
+	u8 buf_ainfo[XHDCP1X_PORT_SIZE_AINFO];
+
+	xlnx_hdcp1x_read_bksv_from_remote(xhdcp1x_tx, XHDCP1X_PORT_OFFSET_BKSV,
+					  buf, XHDCP1X_REMOTE_BKSV_SIZE);
+	remoteksv = xlnx_hdcp1x_buf_to_unit(buf,
+					    XHDCP1X_PORT_SIZE_BKSV * XHDCP1X_BYTE_IN_BITS);
+
+	/* Check the is KSV valid & revocation list from application data*/
+	if (!(xlnx_hdcp1x_is_ksvvalid(remoteksv))) {
+		dev_dbg(xhdcp1x_tx->dev, "Invalid bksv");
+		return false;
+	}
+	xhdcp1x_tx->tmr_cnt = 0;
+	/* Check for repeater */
+	if (xlnx_hdcp1x_tx_test_for_repeater(xhdcp1x_tx))
+		xhdcp1x_tx->is_repeater = 1;
+	else
+		xhdcp1x_tx->is_repeater = 0;
+
+	/* Generate the an */
+	an = xlnx_hdcp1x_tx_generate_an(xhdcp1x_tx);
+
+	/* Save the an in statehelp for later use */
+	xhdcp1x_tx->state_helper = an;
+	/* Determine the Local KSV */
+	localksv = xhdcp1x_cipher_get_localksv(xhdcp1x_tx->cipher);
+	/* Load the cipher with the remote ksv */
+	xhdcp1x_cipher_set_remoteksv(xhdcp1x_tx->cipher,
+				     remoteksv);
+	/* Clear AINFO */
+	memset(buf_ainfo, XHDCP1X_DEFAULT_INIT, XHDCP1X_PORT_SIZE_AINFO);
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP)
+		xlnx_hdcp1x_tx_writedata(xhdcp1x_tx,
+					 XHDMI_HDCP1X_PORT_OFFSET_AINFO,
+					 buf_ainfo, XHDCP1X_PORT_SIZE_AINFO);
+	else
+		xhdcp1x_tx->handlers.wr_handler(xhdcp1x_tx->interface_ref,
+						XHDCP1X_PORT_OFFSET_AINFO,
+						buf_ainfo, XHDCP1X_PORT_SIZE_AINFO);
+
+	xlnx_hdcp1x_uint_to_buf(buf, an, XHDCP1X_PORT_SIZE_AN * XHDCP1X_BYTE_IN_BITS);
+	/* Send an to Remote */
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP)
+		xlnx_hdcp1x_tx_writedata(xhdcp1x_tx,
+					 XHDMI_HDCP1X_PORT_OFFSET_AN,
+					 buf, XHDCP1X_PORT_SIZE_AN);
+	else
+		xhdcp1x_tx->handlers.wr_handler(xhdcp1x_tx->interface_ref,
+						XHDCP1X_PORT_OFFSET_AN,
+						buf, XHDCP1X_PORT_SIZE_AN);
+	/* Send Aksv to remote */
+	xlnx_hdcp1x_uint_to_buf(buf, localksv,
+				XHDCP1X_PORT_SIZE_AKSV * XHDCP1X_BYTE_IN_BITS);
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP)
+		xlnx_hdcp1x_tx_writedata(xhdcp1x_tx,
+					 XHDMI_HDCP1X_PORT_OFFSET_AKSV,
+					 buf, XHDCP1X_PORT_SIZE_AKSV);
+	else
+		xhdcp1x_tx->handlers.wr_handler(xhdcp1x_tx->interface_ref,
+						XHDCP1X_PORT_OFFSET_AKSV,
+						buf, XHDCP1X_PORT_SIZE_AKSV);
+	return true;
+}
+
+/**
+ * xlnx_hdcp1x_computationsstate: This function initiates the computations for a state machine
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ *
+ * @return: true indicates comutations done (true) or not (false)
+ */
+bool xlnx_hdcp1x_computationsstate(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u32 X = 0, Y = 0, Z = 0, cipher_req = XHDCP1X_DEFAULT_INIT;
+	u64 value = XHDCP1X_DEFAULT_INIT;
+
+	/* Update value with an */
+	value = xhdcp1x_tx->state_helper;
+	/* Load the cipher B registers with an */
+	X = (u32)(value & 0x0FFFFFFFul);
+	value >>= 28;
+	Y = (u32)(value & 0x0FFFFFFFul);
+	value >>= 28;
+	Z = (u32)(value & 0x000000FFul);
+	if (xhdcp1x_tx->is_repeater)
+		Z |= (1ul << XHDCP1X_BYTE_IN_BITS);
+
+	xhdcp1x_cipher_setb(xhdcp1x_tx->cipher, X, Y, Z);
+	/* Initiate the block cipher */
+	xhdcp1x_cipher_do_request(xhdcp1x_tx->cipher,
+				  XHDCP1X_CIPHER_REQUEST_BLOCK);
+	cipher_req = xhdcp1x_cipher_is_request_complete(xhdcp1x_tx->cipher);
+
+	if (cipher_req != 1) {
+		dev_dbg(xhdcp1x_tx->dev, "CipherDoRequest Computations not done");
+		return false;
+	}
+
+	return true;
+}
+
+static u16 xlnx_hdcp1x_buf_to_uint16(u8 *buf, u32 size)
+{
+	int byte = 0;
+	u16 buff_to_uint = XHDCP1X_DEFAULT_INIT;
+
+	if ((size) > 0) {
+		for (byte = (((size) - 1) >> 3); byte >= 0; byte--) {
+			buff_to_uint <<= XHDCP1X_BYTE_IN_BITS;
+			buff_to_uint  |= buf[byte];
+		}
+	}
+	return buff_to_uint;
+}
+
+/**
+ * xlnx_hdcp1x_tx_validaterxstate: This function validates the attached receiver
+ * @xhdcp1x_tx: It points to the HDCP1x config structure
+ *
+ * @return: true indicates key matched (true) or not (false)
+ */
+bool xlnx_hdcp1x_tx_validaterxstate(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u8 buf[XHDCP1X_REMOTE_RO_SIZE];
+	int ret = 0;
+	u32 num_tries = XHDCP1X_MAX_RETRIES;
+	/* 100ms delay: The HDCP transmitter must allow the HDCP receiver at least
+	 * 100ms to make ro' available from the time Aksv is written. added based on
+	 * DP HDCP sepecification: HDCP%20on%20DisplayPort%20Specification%20Rev1_1.pdf
+	 */
+	msleep(XHDCP1X_RO_AVILABLE_DELAY);
+	do {
+		if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP) {
+			ret = xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							      XHDMI_HDCP1X_PORT_OFFSET_RO,
+							      buf,
+							      XHDMI_HDCP1X_PORT_SIZE_RO);
+		} else {
+			ret = xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						    XHDCP1X_PORT_OFFSET_RO,
+						    buf, 2);
+		}
+		if (ret > 0) {
+			u16 remotero = 0;
+			u16 localro = 0;
+
+			/* Determine Remote Ro */
+			remotero = xlnx_hdcp1x_buf_to_uint16(buf,
+							     (XHDCP1X_REMOTE_RO_SIZE *
+							     XHDCP1X_BYTE_IN_BITS));
+			/* Determine the Local Ro */
+			xhdcp1x_cipher_get_ro(xhdcp1x_tx->cipher, &localro);
+			/* Compare the Ro == Ro' */
+			if (localro == remotero)
+				return true;
+		}
+		num_tries--;
+	} while (num_tries > 0);
+
+	return false;
+}
+
+/**
+ * xlnx_hdcp1x_is_ksvvalid: This function validates a KSV value as
+ * having 20 1's and 20 0's
+ * @ksv: ksv is the value to validate
+ *
+ * @return: true value indicates valid (true) or not (false)
+ */
+int xlnx_hdcp1x_is_ksvvalid(u64 ksv)
+{
+	u32 is_valid = false, num_ones = 0;
+
+	/* Determine num_ones */
+	while (ksv) {
+		if ((ksv & 1) != 0)
+			num_ones++;
+
+		ksv >>= 1;
+	}
+
+	/* Check for 20 1's */
+	if (num_ones == XHDCP1X_KSV_NUM_OF_1S)
+		is_valid = true;
+
+	return is_valid;
+}
+
+/**
+ * xlnx_hdcp1x_tx_generate_an: This function generates the an from a random number generator
+ * @xhdcp1x_tx:	Instanceptr is the HDCP1x config structure
+ *
+ * @return: A 64-bit pseudo random number (an).
+ */
+u64 xlnx_hdcp1x_tx_generate_an(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u64 an = 0;
+	/* Attempt to generate an */
+
+	if (xhdcp1x_cipher_do_request(xhdcp1x_tx->cipher, 2) == 0) {
+		/* Wait until done */
+		while (!xhdcp1x_cipher_is_request_complete(xhdcp1x_tx->cipher)) {
+			/* Waiting for cipher request completion
+			 * before generating the An,
+			 */
+		}
+		an = xhdcp1x_cipher_get_mi(xhdcp1x_tx->cipher);
+	}
+
+	/* Check if zero */
+	if (!an)
+		an = 0x351F7175406A74Dull;
+
+	return an;
+}
+
+/**
+ * xhdcp1x_tx_set_keyselect: Select the aksv key
+ * @xhdcp1x_tx: reference to HDCP1x config structure
+ * @keyselect: ket selection from a group of input keys
+ *
+ * @return: 0 on success, error otherwise
+ */
+int xhdcp1x_tx_set_keyselect(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+			     u8 keyselect)
+{
+	if (!xhdcp1x_tx)
+		return -EINVAL;
+
+	return xhdcp1x_cipher_set_keyselect(xhdcp1x_tx->cipher, keyselect);
+}
+
+/**
+ * xhdcp1x_tx_load_aksv: loads the local ksv to hdcp port
+ * @xhdcp1x_tx: reference to HDCP1X instance
+ *
+ * @return: 0 on success, error otherwise
+ */
+int xhdcp1x_tx_load_aksv(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u8 buf[XHDCP1X_PORT_SIZE_AKSV] = {0};
+
+	if (!xhdcp1x_tx)
+		return -EINVAL;
+
+	if (xhdcp1x_cipher_load_aksv(xhdcp1x_tx->cipher, buf))
+		return -EAGAIN;
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP)
+		xlnx_hdcp1x_tx_writedata(xhdcp1x_tx,
+					 XHDMI_HDCP1X_PORT_OFFSET_AKSV,
+					 buf, XHDCP1X_PORT_SIZE_AKSV);
+	else
+		xhdcp1x_tx->handlers.wr_handler(xhdcp1x_tx->interface_ref,
+					XHDCP1X_PORT_OFFSET_AKSV,
+					buf, XHDCP1X_PORT_SIZE_AKSV);
+	return 0;
+}
+
+/**
+ * xlnx_hdcp1x_tx_disable: This function disables the HDCP functionality
+ * @xhdcp1x_tx:	Instanceptr is the HDCP config structure
+ *
+ * @return:	no return vale
+ */
+void xlnx_hdcp1x_tx_disable(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	xhdcp1x_tx->is_enabled = XHDCP1X_DISABLE;
+	xhdcp1x_cipher_disable(xhdcp1x_tx->cipher);
+}
+
+/**
+ * xlnx_hdcp1x_tx_reset: This function resets the HDCP functionality
+ * @xhdcp1x_tx:	Instanceptr is the HDCP config structure
+ *
+ * @return:	flase/other values
+ */
+int xlnx_hdcp1x_tx_reset(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	if (!(xhdcp1x_tx->is_enabled)) {
+		dev_dbg(xhdcp1x_tx->dev, "Hdcp is not started");
+		return -EINVAL;
+	}
+
+	xhdcp1x_tx->auth_status = XHDCP1X_TX_UNAUTHENTICATED;
+
+	xhdcp1x_tx->curr_state = A0_HDCP1X_TX_STATE_DETERMINE_RX_CAPABLE;
+	xhdcp1x_tx->prev_state = A0_HDCP1X_TX_STATE_DETERMINE_RX_CAPABLE;
+	xhdcp1x_tx->state_helper = XHDCP1X_DEFAULT_INIT;
+	xhdcp1x_tx->tmr_cnt = 0;
+	xhdcp1x_tx->is_riupdate = 0;
+	xhdcp1x_tx->is_encryption_en = XHDCP1X_DEFAULT_INIT;
+
+	xlnx_hdcp1x_tx_disable_encryption(xhdcp1x_tx, xhdcp1x_tx->encryption_map);
+	xhdcp1x_tx->encryption_map = XHDCP1X_DEFAULT_INIT;
+	xlnx_hdcp1x_tx_disable(xhdcp1x_tx);
+
+	return 0;
+}
+
+/**
+ * xlnx_hdcp1x_tx_enable_encryption: This function enables the encryption
+ * for a HDCP state machine.
+ * @xhdcp1x_tx: points to the HDCP config structure
+ *
+ * @return: no return value
+ */
+void xlnx_hdcp1x_tx_enable_encryption(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u64 stream_map = XHDCP1X_STREAM_MAP;
+
+	if (!(xhdcp1x_tx->is_encryption_en)) {
+		xhdcp1x_tx->encryption_map |= stream_map;
+		/* Check for encryption enabled */
+		if (xhdcp1x_tx->encryption_map) {
+			stream_map = XHDCP1X_DEFAULT_INIT;
+			/* Determine stream_map */
+			stream_map = xhdcp1x_cipher_getencryption(xhdcp1x_tx->cipher);
+
+			/* Check if there is something to do */
+			if (stream_map != xhdcp1x_tx->encryption_map) {
+				/* Enable it */
+				xhdcp1x_cipher_enable_encryption(xhdcp1x_tx->cipher,
+								 xhdcp1x_tx->encryption_map);
+			}
+		}
+		xhdcp1x_tx->is_encryption_en = XHDCP1X_ENCRYPTION_EN;
+	}
+}
+
+/**
+ * xlnx_hdcp1x_tx_disable_encryption: This function resets the HDCP functionality
+ * @xhdcp1x_tx:	Instanceptr is the HDCP config structure
+ * @stream_map: Bit map of the streams to disable encryption.
+ *
+ * @return: flase/other values
+ */
+void xlnx_hdcp1x_tx_disable_encryption(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+				       u64 stream_map)
+{
+	u32 status = 0;
+
+	status = xhdcp1x_cipher_disableencryption(xhdcp1x_tx->cipher, stream_map);
+	if (!status)
+		xhdcp1x_tx->encryption_map &= ~stream_map;
+}
+
+/**
+ * xlnx_hdcp1x_check_link_integrity: This function checks the link
+ * integrity of HDCP link.
+ * @xhdcp1x_tx:	Instanceptr is the HDCP config structure
+ *
+ * @return: 1 if link integrity is passed, error otherwise
+ */
+
+int xlnx_hdcp1x_check_link_integrity(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u8 buf[2];
+	int num_tries = XHDCP1X_MAX_RETRIES, ri_check_status = 0;
+
+	xhdcp1x_tx->is_riupdate = 0;
+	do {
+		if (xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						    XHDMI_HDCP1X_PORT_OFFSET_RO,
+						    buf,
+						    XHDMI_HDCP1X_PORT_SIZE_RO)) {
+			u16 remote_ri = 0, local_ri = 0;
+
+			remote_ri =
+				xlnx_hdcp1x_buf_to_uint16(buf,
+							  XHDMI_HDCP1X_PORT_SIZE_RO
+							  * XHDCP1X_BYTE_IN_BITS);
+
+			xhdcp1x_cipher_get_ri(xhdcp1x_tx->cipher, &local_ri);
+			if (local_ri != remote_ri) {
+				dev_dbg(xhdcp1x_tx->dev, "Ri checking failed\n");
+				ri_check_status = 0;
+			} else {
+				ri_check_status = 1;
+				dev_dbg(xhdcp1x_tx->dev, "Ri checking passed\n");
+			}
+		} else {
+			dev_err(xhdcp1x_tx->dev, "Ri reading failed\n");
+		}
+		num_tries--;
+	} while ((ri_check_status == 0) && (num_tries > 0));
+	return ri_check_status;
+}
+
+/**
+ * xhdcp1x_tx_set_check_linkstate: This function enables/disables the link
+ * integrity, RI checking of HDCP link.
+ * @xhdcp1x_tx: Instanceptr is the HDCP config structure
+ * @is_enabled: Flag to enable/disable RI calculation
+ */
+
+void xhdcp1x_tx_set_check_linkstate(struct xlnx_hdcp1x_config *xhdcp1x_tx, int is_enabled)
+{
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP) {
+		if (is_enabled)
+			xhdcp1x_cipher_set_ri_update(xhdcp1x_tx->cipher, true);
+		else
+			xhdcp1x_cipher_set_ri_update(xhdcp1x_tx->cipher, false);
+	}
+}
+
+int xlnx_hdcp1x_get_repeater_info(struct xlnx_hdcp1x_config *xhdcp1x_tx, u16 *info)
+{
+	u8 value = 0;
+
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP) {
+		if (xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						    XHDMI_HDCP1X_PORT_OFFSET_BCAPS,
+						    (void *)&value,
+						    XHDMI_HDCP1X_PORT_SIZE_BCAPS) > 0) {
+			u8 ready_mask = 0;
+
+			ready_mask  = XHDMI_HDCP1X_PORT_BIT_BCAPS_REPEATER;
+			ready_mask |= XHDMI_HDCP1X_PORT_BIT_BCAPS_READY;
+			if ((value & ready_mask) == ready_mask) {
+				u8 buf[XHDMI_HDCP1X_PORT_SIZE_BSTATUS];
+				u64 converted_value;
+
+				xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+								XHDMI_HDCP1X_PORT_OFFSET_BSTATUS,
+								buf,
+								XHDMI_HDCP1X_PORT_SIZE_BSTATUS);
+				converted_value =
+					xlnx_hdcp1x_buf_to_unit(buf,
+								BITS_PER_BYTE * sizeof(u16));
+				*info = (converted_value & XHDMI_HDCP1X_PORT_BINFO_VALUE);
+				return 1;
+			}
+		}
+	} else {
+		if (xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						    XHDCP1X_PORT_OFFSET_BCAPS,
+						    (void *)&value, 1) > 0) {
+			if ((value & XHDCP1X_PORT_BIT_BCAPS_REPEATER) != 0) {
+				xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+								XHDCP1X_PORT_OFFSET_BSTATUS,
+								&value, 1);
+				if ((value & XHDCP1X_PORT_BIT_BSTATUS_READY) != 0) {
+					u8 buf[XHDMI_HDCP1X_PORT_SIZE_BSTATUS];
+					u16 binfo = 0;
+
+					xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+									XHDCP1X_PORT_OFFSET_BINFO,
+									buf,
+									XHDCP1X_PORT_SIZE_BINFO);
+					binfo = xlnx_hdcp1x_buf_to_unit(buf,
+									BITS_PER_BYTE *
+									sizeof(u16));
+					*info = (binfo & XHDCP1X_PORT_BINFO_VALUE);
+
+					return 1;
+				}
+			}
+		}
+	}
+
+	return 0;
+}
+
+int xlnx_hdcp1x_gettopology_maxcascadeexceeded(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u32 value = 0;
+
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP) {
+		xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						XHDMI_HDCP1X_PORT_OFFSET_BSTATUS,
+						(void *)&value,
+						XHDMI_HDCP1X_PORT_SIZE_BSTATUS);
+		return ((value & XHDMI_HDCP1X_PORT_BSTATUS_BIT_DEPTH_ERR) ? 1 : 0);
+	}
+
+	return ((value & XHDCP1X_PORT_BINFO_BIT_DEPTH_ERR) ? 1 : 0);
+}
+
+int xlnx_hdcp1x_gettopology_maxdevsexceeded(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u32 value = 0;
+
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP) {
+		xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						XHDMI_HDCP1X_PORT_OFFSET_BSTATUS,
+						(void *)&value,
+						XHDMI_HDCP1X_PORT_SIZE_BSTATUS);
+		return ((value & XHDMI_HDCP1X_PORT_BSTATUS_BIT_DEV_CNT_ERR) ? 1 : 0);
+	}
+
+	return ((value & XHDCP1X_PORT_BINFO_BIT_DEV_CNT_ERR) ? 1 : 0);
+}
+
+enum hdcp1x_tx_state xlnx_hdcp1x_tx_wait_for_ready(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u16 repeater_info = 0;
+
+	if (!xhdcp1x_tx->xhdcp1x_internal_timer.timer_expired)
+		return A6_HDCP1X_TX_STATE_WAIT_FOR_READY;
+
+	xhdcp1x_tx->tmr_cnt++;
+	if (xhdcp1x_tx->tmr_cnt > XHDMI_HDCP1X_READY_TIMEOUT)
+		return  H0_HDCP1X_TX_STATE_DISABLED_NO_RX_ATTACHED;
+
+	if (!xlnx_hdcp1x_get_repeater_info(xhdcp1x_tx, &repeater_info)) {
+		xlnx_hdcp1x_tx_start_timer(xhdcp1x_tx, XHDMI_HDCP1X_WAIT_FOR_READY_TIMEOUT, 0);
+
+		return A6_HDCP1X_TX_STATE_WAIT_FOR_READY;
+	}
+	xhdcp1x_tx->state_helper = repeater_info;
+	xhdcp1x_tx->tmr_cnt = 0;
+
+	return A7_HDCP1X_TX_STATE_READ_KSV_LIST;
+}
+
+static u64 xlnx_hdcp1x_buf_to_u64(u8 *buf, u64 size)
+{
+	u64 buff_to_int = 0;
+
+	if ((size) > 0) {
+		int byte;
+
+		for (byte = (((size) - 1) >> 3); byte >= 0; byte--) {
+			buff_to_int <<= XHDCP1X_BYTE_IN_BITS;
+			buff_to_int  |= buf[byte];
+		}
+	}
+
+	return buff_to_int;
+}
+
+int xlnx_hdcp1x_tx_validate_ksv_list(struct xlnx_hdcp1x_config *xhdcp1x_tx, u16 repeater_info)
+{
+	struct xlnx_sha1_context sha1_context;
+	u8 buf[DRM_HDCP_KSV_LEN * XHDCP1X_PORT_SIZE_BKSV];
+	u8 ksv_list_holder[XHDMI_HDCP1X_PORT_MAX_DEV_CNT * XHDCP1X_PORT_SIZE_BKSV];
+	int num_to_read = 0;
+	int ksv_count = 0, byte_count = 0;
+	int ret = 0;
+	unsigned int ksv_list_size = 0;
+	u64 value = 0, buf_read_ksv_count = 0, mo = 0, remote_ksv;
+	u8 sha_result[SHA1_HASH_SIZE];
+	u8 bksv[XHDCP1X_PORT_SIZE_BKSV];
+
+	memset(ksv_list_holder, 0, (XHDMI_HDCP1X_PORT_MAX_DEV_CNT * XHDCP1X_PORT_SIZE_BKSV));
+
+	memset(buf, 0, DRM_HDCP_KSV_LEN * XHDCP1X_PORT_SIZE_BKSV);
+
+	xlnx_sha1_reset(&sha1_context);
+
+	repeater_info = xhdcp1x_tx->state_helper;
+	num_to_read = ((repeater_info & XHDMI_HDCP1X_PORT_MAX_DEV_CNT) * DRM_HDCP_KSV_LEN);
+
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP) {
+		if (xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						    XHDMI_HDCP1X_OFFSET_KSVFIFO,
+						    ksv_list_holder, num_to_read)) {
+			xlnx_sha1_input(&sha1_context, ksv_list_holder, num_to_read);
+
+			while (byte_count < num_to_read) {
+				if ((byte_count + 1) % DRM_HDCP_KSV_LEN == 0) {
+					value = xlnx_hdcp1x_buf_to_unit((ksv_list_holder
+									+ ((((byte_count + 1)
+									/ XHDCP1X_PORT_SIZE_BKSV)
+									- 1)
+									* XHDCP1X_PORT_SIZE_BKSV)),
+									XHDCP1X_PORT_SIZE_BKSV *
+									BITS_PER_BYTE);
+
+					if (!xlnx_hdcp1x_is_ksvvalid(value))
+						return false;
+
+					xhdcp1x_tx->repeatervalues.ksvlist[ksv_count++] = value;
+					value = 0;
+				}
+				byte_count++;
+			}
+		}
+	} else {
+		unsigned int ksv_list_byte_count = 0;
+
+		byte_count = (num_to_read / DRM_HDCP_KSV_LEN);
+		ksv_list_size = byte_count;
+		do {
+			int total_bytes = XHDCP1X_PORT_SIZE_KSVFIFO;
+			int min_bytes_to_read = XHDCP1X_PORT_MIN_BYTES;
+
+			if (total_bytes > num_to_read)
+				total_bytes = num_to_read;
+
+			if (min_bytes_to_read > byte_count)
+				min_bytes_to_read = byte_count;
+
+			ret = xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							      XHDCP1X_PORT_OFFSET_KSVFIFO,
+							      buf, total_bytes);
+			if (!ret)
+				return false;
+
+			xlnx_sha1_input(&sha1_context, buf, total_bytes);
+			while (buf_read_ksv_count < total_bytes) {
+				ksv_list_holder[ksv_list_byte_count++] =
+				buf[buf_read_ksv_count];
+				buf_read_ksv_count++;
+			}
+			num_to_read -= total_bytes;
+			byte_count -= min_bytes_to_read;
+
+		} while (num_to_read > 0);
+	}
+
+	/* Insert repeater_info into the SHA-1 transform */
+	buf[0] = (u8)repeater_info;
+
+	if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP)
+		buf[1] = (u8)(repeater_info
+		>> XHDMI_HDCP1X_PORT_BSTATUS_DEPTH_SHIFT);
+	else
+		buf[1] = (u8)(repeater_info >> XHDCP1X_PORT_BINFO_DEPTH_SHIFT);
+
+	xlnx_sha1_input(&sha1_context, buf, 2);
+
+	/* Insert the mo into the SHA-1 transform */
+	mo = xhdcp1x_cipher_get_mo(xhdcp1x_tx->cipher);
+	xlnx_hdcp1x_uint_to_buf(buf, mo, XHDCP1X_BYTE_IN_BITS * BITS_PER_BYTE);
+
+	xlnx_sha1_input(&sha1_context, buf, BITS_PER_BYTE);
+
+	/* Finalize the SHA-1 result and confirm success */
+	if (xlnx_sha1_result(&sha1_context, sha_result) == XLNX_SHA_SUCCESS) {
+		u64 offset = 0;
+		const u8 *sha1_buf = sha_result;
+		int num_iterations = (SHA1_HASH_SIZE >> 2);
+
+		if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP)
+			offset = XHDMI_HDCP1X_PORT_OFFSET_VH0;
+		else
+			offset = XHDCP1X_PORT_OFFSET_VH0;
+
+		do {
+			u32 calc_calue = 0;
+			u32 read_value = 0;
+
+			/* Determine calc_calue */
+			calc_calue = *sha1_buf++;
+			calc_calue <<= BITS_PER_BYTE;
+			calc_calue |= *sha1_buf++;
+			calc_calue <<= BITS_PER_BYTE;
+			calc_calue |= *sha1_buf++;
+			calc_calue <<= BITS_PER_BYTE;
+			calc_calue |= *sha1_buf++;
+
+			if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP)
+				offset = XHDMI_HDCP1X_PORT_OFFSET_VH0;
+
+			else
+				offset = XHDCP1X_PORT_OFFSET_VH0;
+
+			ret =
+				xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+								offset, buf,
+								XHDCP1X_PORT_SIZE_VH0);
+
+			if (!ret) {
+				dev_err(xhdcp1x_tx->dev, "Unable to read V");
+				return false;
+			}
+			memcpy(&xhdcp1x_tx->repeatervalues.v[offset - XHDMI_HDCP1X_PORT_OFFSET_VH0],
+			       buf, XHDCP1X_PORT_SIZE_VH0);
+			read_value = xlnx_hdcp1x_buf_to_unit(buf,
+							     BITS_PER_BYTE * XHDCP1X_PORT_SIZE_VH0);
+			if (calc_calue != read_value) {
+				dev_err(xhdcp1x_tx->dev, "V` Ksv's miss match");
+				return false;
+			}
+			offset += XHDCP1X_PORT_SIZE_VH0;
+			num_iterations--;
+		} while (num_iterations > 0);
+	} else {
+		dev_err(xhdcp1x_tx->dev, "SHA mismatch Occurred");
+		return false;
+	}
+	if (xhdcp1x_tx->is_repeater) {
+		if (xhdcp1x_tx->protocol == XHDCP1X_TX_DP) {
+			u64 val = 0;
+			u32 this_ksv = 0;
+
+			while (this_ksv < ksv_list_size) {
+				val = xlnx_hdcp1x_buf_to_u64((ksv_list_holder +
+							       (this_ksv *
+							       XHDCP1X_PORT_SIZE_BKSV)),
+							       XHDCP1X_PORT_SIZE_BKSV *
+							       BITS_PER_BYTE);
+				if (!(val)) {
+					this_ksv++;
+					continue;
+				}
+				xhdcp1x_tx->repeatervalues.ksvlist[ksv_count++] = val;
+
+				val = 0;
+				this_ksv++;
+			}
+		}
+
+		memset(bksv, 0, XHDCP1X_PORT_SIZE_BKSV);
+		if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP)
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDMI_HDCP1X_PORT_OFFSET_BKSV,
+							bksv,
+							XHDMI_HDCP1X_PORT_SIZE_BKSV);
+		else
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDCP1X_PORT_OFFSET_BKSV,
+							bksv, XHDCP1X_PORT_SIZE_BKSV);
+
+		/* Determine theremote_ksv */
+		remote_ksv = xlnx_hdcp1x_buf_to_unit(bksv,
+						     XHDCP1X_PORT_SIZE_BKSV * BITS_PER_BYTE);
+		/* Check for invalid */
+		if (!xlnx_hdcp1x_is_ksvvalid(remote_ksv)) {
+			dev_dbg(xhdcp1x_tx->dev, "Invalid Bksv reads");
+			return 0;
+		}
+		xhdcp1x_tx->repeatervalues.ksvlist[ksv_count] = remote_ksv;
+	}
+	return true;
+}
+
+int xlnx_hdcp1x_setrepeaterinfo(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u8 bksv[BITS_PER_BYTE];
+	u32 ksv_count = 0, buf;
+
+	if (xhdcp1x_tx->is_repeater) {
+		if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP) {
+			/* Set the SHA1 Hash value */
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDMI_HDCP1X_PORT_OFFSET_VH0,
+							(void *)&buf,
+							XHDMI_HDCP1X_PORT_SIZE_VH0);
+
+			/* V'H0 */
+			xhdcp1x_tx->repeatervalues.v[0] = (u16)buf;
+
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDMI_HDCP1X_PORT_OFFSET_VH1,
+							(void *)&buf,
+							XHDMI_HDCP1X_PORT_SIZE_VH1);
+
+			/* V'H1 */
+			xhdcp1x_tx->repeatervalues.v[1] = (u16)buf;
+
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDMI_HDCP1X_PORT_OFFSET_VH2,
+							(void *)&buf,
+							XHDMI_HDCP1X_PORT_SIZE_VH2);
+
+			/* V'H2 */
+			xhdcp1x_tx->repeatervalues.v[2] = (u16)buf;
+
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDMI_HDCP1X_PORT_OFFSET_VH3,
+							(void *)&buf,
+							XHDMI_HDCP1X_PORT_SIZE_VH3);
+
+			/* V'H3 */
+			xhdcp1x_tx->repeatervalues.v[3] = (u16)buf;
+
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDMI_HDCP1X_PORT_OFFSET_VH4,
+							(void *)&buf,
+							XHDMI_HDCP1X_PORT_SIZE_VH4);
+
+			/* V'H4 */
+			xhdcp1x_tx->repeatervalues.v[4] = (u16)buf;
+			/* Copy the Depth read from the downstream HDCP device */
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDMI_HDCP1X_PORT_OFFSET_BSTATUS,
+							(void *)&buf,
+							XHDMI_HDCP1X_PORT_SIZE_BSTATUS);
+
+			xhdcp1x_tx->repeatervalues.depth = ((buf &
+							     XHDCP1X_PORT_BINFO_DEPTH_MASK) >>
+							     BITS_PER_BYTE);
+			xhdcp1x_tx->repeatervalues.device_count = (buf &
+								  XHDCP1X_PORT_BINFO_DEV_CNT_MASK);
+			xhdcp1x_tx->repeatervalues.device_count++;
+		} else {
+			u16 repeater_info;
+
+			repeater_info = (u16)xhdcp1x_tx->state_helper;
+
+			xhdcp1x_tx->repeatervalues.depth = ((repeater_info &
+							    XHDCP1X_PORT_BINFO_DEPTH_MASK) >>
+							    BITS_PER_BYTE);
+			xhdcp1x_tx->repeatervalues.device_count = repeater_info &
+								  XHDCP1X_PORT_BINFO_DEV_CNT_MASK;
+			xhdcp1x_tx->repeatervalues.device_count++;
+		}
+	} else {
+		u64 remote_ksv = 0;
+
+		xhdcp1x_tx->repeatervalues.depth = 0;
+
+		xhdcp1x_tx->repeatervalues.device_count = 1;
+
+		if (xhdcp1x_tx->protocol != XHDCP1X_TX_DP)
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDMI_HDCP1X_PORT_OFFSET_BKSV,
+							bksv,
+							XHDMI_HDCP1X_PORT_SIZE_BKSV);
+		else
+			xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+							XHDCP1X_PORT_OFFSET_BKSV,
+							bksv, XHDCP1X_PORT_SIZE_BKSV);
+
+		remote_ksv = xlnx_hdcp1x_buf_to_uint16(bksv,
+						       XHDCP1X_PORT_SIZE_BKSV * BITS_PER_BYTE);
+
+		if (!xlnx_hdcp1x_is_ksvvalid(remote_ksv)) {
+			dev_dbg(xhdcp1x_tx->dev, "bksv invalid");
+			return 0;
+		}
+		xhdcp1x_tx->repeatervalues.ksvlist[ksv_count++] = remote_ksv;
+	}
+
+	return 1;
+}
+
+int xlnx_hdcp1x_tx_read_ksv_list(struct xlnx_hdcp1x_config *xhdcp1x_tx)
+{
+	u32 num_attempts = 3;
+	u32 ksv_list_valid = 0;
+	u16 repeater_info;
+	u8 bksv[BITS_PER_BYTE];
+
+	repeater_info = (xhdcp1x_tx->state_helper & XHDMI_HDCP1X_PORT_BINFO_VALUE);
+
+	if ((!xlnx_hdcp1x_gettopology_maxcascadeexceeded(xhdcp1x_tx)) &&
+	    (!xlnx_hdcp1x_gettopology_maxdevsexceeded(xhdcp1x_tx))) {
+		dev_dbg(xhdcp1x_tx->dev, "Received Correct topology from Downstream Devices");
+	} else {
+		u64 remote_ksv = 0;
+
+		dev_dbg(xhdcp1x_tx->dev, "Received Incorrect topology from Downstream Devices");
+		xlnx_hdcp1x_tx_disable_encryption(xhdcp1x_tx, xhdcp1x_tx->encryption_map);
+		xhdcp1x_tx->repeatervalues.depth =
+				((repeater_info & XHDCP1X_PORT_BINFO_DEPTH_MASK) >>
+				 XHDMI_HDCP1X_PORT_BSTATUS_DEPTH_SHIFT);
+		xhdcp1x_tx->repeatervalues.device_count =
+				(repeater_info &
+				 XHDMI_HDCP1X_PORT_BSTATUS_DEV_CNT_MASK);
+
+		xhdcp1x_tx->handlers.rd_handler(xhdcp1x_tx->interface_ref,
+						XHDMI_HDCP1X_PORT_OFFSET_BKSV,
+						bksv, XHDCP1X_PORT_SIZE_BKSV);
+		remote_ksv = xlnx_hdcp1x_buf_to_uint16(bksv,
+						       XHDCP1X_PORT_SIZE_BKSV * BITS_PER_BYTE);
+
+		if (!xlnx_hdcp1x_is_ksvvalid(remote_ksv))
+			xhdcp1x_tx->repeatervalues.ksvlist[0] =	remote_ksv;
+		else
+			xhdcp1x_tx->repeatervalues.ksvlist[0] = 0x0;
+
+		memset(xhdcp1x_tx->repeatervalues.v, 0x0, sizeof(u32) * XHDCP1X_PORT_SIZE_BKSV);
+
+		xhdcp1x_tx->repeatervalues.hdcp14_propagatetopo_errupstream = true;
+
+		if ((repeater_info & 0x800) != 0)
+			dev_dbg(xhdcp1x_tx->dev, "Max Cascade Exceeded");
+		else
+			dev_dbg(xhdcp1x_tx->dev, "Max Devicec Exceeded");
+
+		return 0;
+	}
+
+	do {
+		ksv_list_valid = xlnx_hdcp1x_tx_validate_ksv_list(xhdcp1x_tx, repeater_info);
+		num_attempts--;
+	} while ((num_attempts > 0) && (!ksv_list_valid));
+
+	if (ksv_list_valid) {
+		if (xhdcp1x_tx->is_repeater)
+			xlnx_hdcp1x_setrepeaterinfo(xhdcp1x_tx);
+		xhdcp1x_tx->downstreamready = 1;
+		return 1;
+	}
+
+	return 0;
+}
+
+void xlnx_hdcp1x_tx_timer_init(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+			       struct xlnx_hdcp_timer_config *tmr_cntrl)
+{
+	xhdcp1x_tx->xhdcp1x_internal_timer.tmr_ctr = *tmr_cntrl;
+
+	xlnx_hdcp_tmrcntr_set_options(&xhdcp1x_tx->xhdcp1x_internal_timer.tmr_ctr,
+				      0,
+				      XTC_INT_MODE_OPTION | XTC_DOWN_COUNT_OPTION);
+}
+
+void xlnx_hdcp1x_tx_start_timer(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+				u32 timeout, u8 reason_id)
+{
+	u32 ticks = (u32)(xhdcp1x_tx->xhdcp1x_internal_timer.tmr_ctr.hw_config.sys_clock_freq
+					/ XHDCP1X_TX_CLKDIV_MHZ) * timeout * XHDCP1X_TX_CLKDIV_HZ;
+
+	xlnx_hdcp_tmrcntr_stop(&xhdcp1x_tx->xhdcp1x_internal_timer.tmr_ctr, 0);
+
+	xhdcp1x_tx->xhdcp1x_internal_timer.timer_expired = (0);
+	xhdcp1x_tx->xhdcp1x_internal_timer.reason_id = reason_id;
+	xhdcp1x_tx->xhdcp1x_internal_timer.initial_ticks = ticks;
+
+	xlnx_hdcp_tmrcntr_set_reset_value(&xhdcp1x_tx->xhdcp1x_internal_timer.tmr_ctr,
+					  0, ticks);
+	xlnx_hdcp_tmrcntr_start(&xhdcp1x_tx->xhdcp1x_internal_timer.tmr_ctr, 0);
+}
+
+void xlnx_hdcp1x_tx_timer_handler(void *callbackref, u8 tmr_cnt_number)
+{
+	struct xlnx_hdcp1x_config *xhdcp1x_tx =	(struct xlnx_hdcp1x_config *)callbackref;
+
+	if (tmr_cnt_number == XTC_TIMER_1)
+		return;
+
+	xhdcp1x_tx->xhdcp1x_internal_timer.timer_expired = 1;
+}
diff --git a/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp1x_tx.h b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp1x_tx.h
new file mode 100644
index 000000000..ddd32cd34
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp1x_tx.h
@@ -0,0 +1,363 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx Specific HDCP1X driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Katta Dhanunjanrao <katta.dhanunjanrao@amd.com>
+ *
+ */
+#include <drm/display/drm_hdcp.h>
+#include <linux/io.h>
+#include <linux/regmap.h>
+#include <linux/time.h>
+#include <linux/workqueue.h>
+#include <linux/xlnx/xlnx_timer.h>
+#include "xhdcp1x_tx.h"
+
+/* Basic configuration enable/disable list of macros */
+#define XHDCP1X_ENABLE			1
+#define XHDCP1X_DISABLE			0
+#define XHDCP1X_DEFAULT_INIT		0
+#define XHDCP1X_ENCRYPTION_EN		1
+#define XHDCP1X_ENCRYPTION_DISABLE	0
+#define XHDCP1X_MAX_RETRIES		3
+#define XHDCP1X_BYTE_IN_BITS		8
+#define XHDCP1X_REMOTE_BKSV_SIZE	5
+#define XHDCP1X_REMOTE_INFO_BCAPS_VAL	1
+#define XHDCP1X_REMOTE_RO_SIZE		2
+#define XHDCP1X_KSV_NUM_OF_1S		20
+#define XHDCP1X_RO_AVILABLE_DELAY	100
+#define XHDCP1X_VERSION			(0x01u)
+#define XHDCP1X_STREAM_MAP		(0x01)
+#define XHDCP1X_BUF_OFFSET_LEN		(0x100)
+#define XHDCP1X_TX_REVOCLIST_MAX_DEVICES	944
+#define XHDCP1X_TX_ENCRYPTION_KEY_SIZE		336
+#define XHDCP1X_PORT_MIN_BYTES 3
+/* These constants specify the offsets for the various fields and/or
+ * attributes within the hdcp port
+ */
+#define XDPTX_HDCP1X_DPCD_OFFSET	0x68000
+#define XHDCP1X_PORT_OFFSET_BKSV	(0x00 + XDPTX_HDCP1X_DPCD_OFFSET)   /* Bksv Offset        */
+#define XHDCP1X_PORT_OFFSET_RO		(0x05 + XDPTX_HDCP1X_DPCD_OFFSET)   /* R0' Offset         */
+#define XHDCP1X_PORT_OFFSET_AKSV	(0x07 + XDPTX_HDCP1X_DPCD_OFFSET)   /* Aksv Offset        */
+#define XHDCP1X_PORT_OFFSET_AN		(0x0C + XDPTX_HDCP1X_DPCD_OFFSET)   /* An Offset          */
+#define XHDCP1X_PORT_OFFSET_VH0		(0x14 + XDPTX_HDCP1X_DPCD_OFFSET)   /* V'.H0 Offset       */
+#define XHDCP1X_PORT_OFFSET_VH1		(0x18 + XDPTX_HDCP1X_DPCD_OFFSET)   /* V'.H1 Offset       */
+#define XHDCP1X_PORT_OFFSET_VH2		(0x1C + XDPTX_HDCP1X_DPCD_OFFSET)   /* V'.H2 Offset       */
+#define XHDCP1X_PORT_OFFSET_VH3		(0x20 + XDPTX_HDCP1X_DPCD_OFFSET)   /* V'.H3 Offset       */
+#define XHDCP1X_PORT_OFFSET_VH4		(0x24 + XDPTX_HDCP1X_DPCD_OFFSET)   /* V'.H4 Offset       */
+#define XHDCP1X_PORT_OFFSET_BCAPS	(0x28 + XDPTX_HDCP1X_DPCD_OFFSET)   /* Bcaps Offset       */
+#define XHDCP1X_PORT_OFFSET_BSTATUS	(0x29 + XDPTX_HDCP1X_DPCD_OFFSET)   /* Bstatus Offset     */
+#define XHDCP1X_PORT_OFFSET_BINFO	(0x2A + XDPTX_HDCP1X_DPCD_OFFSET)   /* Binfo Offset       */
+#define XHDCP1X_PORT_OFFSET_KSVFIFO	(0x2C + XDPTX_HDCP1X_DPCD_OFFSET)   /* KSV FIFO Offset    */
+#define XHDCP1X_PORT_OFFSET_AINFO	(0x3B + XDPTX_HDCP1X_DPCD_OFFSET)   /* Ainfo Offset       */
+#define XHDCP1X_PORT_OFFSET_DBG		(0xC0 + XDPTX_HDCP1X_DPCD_OFFSET)   /* Debug Space Offset */
+#define XHDCP1X_PORT_HDCP_RESET_KSV	(0xD0 + XDPTX_HDCP1X_DPCD_OFFSET)   /* KSV FIFO Read pointer
+									     * reset Offset
+									     */
+/*
+ * These constants specify the sizes for the various fields and/or
+ * attributes within the hdcp port for HDMI Interface
+ */
+#define XHDCP1X_PORT_SIZE_BKSV		(0x05u)   /* Bksv Size          */
+#define XHDCP1X_PORT_SIZE_RO		(0x02u)   /* R0' Size           */
+#define XHDCP1X_PORT_SIZE_AKSV		(0x05u)   /* Aksv Size          */
+#define XHDCP1X_PORT_SIZE_AN		(0x08u)   /* An Size            */
+#define XHDCP1X_PORT_SIZE_VH0		(0x04u)   /* V'.H0 Size         */
+#define XHDCP1X_PORT_SIZE_VH1		(0x04u)   /* V'.H1 Size         */
+#define XHDCP1X_PORT_SIZE_VH2		(0x04u)   /* V'.H2 Size         */
+#define XHDCP1X_PORT_SIZE_VH3		(0x04u)   /* V'.H3 Size         */
+#define XHDCP1X_PORT_SIZE_VH4		(0x04u)   /* V'.H4 Size         */
+#define XHDCP1X_PORT_SIZE_BCAPS		(0x01u)   /* Bcaps Size         */
+#define XHDCP1X_PORT_SIZE_BSTATUS	(0x01u)   /* Bstatus Size       */
+#define XHDCP1X_PORT_SIZE_BINFO		(0x02u)   /* Binfo Size         */
+#define XHDCP1X_PORT_SIZE_KSVFIFO	(0x0Fu)   /* KSV FIFO Size      */
+#define XHDCP1X_PORT_SIZE_AINFO		(0x01u)   /* Ainfo Offset       */
+#define XHDCP1X_PORT_SIZE_DBG		(0x40u)   /* Debug Space Size   */
+#define XHDCP1X_PORT_SIZE_HDCP_RESET_KSV (0x40u)  /* KSV FIFO pointer reset Size  */
+/*
+ * These constants specify the bit definitions within the various fields
+ * and/or attributes within the hdcp port
+ */
+#define XHDCP1X_PORT_BIT_BSTATUS_READY		BIT(0) /* BStatus Ready Mask */
+#define XHDCP1X_PORT_BIT_BSTATUS_RO_AVAILABLE	BIT(1) /* BStatus Ro available Mask */
+#define XHDCP1X_PORT_BIT_BSTATUS_LINK_FAILURE	BIT(2) /* BStatus Link Failure Mask  */
+#define XHDCP1X_PORT_BIT_BSTATUS_REAUTH_REQUEST	BIT(3) /* BStatus Reauth Request Mask  */
+#define XHDCP1X_PORT_BIT_BCAPS_HDCP_CAPABLE	BIT(0) /* BCaps HDCP Capable Mask  */
+#define XHDCP1X_PORT_BIT_BCAPS_REPEATER		BIT(1) /* BCaps HDCP Repeater Mask */
+#define XHDCP1X_PORT_BIT_AINFO_REAUTH_ENABLE_IRQ	BIT(0) /**< Ainfo Reauth Enable Mask  */
+#define XHDCP1X_PORT_HDCP_RESET_KSV_RST		BIT(0) /* KSV FIFO pointer Reset Mask    */
+#define XHDCP1X_PORT_BINFO_BIT_DEV_CNT_ERR	BIT(7) /* BInfo Device Count Error Mask */
+/* BInfo Device Count for No Error Mask */
+#define XHDCP1X_PORT_BINFO_BIT_DEV_CNT_NO_ERR	(0u << 7)
+#define XHDCP1X_PORT_BINFO_DEV_CNT_MASK		(0x7F) /* BInfo Device Count Error Mask */
+#define XHDCP1X_PORT_BINFO_DEPTH_MASK		0x0700 /* BIndo Depth Mask */
+#define XHDCP1X_PORT_BINFO_BIT_DEPTH_ERR	BIT(11) /* BInfo Depth Error Mask    */
+/* BInfo Depth Error for No Error Mask */
+#define XHDCP1X_PORT_BINFO_BIT_DEPTH_NO_ERR	(0u << 11)
+#define XHDCP1X_PORT_BINFO_DEV_CNT_ERR_SHIFT	(7) /* BStatus Device Count Error Shift Mask */
+#define XHDCP1X_PORT_BINFO_DEPTH_ERR_SHIFT	(11) /* BStatus Depth Error Shift Mask */
+#define XHDCP1X_PORT_BINFO_DEPTH_SHIFT		(8) /* BInfo Device Count Error Mask */
+#define XHDCP1X_PORT_BINFO_VALUE		GENMASK(12, 0)
+/*
+ * These constants specify the sizes for the various fields and/or
+ * attributes within the hdcp port for HDMI interface
+ */
+#define XHDMI_HDCP1X_PORT_SIZE_BKSV		(0x05u)   /**< Bksv Size          */
+#define XHDMI_HDCP1X_PORT_SIZE_RO		(0x02u)   /**< Ri' Size           */
+#define XHDMI_HDCP1X_PORT_SIZE_PJ		(0x01u)   /**< Pj' Size           */
+#define XHDMI_HDCP1X_PORT_SIZE_AKSV		(0x05u)   /**< Aksv Size          */
+#define XHDMI_HDCP1X_PORT_SIZE_AINFO		(0x01u)   /**< Ainfo Size         */
+#define XHDMI_HDCP1X_PORT_SIZE_AN		(0x08u)   /**< An Size            */
+#define XHDMI_HDCP1X_PORT_SIZE_VH0		(0x04u)   /**< V'.H0 Size         */
+#define XHDMI_HDCP1X_PORT_SIZE_VH1		(0x04u)   /**< V'.H1 Size         */
+#define XHDMI_HDCP1X_PORT_SIZE_VH2		(0x04u)   /**< V'.H2 Size         */
+#define XHDMI_HDCP1X_PORT_SIZE_VH3		(0x04u)   /**< V'.H3 Size         */
+#define XHDMI_HDCP1X_PORT_SIZE_VH4		(0x04u)   /**< V'.H4 Size         */
+#define XHDMI_HDCP1X_PORT_SIZE_BCAPS		(0x01u)   /**< Bcaps Size         */
+#define XHDMI_HDCP1X_PORT_SIZE_BSTATUS		(0x02u)   /**< Bstatus Size       */
+#define XHDMI_HDCP1X_PORT_SIZE_KSVFIFO		(0x01u)   /**< KSV FIFO Size      */
+#define XHDMI_HDCP1X_PORT_SIZE_DBG		(0xC0u)   /**< Debug Space Size   */
+/*
+ * These constants specify the offsets for the various fields and/or
+ * attributes within the hdcp port for HDMI interface
+ */
+#define XHDMI_HDCP1X_PORT_OFFSET_BKSV		(0x00u)   /**< Bksv Offset        */
+#define XHDMI_HDCP1X_PORT_OFFSET_RO		(0x08u)   /**< Ri'/Ro' Offset     */
+#define XHDMI_HDCP1X_PORT_OFFSET_PJ		(0x0Au)   /**< Pj' Offset         */
+#define XHDMI_HDCP1X_PORT_OFFSET_AKSV		(0x10u)   /**< Aksv Offset        */
+#define XHDMI_HDCP1X_PORT_OFFSET_AINFO		(0x15u)   /**< Ainfo Offset       */
+#define XHDMI_HDCP1X_PORT_OFFSET_AN		(0x18u)   /**< An Offset          */
+#define XHDMI_HDCP1X_PORT_OFFSET_VH0		(0x20u)   /**< V'.H0 Offset       */
+#define XHDMI_HDCP1X_PORT_OFFSET_VH1		(0x24u)   /**< V'.H1 Offset       */
+#define XHDMI_HDCP1X_PORT_OFFSET_VH2		(0x28u)   /**< V'.H2 Offset       */
+#define XHDMI_HDCP1X_PORT_OFFSET_VH3		(0x2Cu)   /**< V'.H3 Offset       */
+#define XHDMI_HDCP1X_PORT_OFFSET_VH4		(0x30u)   /**< V'.H4 Offset       */
+#define XHDMI_HDCP1X_PORT_OFFSET_BCAPS		(0x40u)   /**< Bcaps Offset       */
+#define XHDMI_HDCP1X_PORT_OFFSET_BSTATUS	(0x41u)   /**< Bstatus Offset     */
+#define XHDMI_HDCP1X_OFFSET_KSVFIFO		(0x43u)   /**< KSV FIFO Offset    */
+#define XHDMI_HDCP1X_PORT_OFFSET_DBG		(0xC0u)   /**< Debug Space Offset */
+
+#define XHDMI_HDCP1X_PORT_BIT_BSTATUS_HDMI_MODE         BIT(12)
+#define XHDMI_HDCP1X_PORT_BIT_BCAPS_FAST_REAUTH         BIT(0)
+#define XHDMI_HDCP1X_PORT_BIT_BCAPS_1d1_FEATURES        BIT(1)
+#define XHDMI_HDCP1X_PORT_BIT_BCAPS_FAST                BIT(4)
+#define XHDMI_HDCP1X_PORT_BIT_BCAPS_READY               BIT(5)
+#define XHDMI_HDCP1X_PORT_BIT_BCAPS_REPEATER            BIT(6)
+#define XHDMI_HDCP1X_PORT_BIT_BCAPS_HDMI                BIT(7)
+#define XHDMI_HDCP1X_PORT_BIT_AINFO_ENABLE_1d1_FEATURES BIT(1)
+#define XHDMI_HDCP1X_PORT_BSTATUS_BIT_DEV_CNT_ERR       BIT(7)
+#define XHDMI_HDCP1X_PORT_BSTATUS_BIT_DEV_CNT_NO_ERR    (0u << 7)
+#define XHDMI_HDCP1X_PORT_BSTATUS_DEV_CNT_MASK          (0x7F)
+#define XHDMI_HDCP1X_PORT_BSTATUS_BIT_DEPTH_ERR         BIT(11)
+#define XHDMI_HDCP1X_PORT_BSTATUS_BIT_DEPTH_NO_ERR      (0u << 11)
+#define XHDMI_HDCP1X_PORT_BSTATUS_DEV_CNT_ERR_SHIFT     (7)
+#define XHDMI_HDCP1X_PORT_BSTATUS_DEPTH_ERR_SHIFT       (11)
+#define XHDMI_HDCP1X_PORT_BSTATUS_DEPTH_SHIFT           (8)
+#define XHDMI_HDCP1X_PORT_BINFO_VALUE			GENMASK(13, 0)
+#define XHDMI_HDCP1X_PORT_MAX_DEV_CNT			(0x7F)
+#define XHDMI_HDCP1X_READY_TIMEOUT			25
+#define XHDMI_HDCP1X_WAIT_FOR_READY_TIMEOUT		200
+#define XHDMI_HDCP1X_WAIT_FOR_ACTIVE_RECEIVER		2000
+#define XHDCP1X_TX_CLKDIV_MHZ			1000000
+#define XHDCP1X_TX_CLKDIV_HZ			1000
+
+/*
+ * struct xhdcp1x_tx_callbacks - This structure contains the callback handlers.
+ * @rd_handler: The DP/HDMI read handler call for the aux channels
+ * @wr_handler: The DP/HDMI write handler call for the aux channels
+ * @notify_handler: The DP/HDMI notify handler call for the aux channels
+ */
+struct xhdcp1x_tx_callbacks {
+	int (*rd_handler)(void *interface_ref, u32 offset, u8 *buf, u32 size);
+	int (*wr_handler)(void *interface_ref, u32 offset, u8 *buf, u32 size);
+	void (*notify_handler)(void *interface_ref, u32 notification);
+};
+
+enum xlnx_hdcp1x_tx_callback_type {
+	XHDCP1X_TX_HANDLER_AUX_READ = 0,
+	XHDCP1X_TX_HANDLER_AUX_WRITE = 1,
+	XHDCP1X_TX_HANDLER_HDCP_STATUS = 2,
+	XHDCP1X_TX_HANDLER_INVALID = 3
+};
+
+enum xhdcp1x_tx_authtype {
+	XHDCP1X_TX_AUTHENTICATED = 0,
+	XHDCP1X_TX_UNAUTHENTICATED = 1,
+	XHDCP1X_TX_INCOMPATIBLE_RX = 2,
+	XHDCP1X_TX_AUTHENTICATION_BUSY = 3,
+	XHDCP1X_TX_REAUTHENTICATE_REQUESTED = 4,
+	XHDCP1X_TX_DEVICE_IS_REVOKED = 5,
+};
+
+enum xhdcp1x_tx_protocol {
+	XHDCP1X_TX_DP = 0,
+	XHDCP1X_TX_HDMI = 1,
+};
+
+/*
+ * struct hdcp1x_tx_revoclist - This structure contains the HDCP
+ * keys revocation list information
+ * @rcvid: The array contains the revocation keys list of information
+ * @num_of_devices: Number of devices in the revocated list count
+ */
+struct hdcp1x_tx_revoclist {
+	u8  rcvid[XHDCP1X_TX_REVOCLIST_MAX_DEVICES][DRM_HDCP_KSV_LEN];
+	u32 num_of_devices;
+};
+
+/*
+ * struct xhdcp1x_repeater_exchange - This structure contains an instance of the HDCP
+ * Repeater values to exchanged between HDCP Tx and HDCP Rx
+ * @v[5]: The 20 byte value of SHA1 hash, v'h0,v'h1,v'h2,v'h3,v'h4
+ * read from downstream repeater.
+ * @ksvlist[32]: An array of 32 elements each of 64 bits to store the KSVs
+ * for the KSV FIFO
+ * @depth: depeth of downstream topology
+ * @device_count: Number of downstream devices attached to the repeater
+ * @hdcp14_propagatetopo_errupstream: propagate the topology error to upstream
+ */
+struct xhdcp1x_repeater_exchange {
+	u32 v[DRM_HDCP_KSV_LEN];
+	u64 ksvlist[HDCP_2_2_MAX_DEVICE_COUNT + 1];
+	u8 depth;
+	u8 device_count;
+	u8 hdcp14_propagatetopo_errupstream;
+};
+
+/*
+ * struct xhdcp1x_tx_status - This structure contains Hdcp1x driver
+ * status information fields
+ * @auth_failed: Authentication failures count
+ * @auth_passed: Authentication passed status/count
+ * @reauth_requested: Re-Authentication request if any link failures..etc
+ * @read_failure: remote device read failures
+ * @link_checkpassed: Link verification that is passed
+ * @link_checkfailed: Link verification that is failure
+ *
+ */
+struct xhdcp1x_tx_status {
+	u32 auth_status;
+	u32 auth_failed;
+	u32 auth_passed;
+	u32 reauth_requested;
+	u32 read_failure;
+	u32 link_checkpassed;
+	u32 link_checkfailed;
+};
+
+/*
+ * struct xhdcp1x_tx_internal_timer - Current state and data used for internal timer
+ * @tmr_ctr: hardware timer configuration structure
+ * @initial_ticks: Keep track of the start value of the timer.
+ * @timer_expired: Expiration flag set when the hardware timer has interrupted.
+ * @reason_id: Keep track of why the timer was started (message or status checking)
+ */
+struct xhdcp1x_tx_internal_timer {
+	struct xlnx_hdcp_timer_config tmr_ctr;
+	u32 initial_ticks;
+	u8 timer_expired;
+	u8 reason_id;
+};
+
+/*
+ * struct xlnx_hdcp1x_config - This structure contains Hdcp1x driver
+ * configuration information
+ * @dev: device information
+ * @handlers: Callback handlers
+ * @sm_work: state machine worker
+ * @curr_state: current authentication state
+ * @prev_sate: Previous Authentication State
+ * @repeatervalues: The downstream repeater capabilities
+ * @stats: authentication status
+ * @hdcp1x_keymgmt_base: Key management base address
+ * @cipher: Pointer to cipher driver instance
+ * @interface_ref: Pointer to interface(DP/HDMI) driver instance
+ * @interface_base: Pointer to instance iomem base
+ * @pending_events: Evenets that are set by interface driver
+ * @downstreamready: To check the downstream device status ready or not
+ * @is_repeater: says whether downstream is repeater or receiver
+ * @hdcp1x_key_availble: The KMS block has key exists or not.
+ * @lane_count: number of lanes data to be encrypted
+ * @hdcp1x_key: hdcp1x key pointer
+ * @auth_status: first stage authentication status
+ * @keyinit: Key Management Block with key initiliazed properly or not
+ * @is_encryption_en: Encryption enbalemnet is done or not
+ * @is_cipher: is cipher init is done or not
+ * @state_helper: to store the An value temp basis
+ * @encryption_map: To check the encryption progress
+ *
+ */
+struct xlnx_hdcp1x_config {
+	struct device *dev;
+	struct xhdcp1x_tx_callbacks handlers;
+	struct hdcp1x_tx_revoclist xhdcp1x_revoc_list;
+	struct xhdcp1x_tx_internal_timer xhdcp1x_internal_timer;
+	struct delayed_work	sm_work;
+	enum hdcp1x_tx_state	curr_state;
+	enum hdcp1x_tx_state	prev_state;
+	struct xhdcp1x_repeater_exchange repeatervalues;
+	struct xhdcp1x_tx_status stats;
+	struct regmap *hdcp1x_keymgmt_base;
+	void	*cipher;
+	void	*interface_ref;
+	void __iomem	*interface_base;
+	u32	pending_events;
+	u32	downstreamready;
+	u32	tmr_cnt;
+	bool	is_repeater;
+	bool	hdcp1x_key_available;
+	u8	lane_count;
+	u8	*hdcp1x_key;
+	u8	auth_status;
+	u8	keyinit;
+	u8	is_encryption_en;
+	u8	is_enabled;
+	u8	is_cipher;
+	u8	is_hdmi;
+	u8	protocol;
+	u8	is_riupdate;
+	u64	state_helper;
+	u64	encryption_map;
+	u8	*xlnx_hdcp1x_key;
+};
+
+void xlnx_start_hdcp1x_engine(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+bool xlnx_hdcp1x_tx_init(struct xlnx_hdcp1x_config *xhdcp1x_tx, bool is_repeater);
+int xlnx_hdcp1x_task_monitor(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+bool xlnx_hdcp1x_downstream_capbility(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+bool xlnx_hdcp1x_tx_check_rxcapable(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+bool xlnx_hdcp1x_read_bksv_from_remote(struct xlnx_hdcp1x_config *xhdcp1x_tx, u32 offset,
+				       void *buf, u32 buf_size);
+bool xlnx_hdcp1x_exchangeksvs(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+bool xlnx_hdcp1x_computationsstate(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+bool xlnx_hdcp1x_tx_validaterxstate(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xlnx_hdcp1x_check_link_integrity(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+void xhdcp1x_tx_set_check_linkstate(struct xlnx_hdcp1x_config *xhdcp1x_tx, int is_enabled);
+void xlnx_hdcp1x_tx_process_ri_event(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xlnx_hdcp1x_is_ksvvalid(u64 ksv);
+u64 xlnx_hdcp1x_tx_generate_an(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xhdcp1x_tx_set_keyselect(struct xlnx_hdcp1x_config *xhdcp1x_tx, u8 keyselect);
+int xhdcp1x_tx_load_aksv(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+void xlnx_hdcp1x_tx_disable(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xlnx_hdcp1x_tx_reset(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+void xlnx_hdcp1x_tx_enable_encryption(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+void xlnx_hdcp1x_tx_disable_encryption(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+				       u64 stream_map);
+int hdcp1x_tx_protocol_authenticate_sm(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xlnx_hdcp1x_tx_test_for_repeater(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xlnx_hdcp1x_tx_read_ksv_list(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xlnx_hdcp1x_setrepeaterinfo(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xlnx_hdcp1x_tx_validate_ksv_list(struct xlnx_hdcp1x_config *xhdcp1x_tx, u16 repeaterinfo);
+enum hdcp1x_tx_state xlnx_hdcp1x_tx_wait_for_ready(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xlnx_hdcp1x_get_repeater_info(struct xlnx_hdcp1x_config *xhdcp1x_tx, u16 *info);
+int xlnx_hdcp1x_gettopology_maxcascadeexceeded(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xlnx_hdcp1x_gettopology_maxdevsexceeded(struct xlnx_hdcp1x_config *xhdcp1x_tx);
+int xlnx_hdcp1x_set_keys(struct xlnx_hdcp1x_config *xhdcp1x_tx, u8 *data);
+int xlnx_hdcp1x_keymngt_init(struct xlnx_hdcp1x_config *xhdcp1x_tx, u8 *data);
+void xlnx_hdcp1x_tx_timer_init(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+			       struct xlnx_hdcp_timer_config *tmr_cntrl);
+void xlnx_hdcp1x_tx_timer_handler(void *callbackref, u8 tmr_cnt_number);
+void xlnx_hdcp1x_tx_start_timer(struct xlnx_hdcp1x_config *xhdcp1x_tx,
+				u32 timeout, u8 reason_id);
diff --git a/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp2x_crypt.c b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp2x_crypt.c
new file mode 100644
index 000000000..70e8fe520
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp2x_crypt.c
@@ -0,0 +1,494 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx HDCP2X Cryptography driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Lakshmi Prasanna Eachuri <lakshmi.prasanna.eachuri@amd.com>
+ *
+ * This driver provides Xilinx HDCP 2X transmitter cryptographic functionality.
+ *
+ * References:
+ *
+ * http://www.citi.umich.edu/projects/nfsv4/rfc/pkcs-1v2-1.pdf
+ * https://www.cryptrec.go.jp/cryptrec_03_spec_cypherlist_files/PDF/pkcs-1v2-12.pdf
+ * https://www.digital-cp.com/sites/default/files/HDCP%20on%20DisplayPort%20Specification%20Rev2_3.pdf
+ */
+
+#include <crypto/aes.h>
+#include <crypto/sha2.h>
+#include <linux/xlnx/xlnx_hdcp_common.h>
+#include "xlnx_hdcp2x_tx.h"
+
+#define BD_MAX_MOD_SIZE  (HDCP2X_TX_CERT_RSA_PARAMETER_SIZE / sizeof(u32))
+
+#define XHDCP2X_TX_SHA256_SIZE		(256 / 8)
+#define XHDCP2X_TX_INNER_PADDING_BYTE	0x36
+#define XHDCP2X_TX_OUTER_PADDING_BYTE	0x5C
+
+/*
+ * DER encoding T of the Digestinfo value is equal to this hash values
+ * Reference: http://www.citi.umich.edu/projects/nfsv4/rfc/pkcs-1v2-1.pdf
+ * Section 8.2.2 and 9.2.
+ */
+static u8 ti_identifier[] = {0x30, 0x31, 0x30, 0x0d, 0x06, 0x09, 0x60, 0x86,
+			     0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01, 0x05,
+			     0x00, 0x04, 0x20};
+
+/* RSA OAEP masking function */
+static void xlnx_hdcp2x_tx_mg_f1(const u8 *seed, unsigned int seedlen,
+				 u8 *mask, unsigned int mask_len)
+{
+	u8  hash_data[HDCP2X_TX_CERT_PUB_KEY_N_SIZE] = {0};
+	u8  tx_cert_key[HDCP2X_TX_CERT_PUB_KEY_N_SIZE] = {0};
+	u8  hash[HDCP2X_TX_SHA256_HASH_SIZE] = {0};
+	u32 i;
+
+	memcpy(hash_data, seed, seedlen);
+
+	/*
+	 * Reference: https://www.cryptrec.go.jp/cryptrec_03_spec_cypherlist_files/PDF/pkcs-1v2-12.pdf
+	 * Section: 7.1
+	 */
+	for (i = 0; (i * HDCP2X_TX_SHA256_HASH_SIZE) < mask_len; i++) {
+		u32 counter;
+
+		counter = ntohl(i);
+		memcpy(hash_data + seedlen, &counter, HDCP2X_TX_CERT_PUBLIC_EXPONENT_E);
+		sha256(hash_data, seedlen + HDCP2X_TX_CERT_PUBLIC_EXPONENT_E, hash);
+		memcpy(tx_cert_key + (i * HDCP2X_TX_SHA256_HASH_SIZE), hash,
+		       HDCP2X_TX_SHA256_HASH_SIZE);
+	}
+	memcpy(mask, tx_cert_key, mask_len);
+}
+
+static void xlnx_hdcp2x_tx_memxor(u8 *out, const u8 *inputparam1,
+				  const u8 *inputparam2, u32 size)
+{
+	u32 i;
+
+	for (i = 0; i < size; i++)
+		out[i] = inputparam1[i] ^ inputparam2[i];
+}
+
+/* Reference: PKCS#1 v2.1, Section 7.1.1, Part 2 */
+static void xlnx_hdcp2x_tx_pkcs1_eme_oaep_encode(const u8 *message, const u32 message_length,
+						 const u8 *masking_seed, u8 *encoded_msg)
+{
+	u8  db_mask[HDCP2X_TX_CERT_PUB_KEY_N_SIZE - HDCP2X_TX_SHA256_HASH_SIZE - 1] = {0};
+	u8  db[HDCP2X_TX_CERT_PUB_KEY_N_SIZE - HDCP2X_TX_SHA256_HASH_SIZE - 1] = {0};
+	u8  seed_mask[HDCP2X_TX_SHA256_HASH_SIZE] = {0};
+	u8  l_hash[HDCP2X_TX_SHA256_HASH_SIZE] = {0};
+	u8  seed[HDCP2X_TX_SHA256_HASH_SIZE] = {0};
+
+	/* Step 2a: l_hash is the empty string */
+	sha256(NULL, 0, l_hash);
+
+	/* Step 2b: Generate PS by initializing DB to zeros */
+	memcpy(db, l_hash, HDCP2X_TX_SHA256_HASH_SIZE);
+
+	/* Step 2c: Generate DB = lHash || PS || 0x01 || M */
+	db[HDCP2X_TX_CERT_PUB_KEY_N_SIZE - message_length -
+	   HDCP2X_TX_SHA256_HASH_SIZE - 2] = 0x01;
+
+	/*
+	 * Step 2d: Generate random seed of length hLen
+	 * The random seed is passed in as an argument to this function.
+	 */
+	memcpy(db + HDCP2X_TX_CERT_PUB_KEY_N_SIZE - message_length -
+	       HDCP2X_TX_SHA256_HASH_SIZE - 1,
+	       message, message_length);
+
+	/* Step 2e: Generate dbMask = MGF1(seed, length(DB)) */
+	xlnx_hdcp2x_tx_mg_f1(masking_seed,
+			     HDCP2X_TX_SHA256_HASH_SIZE, db_mask,
+			     HDCP2X_TX_CERT_PUB_KEY_N_SIZE - HDCP2X_TX_SHA256_HASH_SIZE
+			     - 1);
+
+	/* Step 2f: Generate maskedDB = DB xor dbMask */
+	xlnx_hdcp2x_tx_memxor(db, db, db_mask,
+			      HDCP2X_TX_CERT_PUB_KEY_N_SIZE - HDCP2X_TX_SHA256_HASH_SIZE - 1);
+
+	/* Step 2g: Generate seedMask = MGF(maskedDB, length(seed)) */
+	xlnx_hdcp2x_tx_mg_f1(db,
+			     HDCP2X_TX_CERT_PUB_KEY_N_SIZE - HDCP2X_TX_SHA256_HASH_SIZE - 1,
+			     seed_mask, HDCP2X_TX_SHA256_HASH_SIZE);
+
+	/* Step 2h: Generate maskedSeed = seed xor seedMask */
+	xlnx_hdcp2x_tx_memxor(seed, masking_seed, seed_mask,
+			      HDCP2X_TX_SHA256_HASH_SIZE);
+
+	/* Step 2i: Form encoded message EM = 0x00 || maskedSeed || maskedDB */
+	memset(encoded_msg, 0, HDCP2X_TX_CERT_PUB_KEY_N_SIZE);
+	memcpy(encoded_msg + 1, seed, HDCP2X_TX_SHA256_HASH_SIZE);
+	memcpy(encoded_msg + 1 + HDCP2X_TX_SHA256_HASH_SIZE, db,
+	       HDCP2X_TX_CERT_PUB_KEY_N_SIZE - HDCP2X_TX_SHA256_HASH_SIZE - 1);
+}
+
+static int xlnx_hdcp2x_tx_rsa_encrypt(const u8 *rsa_public_key, int public_key_size,
+				      const u8 *exponent_key, int exponent_key_size,
+				      const u8 *msg, int msg_size, u8 *encrypted_msg)
+{
+	unsigned int *n, *e, *m, *s;
+	unsigned int mod_size = public_key_size / sizeof(unsigned int);
+
+	if (msg_size != public_key_size)
+		return -EINVAL;
+
+	n = kzalloc(4 * BD_MAX_MOD_SIZE * sizeof(u32), GFP_KERNEL);
+	if (!n)
+		return -ENOMEM;
+
+	/*
+	 * Divide the mem allocated to n into 4 parts such that
+	 * e follows n, m follows e and s follows m.
+	 */
+	e = &n[BD_MAX_MOD_SIZE];
+	m = &e[BD_MAX_MOD_SIZE];
+	s = &m[BD_MAX_MOD_SIZE];
+
+	mp_conv_from_octets(n, mod_size, rsa_public_key, public_key_size);
+	mp_conv_from_octets(e, mod_size, exponent_key, exponent_key_size);
+
+	mp_conv_from_octets(m, mod_size, msg, msg_size);
+	mp_mod_exp(s, m, e, n, mod_size);
+	mp_conv_to_octets(s, mod_size, encrypted_msg, msg_size);
+
+	kfree(n);
+
+	return 0;
+}
+
+/* Reference: PKCS#1 v2.1, Section 7.1. */
+static int xlnx_hdcp2x_tx_rsa_oae_encrypt(const u8 *rsa_public_key,
+					  int public_key_size,
+					  const u8 *exponent_key, int exponent_key_size,
+					  const u8 *message, const u32 message_length,
+					  const u8 *masking_seed, u8 *encrypted_msg)
+{
+	int status;
+	u8 encrypt_msg[HDCP2X_TX_CERT_PUB_KEY_N_SIZE];
+
+	/* Step 1: Length checking */
+	if (message_length > (HDCP2X_TX_CERT_PUB_KEY_N_SIZE -
+			2 * HDCP2X_TX_SHA256_HASH_SIZE - 2))
+		return -EINVAL;
+
+	/* Step 2: EME-OAEP Encoding */
+	xlnx_hdcp2x_tx_pkcs1_eme_oaep_encode(message, message_length,
+					     masking_seed, encrypt_msg);
+
+	/* Step 3: RSA encryption */
+	status = xlnx_hdcp2x_tx_rsa_encrypt(rsa_public_key, public_key_size,
+					    exponent_key, exponent_key_size,
+					    encrypt_msg, public_key_size,
+					    encrypted_msg);
+	if (status)
+		return -EINVAL;
+
+	return 0;
+}
+
+/* Reference: PKCS#1 v2.1, Section 8.2.2 and Section 9.2 */
+static int xlnx_hdcp2x_tx_rsa_signature_verify(const u8 *msg_ptr, int msg_size,
+					       const u8 *signature,
+					       const u8 *dcp_cert_nvalue, int dcp_cert_nsize,
+					       const u8 *dcp_cert_evalue, int dcp_cert_esize)
+{
+	u8 encrypted_msg[HDCP2X_TX_CERT_SIGNATURE_SIZE];
+	u8 t_hash[HDCP2X_TX_SHA256_HASH_SIZE];
+	u8 *encrypted_msg_ptr = NULL;
+	int i;
+	int result = 0;
+
+	sha256(msg_ptr, msg_size, t_hash);
+
+	result = xlnx_hdcp2x_tx_rsa_encrypt(dcp_cert_nvalue, dcp_cert_nsize,
+					    dcp_cert_evalue, dcp_cert_esize,
+					    signature, HDCP2X_TX_CERT_SIGNATURE_SIZE,
+					    encrypted_msg);
+	if (result)
+		return -EINVAL;
+
+	if (encrypted_msg[0] != 0 || encrypted_msg[1] != 1)
+		return -EFAULT;
+
+	encrypted_msg_ptr = &encrypted_msg[HDCP2X_TX_CERT_RSVD_SIZE];
+	for (i = 0; i < HDCP2X_TX_CERT_PADDING_BYTES; i++) {
+		if (encrypted_msg_ptr[i] != GENMASK(7, 0))
+			return -EFAULT;
+	}
+
+	encrypted_msg_ptr = &encrypted_msg[HDCP2X_TX_CERT_PADDING_END_DELIMITER];
+	if (encrypted_msg_ptr[0])
+		return -EFAULT;
+
+	encrypted_msg_ptr = &encrypted_msg[HDCP2X_TX_CERT_PADDING_TI_IDENTIFIER];
+	if (memcmp(ti_identifier, encrypted_msg_ptr, HDCP2X_TX_CERT_TI_IDENTIFIER_SIZE))
+		return -EFAULT;
+
+	encrypted_msg_ptr = &encrypted_msg[HDCP2X_TX_CERT_PADDING_T_HASH];
+	if (memcmp(t_hash, encrypted_msg_ptr, HDCP2X_TX_CERT_T_HASH_SIZE))
+		return -EFAULT;
+
+	return result;
+}
+
+int xlnx_hdcp2x_tx_verify_certificate(const struct hdcp2x_tx_cert_rx *rx_certificate,
+				      const u8 *dcp_cert_nvalue, int dcp_cert_nsize,
+				      const u8 *dcp_cert_evalue, int dcp_cert_esize)
+{
+	return xlnx_hdcp2x_tx_rsa_signature_verify((u8 *)rx_certificate,
+						  (sizeof(struct hdcp2x_tx_cert_rx) -
+						  sizeof(rx_certificate->signature)),
+						  rx_certificate->signature,
+						  dcp_cert_nvalue, dcp_cert_nsize,
+						  dcp_cert_evalue, dcp_cert_esize);
+}
+
+int xlnx_hdcp2x_verify_srm(const u8 *srm, int srm_size,
+			   const u8 *dcp_cert_nvalue, int dcp_cert_nsize,
+			   const u8 *dcp_cert_evalue, int dcp_cert_esize)
+{
+	return xlnx_hdcp2x_tx_rsa_signature_verify((u8 *)srm,
+						  srm_size - HDCP2X_TX_SRM_SIGNATURE_SIZE,
+						  srm + (srm_size - HDCP2X_TX_SRM_SIGNATURE_SIZE),
+						  dcp_cert_nvalue, dcp_cert_nsize,
+						  dcp_cert_evalue, dcp_cert_esize);
+}
+
+static void xlnx_hdcp2x_tx_aes128_encrypt(const u8 *data, const u8 *key, u8 *output)
+{
+	struct crypto_aes_ctx ctx;
+
+	aes_expandkey(&ctx, key, HDCP2X_TX_AES128_SIZE);
+	aes_encrypt(&ctx, output, data);
+	memzero_explicit(&ctx, sizeof(ctx));
+}
+
+/*
+ * This function implements the HMAC Hash message for Authentication.
+ * Reference: http://www.citi.umich.edu/projects/nfsv4/rfc/pkcs-1v2-1.pdf
+ */
+static int xlnx_hdcp2x_cmn_hmac_sha256_hash(const u8 *data, int data_size, const u8 *key,
+					    int key_size, u8  *hashed_data)
+{
+	u8 buffer_in[XHDCP2X_TX_SHA_SIZE] = {0};
+	u8 buffer_out[XHDCP2X_TX_SHA_SIZE] = {0};
+	u8 ktemp[XHDCP2X_TX_SHA256_SIZE] = {0};
+	u8 ktemp2[XHDCP2X_TX_SHA256_SIZE] = {0};
+	u8 ipad[XHDCP2X_TX_SHA_KEY_LENGTH + 1] = {0};
+	u8 opad[XHDCP2X_TX_SHA_KEY_LENGTH + 1] = {0};
+	int i;
+
+	if (data_size + XHDCP2X_TX_SHA_KEY_LENGTH >  XHDCP2X_TX_SHA_SIZE)
+		return -EINVAL;
+
+	if (key_size > XHDCP2X_TX_SHA_KEY_LENGTH) {
+		sha256(key, key_size, ktemp);
+		key     = ktemp;
+		key_size = XHDCP2X_TX_SHA256_SIZE;
+	}
+
+	memcpy(ipad, key, key_size);
+	memcpy(opad, key, key_size);
+
+	for (i = 0; i < XHDCP2X_TX_SHA_KEY_LENGTH; i++) {
+		ipad[i] ^= XHDCP2X_TX_INNER_PADDING_BYTE;
+		opad[i] ^= XHDCP2X_TX_OUTER_PADDING_BYTE;
+	}
+
+	memcpy(buffer_in, ipad, XHDCP2X_TX_SHA_KEY_LENGTH);
+	memcpy(buffer_in + XHDCP2X_TX_SHA_KEY_LENGTH, data, data_size);
+	sha256(buffer_in, XHDCP2X_TX_SHA_KEY_LENGTH + data_size, ktemp2);
+
+	memcpy(buffer_out, opad, XHDCP2X_TX_SHA_KEY_LENGTH);
+	memcpy(buffer_out + XHDCP2X_TX_SHA_KEY_LENGTH, ktemp2, XHDCP2X_TX_SHA256_SIZE);
+	sha256(buffer_out, XHDCP2X_TX_SHA_KEY_LENGTH + XHDCP2X_TX_SHA256_SIZE, (u8 *)hashed_data);
+
+	return 0;
+}
+
+void xlnx_hdcp2x_tx_compute_hprime(const u8 *r_rx, const u8 *rxcaps,
+				   const u8 *r_tx, const u8 *txcaps,
+				   const u8 *km, u8 *hprime)
+{
+	u8 kd[HDCP2X_TX_DKEY_SIZE * HDCP2X_TX_AES128_SIZE] = {0};
+	u8 aes_iv[HDCP2X_TX_AES128_SIZE] = {0};
+	u8 aes_key[HDCP2X_TX_AES128_SIZE] = {0};
+	u8 hash_input[HDCP_2_2_RTX_LEN + HDCP_2_2_RXCAPS_LEN +
+				HDCP2X_TX_TXCAPS_SIZE] = {0};
+	int idx = 0;
+
+	memcpy(aes_key, km, HDCP2X_TX_KM_SIZE);
+	memcpy(aes_iv, r_tx, HDCP_2_2_RTX_LEN);
+	memcpy(&aes_iv[HDCP_2_2_RTX_LEN], r_rx, HDCP_2_2_RRX_LEN);
+
+	xlnx_hdcp2x_tx_aes128_encrypt(aes_iv, aes_key, kd);
+
+	/* Determine dkey1, counter is 1: Rrx | 0x01. */
+
+	/*
+	 * Reference: Section 2.7.1: Key derivation
+	 * https://www.digital-cp.com/sites/default/files/HDCP%20on%20DisplayPort%20Specification%20Rev2_3.pdf
+	 */
+	aes_iv[HDCP2X_TX_DKEY] ^= HDCP2X_TX_DKEY_CTR1;
+
+	xlnx_hdcp2x_tx_aes128_encrypt(aes_iv, aes_key, &kd[HDCP2X_TX_KM_SIZE]);
+	memcpy(hash_input, r_tx, HDCP_2_2_RTX_LEN);
+	idx += HDCP_2_2_RTX_LEN;
+	memcpy(&hash_input[idx], rxcaps, HDCP_2_2_RXCAPS_LEN);
+	idx += HDCP_2_2_RXCAPS_LEN;
+	memcpy(&hash_input[idx], txcaps, HDCP2X_TX_TXCAPS_SIZE);
+
+	xlnx_hdcp2x_cmn_hmac_sha256_hash(hash_input, sizeof(hash_input), kd,
+					 sizeof(kd), hprime);
+}
+
+void xlnx_hdcp2x_tx_compute_edkey_ks(const u8 *rn, const u8 *km, const u8 *ks,
+				     const u8 *r_rx, const u8 *r_tx,
+				     u8 *encrypted_ks)
+{
+	u8 aes_iv[HDCP2X_TX_AES128_SIZE] = {0};
+	u8 aes_key[HDCP2X_TX_AES128_SIZE] = {0};
+	u8 dkey2[HDCP2X_TX_AES128_SIZE] = {0};
+
+	memcpy(&aes_key[HDCP_2_2_RN_LEN], rn, HDCP_2_2_RN_LEN);
+
+	xlnx_hdcp2x_tx_memxor(aes_key, aes_key, km, HDCP2X_TX_KM_SIZE);
+
+	/* Determine dkey2. */
+	/* Add m = Rtx || Rrx. */
+	memcpy(aes_iv, r_tx, HDCP_2_2_RTX_LEN);
+	memcpy(&aes_iv[HDCP_2_2_RTX_LEN], r_rx, HDCP_2_2_RRX_LEN);
+
+	aes_iv[HDCP2X_TX_DKEY] ^= HDCP2X_TX_DKEY_CTR2;
+
+	xlnx_hdcp2x_tx_aes128_encrypt(aes_iv, aes_key, dkey2);
+
+	/* EdkeyKs = Ks XOR (Dkey2 XOR Rrx). */
+	/* Rrx XOR Dkey2. */
+	memset(encrypted_ks, 0, HDCP_2_2_E_DKEY_KS_LEN);
+
+	memcpy(&encrypted_ks[HDCP_2_2_E_DKEY_KS_LEN - HDCP_2_2_RRX_LEN], r_rx,
+	       HDCP_2_2_RRX_LEN);
+
+	xlnx_hdcp2x_tx_memxor(encrypted_ks, encrypted_ks, dkey2, HDCP2X_TX_AES128_SIZE);
+	xlnx_hdcp2x_tx_memxor(encrypted_ks, encrypted_ks, ks, HDCP2X_TX_KS_SIZE);
+}
+
+void xlnx_hdcp2x_tx_compute_lprime(const u8 *rn, const u8 *km,
+				   const u8 *r_rx, const u8 *r_tx,
+				   u8 *lprime)
+{
+	u8 hash_key[HDCP2X_TX_SHA256_HASH_SIZE] = {0};
+	u8 aes_iv[HDCP2X_TX_AES128_SIZE] = {0};
+	u8 aes_key[HDCP2X_TX_AES128_SIZE] = {0};
+	u8 kd[HDCP2X_TX_DKEY_SIZE * HDCP2X_TX_AES128_SIZE] = {0};
+
+	memcpy(aes_key, km, HDCP2X_TX_KM_SIZE);
+	memcpy(aes_iv, r_tx, HDCP_2_2_RTX_LEN);
+	memcpy(&aes_iv[HDCP_2_2_RTX_LEN], r_rx, HDCP_2_2_RRX_LEN);
+
+	/* Compute Dkey0. */
+	/* Add m = Rtx || Rrx. */
+	xlnx_hdcp2x_tx_aes128_encrypt(aes_iv, aes_key, kd);
+
+	/* Compute Dkey , counter is 1: Rrx | 0x01. */
+	aes_iv[HDCP2X_TX_DKEY] ^= HDCP2X_TX_DKEY_CTR1;
+	xlnx_hdcp2x_tx_aes128_encrypt(aes_iv, aes_key, &kd[HDCP2X_TX_KM_SIZE]);
+
+	/* Create hash with HMAC-SHA256. */
+	/* Key:	Kd XOR Rrx (least sign. 64 bits). */
+	memcpy(&hash_key[HDCP2X_TX_SHA256_HASH_SIZE - HDCP_2_2_RRX_LEN], r_rx,
+	       HDCP_2_2_RRX_LEN);
+
+	xlnx_hdcp2x_tx_memxor(hash_key, hash_key, kd, HDCP2X_TX_SHA256_HASH_SIZE);
+	xlnx_hdcp2x_cmn_hmac_sha256_hash(rn, HDCP_2_2_RN_LEN, hash_key,
+					 HDCP2X_TX_SHA256_HASH_SIZE, lprime);
+}
+
+void xlnx_hdcp2x_tx_compute_v(const u8 *rn, const u8 *r_rx, const u8 *rx_info,
+			      const u8 *r_tx, const u8 *rcvid_list, const u8 rcvid_count,
+			      const u8 *seq_num_v, const u8 *km, u8 *hash_v)
+{
+	u8 kd[HDCP2X_TX_DKEY_SIZE * HDCP2X_TX_AES128_SIZE] = {0};
+	u8 aes_iv[HDCP2X_TX_AES128_SIZE] = {0};
+	u8 aes_key[HDCP2X_TX_AES128_SIZE] = {0};
+	u8 hash_input[(HDCP_2_2_MAX_DEVICE_COUNT * HDCP_2_2_RECEIVER_ID_LEN) +
+				  HDCP_2_2_RXINFO_LEN + HDCP_2_2_SEQ_NUM_LEN];
+	int idx = 0;
+
+	memcpy(aes_key, km, HDCP2X_TX_KM_SIZE);
+
+	/* Determine Dkey. */
+	/* Add m = Rtx || Rrx. */
+	memcpy(aes_iv, r_tx, HDCP_2_2_RTX_LEN);
+	memcpy(&aes_iv[HDCP_2_2_RTX_LEN], r_rx, HDCP_2_2_RRX_LEN);
+
+	xlnx_hdcp2x_tx_aes128_encrypt(aes_iv, aes_key, kd);
+
+	aes_iv[HDCP2X_TX_DKEY] ^= HDCP2X_TX_DKEY_CTR1;
+	xlnx_hdcp2x_tx_aes128_encrypt(aes_iv, aes_key, &kd[HDCP2X_TX_KM_SIZE]);
+
+	/* Create hash with HMAC-SHA256. */
+	/* Input: ReceiverID list || RxInfo || seq_num_V. */
+	memcpy(hash_input, rcvid_list, (rcvid_count * HDCP_2_2_RECEIVER_ID_LEN));
+	idx += (rcvid_count * HDCP_2_2_RECEIVER_ID_LEN);
+	memcpy(&hash_input[idx], rx_info, HDCP_2_2_RXINFO_LEN);
+	idx += HDCP_2_2_RXINFO_LEN;
+	memcpy(&hash_input[idx], seq_num_v, HDCP_2_2_SEQ_NUM_LEN);
+	idx += HDCP_2_2_SEQ_NUM_LEN;
+
+	xlnx_hdcp2x_cmn_hmac_sha256_hash(hash_input, idx, kd, sizeof(kd), hash_v);
+}
+
+void xlnx_hdcp2x_tx_compute_m(const u8 *rn, const u8 *r_rx, const u8 *r_tx,
+			      const u8 *stream_id_type, const u8 *k,
+			      const u8 *seq_num_m, const u8 *km, u8 *m_hash)
+{
+	u8 aes_iv[HDCP2X_TX_AES128_SIZE];
+	u8 aes_key[HDCP2X_TX_AES128_SIZE];
+	u8 kd[HDCP2X_TX_DKEY_SIZE * HDCP2X_TX_AES128_SIZE];
+	u8 sha256_kd[HDCP2X_TX_SHA256_HASH_SIZE];
+	u8 hash_input[(HDCP_2_2_MAX_DEVICE_COUNT * HDCP_2_2_RECEIVER_ID_LEN) +
+				  HDCP_2_2_RXINFO_LEN + HDCP_2_2_SEQ_NUM_LEN];
+	u16 stream_id_count;
+	int idx = 0;
+
+	stream_id_count  = k[0] << BITS_PER_BYTE;
+	stream_id_count |= k[1];
+
+	memcpy(aes_key, km, HDCP2X_TX_KM_SIZE);
+	memcpy(aes_iv, r_tx, HDCP_2_2_RTX_LEN);
+	memcpy(&aes_iv[HDCP_2_2_RTX_LEN], r_rx, HDCP_2_2_RRX_LEN);
+
+	xlnx_hdcp2x_tx_aes128_encrypt(aes_iv, aes_key, kd);
+
+	/* Determine Dkey0. */
+	/* Add m = Rtx || Rrx. */
+	aes_iv[HDCP2X_TX_DKEY] ^= HDCP2X_TX_DKEY_CTR1;
+
+	xlnx_hdcp2x_tx_aes128_encrypt(aes_iv, aes_key, &kd[HDCP2X_TX_KM_SIZE]);
+
+	sha256(kd, sizeof(kd), sha256_kd);
+
+	/* Create hash with HMAC-SHA256. */
+	/* Input: StreamID_Type list || seq_num_M. */
+	memcpy(hash_input, stream_id_type, (stream_id_count * HDCP2X_TX_STREAMID_TYPE_SIZE));
+	idx += (stream_id_count * HDCP2X_TX_STREAMID_TYPE_SIZE);
+	memcpy(&hash_input[idx], seq_num_m, HDCP_2_2_SEQ_NUM_LEN);
+	idx += HDCP_2_2_SEQ_NUM_LEN;
+
+	/* HashKey:	SHA256(Kd) */
+	xlnx_hdcp2x_cmn_hmac_sha256_hash(hash_input, idx, sha256_kd, sizeof(sha256_kd), m_hash);
+}
+
+int xlnx_hdcp2x_tx_encryptedkm(const struct hdcp2x_tx_cert_rx *rx_certificate,
+			       const u8 *km_ptr, u8 *masking_seed, u8 *encrypted_km)
+{
+	return xlnx_hdcp2x_tx_rsa_oae_encrypt(rx_certificate->N, HDCP2X_TX_CERT_PUB_KEY_N_SIZE,
+					      rx_certificate->e, HDCP2X_TX_CERT_PUB_KEY_E_SIZE,
+					      km_ptr, HDCP2X_TX_KM_SIZE,
+					      masking_seed, encrypted_km);
+}
diff --git a/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp2x_tx.c b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp2x_tx.c
new file mode 100644
index 000000000..9735a1cec
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp2x_tx.c
@@ -0,0 +1,1267 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx Specific HDCP2X driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Lakshmi Prasanna Eachuri <lakshmi.prasanna.eachuri@amd.com>
+ *
+ * This driver configures Xilinx HDCP IP and its internal modules like Cipher and
+ * Random Number Generator.
+ * It consists of:
+ * - Functionality for checking if the HDCP2X Receiver sink does respond within
+ *   specified times.
+ * - Message handling from/to the HDCP2X receiver sink.
+ *
+ * Reference:
+ * https://www.digital-cp.com/sites/default/files/HDCP%20on%20DisplayPort%20Specification%20Rev2_3.pdf
+ */
+
+#include <linux/io.h>
+#include <linux/xlnx/xlnx_hdcp_common.h>
+#include <linux/xlnx/xlnx_hdcp2x_cipher.h>
+#include <linux/xlnx/xlnx_hdcp_rng.h>
+#include <linux/xlnx/xlnx_timer.h>
+#include "xhdcp2x_tx.h"
+#include "xlnx_hdcp2x_tx.h"
+
+#define XHDCP2X_CIPHER_OFFSET	0U
+#define XHDCP2X_RNG_OFFSET	0x1000U
+
+#define XHDCP2X_SRM_MESSAGE_HEADER_LENGTH	0x05
+
+/* Public transmitter DCP LLC key - n=384 bytes, e=1 byte */
+
+/*
+ * Reference:
+ * https://www.digital-cp.com/sites/default/files/HDCP%20on%20HDMI%20Specification%20Rev2_3.pdf
+ * Table B.1
+ */
+static const u8 hdcp2x_tx_kpubdpc[HDCP2X_TX_KPUB_DCP_LLC_N_SIZE
+				 + XHDCP2X_TX_KPUB_DCP_LLC_E_SIZE] = {
+	0xB0, 0xE9, 0xAA, 0x45, 0xF1, 0x29, 0xBA, 0x0A,
+	0x1C, 0xBE, 0x17, 0x57, 0x28, 0xEB, 0x2B, 0x4E,
+	0x8F, 0xD0, 0xC0, 0x6A, 0xAD, 0x79, 0x98, 0x0F,
+	0x8D, 0x43, 0x8D, 0x47, 0x04, 0xB8, 0x2B, 0xF4,
+	0x15, 0x21, 0x56, 0x19, 0x01, 0x40, 0x01, 0x3B,
+	0xD0, 0x91, 0x90, 0x62, 0x9E, 0x89, 0xC2, 0x27,
+	0x8E, 0xCF, 0xB6, 0xDB, 0xCE, 0x3F, 0x72, 0x10,
+	0x50, 0x93, 0x8C, 0x23, 0x29, 0x83, 0x7B, 0x80,
+	0x64, 0xA7, 0x59, 0xE8, 0x61, 0x67, 0x4C, 0xBC,
+	0xD8, 0x58, 0xB8, 0xF1, 0xD4, 0xF8, 0x2C, 0x37,
+	0x98, 0x16, 0x26, 0x0E, 0x4E, 0xF9, 0x4E, 0xEE,
+	0x24, 0xDE, 0xCC, 0xD1, 0x4B, 0x4B, 0xC5, 0x06,
+	0x7A, 0xFB, 0x49, 0x65, 0xE6, 0xC0, 0x00, 0x83,
+	0x48, 0x1E, 0x8E, 0x42, 0x2A, 0x53, 0xA0, 0xF5,
+	0x37, 0x29, 0x2B, 0x5A, 0xF9, 0x73, 0xC5, 0x9A,
+	0xA1, 0xB5, 0xB5, 0x74, 0x7C, 0x06, 0xDC, 0x7B,
+	0x7C, 0xDC, 0x6C, 0x6E, 0x82, 0x6B, 0x49, 0x88,
+	0xD4, 0x1B, 0x25, 0xE0, 0xEE, 0xD1, 0x79, 0xBD,
+	0x39, 0x85, 0xFA, 0x4F, 0x25, 0xEC, 0x70, 0x19,
+	0x23, 0xC1, 0xB9, 0xA6, 0xD9, 0x7E, 0x3E, 0xDA,
+	0x48, 0xA9, 0x58, 0xE3, 0x18, 0x14, 0x1E, 0x9F,
+	0x30, 0x7F, 0x4C, 0xA8, 0xAE, 0x53, 0x22, 0x66,
+	0x2B, 0xBE, 0x24, 0xCB, 0x47, 0x66, 0xFC, 0x83,
+	0xCF, 0x5C, 0x2D, 0x1E, 0x3A, 0xAB, 0xAB, 0x06,
+	0xBE, 0x05, 0xAA, 0x1A, 0x9B, 0x2D, 0xB7, 0xA6,
+	0x54, 0xF3, 0x63, 0x2B, 0x97, 0xBF, 0x93, 0xBE,
+	0xC1, 0xAF, 0x21, 0x39, 0x49, 0x0C, 0xE9, 0x31,
+	0x90, 0xCC, 0xC2, 0xBB, 0x3C, 0x02, 0xC4, 0xE2,
+	0xBD, 0xBD, 0x2F, 0x84, 0x63, 0x9B, 0xD2, 0xDD,
+	0x78, 0x3E, 0x90, 0xC6, 0xC5, 0xAC, 0x16, 0x77,
+	0x2E, 0x69, 0x6C, 0x77, 0xFD, 0xED, 0x8A, 0x4D,
+	0x6A, 0x8C, 0xA3, 0xA9, 0x25, 0x6C, 0x21, 0xFD,
+	0xB2, 0x94, 0x0C, 0x84, 0xAA, 0x07, 0x29, 0x26,
+	0x46, 0xF7, 0x9B, 0x3A, 0x19, 0x87, 0xE0, 0x9F,
+	0xEB, 0x30, 0xA8, 0xF5, 0x64, 0xEB, 0x07, 0xF1,
+	0xE9, 0xDB, 0xF9, 0xAF, 0x2C, 0x8B, 0x69, 0x7E,
+	0x2E, 0x67, 0x39, 0x3F, 0xF3, 0xA6, 0xE5, 0xCD,
+	0xDA, 0x24, 0x9B, 0xA2, 0x78, 0x72, 0xF0, 0xA2,
+	0x27, 0xC3, 0xE0, 0x25, 0xB4, 0xA1, 0x04, 0x6A,
+	0x59, 0x80, 0x27, 0xB5, 0xDA, 0xB4, 0xB4, 0x53,
+	0x97, 0x3B, 0x28, 0x99, 0xAC, 0xF4, 0x96, 0x27,
+	0x0F, 0x7F, 0x30, 0x0C, 0x4A, 0xAF, 0xCB, 0x9E,
+	0xD8, 0x71, 0x28, 0x24, 0x3E, 0xBC, 0x35, 0x15,
+	0xBE, 0x13, 0xEB, 0xAF, 0x43, 0x01, 0xBD, 0x61,
+	0x24, 0x54, 0x34, 0x9F, 0x73, 0x3E, 0xB5, 0x10,
+	0x9F, 0xC9, 0xFC, 0x80, 0xE8, 0x4D, 0xE3, 0x32,
+	0x96, 0x8F, 0x88, 0x10, 0x23, 0x25, 0xF3, 0xD3,
+	0x3E, 0x6E, 0x6D, 0xBB, 0xDC, 0x29, 0x66, 0xEB,
+	0x03
+};
+
+/*
+ * This function is used to load the system renewability messages (SRMs)
+ * which carries the Receiver ID revocation list.
+ * Reference:
+ * https://www.digital-cp.com/sites/default/files/HDCP%20on%20DisplayPort%20Specification%20Rev2_3.pdf
+ * Section 5.1.
+ */
+static int xlnx_hdcp2x_loadsrm_revocation_table(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+						const u8 *srm_input)
+{
+	struct hdcp2x_tx_revoclist *revocation_list = &xhdcp2x_tx->xhdcp2x_revoc_list;
+	const u8 *kpubdpc = NULL;
+	const u8 *srmblock = NULL;
+	const u8 *rcv_id;
+	u32 block_size, length_field;
+	u16 num_of_devices;
+	int ret, i, j;
+	u8 srm_generator, srm_id;
+
+	srmblock = srm_input;
+
+	/* Byte 1 contains the SRM ID and HDCP2 Indicator field */
+	srm_id = srmblock[0];
+
+	if (srm_id != HDCP2X_TX_SRM_ID)
+		return -EINVAL;
+
+	/* Byte 5 contains the SRM Generation Number */
+	srm_generator = srmblock[4];
+
+	/* Get the length of the first-generation SRM in bytes.*/
+	length_field  = drm_hdcp_be24_to_cpu(srmblock + XHDCP2X_SRM_MESSAGE_HEADER_LENGTH);
+
+	/* The size of the first-generation SRM block */
+	block_size = length_field + XHDCP2X_SRM_MESSAGE_HEADER_LENGTH;
+
+	kpubdpc = hdcp2x_tx_kpubdpc;
+
+	ret = xlnx_hdcp2x_verify_srm(srmblock, block_size, kpubdpc, HDCP2X_TX_KPUB_DCP_LLC_N_SIZE,
+				     &kpubdpc[HDCP2X_TX_KPUB_DCP_LLC_N_SIZE],
+				     HDCP2X_TX_KPUB_DCP_LLC_E_SIZE);
+	if (ret)
+		return -EINVAL;
+
+	srmblock += block_size;
+
+	for (i = 1; i < srm_generator; i++) {
+		/*
+		 * Byte 1-2 contain the length of the next-generation SRM in bytes.
+		 * Value is in big endian format, Microblaze is little endian.
+		 */
+		length_field  = srmblock[0] << BITS_PER_BYTE;
+		length_field |= srmblock[1];
+
+		block_size = length_field;
+
+		ret = xlnx_hdcp2x_verify_srm(srmblock, block_size,
+					     kpubdpc, HDCP2X_TX_KPUB_DCP_LLC_N_SIZE,
+					     &kpubdpc[HDCP2X_TX_KPUB_DCP_LLC_N_SIZE],
+					     HDCP2X_TX_KPUB_DCP_LLC_E_SIZE);
+		if (ret)
+			return -EINVAL;
+
+		srmblock += block_size;
+	}
+
+	srmblock = srm_input;
+
+	/* Get the length of the first-generation SRM in bytes.*/
+	length_field  = drm_hdcp_be24_to_cpu(srmblock + XHDCP2X_SRM_MESSAGE_HEADER_LENGTH);
+
+	block_size = length_field + XHDCP2X_SRM_MESSAGE_HEADER_LENGTH;
+
+	/*
+	 * Byte 9,10 contain the number of devices of the firs-generation SRM block
+	 * Value is in big endian format, Microblaze is little endia.
+	 */
+	num_of_devices = ((srmblock[8] << 2) | DRM_HDCP_2_KSV_COUNT_2_LSBITS(srmblock[9]));
+	revocation_list->num_of_devices = 0;
+
+	/* Byte 12 will contain the first byte of the first receiver ID */
+	rcv_id = &srmblock[12];
+
+	for (i = 0; i < num_of_devices; i++) {
+		if (revocation_list->num_of_devices ==
+				HDCP2X_TX_REVOCATION_LIST_MAX_DEVICES)
+			return -EINVAL;
+		memcpy(revocation_list->rcvid[revocation_list->num_of_devices],
+		       rcv_id, XHDCP2X_TX_SRM_RCVID_SIZE);
+		revocation_list->num_of_devices++;
+		rcv_id += XHDCP2X_TX_SRM_RCVID_SIZE;
+	}
+	srmblock += block_size;
+
+	for (j = 1; j < srm_generator; j++) {
+		/*
+		 * Byte 1-2 contain the length of the next-generation SRM in bytes.
+		 * Value is in big endian format, Microblaze is little endian.
+		 */
+		length_field  = srmblock[0] << BITS_PER_BYTE;
+		length_field |= srmblock[1];
+
+		block_size = length_field;
+
+		/*
+		 * Byte 3,4 contain the number of devices of the next-generation SRM block
+		 * Value is in big endian format, Microblaze is little endian.
+		 */
+		num_of_devices  = (srmblock[2] & DRM_HDCP_2_VRL_LENGTH_SIZE) << BITS_PER_BYTE;
+		num_of_devices |=  srmblock[3];
+
+		/* Byte 5 will contain the first byte of the first receiver ID */
+		rcv_id = &srmblock[4];
+
+		for (i = 0; i < num_of_devices; i++) {
+			if (revocation_list->num_of_devices ==
+					HDCP2X_TX_REVOCATION_LIST_MAX_DEVICES)
+				return -EINVAL;
+			memcpy(revocation_list->rcvid[revocation_list->num_of_devices],
+			       rcv_id, XHDCP2X_TX_SRM_RCVID_SIZE);
+			revocation_list->num_of_devices++;
+			rcv_id += XHDCP2X_TX_SRM_RCVID_SIZE;
+		}
+		srmblock += block_size;
+	}
+
+	xhdcp2x_tx->xhdcp2x_info.is_revoc_list_valid = 1;
+
+	return 0;
+}
+
+static bool xlnx_hdcp2x_tx_ds_authenticated(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	return((xhdcp2x_tx->xhdcp2x_info.auth_status ==
+			XHDCP2X_TX_AUTHENTICATED) ? 1 : 0);
+}
+
+const u8 *xlnx_hdcp2x_tx_get_publickey(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	if (!xhdcp2x_tx->xhdcp2x_info.is_enabled)
+		return NULL;
+
+	return hdcp2x_tx_kpubdpc;
+}
+
+int xlnx_hdcp2x_tx_init(struct xlnx_hdcp2x_config *xhdcp2x_tx, bool is_repeater)
+{
+	/**
+	 * This array contains the capabilities of the HDCP2X TX core,
+	 * and is transmitted during authentication as part of the AKE_Init message.
+	 */
+	u8 hdcp2x_txcaps[] = { 0x02, 0x00, 0x00 };
+
+	int ret = 0;
+
+	xhdcp2x_tx->txcaps = (u8 *)hdcp2x_txcaps;
+	xhdcp2x_tx->is_hdmi = xhdcp2x_tx->xhdcp2x_hw.protocol == XHDCP2X_TX_HDMI ? 1 : 0;
+
+	xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher.cipher_coreaddress =
+			xhdcp2x_tx->xhdcp2x_hw.hdcp2xcore_address + XHDCP2X_CIPHER_OFFSET;
+	xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_rng.rng_coreaddress =
+			xhdcp2x_tx->xhdcp2x_hw.hdcp2xcore_address + XHDCP2X_RNG_OFFSET;
+
+	ret = xlnx_hdcp2x_rng_cfg_init(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_rng);
+	if (ret < 0)
+		return -EINVAL;
+
+	xlnx_hdcp2x_rng_enable(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_rng);
+	xhdcp2x_tx->xhdcp2x_hw.tx_mode = is_repeater;
+
+	ret = xlnx_hdcp2x_cipher_cfg_init(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher);
+	if (ret < 0)
+		return -EINVAL;
+
+	xhdcp2x_tx->xhdcp2x_info.polling_value = 0;
+
+	memcpy(xhdcp2x_tx->xhdcp2x_info.txcaps, (u8 *)xhdcp2x_tx->txcaps,
+	       sizeof(xhdcp2x_tx->xhdcp2x_info.txcaps));
+
+	xlnx_hdcp2x_cipher_init(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher);
+
+	return ret;
+}
+
+int xlnx_hdcp2x_loadkeys(struct xlnx_hdcp2x_config *xhdcp2x_tx, u8 *srm_key, u8 *lc128_key)
+{
+	int ret;
+
+	xhdcp2x_tx->srmkey = (u8 *)srm_key;
+	xhdcp2x_tx->lc128key = (u8 *)lc128_key;
+
+	xlnx_hdcp2x_cipher_set_keys(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher,
+				    xhdcp2x_tx->lc128key, XHDCP2X_CIPHER_REG_LC128_1_OFFSET,
+				    XHDCP2X_TX_LC128_SIZE);
+
+	ret = xlnx_hdcp2x_loadsrm_revocation_table(xhdcp2x_tx, xhdcp2x_tx->srmkey);
+	if (ret < 0)
+		return -EINVAL;
+
+	return ret;
+}
+
+u8 xlnx_hdcp2x_tx_is_device_revoked(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+				    u8 *rcvid)
+{
+	struct hdcp2x_tx_revoclist *revoc_list = NULL;
+	u32 result, i;
+
+	revoc_list = &xhdcp2x_tx->xhdcp2x_revoc_list;
+
+	for (i = 0; i < revoc_list->num_of_devices; i++) {
+		result = memcmp(rcvid, revoc_list->rcvid[i], XHDCP2X_TX_SRM_RCVID_SIZE);
+		if (!result)
+			return 1;
+	}
+
+	return 0;
+}
+
+static void xlnx_hdcp2x_tx_enble(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	xhdcp2x_tx->xhdcp2x_info.is_enabled = 1;
+	xlnx_hdcp2x_cipher_enable(xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher.cipher_coreaddress);
+	xlnx_hdcp2x_cipher_set_lanecount(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher,
+					 xhdcp2x_tx->lane_count);
+	xlnx_hdcp_tmrcntr_stop(&xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr,
+			       XHDCP2X_TX_TIMER_CNTR_0);
+}
+
+static u8 xlnx_hdcp2x_tx_is_ds_repeater(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	return (xhdcp2x_tx->xhdcp2x_hw.tx_mode != XHDCP2X_TX_TRANSMITTER) ? 1 : 0;
+}
+
+static int xlnx_hdcp2x_tx_start_authenticate(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	if (!xhdcp2x_tx->xhdcp2x_info.is_enabled)
+		return -EINVAL;
+
+	xhdcp2x_tx->xhdcp2x_info.is_rcvr_hdcp2x_capable = 0;
+
+	xhdcp2x_tx->xhdcp2x_info.auth_status =
+			XHDCP2X_TX_AUTHENTICATION_BUSY;
+
+	xhdcp2x_tx->xhdcp2x_info.curr_state = H0_HDCP2X_TX_NO_RX_ATTACHED;
+	xhdcp2x_tx->xhdcp2x_info.prev_state = H0_HDCP2X_TX_NO_RX_ATTACHED;
+
+	if (xlnx_hdcp2x_tx_is_ds_repeater(xhdcp2x_tx))
+		xhdcp2x_tx->xhdcp2x_info.is_content_stream_type_set = 0;
+
+	return 0;
+}
+
+void xlnx_start_hdcp2x_engine(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	xlnx_hdcp2x_tx_enble(xhdcp2x_tx);
+	xlnx_hdcp2x_tx_start_authenticate(xhdcp2x_tx);
+}
+
+static void xlnx_hdcp2x_tx_disable(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	xhdcp2x_tx->xhdcp2x_info.is_enabled = 0;
+	xlnx_hdcp2x_cipher_disable(xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher.cipher_coreaddress);
+}
+
+int xlnx_hdcp2x_tx_reset(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	if (!xhdcp2x_tx->xhdcp2x_info.is_enabled) {
+		dev_dbg(xhdcp2x_tx->dev, "HDCP is not started");
+		return -EINVAL;
+	}
+	xhdcp2x_tx->xhdcp2x_info.auth_status =	XHDCP2X_TX_UNAUTHENTICATED;
+
+	xhdcp2x_tx->xhdcp2x_info.curr_state = H0_HDCP2X_TX_NO_RX_ATTACHED;
+	xhdcp2x_tx->xhdcp2x_info.prev_state = H0_HDCP2X_TX_NO_RX_ATTACHED;
+	xhdcp2x_tx->xhdcp2x_info.lc_counter = 0;
+
+	xlnx_hdcp_tmrcntr_stop(&xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr,
+			       XHDCP2X_TX_TIMER_CNTR_0);
+	xlnx_hdcp_tmrcntr_reset(&xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr, 0);
+
+	xhdcp2x_tx->xhdcp2x_info.content_stream_type = XHDCP2X_STREAMTYPE_0;
+	xhdcp2x_tx->xhdcp2x_info.is_content_stream_type_set = 1;
+	xhdcp2x_tx->xhdcp2x_revoc_list.num_of_devices = 0;
+	xlnx_hdcp2x_tx_disable_encryption(xhdcp2x_tx);
+
+	xlnx_hdcp2x_tx_disable(xhdcp2x_tx);
+
+	return 0;
+}
+
+void xlnx_hdcp2x_tx_enable_encryption(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	if (xlnx_hdcp2x_tx_ds_authenticated(xhdcp2x_tx)) {
+		xlnx_hdcp2x_tx_cipher_update_encryption(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher,
+							1);
+		dev_dbg(xhdcp2x_tx->dev, "enable encryption");
+	}
+}
+
+void xlnx_hdcp2x_tx_disable_encryption(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	xlnx_hdcp2x_tx_cipher_update_encryption(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher, 0);
+	dev_dbg(xhdcp2x_tx->dev, "disable encryption");
+}
+
+bool xlnx_hdcp2x_downstream_capbility(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	u8 rxcaps[HDCP_2_2_RXCAPS_LEN] = {0};
+	u8 hdcp2_version;
+
+	if (xhdcp2x_tx->is_hdmi) {
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP_2_2_HDMI_REG_VER_OFFSET,
+						(void *)&hdcp2_version,
+						sizeof(hdcp2_version));
+
+		return (hdcp2_version & HDCP_2_2_HDMI_SUPPORT_MASK);
+	}
+	xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+					HDCP2X_TX_HDCPPORT_RX_CAPS_OFFSET,
+					(void *)rxcaps,
+					HDCP_2_2_RXCAPS_LEN);
+
+	return ((rxcaps[0] == HDCP_2_2_RX_CAPS_VERSION_VAL) &&
+		HDCP_2_2_DP_HDCP_CAPABLE(rxcaps[2]));
+}
+
+static u32 xlnx_hdcp2x_tx_get_timer_count(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	return xlnx_hdcp_tmrcntr_get_value(&xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr,
+					   XHDCP2X_TX_TIMER_CNTR_0);
+}
+
+static int xlnx_hdcp2x_hdmitx_read_msg(struct xlnx_hdcp2x_config *xhdcp2x_tx, u8 msg_id)
+{
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+	int msg_read = 0;
+	int status = -EINVAL;
+
+	tx_msg->msg = msg_id;
+
+	switch (msg_id) {
+	case HDCP_2_2_AKE_SEND_CERT:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP_2_2_HDMI_REG_RD_MSG_OFFSET,
+						(u8 *)&tx_msg->msg_type.msg_id,
+						sizeof(struct hdcp2x_tx_ake_sendcert));
+
+		if (msg_read == sizeof(struct hdcp2x_tx_ake_sendcert))
+			status = 0;
+		break;
+	case HDCP_2_2_AKE_SEND_HPRIME:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP_2_2_HDMI_REG_RD_MSG_OFFSET,
+						(u8 *)&tx_msg->msg_type.msg_id,
+						sizeof(struct hdcp2x_tx_ake_sendprime));
+
+		if (msg_read == sizeof(struct hdcp2x_tx_ake_sendprime))
+			status = 0;
+		break;
+	case HDCP_2_2_AKE_SEND_PAIRING_INFO:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP_2_2_HDMI_REG_RD_MSG_OFFSET,
+						(u8 *)&tx_msg->msg_type.msg_id,
+						sizeof(struct
+						hdcp2x_tx_ake_send_pairing_info));
+
+		if (msg_read == sizeof(struct hdcp2x_tx_ake_send_pairing_info))
+			status = 0;
+		break;
+	case HDCP_2_2_LC_SEND_LPRIME:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP_2_2_HDMI_REG_RD_MSG_OFFSET,
+						(u8 *)&tx_msg->msg_type.msg_id,
+						sizeof(struct hdcp2x_tx_lc_send_lc_prime));
+
+		if (msg_read == sizeof(struct hdcp2x_tx_lc_send_lc_prime))
+			status = 0;
+		break;
+	case HDCP_2_2_REP_SEND_RECVID_LIST:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP_2_2_HDMI_REG_RD_MSG_OFFSET,
+						(u8 *)&tx_msg->msg_type.msg_id,
+						sizeof(struct hdcp2x_tx_rpt_auth_send_rcvid_list));
+
+		if (msg_read == sizeof(struct hdcp2x_tx_rpt_auth_send_rcvid_list))
+			status = 0;
+		break;
+	case HDCP_2_2_REP_STREAM_READY:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP_2_2_HDMI_REG_RD_MSG_OFFSET,
+						(u8 *)&tx_msg->msg_type.msg_id,
+						sizeof(struct
+						hdcp2x_tx_rpt_auth_stream_ready));
+
+		if (msg_read == sizeof(struct hdcp2x_tx_rpt_auth_stream_ready))
+			status = 0;
+		break;
+	default:
+		status = -EINVAL;
+		break;
+	}
+
+	return status;
+}
+
+int xlnx_hdcp2x_tx_read_msg(struct xlnx_hdcp2x_config *xhdcp2x_tx, u8 msg_id)
+{
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+	int msg_read = 0;
+	int status = -EINVAL;
+
+	if (xhdcp2x_tx->xhdcp2x_hw.protocol == XHDCP2X_TX_HDMI)
+		return xlnx_hdcp2x_hdmitx_read_msg(xhdcp2x_tx, msg_id);
+
+	switch (msg_id) {
+	case HDCP_2_2_AKE_SEND_CERT:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_CERT_RX_OFFSET,
+						tx_msg->msg_type.ake_send_cert.cert_rx.rcvid,
+						HDCP2X_TX_CERT_SIZE);
+		msg_read +=
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_R_RX_OFFSET,
+						tx_msg->msg_type.ake_send_cert.r_rx,
+						HDCP_2_2_RRX_LEN);
+		msg_read +=
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_RX_CAPS_OFFSET,
+						tx_msg->msg_type.ake_send_cert.rxcaps,
+						HDCP_2_2_RXCAPS_LEN);
+		if (msg_read == (HDCP2X_TX_CERT_SIZE +
+				 HDCP_2_2_RRX_LEN +
+				 HDCP_2_2_RXCAPS_LEN))
+			status = 0;
+		break;
+	case HDCP_2_2_AKE_SEND_HPRIME:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_H_PRIME_OFFSET,
+						tx_msg->msg_type.ake_send_prime.h_prime,
+						HDCP_2_2_H_PRIME_LEN);
+		if (msg_read == HDCP_2_2_H_PRIME_LEN)
+			status = 0;
+		break;
+	case HDCP_2_2_AKE_SEND_PAIRING_INFO:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_E_KH_KM_PAIRING_OFFSET,
+						tx_msg->msg_type.ake_send_pairing_info.ekh_km,
+						HDCP_2_2_E_KH_KM_LEN);
+		if (msg_read == HDCP_2_2_E_KH_KM_LEN)
+			status = 0;
+		break;
+	case HDCP_2_2_LC_SEND_LPRIME:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_L_PRIME_OFFSET,
+						tx_msg->msg_type.lcsend_lcprime.lprime,
+						HDCP_2_2_L_PRIME_LEN);
+		if (msg_read == HDCP_2_2_L_PRIME_LEN)
+			status = 0;
+		break;
+	case HDCP_2_2_REP_SEND_RECVID_LIST:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_RX_INFO_OFFSET,
+						tx_msg->msg_type.rpt_auth_send_rcvid.rxinfo,
+						HDCP_2_2_RXINFO_LEN);
+		msg_read +=
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_SEQ_NUM_V_OFFSET,
+						tx_msg->msg_type.rpt_auth_send_rcvid.seq_num_v,
+						HDCP_2_2_SEQ_NUM_LEN);
+		msg_read +=
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_V_PRIME_OFFSET,
+						tx_msg->msg_type.rpt_auth_send_rcvid.vprime,
+						HDCP_2_2_V_PRIME_HALF_LEN);
+		msg_read +=
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_RCVR_ID_LST_OFFSET, (u8 *)
+						tx_msg->msg_type.rpt_auth_send_rcvid.rcvids,
+						HDCP2X_TX_HDCPPORT_RCVR_ID_LST_MAX_SIZE);
+		if (msg_read == HDCP_2_2_RXINFO_LEN +
+				HDCP_2_2_SEQ_NUM_LEN +
+				HDCP_2_2_V_PRIME_HALF_LEN +
+				HDCP2X_TX_HDCPPORT_RCVR_ID_LST_MAX_SIZE)
+			status = 0;
+		break;
+	case HDCP_2_2_REP_STREAM_READY:
+		msg_read =
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_M_PRIME_OFFSET,
+						tx_msg->msg_type.rpt_auth_stream_rdy.m_prime,
+						HDCP_2_2_MPRIME_LEN);
+		if (msg_read == HDCP_2_2_MPRIME_LEN)
+			status = 0;
+		break;
+	default:
+		status = -EINVAL;
+		break;
+	}
+
+	return status;
+}
+
+static int xlnx_hdmi_hdcp2x_tx_write_msg(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct xhdcp2x_tx_msg tx_msg;
+	int message_size = 0;
+	int status = -EINVAL;
+
+	memcpy(&tx_msg, xhdcp2x_tx->msg_buffer, sizeof(struct xhdcp2x_tx_msg));
+
+	switch (tx_msg.msg_type.msg_id) {
+	case HDCP_2_2_AKE_INIT:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP_2_2_HDMI_REG_WR_MSG_OFFSET,
+							(u8 *)&tx_msg,
+							sizeof(struct hdcp2x_tx_ake_init) + 1);
+		if (message_size == sizeof(struct hdcp2x_tx_ake_init) + 1)
+			status = 0;
+		break;
+	case HDCP_2_2_AKE_NO_STORED_KM:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP_2_2_HDMI_REG_WR_MSG_OFFSET,
+							(u8 *)&tx_msg,
+							sizeof(struct hdcp2x_tx_ake_no_stored_km)
+							+ 1);
+
+		if (message_size == sizeof(struct hdcp2x_tx_ake_no_stored_km) + 1)
+			status = 0;
+		break;
+	case HDCP_2_2_AKE_STORED_KM:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP_2_2_HDMI_REG_WR_MSG_OFFSET,
+							(u8 *)&tx_msg,
+							sizeof(struct hdcp2x_tx_ake_stored_km)
+							+ 1);
+
+		if (message_size == (sizeof(struct hdcp2x_tx_ake_stored_km) + 1))
+			status = 0;
+		break;
+	case HDCP_2_2_LC_INIT:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP_2_2_HDMI_REG_WR_MSG_OFFSET,
+							(u8 *)&tx_msg,
+							sizeof(struct hdcp2x_tx_lc_init) + 1);
+
+		if (message_size == (sizeof(struct hdcp2x_tx_lc_init) + 1))
+			status = 0;
+		break;
+	case HDCP_2_2_SKE_SEND_EKS:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP_2_2_HDMI_REG_WR_MSG_OFFSET,
+							(u8 *)&tx_msg,
+							sizeof(struct hdcp2x_tx_ske_send_eks)
+							+ 1);
+
+		if (message_size == (sizeof(struct hdcp2x_tx_ske_send_eks) + 1))
+			status = 0;
+		break;
+	case HDCP2X_TX_TYPE_VALUE:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_TYPE_VALUE_OFFSET,
+							(u8 *)&xhdcp2x_tx
+							->xhdcp2x_info.content_stream_type,
+							HDCP2X_TX_HDCPPORT_TYPE_VALUE_SIZE);
+		if (message_size == HDCP2X_TX_HDCPPORT_TYPE_VALUE_SIZE)
+			status = 0;
+		break;
+	case HDCP_2_2_REP_SEND_ACK:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP_2_2_HDMI_REG_WR_MSG_OFFSET,
+							(u8 *)&tx_msg,
+							sizeof(struct hdcp2x_tx_rpt_auth_send_ack)
+							+ 1);
+
+		if (message_size == (sizeof(struct hdcp2x_tx_rpt_auth_send_ack) + 1))
+			status = 0;
+		break;
+	case HDCP_2_2_REP_STREAM_MANAGE:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+						HDCP_2_2_HDMI_REG_WR_MSG_OFFSET,
+						(u8 *)&tx_msg,
+						sizeof(struct hdcp2x_tx_rpt_auth_stream_manage)
+						+ 1);
+
+		if (message_size == (sizeof(struct hdcp2x_tx_rpt_auth_stream_manage) + 1))
+			status = 0;
+		break;
+	default:
+		status = -EINVAL;
+		break;
+	}
+	return status;
+}
+
+static int xlnx_hdcp2x_tx_write_msg(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct xhdcp2x_tx_msg buffer;
+	int message_size = 0;
+	int status = -EINVAL;
+
+	memcpy(&buffer, xhdcp2x_tx->msg_buffer, sizeof(struct xhdcp2x_tx_msg));
+
+	if (xhdcp2x_tx->is_hdmi)
+		return xlnx_hdmi_hdcp2x_tx_write_msg(xhdcp2x_tx);
+
+	switch (buffer.msg_type.msg_id) {
+	case HDCP_2_2_AKE_INIT:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_R_TX_OFFSET,
+							buffer.msg_type.ake_int.r_tx,
+							HDCP_2_2_RTX_LEN);
+		message_size +=
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_TX_CAPS_OFFSET,
+							buffer.msg_type.ake_int.txcaps,
+							HDCP2X_TX_TXCAPS_SIZE);
+
+		if (message_size == (HDCP_2_2_RTX_LEN + HDCP2X_TX_TXCAPS_SIZE))
+			status = 0;
+		break;
+	case HDCP_2_2_AKE_NO_STORED_KM:
+		message_size =
+		xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_E_KPUB_KM_OFFSET,
+						buffer.msg_type.ake_nostored_km.ek_pubkm,
+						HDCP2X_TX_HDCPPORT_E_KPUB_KM_SIZE);
+
+		if (message_size == HDCP2X_TX_HDCPPORT_E_KPUB_KM_SIZE)
+			status = 0;
+		break;
+	case HDCP_2_2_AKE_STORED_KM:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_E_KH_KM_OFFSET,
+							buffer.msg_type.ake_stored_km.ekh_km,
+							HDCP_2_2_E_KH_KM_LEN);
+		message_size +=
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_M_OFFSET,
+							buffer.msg_type.ake_stored_km.r_tx,
+							HDCP_2_2_E_KH_KM_LEN);
+
+		if (message_size == (HDCP_2_2_E_KH_KM_LEN + HDCP_2_2_E_KH_KM_LEN))
+			status = 0;
+		break;
+	case HDCP_2_2_LC_INIT:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_R_N_OFFSET,
+							buffer.msg_type.lcinit.rn,
+							HDCP_2_2_RN_LEN);
+		if (message_size == HDCP_2_2_RN_LEN)
+			status = 0;
+		break;
+	case HDCP_2_2_SKE_SEND_EKS:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_E_DKEY_KS_OFFSET,
+							buffer.msg_type.ske_send_eks.edkeys_ks,
+							HDCP_2_2_E_DKEY_KS_LEN);
+		message_size +=
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_R_IV_OFFSET,
+							buffer.msg_type.ske_send_eks.riv,
+							HDCP_2_2_RIV_LEN);
+
+		if (message_size == (HDCP_2_2_E_DKEY_KS_LEN +
+				HDCP_2_2_RIV_LEN))
+			status = 0;
+		break;
+	case HDCP2X_TX_TYPE_VALUE:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_TYPE_VALUE_OFFSET,
+							(u8 *)&xhdcp2x_tx
+							->xhdcp2x_info.content_stream_type,
+							HDCP2X_TX_HDCPPORT_TYPE_VALUE_SIZE);
+		if (message_size == HDCP2X_TX_HDCPPORT_TYPE_VALUE_SIZE)
+			status = 0;
+		break;
+	case HDCP_2_2_REP_SEND_ACK:
+		message_size =
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_V_OFFSET,
+							buffer.msg_type.rpt_auth_send_ack.V,
+							HDCP_2_2_V_PRIME_HALF_LEN);
+		if (message_size == HDCP_2_2_V_PRIME_HALF_LEN)
+			status = 0;
+		break;
+	case HDCP_2_2_REP_STREAM_MANAGE:
+		message_size =
+		xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_SEQ_NUM_M_OFFSET,
+						buffer.msg_type.rpt_auth_stream_mng.seq_num_m,
+						HDCP_2_2_SEQ_NUM_LEN);
+		message_size +=
+			xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+							HDCP2X_TX_HDCPPORT_K_OFFSET,
+							buffer.msg_type.rpt_auth_stream_mng.K,
+							HDCP2X_TX_HDCPPORT_K_SIZE);
+		message_size +=
+		xhdcp2x_tx->handlers.wr_handler(xhdcp2x_tx->interface_ref,
+						HDCP2X_TX_HDCPPORT_STREAM_ID_TYPE_OFFSET,
+						buffer.msg_type.rpt_auth_stream_mng.streamid_type,
+						HDCP2X_TX_HDCPPORT_STREAM_ID_TYPE_SIZE);
+		if (message_size == (HDCP_2_2_SEQ_NUM_LEN +
+				HDCP2X_TX_HDCPPORT_K_SIZE +
+				HDCP2X_TX_HDCPPORT_STREAM_ID_TYPE_SIZE))
+			status = 0;
+		break;
+	default:
+		status = -EINVAL;
+		break;
+	}
+
+	return status;
+}
+
+void xlnx_hdcp2x_tx_process_cp_irq(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	u8 rx_status = 0;
+
+	xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+					HDCP2X_TX_HDCPPORT_RX_STATUS_OFFSET,
+					&rx_status,
+					HDCP_2_2_HDMI_RXSTATUS_LEN);
+	xhdcp2x_tx->xhdcp2x_info.dp_rx_status = rx_status;
+}
+
+int xlnx_hdcp2x_task_monitor(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	enum hdcp2x_tx_state new_state;
+
+	if (!xhdcp2x_tx->xhdcp2x_info.is_enabled)
+		return (int)(xhdcp2x_tx->xhdcp2x_info.auth_status);
+
+	new_state = hdcp2x_tx_protocol_authenticate_sm(xhdcp2x_tx);
+
+	xhdcp2x_tx->xhdcp2x_info.prev_state =
+			xhdcp2x_tx->xhdcp2x_info.curr_state;
+	xhdcp2x_tx->xhdcp2x_info.curr_state = new_state;
+
+	return xhdcp2x_tx->xhdcp2x_info.auth_status;
+}
+
+void xlnx_hdcp2x_tx_timer_init(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+			       struct xlnx_hdcp_timer_config *tmr_cntrl)
+{
+	xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr = *tmr_cntrl;
+
+	xlnx_hdcp_tmrcntr_set_options(&xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr,
+				      XHDCP2X_TX_TIMER_CNTR_0,
+				      XTC_INT_MODE_OPTION | XTC_DOWN_COUNT_OPTION);
+
+	xlnx_hdcp_tmrcntr_set_options(&xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr,
+				      XHDCP2X_TX_TIMER_CNTR_1, XTC_AUTO_RELOAD_OPTION);
+}
+
+void xlnx_hdcp2x_tx_start_timer(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+				u32 timeout, u8 reason_id)
+{
+	u32 ticks = (u32)(xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr.hw_config.sys_clock_freq
+					/ XHDCP2X_TX_CLKDIV_MHZ) * timeout * XHDCP2X_TX_CLKDIV_HZ;
+
+	xhdcp2x_tx->xhdcp2x_internal_timer.timer_expired = 0;
+	xhdcp2x_tx->xhdcp2x_internal_timer.reason_id = reason_id;
+	xhdcp2x_tx->xhdcp2x_internal_timer.initial_ticks = ticks;
+
+	if (reason_id != XHDCP2X_TX_TS_UNDEFINED &&
+	    reason_id != XHDCP2X_TX_TS_RX_REAUTH_CHECK &&
+	    reason_id != XHDCP2X_TX_TS_RX_REAUTH_CHECK)
+		xhdcp2x_tx->xhdcp2x_info.msg_available = 0;
+
+	xlnx_hdcp_tmrcntr_set_reset_value(&xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr,
+					  XHDCP2X_TX_TIMER_CNTR_0, ticks);
+
+	xlnx_hdcp_tmrcntr_start(&xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr,
+				XHDCP2X_TX_TIMER_CNTR_0);
+}
+
+void xlnx_hdcp2x_tx_timer_handler(void *callbackref, u8 tmr_cnt_number)
+{
+	struct xlnx_hdcp2x_config *xhdcp2x_tx =	(struct xlnx_hdcp2x_config *)callbackref;
+
+	if (tmr_cnt_number == XHDCP2X_TX_TIMER_CNTR_1)
+		return;
+
+	xhdcp2x_tx->xhdcp2x_internal_timer.timer_expired = 1;
+	if (xhdcp2x_tx->xhdcp2x_info.is_enabled)
+		xlnx_hdcp2x_tx_read_rxstatus(xhdcp2x_tx);
+}
+
+void xlnx_hdcp2x_tx_read_rxstatus(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	u8 read_buffer[2];
+
+	if (xhdcp2x_tx->xhdcp2x_hw.protocol == XHDCP2X_TX_HDMI) {
+		xhdcp2x_tx->handlers.rd_handler(xhdcp2x_tx->interface_ref,
+						HDCP_2_2_HDMI_REG_RXSTATUS_OFFSET,
+						(void *)read_buffer,
+						sizeof(read_buffer));
+
+		xhdcp2x_tx->xhdcp2x_info.rx_status = read_buffer[0]
+					| (read_buffer[1] << BITS_PER_BYTE);
+	}
+}
+
+int xlnx_hdcp2x_tx_write_type_value(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+
+	tx_msg->msg_type.msg_id = HDCP2X_TX_TYPE_VALUE;
+
+	return xlnx_hdcp2x_tx_write_msg(xhdcp2x_tx);
+}
+
+int xlnx_hdcp2x_tx_write_ake_init(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+
+	tx_msg->msg = (xhdcp2x_tx->xhdcp2x_hw.protocol != XHDCP2X_TX_DP) ?
+				HDCP_2_2_HDMI_REG_WR_MSG_OFFSET :
+				HDCP2X_TX_HDCPPORT_WRITE_MSG_OFFSET;
+	tx_msg->msg_type.msg_id  = HDCP_2_2_AKE_INIT;
+
+	xlnx_hdcp2x_rng_get_random_number(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_rng,
+					  xhdcp2x_tx->xhdcp2x_info.r_tx,
+					  HDCP_2_2_RTX_LEN, HDCP_2_2_RTX_LEN);
+
+	memcpy(&tx_msg->msg_type.ake_int.r_tx, xhdcp2x_tx->xhdcp2x_info.r_tx,
+	       sizeof(tx_msg->msg_type.ake_int.r_tx));
+	memcpy(&tx_msg->msg_type.ake_int.txcaps, xhdcp2x_tx->xhdcp2x_info.txcaps,
+	       sizeof(tx_msg->msg_type.ake_int.txcaps));
+
+	dev_dbg(xhdcp2x_tx->dev, "write ake init");
+
+	return xlnx_hdcp2x_tx_write_msg(xhdcp2x_tx);
+}
+
+int xlnx_hdcp2x_tx_write_ske_send_eks(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+				      const u8 *edkey_ptr, const u8 *riv_ptr)
+{
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+
+	tx_msg->msg = (xhdcp2x_tx->xhdcp2x_hw.protocol != XHDCP2X_TX_DP) ?
+				HDCP_2_2_HDMI_REG_WR_MSG_OFFSET :
+				HDCP2X_TX_HDCPPORT_WRITE_MSG_OFFSET;
+	tx_msg->msg_type.msg_id = HDCP_2_2_SKE_SEND_EKS;
+
+	memcpy(tx_msg->msg_type.ske_send_eks.edkeys_ks, edkey_ptr,
+	       sizeof(tx_msg->msg_type.ske_send_eks.edkeys_ks));
+
+	memcpy(tx_msg->msg_type.ske_send_eks.riv, riv_ptr,
+	       sizeof(tx_msg->msg_type.ske_send_eks.riv));
+
+	dev_dbg(xhdcp2x_tx->dev, "write ske send eks");
+
+	return xlnx_hdcp2x_tx_write_msg(xhdcp2x_tx);
+}
+
+int xlnx_hdcp2x_tx_write_lcinit(struct xlnx_hdcp2x_config *xhdcp2x_tx, const u8 *rn_ptr)
+{
+	struct xhdcp2x_tx_msg *tx_msg =	(struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+
+	tx_msg->msg = (xhdcp2x_tx->xhdcp2x_hw.protocol != XHDCP2X_TX_DP) ?
+				HDCP_2_2_HDMI_REG_WR_MSG_OFFSET :
+				HDCP2X_TX_HDCPPORT_WRITE_MSG_OFFSET;
+	tx_msg->msg_type.msg_id = HDCP_2_2_LC_INIT;
+
+	memcpy(tx_msg->msg_type.lcinit.rn, rn_ptr, sizeof(tx_msg->msg_type.lcinit.rn));
+
+	dev_dbg(xhdcp2x_tx->dev, "write lc-init\r");
+
+	return xlnx_hdcp2x_tx_write_msg(xhdcp2x_tx);
+}
+
+int xlnx_hdcp2x_tx_write_ake_storedkm(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+				      const struct hdcp2x_tx_pairing_info  *hdcp2x_tx_pairing_info)
+{
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+
+	tx_msg->msg = (xhdcp2x_tx->xhdcp2x_hw.protocol != XHDCP2X_TX_DP) ?
+				HDCP_2_2_HDMI_REG_WR_MSG_OFFSET :
+				HDCP2X_TX_HDCPPORT_WRITE_MSG_OFFSET;
+	tx_msg->msg_type.msg_id = HDCP_2_2_AKE_STORED_KM;
+
+	memcpy(tx_msg->msg_type.ake_stored_km.ekh_km, hdcp2x_tx_pairing_info->ekh_km,
+	       sizeof(tx_msg->msg_type.ake_stored_km.ekh_km));
+	memcpy(tx_msg->msg_type.ake_stored_km.r_tx, hdcp2x_tx_pairing_info->rtx,
+	       sizeof(tx_msg->msg_type.ake_stored_km.r_tx));
+	memcpy(tx_msg->msg_type.ake_stored_km.r_rx, hdcp2x_tx_pairing_info->rrx,
+	       sizeof(tx_msg->msg_type.ake_stored_km.r_rx));
+
+	dev_dbg(xhdcp2x_tx->dev, "write AKE stored km");
+
+	return xlnx_hdcp2x_tx_write_msg(xhdcp2x_tx);
+}
+
+int xlnx_hdcp2x_tx_write_akenostored_km(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+					const struct hdcp2x_tx_pairing_info *pairing_info,
+					const struct hdcp2x_tx_cert_rx *cert_ptr)
+{
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+	u8 masking_seed[HDCP2X_TX_KM_MSK_SEED_SIZE];
+	u8 ek_pubkm[HDCP_2_2_E_KPUB_KM_LEN];
+
+	tx_msg->msg = (xhdcp2x_tx->xhdcp2x_hw.protocol != XHDCP2X_TX_DP) ?
+				HDCP_2_2_HDMI_REG_WR_MSG_OFFSET :
+				HDCP2X_TX_HDCPPORT_WRITE_MSG_OFFSET;
+	tx_msg->msg_type.msg_id = HDCP_2_2_AKE_NO_STORED_KM;
+
+	xlnx_hdcp2x_rng_get_random_number(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_rng,
+					  masking_seed, HDCP2X_TX_KM_MSK_SEED_SIZE,
+					  HDCP2X_TX_KM_MSK_SEED_SIZE);
+	xlnx_hdcp2x_tx_encryptedkm((const struct hdcp2x_tx_cert_rx *)cert_ptr,
+				   pairing_info->km, masking_seed, ek_pubkm);
+
+	memcpy(tx_msg->msg_type.ake_nostored_km.ek_pubkm, ek_pubkm,
+	       sizeof(tx_msg->msg_type.ake_nostored_km.ek_pubkm));
+
+	dev_dbg(xhdcp2x_tx->dev, "write AKE no stored km");
+
+	return xlnx_hdcp2x_tx_write_msg(xhdcp2x_tx);
+}
+
+int xlnx_hdcp2x_tx_write_rptr_auth_send_ack(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+					    const u8 *v_ptr)
+{
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+
+	tx_msg->msg = (xhdcp2x_tx->xhdcp2x_hw.protocol != XHDCP2X_TX_DP) ?
+				HDCP_2_2_HDMI_REG_WR_MSG_OFFSET :
+				HDCP2X_TX_HDCPPORT_WRITE_MSG_OFFSET;
+	tx_msg->msg_type.msg_id = HDCP_2_2_REP_SEND_ACK;
+
+	memcpy(tx_msg->msg_type.rpt_auth_send_ack.V, v_ptr,
+	       sizeof(tx_msg->msg_type.rpt_auth_send_ack.V));
+
+	return xlnx_hdcp2x_tx_write_msg(xhdcp2x_tx);
+}
+
+struct hdcp2x_tx_pairing_info *xlnx_hdcp2x_tx_get_pairing_info(struct xlnx_hdcp2x_config
+							       *xhdcp2x_tx, const u8 *rcvid)
+{
+	struct hdcp2x_tx_pairing_info *pairing_info_ptr;
+	u8 illegal_rcvd[] = {0x0, 0x0, 0x0, 0x0, 0x0};
+	int i = 0;
+
+	if (!memcmp(rcvid, illegal_rcvd, HDCP_2_2_RECEIVER_ID_LEN))
+		return NULL;
+
+	for (i = 0; i < XHDCP2X_TX_MAX_STORED_PAIRINGINFO; i++) {
+		pairing_info_ptr = &xhdcp2x_tx->xhdcp2x_info.pairing_info[i];
+		if (!memcmp(rcvid, pairing_info_ptr->rcvid, HDCP_2_2_RECEIVER_ID_LEN))
+			return pairing_info_ptr;
+	}
+
+	return NULL;
+}
+
+void xlnx_hdcp2x_tx_invalidate_paring_info(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+					   const u8 *rcvid)
+{
+	struct hdcp2x_tx_pairing_info *pairing_info_ptr =
+			xlnx_hdcp2x_tx_get_pairing_info(xhdcp2x_tx, rcvid);
+
+	if (!pairing_info_ptr)
+		return;
+
+	memset(pairing_info_ptr, 0, sizeof(struct hdcp2x_tx_pairing_info));
+}
+
+struct hdcp2x_tx_pairing_info *xlnx_hdcp2x_tx_update_pairinginfo(struct xlnx_hdcp2x_config
+					*xhdcp2x_tx,
+					struct hdcp2x_tx_pairing_info *pairing_info,
+					u8 ready)
+{
+	struct hdcp2x_tx_pairing_info  *xhdcp2x_pairing_info_ptr;
+	int i;
+	int i_match = 0;
+	u8 match = 0;
+
+	for (i = 0; i < XHDCP2X_TX_MAX_STORED_PAIRINGINFO; i++) {
+		xhdcp2x_pairing_info_ptr =
+			&xhdcp2x_tx->xhdcp2x_info.pairing_info[i];
+		if (!(xhdcp2x_pairing_info_ptr->ready) && !(match)) {
+			i_match = i;
+			match = 1;
+		}
+		if (!memcmp(pairing_info->rcvid, xhdcp2x_pairing_info_ptr->rcvid,
+			    HDCP_2_2_RECEIVER_ID_LEN)) {
+			i_match = i;
+			break;
+		}
+	}
+	xhdcp2x_pairing_info_ptr = &xhdcp2x_tx->xhdcp2x_info.pairing_info[i_match];
+
+	memcpy(xhdcp2x_pairing_info_ptr, pairing_info, sizeof(struct hdcp2x_tx_pairing_info));
+	xhdcp2x_pairing_info_ptr->ready = ready;
+
+	return xhdcp2x_pairing_info_ptr;
+}
+
+int xlnx_hdcp2x_tx_rptr_auth_stream_mng(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	struct hdcp2x_tx_pairing_info  *xhdcp2x_pairing_info =
+			(struct hdcp2x_tx_pairing_info *)
+			xhdcp2x_tx->xhdcp2x_info.state_context;
+	struct xhdcp2x_tx_msg *tx_msg = (struct xhdcp2x_tx_msg *)xhdcp2x_tx->msg_buffer;
+
+	tx_msg->msg = (xhdcp2x_tx->xhdcp2x_hw.protocol != XHDCP2X_TX_DP) ?
+				HDCP_2_2_HDMI_REG_WR_MSG_OFFSET :
+				HDCP2X_TX_HDCPPORT_WRITE_MSG_OFFSET;
+	tx_msg->msg_type.msg_id = HDCP_2_2_REP_STREAM_MANAGE;
+
+	drm_hdcp_cpu_to_be24(tx_msg->msg_type.rpt_auth_stream_mng.seq_num_m,
+			     xhdcp2x_tx->xhdcp2x_info.seq_num_m);
+
+	/* The parameter K is always set to 0x1 by the HDCP transmitter */
+	/* Value is sent in big endian format */
+	tx_msg->msg_type.rpt_auth_stream_mng.K[0] = 0x0;
+	tx_msg->msg_type.rpt_auth_stream_mng.K[1] = 0x1;
+
+	tx_msg->msg_type.rpt_auth_stream_mng.streamid_type[0] = HDCP_STREAM_TYPE0;
+	tx_msg->msg_type.rpt_auth_stream_mng.streamid_type[1] =
+			(u8)xhdcp2x_tx->xhdcp2x_info.content_stream_type;
+
+	xlnx_hdcp2x_tx_compute_m(xhdcp2x_tx->xhdcp2x_info.rn,
+				 xhdcp2x_tx->xhdcp2x_info.r_rx,
+				 xhdcp2x_tx->xhdcp2x_info.r_tx,
+				 tx_msg->msg_type.rpt_auth_stream_mng.streamid_type,
+				 tx_msg->msg_type.rpt_auth_stream_mng.K,
+				 tx_msg->msg_type.rpt_auth_stream_mng.seq_num_m,
+				 xhdcp2x_pairing_info->km,
+				 xhdcp2x_tx->xhdcp2x_info.M);
+
+	/* Increment the M on every Stream message */
+	xhdcp2x_tx->xhdcp2x_info.seq_num_m++;
+
+	return xlnx_hdcp2x_tx_write_msg(xhdcp2x_tx);
+}
+
+void xlnx_hdcp2x_tx_generatekm(struct xlnx_hdcp2x_config *xhdcp2x_tx, u8 *kmptr)
+{
+	xlnx_hdcp2x_rng_get_random_number(&xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_rng,
+					  kmptr, HDCP2X_TX_KM_SIZE,
+					  HDCP2X_TX_KM_SIZE);
+}
+
+int xlnx_hdcp2x_tx_wait_for_receiver(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+				     int expected_size, u8 ready_bit)
+{
+	u32 timer_cnt = 0;
+	u32 interval_cnt = xhdcp2x_tx->xhdcp2x_info.polling_value *
+		((u32)(xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr.hw_config.sys_clock_freq)
+		      / XHDCP2X_TX_CLKDIV_HZ);
+
+	if (xhdcp2x_tx->xhdcp2x_internal_timer.timer_expired) {
+		if (xhdcp2x_tx->xhdcp2x_hw.protocol == XHDCP2X_TX_DP) {
+			xhdcp2x_tx->xhdcp2x_info.msg_available = 1;
+			return 0;
+		}
+		if ((!ready_bit && ((xhdcp2x_tx->xhdcp2x_info.rx_status &
+			XHDCP2X_TX_RXSTATUS_AVAIL_BYTES_MASK) == expected_size)) ||
+			(ready_bit && (xhdcp2x_tx->xhdcp2x_info.rx_status &
+			XHDCP2X_TX_RXSTATUS_READY_MASK))) {
+			xhdcp2x_tx->xhdcp2x_info.msg_available = 1;
+			return 0;
+		}
+
+		return -EINVAL;
+	}
+	timer_cnt = xlnx_hdcp2x_tx_get_timer_count(xhdcp2x_tx);
+
+	if (!xhdcp2x_tx->xhdcp2x_info.polling_value ||
+	    ((xhdcp2x_tx->xhdcp2x_internal_timer.initial_ticks - timer_cnt)
+	    >= interval_cnt)) {
+		xhdcp2x_tx->xhdcp2x_internal_timer.initial_ticks = timer_cnt;
+		if (xhdcp2x_tx->xhdcp2x_hw.protocol == XHDCP2X_TX_DP) {
+			if (xhdcp2x_tx->xhdcp2x_internal_timer.reason_id ==
+					HDCP_2_2_AKE_SEND_HPRIME) {
+				if (xhdcp2x_tx->xhdcp2x_info.dp_rx_status &
+					XHDCP2X_RX_STATUS_H_PRIME_AVAILABLE) {
+					xhdcp2x_tx->xhdcp2x_info.dp_rx_status &=
+					~XHDCP2X_RX_STATUS_H_PRIME_AVAILABLE;
+					xhdcp2x_tx->xhdcp2x_info.msg_available = 1;
+					dev_dbg(xhdcp2x_tx->dev,
+						"HDCP2XTX: H' is Available through CP_IRQ\n\r");
+				}
+			} else if (xhdcp2x_tx->xhdcp2x_internal_timer.reason_id ==
+					HDCP_2_2_AKE_SEND_PAIRING_INFO) {
+				if (xhdcp2x_tx->xhdcp2x_info.dp_rx_status &
+						XHDCP2X_RX_STATUS_PAIRING_AVAILABLE) {
+					xhdcp2x_tx->xhdcp2x_info.dp_rx_status &=
+						~XHDCP2X_RX_STATUS_PAIRING_AVAILABLE;
+					xhdcp2x_tx->xhdcp2x_info.msg_available = 1;
+				}
+			} else if (xhdcp2x_tx->xhdcp2x_internal_timer.reason_id ==
+					HDCP_2_2_REP_SEND_RECVID_LIST) {
+				if (xhdcp2x_tx->xhdcp2x_info.dp_rx_status &
+						XHDCP2X_RX_STATUS_RPTR_RDY) {
+					xhdcp2x_tx->xhdcp2x_info.dp_rx_status =
+							~XHDCP2X_RX_STATUS_RPTR_RDY;
+					xhdcp2x_tx->xhdcp2x_info.msg_available = 1;
+				}
+			}
+			if (xhdcp2x_tx->xhdcp2x_info.msg_available) {
+				xlnx_hdcp_tmrcntr_stop(&
+					xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr,
+					XHDCP2X_TX_TIMER_CNTR_0);
+				xhdcp2x_tx->xhdcp2x_internal_timer.timer_expired = 1;
+			}
+			return 0;
+		}
+		xlnx_hdcp2x_tx_read_rxstatus(xhdcp2x_tx);
+
+		if ((!ready_bit && ((xhdcp2x_tx->xhdcp2x_info.rx_status &
+		    XHDCP2X_TX_RXSTATUS_AVAIL_BYTES_MASK) == expected_size)) ||
+		    ((ready_bit &&
+		    (xhdcp2x_tx->xhdcp2x_info.rx_status &
+		    XHDCP2X_TX_RXSTATUS_READY_MASK)) &&
+		    ((xhdcp2x_tx->xhdcp2x_info.rx_status &
+		    XHDCP2X_TX_RXSTATUS_AVAIL_BYTES_MASK) > 0))) {
+			xlnx_hdcp_tmrcntr_stop(&xhdcp2x_tx->xhdcp2x_internal_timer.tmr_ctr,
+					       XHDCP2X_TX_TIMER_CNTR_0);
+			xhdcp2x_tx->xhdcp2x_internal_timer.timer_expired = 1;
+			xhdcp2x_tx->xhdcp2x_info.msg_available = 1;
+		}
+
+		return 0;
+	}
+
+	return 0;
+}
+
+void xlnx_hdcp2x_handle_reauth_request(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	xhdcp2x_tx->xhdcp2x_info.auth_status =
+			XHDCP2X_TX_REAUTHENTICATE_REQUESTED;
+
+	xlnx_hdcp2x_tx_disable_encryption(xhdcp2x_tx);
+	xlnx_hdcp2x_cipher_disable(xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher.cipher_coreaddress);
+	xlnx_hdcp2x_cipher_enable(xhdcp2x_tx->xhdcp2x_hw.xlnxhdcp2x_cipher.cipher_coreaddress);
+}
+
+void xlnx_hdcp2x_tx_auth_failed(struct xlnx_hdcp2x_config *xhdcp2x_tx)
+{
+	xhdcp2x_tx->xhdcp2x_info.auth_status =
+			XHDCP2X_TX_AUTHENTICATION_BUSY;
+
+	xhdcp2x_tx->xhdcp2x_info.is_rcvr_hdcp2x_capable =
+			xlnx_hdcp2x_downstream_capbility(xhdcp2x_tx);
+}
diff --git a/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp2x_tx.h b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp2x_tx.h
new file mode 100644
index 000000000..dfd1edb36
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp2x_tx.h
@@ -0,0 +1,293 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx Specific HDCP2X driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Lakshmi Prasanna Eachuri <lakshmi.prasanna.eachuri@amd.com>
+ */
+
+#ifndef _XLNX_HDCP2X_TX_H_
+#define _XLNX_HDCP2X_TX_H_
+
+#include <linux/bits.h>
+#include <linux/device.h>
+#include <linux/xlnx/xlnx_hdcp2x_cipher.h>
+#include <linux/xlnx/xlnx_hdcp_rng.h>
+#include <linux/xlnx/xlnx_timer.h>
+#include "xhdcp2x_tx.h"
+
+#define XHDCP2X_TX_MAX_ALLOWED_STREAM_MANAGE_CHECKS	128
+#define XHDCP2X_TX_LC128_SIZE				16
+#define XHDCP2X_TX_MAX_STORED_PAIRINGINFO		2
+#define XHDCP2X_TX_TS_WAIT_FOR_STREAM_TYPE		0xFD
+#define XHDCP2X_TX_TS_WAIT_FOR_CIPHER			GENMASK(7, 1)
+#define XHDCP2X_TX_TS_RX_REAUTH_CHECK			GENMASK(7, 0)
+#define XHDCP2X_TX_RXSTATUS_REAUTH_REQ_MASK		BIT(11)
+#define XHDCP2X_TX_RXSTATUS_READY_MASK			BIT(10)
+#define XHDCP2X_TX_RXSTATUS_AVAIL_BYTES_MASK		GENMASK(9, 0)
+#define XHDCP2X_TX_SRM_RCVID_SIZE		HDCP_2_2_RECEIVER_ID_LEN
+#define XHDCP2X_TX_SRM_SIGNATURE_SIZE		384
+#define XHDCP2X_TX_MAX_MESSAGE_SIZE		(1 + 534)
+#define XHDCP2X_TX_INVALID_RXSTATUS		GENMASK(15, 0)
+#define XHDCP2X_TX_KPUB_DCP_LLC_N_SIZE		384
+#define XHDCP2X_TX_KPUB_DCP_LLC_E_SIZE		1
+#define XHDCP2X_TX_LC128_SIZE			16
+#define XHDCP2X_TX_SRM_SIZE			396
+#define XHDCP2X_TX_SHA_SIZE			256
+#define XHDCP2X_TX_SHA_KEY_LENGTH		64
+#define XHDCP2X_TX_RXCAPS_MASK			0x02
+#define XHDCP2X_TX_CLKDIV_MHZ			1000000
+#define XHDCP2X_TX_CLKDIV_HZ			1000
+
+#define XHDCP2X_TX_TIMER_CNTR_0			0
+#define XHDCP2X_TX_TIMER_CNTR_1			1
+#define XHDCP2X_TX_TS_UNDEFINED			0
+
+typedef u32 (*xhdcp2x_notify_msg) (void *callbackref, u32 offset,
+		u8 *buf, u32 size);
+typedef void (*xhdcp2x_callback_msg)(void *callbackref);
+
+enum xhdcp2x_tx_protocol {
+	XHDCP2X_TX_DP = 0,
+	XHDCP2X_TX_HDMI = 1
+};
+
+enum xhdcp2x_tx_mode {
+	XHDCP2X_TX_TRANSMITTER = 0,
+	XHDCP2X_TX_REPEATER = 1,
+};
+
+/**
+ * struct xlnx_hdcp2x_hw - HDCP2X subsystem configuration structure
+ * @xlnxhdcp2x_cipher: HDCP2X cipher engine configuration
+ * @xlnxhdcp2x_rng: HDCP2X random number generator configuration
+ * @hdcp2xcore_address: HDCP2X core address
+ * @tx_mode: HDCP Transmitter or Repeater
+ * @protocol: Protocol type, DP or HDMI
+ */
+struct xlnx_hdcp2x_hw {
+	struct xlnx_hdcp2x_cipher_hw   xlnxhdcp2x_cipher;
+	struct xlnx_hdcp2x_rng_hw  xlnxhdcp2x_rng;
+	void __iomem *hdcp2xcore_address;
+	enum xhdcp2x_tx_mode tx_mode;
+	enum xhdcp2x_tx_protocol  protocol;
+};
+
+enum xhdcp2x_tx_content_stream_type {
+	XHDCP2X_STREAMTYPE_0 = 0,
+	XHDCP2X_STREAMTYPE_1 = 1,
+};
+
+enum xhdcp2x_tx_authtype {
+	XHDCP2X_TX_INCOMPATIBLE_RX = 0,
+	XHDCP2X_TX_AUTHENTICATION_BUSY = 1,
+	XHDCP2X_TX_AUTHENTICATED = 2,
+	XHDCP2X_TX_UNAUTHENTICATED = 3,
+	XHDCP2X_TX_REAUTHENTICATE_REQUESTED = 4,
+	XHDCP2X_TX_DEVICE_IS_REVOKED = 5,
+	XHDCP2X_TX_NO_SRM_LOADED = 6
+};
+
+enum xhdcp2x_tx_rx_status {
+	XHDCP2X_RX_STATUS_RPTR_RDY = 0x01,
+	XHDCP2X_RX_STATUS_H_PRIME_AVAILABLE = 0x02,
+	XHDCP2X_RX_STATUS_PAIRING_AVAILABLE = 0x04,
+	XHDCP2X_RX_STATUS_REAUTH_REQ = 0x08,
+	XHDCP2X_RX_STATUS_LINK_INTEGRITY_FAIL = 0x10
+};
+
+/**
+ * struct xhdcp2x_tx_internal_timer - Current state and data used for internal timer
+ * @tmr_ctr: Hardware timer configuration structure
+ * @initial_ticks: Keep track of the start value of the timer.
+ * @reason_id: Keep track of why the timer was started (message or status checking)
+ * @timer_expired: Expiration flag set when the hardware timer has interrupted.
+ */
+struct xhdcp2x_tx_internal_timer {
+	struct xlnx_hdcp_timer_config tmr_ctr;
+	u32 initial_ticks;
+	u8 reason_id;
+	bool timer_expired;
+
+};
+
+struct xhdcp2x_tx_msg {
+	u8 msg;
+	union hdcp2x_tx_msg_type msg_type;
+};
+
+/**
+ * struct xhdcp2x_tx_internal_info - This structure contains configuration information
+ * for the device.
+ * @pairing_info: HDCP2X pairing info
+ * @curr_state: Current state of internal state machine
+ * @prev_state: Previous state of internal state machine
+ * @auth_status: The result of internal state machine transaction
+ * @content_stream_type: Content stream type used with Content Stream Management
+ * @state_context: Context used internally by the state machine
+ * @M: Calculated M value
+ * @r_tx: Internal used rtx
+ * @r_rx: Internal used rrx
+ * @rn: Internal used rn
+ * @txcaps: HDCP tx capabilities
+ * @seq_num_v: Sequence number V used with Received Id list
+ * @seq_num_m: Sequence number M used with Content Stream Management
+ * @prev_seq_num_m: Previous sequence number M used with Content Stream Management
+ * @polling_value: The currently used polling interval value for a message
+ * @content_strm_mng_chk_cntr: Keeps track of Content Stream Management checks performed
+ * @rx_status: HDCP RX status read on timer interrupt
+ * @lc_counter: Locality may attempt 1024 times
+ * @dp_rx_status: HDCP RX status read on CP_IRQ interrupt
+ * @is_content_stream_type_set:Content stream type is set
+ * @is_enabled:Is HDCP TX enabled state machine is active
+ * @is_rcvr_hdcp2x_capable: Is receiver a HDCP2x capable
+ * @is_rcvr_repeater: Is the receiver a HDCP repeater
+ * @is_revoc_list_valid: Is revocation list valid
+ * @is_device_revoked: Is a device listed in the revocation list
+ * @msg_available: Message is available for reading
+ */
+struct xhdcp2x_tx_internal_info {
+	struct hdcp2x_tx_pairing_info pairing_info[XHDCP2X_TX_MAX_STORED_PAIRINGINFO];
+	enum hdcp2x_tx_state curr_state;
+	enum hdcp2x_tx_state prev_state;
+	enum xhdcp2x_tx_authtype auth_status;
+	enum xhdcp2x_tx_content_stream_type content_stream_type;
+	void *state_context;
+	u8 M[32];
+	u8 r_tx[8];
+	u8 r_rx[8];
+	u8 rn[8];
+	u8 txcaps[3];
+	u32 seq_num_v;
+	u32 seq_num_m;
+	u32 prev_seq_num_m;
+	u32 polling_value;
+	u16 content_strm_mng_chk_cntr;
+	u16 rx_status;
+	u16 lc_counter;
+	u8 dp_rx_status;
+	bool is_content_stream_type_set;
+	bool is_enabled;
+	bool is_rcvr_hdcp2x_capable;
+	bool is_rcvr_repeater;
+	bool is_revoc_list_valid;
+	bool is_device_revoked;
+	bool msg_available;
+};
+
+struct xhdcp2x_tx_callbacks {
+	int (*rd_handler)(void *interface_ref, u32 offset, u8 *buf, u32 size);
+	int (*wr_handler)(void *interface_ref, u32 offset, u8 *buf, u32 size);
+	void (*notify_handler)(void *interface_ref, u32 notification);
+};
+
+/**
+ * struct xlnx_hdcp2x_config - This structure contains HDCP2X driver
+ * configuration information
+ * @dev: device information
+ * @xhdcp2x_hw: Configuration HDCP2x hardware
+ * @xhdcp2x_pairing_info: HDCP2X pairing information
+ * @xhdcp2x_revoc_list: HDCP2X revocation list
+ * @xhdcp2x_topology: HDCP2x topology information
+ * @xhdcp2x_info: Provides the control and status of internal driver parameters
+ * @xhdcp2x_internal_timer: Internal timer parameters
+ * @handlers: Callback handlers
+ * @interface_ref: Interface reference
+ * @interface_base: Interface base
+ * @msg_buffer: Message buffer for messages that are sent/received
+ * @lc128key: LC128 encryption key
+ * @msg_buffer: Message buffer to store HDCP input/output messages
+ * @srmkey: SRM encryption key
+ * @is_hdmi: Interface type HDMI or DP
+ * @txcaps: transmitter capabilities
+ * @lane_count: Number of lanes data to be encrypted
+ * @is_repeater: Says whether downstream is repeater or receiver
+ */
+struct xlnx_hdcp2x_config {
+	struct device *dev;
+	struct xlnx_hdcp2x_hw  xhdcp2x_hw;
+	struct hdcp2x_tx_pairing_info xhdcp2x_pairing_info;
+	struct hdcp2x_tx_revoclist xhdcp2x_revoc_list;
+	struct hdcp2x_tx_topology xhdcp2x_topology;
+	struct xhdcp2x_tx_internal_info xhdcp2x_info;
+	struct xhdcp2x_tx_internal_timer xhdcp2x_internal_timer;
+	struct xhdcp2x_tx_callbacks handlers;
+	void *interface_ref;
+	void __iomem *interface_base;
+	u8 msg_buffer[XHDCP2X_TX_MAX_MESSAGE_SIZE];
+	u8 *lc128key;
+	u8 *srmkey;
+	u8 is_hdmi;
+	u8 *txcaps;
+	u8 lane_count;
+	bool is_repeater;
+};
+
+struct hdcp2x_tx_pairing_info
+		*xlnx_hdcp2x_tx_update_pairinginfo(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+		struct hdcp2x_tx_pairing_info *pairing_info, u8 ready);
+struct hdcp2x_tx_pairing_info *xlnx_hdcp2x_tx_get_pairing_info(struct xlnx_hdcp2x_config
+				*xhdcp2x_tx, const u8 *rcvid);
+int xlnx_hdcp2x_tx_init(struct xlnx_hdcp2x_config *xhdcp2x_tx, bool is_repeater);
+int xlnx_hdcp2x_task_monitor(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+int xlnx_hdcp2x_tx_reset(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+int xlnx_hdcp2x_tx_verify_certificate(const struct hdcp2x_tx_cert_rx *rx_certificate,
+				      const u8 *dcp_cert_nvalue, int dcp_cert_nsize,
+				      const u8 *dcp_cert_evalue, int dcp_cert_esize);
+int xlnx_hdcp2x_tx_write_akenostored_km(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+					const struct hdcp2x_tx_pairing_info *pairing_info,
+					const struct hdcp2x_tx_cert_rx *cert_ptr);
+int xlnx_hdcp2x_tx_write_rptr_auth_send_ack(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+					    const u8 *v_ptr);
+int xlnx_hdcp2x_tx_write_ake_storedkm(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+				      const struct hdcp2x_tx_pairing_info *hdcp2x_tx_pairing_info);
+int xlnx_hdcp2x_tx_read_msg(struct xlnx_hdcp2x_config *xhdcp2x_tx, u8 msg_id);
+int xlnx_hdcp2x_tx_write_lcinit(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+				const u8 *rn_ptr);
+int xlnx_hdcp2x_tx_write_type_value(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+int xlnx_hdcp2x_tx_write_ske_send_eks(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+				      const u8 *edkey_ptr, const u8 *riv_ptr);
+int xlnx_hdcp2x_tx_write_ake_init(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+int xlnx_hdcp2x_tx_encryptedkm(const struct hdcp2x_tx_cert_rx *rx_certificate,
+			       const u8 *km_ptr, u8 *masking_seed, u8 *encrypted_km);
+int xlnx_hdcp2x_tx_wait_for_receiver(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+				     int expected_size, u8 ready_bit);
+int xlnx_hdcp2x_tx_rptr_auth_stream_mng(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+int hdcp2x_tx_protocol_authenticate_sm(struct xlnx_hdcp2x_config *hdcp2x_tx);
+int xlnx_hdcp2x_verify_srm(const u8 *srm, int srm_size, const u8 *dcp_cert_nvalue,
+			   int dcp_cert_nsize, const u8 *dcp_cert_evalue, int dcp_cert_esize);
+int xlnx_hdcp2x_loadkeys(struct xlnx_hdcp2x_config *xhdcp2x_tx, u8 *srm, u8 *lc128);
+void xlnx_start_hdcp2x_engine(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+void xlnx_hdcp2x_tx_timer_init(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+			       struct xlnx_hdcp_timer_config *tmr_cntrl);
+void xlnx_hdcp2x_tx_auth_failed(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+void xlnx_hdcp2x_handle_reauth_request(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+void xlnx_hdcp2x_tx_generatekm(struct xlnx_hdcp2x_config *xhdcp2x_tx, u8 *kmptr);
+void xlnx_hdcp2x_tx_invalidate_paring_info(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+					   const u8 *rcvid);
+void xlnx_hdcp2x_tx_read_rxstatus(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+void xlnx_hdcp2x_tx_process_cp_irq(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+void xlnx_hdcp2x_tx_timer_handler(void *callbackref, u8 tmr_cnt_number);
+void xlnx_hdcp2x_tx_compute_edkey_ks(const u8 *rn, const u8 *km, const u8 *ks, const u8 *r_rx,
+				     const u8 *r_tx, u8 *encrypted_ks);
+void xlnx_hdcp2x_tx_compute_lprime(const u8 *rn, const u8 *km, const u8 *r_rx, const u8 *r_tx,
+				   u8 *lprime);
+void xlnx_hdcp2x_tx_compute_v(const u8 *rn, const u8 *r_rx, const u8 *rx_info,
+			      const u8 *r_tx, const u8 *rcvid_list, const u8 rcvid_count,
+			      const u8 *seq_num_v, const u8 *km, u8 *hash_v);
+void xlnx_hdcp2x_tx_compute_m(const u8 *rn, const u8 *r_rx, const u8 *r_tx,
+			      const u8 *stream_id_type, const u8 *k,
+			      const u8 *seq_num_m, const u8 *km, u8 *m_hash);
+void xlnx_hdcp2x_tx_compute_hprime(const u8 *r_rx, const u8 *rxcaps,
+				   const u8 *r_tx, const u8 *txcaps,
+				   const u8 *km, u8 *hprime);
+void xlnx_hdcp2x_tx_disable_encryption(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+void xlnx_hdcp2x_tx_start_timer(struct xlnx_hdcp2x_config *xhdcp2x_tx,
+				u32 timeout, u8 reason_id);
+void xlnx_hdcp2x_tx_enable_encryption(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+u8 xlnx_hdcp2x_tx_is_device_revoked(struct xlnx_hdcp2x_config *xhdcp2x_tx, u8 *rcvid);
+const u8 *xlnx_hdcp2x_tx_get_publickey(struct xlnx_hdcp2x_config *xhdcp2x_tx);
+bool xlnx_hdcp2x_downstream_capbility(struct xlnx_hdcp2x_config
+				*xhdcp2x_tx);
+#endif
diff --git a/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_sha1.c b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_sha1.c
new file mode 100644
index 000000000..b287d5465
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_sha1.c
@@ -0,0 +1,287 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ *  xlnx_hdcp_sha1.c
+ *
+ *  Description:
+ *      This file implements the Secure Hashing Algorithm 1 as
+ *      defined in FIPS PUB 180-1 published April 17, 1995.
+ *
+ *      The SHA-1, produces a 160-bit message digest for a given
+ *      data stream.  It should take about 2**n steps to find a
+ *      message with the same digest as a given message and
+ *      2**(n/2) to find any two messages with the same digest,
+ *      when n is the digest size in bits.  Therefore, this
+ *      algorithm can serve as a means of providing a
+ *      "fingerprint" for a message.
+ *
+ *  Caveats:
+ *      SHA-1 is designed to work with messages less than 2^64 bits
+ *      long.  Although SHA-1 allows a message digest to be generated
+ *      for messages of any number of bits less than 2^64, this
+ *      implementation only works with messages with a length that is
+ *      a multiple of the size of an 8-bit character.
+ *
+ */
+
+/* Some part of Code for sha calculations are modified according to Xilinx standards */
+
+/* Reference : https://nvlpubs.nist.gov/nistpubs/Legacy/FIPS/NIST.FIPS.180.pdf */
+
+#include <crypto/sha1.h>
+#include "xlnx_hdcp_sha1.h"
+
+/*
+ *  Define the SHA1 circular left shift macro
+ */
+#define xlnx_sha1_circular_shift(bits, word) \
+({\
+	typeof(bits) (_x) = (bits); \
+	typeof(word) (_y) = (word); \
+	(((_y) << (_x)) | ((_y) >> (32 - (_x)))); \
+})
+
+/**
+ * xlnx_sha1_reset - This function will initialize the xlnx_sha1_context in
+ * preparation for computing a new SHA1 message digest
+ * @context: SHA context structure
+ * return: success on reset or SHA error code otherwise
+ */
+int xlnx_sha1_reset(struct xlnx_sha1_context *context)
+{
+	if (!context)
+		return XLNX_SHA_NULL;
+
+	context->length_low	= 0;
+	context->length_high	= 0;
+	context->msg_block_index = 0;
+
+	memset(context->message_block, 0, MESSAGE_BLOCK_SIZE);
+	context->intermediate_hash[0]   = SHA1_H0;
+	context->intermediate_hash[1]   = SHA1_H1;
+	context->intermediate_hash[2]   = SHA1_H2;
+	context->intermediate_hash[3]   = SHA1_H3;
+	context->intermediate_hash[4]   = SHA1_H4;
+
+	context->computed   = 0;
+	context->corrupted  = 0;
+
+	return XLNX_SHA_SUCCESS;
+}
+
+/**
+ * xlnx_sha1_result - This function will return the 160-bit message
+ * digest into the message_digest array  provided by the caller.
+ * NOTE: The first octet of hash is stored in the 0th element,
+ * the last octet of hash in the 19th element
+ * @context: SHA context structure
+ * @message_digest: Message digest output
+ * return: success when message digest is correct or
+ * SHA error code otherwise
+ */
+int xlnx_sha1_result(struct xlnx_sha1_context *context,
+		     u8 message_digest[SHA1_HASH_SIZE])
+{
+	int i;
+
+	if (!context || !message_digest)
+		return XLNX_SHA_NULL;
+	if (context->corrupted)
+		return context->corrupted;
+	if (!context->computed) {
+		xlnx_sha1_pad_message(context);
+		for (i = 0; i < MESSAGE_BLOCK_SIZE; ++i) {
+			/* message may be sensitive, clear it out */
+			context->message_block[i] = 0;
+		}
+		context->length_low = 0; /* and clear length */
+		context->length_high = 0;
+		context->computed = 1;
+	}
+	for (i = 0; i < SHA1_HASH_SIZE; ++i) {
+		message_digest[i] = context->intermediate_hash[i >> 2]
+					>> BITS_PER_BYTE * (SHA_INTERMEDIATE_HASH_H3 -
+					(i & SHA_INTERMEDIATE_HASH_H3));
+	}
+
+	return XLNX_SHA_SUCCESS;
+}
+
+/**
+ * xlnx_sha1_process_message_block - This function will process the next
+ * 512 bits of the message stored in the message_block array.
+ * NOTE: Many of the variable names in this code, especially the
+ * single character names, were used because those were the
+ * names used in the publication.
+ * @context: SHA context structure
+ * return: none
+ */
+void xlnx_sha1_process_message_block(struct xlnx_sha1_context *context)
+{
+	const unsigned int K[] = {
+					/* Constants defined in SHA-1   */
+					K1,
+					K2,
+					K3,
+					K4
+				 };
+	int t; /* Loop counter */
+	unsigned int temp;   /* Temporary word value  */
+	unsigned int word_seq[SHA_MAX_HASH_OPERATIONS]; /* Word sequence  */
+	unsigned int A, B, C, D, E; /* Word buffers */
+
+	/*
+	 * Initialize the first 16 words in the array word_seq
+	 */
+	for (t = 0; t < SHA1_WORKSPACE_WORDS; t++) {
+		word_seq[t] = context->message_block[t * 4] << 24;
+		word_seq[t] |= context->message_block[t * 4 + 1] << 16;
+		word_seq[t] |= context->message_block[t * 4 + 2] << 8;
+		word_seq[t] |= context->message_block[t * 4 + 3];
+	}
+	for (t = SHA1_WORKSPACE_WORDS; t < SHA_MAX_HASH_OPERATIONS; t++)
+		word_seq[t] = xlnx_sha1_circular_shift(1,
+						       word_seq[t - 3] ^ word_seq[t - 8] ^
+						       word_seq[t - 14] ^ word_seq[t - 16]);
+	A = context->intermediate_hash[0];
+	B = context->intermediate_hash[1];
+	C = context->intermediate_hash[2];
+	D = context->intermediate_hash[3];
+	E = context->intermediate_hash[4];
+
+	for (t = 0; t < SHA1_DIGEST_SIZE; t++) {
+		temp =  xlnx_sha1_circular_shift(5, A) +
+			((B & C) | ((~B) & D)) + E +
+			word_seq[t] + K[0];
+		E = D;
+		D = C;
+		C = xlnx_sha1_circular_shift(SHA_BITS_TO_ROTATE, B);
+		B = A;
+		A = temp;
+	}
+	for (t = SHA1_DIGEST_SIZE; t < SHA_BITS_TO_ROTATE_ROUND2; t++) {
+		temp = xlnx_sha1_circular_shift(5, A) + (B ^ C ^ D) + E + word_seq[t] + K[1];
+		E = D;
+		D = C;
+		C = xlnx_sha1_circular_shift(SHA_BITS_TO_ROTATE, B);
+		B = A;
+		A = temp;
+	}
+	for (t = SHA_BITS_TO_ROTATE_ROUND2; t < SHA_BITS_TO_ROTATE_ROUND3; t++) {
+		temp = xlnx_sha1_circular_shift(5, A) +
+		       ((B & C) | (B & D) | (C & D)) + E +
+		       word_seq[t] + K[2];
+		E = D;
+		D = C;
+		C = xlnx_sha1_circular_shift(SHA_BITS_TO_ROTATE, B);
+		B = A;
+		A = temp;
+	}
+	for (t = SHA_BITS_TO_ROTATE_ROUND2; t < SHA_MAX_HASH_OPERATIONS; t++) {
+		temp = xlnx_sha1_circular_shift(5, A) + (B ^ C ^ D) + E + word_seq[t] + K[3];
+		E = D;
+		D = C;
+		C = xlnx_sha1_circular_shift(SHA_BITS_TO_ROTATE, B);
+		B = A;
+		A = temp;
+	}
+
+	context->intermediate_hash[0] += A;
+	context->intermediate_hash[1] += B;
+	context->intermediate_hash[2] += C;
+	context->intermediate_hash[3] += D;
+	context->intermediate_hash[4] += E;
+
+	context->msg_block_index = 0;
+}
+
+/**
+ * xlnx_sha1_input - This function accepts an array of octets as the
+ * next portion of the message
+ * @context: SHA context structure
+ * @message_array: An array of characters represetning the next
+ * portion of the message
+ * @length: The length of the message in message_array
+ * return: success when new input is added to the SHA message or
+ * SHA error code otherwise
+ */
+int xlnx_sha1_input(struct xlnx_sha1_context *context,
+		    const unsigned char *message_array,
+		    unsigned int length)
+{
+	if (!length)
+		return XLNX_SHA_SUCCESS;
+	if (!context || !message_array)
+		return XLNX_SHA_NULL;
+	if (context->computed) {
+		context->corrupted = XLNX_SHA_STATE_ERROR;
+		return XLNX_SHA_STATE_ERROR;
+	}
+
+	if (context->corrupted)
+		return context->corrupted;
+	while (length-- && !context->corrupted) {
+		context->message_block[context->msg_block_index++] =
+				(*message_array & 0xFF);
+		context->length_low += 8;
+		if (context->length_low == 0) {
+			context->length_high++;
+			if (context->length_high == 0) {
+				/* Message is too long */
+				context->corrupted = 1;
+			}
+		}
+		if (context->msg_block_index == MESSAGE_BLOCK_SIZE)
+			xlnx_sha1_process_message_block(context);
+
+		message_array++;
+	}
+
+	return XLNX_SHA_SUCCESS;
+}
+
+/**
+ * xlnx_sha1_pad_message - According to the standard, the message must be
+ * padded to an even 512 bits.The first padding bit must be a '1'.
+ * The last 64 bits represent the length of the original message.
+ * All bits in between should be 0.This function will pad the message
+ * according to those rules by filling the Message_Block array
+ * accordingly.  It will also call the ProcessMessageBlock function
+ * provided appropriately.  When it returns, it can be assumed that
+ * the message digest has been computed.
+ * @context: SHA context structure
+ * return: None
+ */
+void xlnx_sha1_pad_message(struct xlnx_sha1_context *context)
+{
+	/*
+	 * Check to see if the current message block is too small to hold
+	 * the initial padding bits and length.  If so, we will pad the
+	 * block, process it, and then continue padding into a second
+	 * block.
+	 */
+	if (context->msg_block_index > 55) {
+		context->message_block[context->msg_block_index++] = 0x80;
+		while (context->msg_block_index < SHA1_BLOCK_SIZE)
+			context->message_block[context->msg_block_index++] = 0;
+		xlnx_sha1_process_message_block(context);
+		while (context->msg_block_index < 56)
+			context->message_block[context->msg_block_index++] = 0;
+	} else {
+		context->message_block[context->msg_block_index++] = 0x80;
+		while (context->msg_block_index < 56)
+			context->message_block[context->msg_block_index++] = 0;
+	}
+	/*
+	 * Store the message length as the last 8 octets.
+	 */
+	context->message_block[56] = context->length_high >> 24;
+	context->message_block[57] = context->length_high >> 16;
+	context->message_block[58] = context->length_high >> 8;
+	context->message_block[59] = context->length_high;
+	context->message_block[60] = context->length_low >> 24;
+	context->message_block[61] = context->length_low >> 16;
+	context->message_block[62] = context->length_low >> 8;
+	context->message_block[63] = context->length_low;
+
+	xlnx_sha1_process_message_block(context);
+}
diff --git a/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_sha1.h b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_sha1.h
new file mode 100644
index 000000000..be9678e96
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_sha1.h
@@ -0,0 +1,73 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ *  xlnx_hdcp_sha1.h
+ *
+ *  Description:
+ *      This is the header file for code which implements the Secure
+ *      Hashing Algorithm 1 as defined in FIPS PUB 180-1 published
+ *      April 17, 1995.
+ *
+ *      Many of the variable names in this code, especially the
+ *      single character names, were used because those were the names
+ *      used in the publication.
+ *
+ *      Please read the file xlnx_hdcp_sha1.c for more information.
+ *
+ */
+
+#ifndef _XLNX_HDCP_SHA1_H_
+#define _XLNX_HDCP_SHA1_H_
+
+#include <linux/device.h>
+#include <linux/io.h>
+
+enum {
+	XLNX_SHA_SUCCESS = 0,
+	XLNX_SHA_NULL = 1,  /* Null pointer parameter */
+	XLNX_SHA_INPUT_TOO_LONG = 2,  /* input data too long */
+	XLNX_SHA_STATE_ERROR = 3     /* called Input after Result */
+};
+
+#define SHA1_HASH_SIZE 20
+#define MESSAGE_BLOCK_SIZE 64
+#define SHA_INTERMEDIATE_HASH_H3 3
+#define SHA_MAX_HASH_OPERATIONS 80
+#define SHA_BITS_TO_ROTATE 30
+#define SHA_BITS_TO_ROTATE_ROUND2 40
+#define SHA_BITS_TO_ROTATE_ROUND3 60
+
+#define K1	0x5a827999
+#define K2	0x6ed9eba1
+#define K3	0x8f1bbcdc
+#define K4	0xca62c1d6
+
+/**
+ * struct xlnx_sha1_context - This structure holds the context
+ * information for the SHA-1 hashing operation.
+ * @intermediate_hash: Message digest
+ * @length_low: Message length in bits
+ * @length_high: Message length in bits
+ * @msg_block_index: Index into message block array
+ * @message_block: 512-bit message block array
+ * @computed: Indicates the message digest is computed
+ * @corrupted: Indicates the message digest is corrupted
+ */
+struct xlnx_sha1_context {
+	unsigned int intermediate_hash[SHA1_HASH_SIZE / 4];
+	unsigned int length_low;
+	unsigned int length_high;
+	u16 msg_block_index;
+	unsigned char message_block[MESSAGE_BLOCK_SIZE];
+	int computed;
+	int corrupted;
+};
+
+int xlnx_sha1_reset(struct xlnx_sha1_context *context);
+int xlnx_sha1_input(struct xlnx_sha1_context *context, const unsigned char *msg,
+		    unsigned int length);
+int xlnx_sha1_result(struct xlnx_sha1_context *context,
+		     unsigned char message_digest[SHA1_HASH_SIZE]);
+void xlnx_sha1_pad_message(struct xlnx_sha1_context *context);
+void xlnx_sha1_process_message_block(struct xlnx_sha1_context *context);
+
+#endif
diff --git a/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_tx.c b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_tx.c
new file mode 100644
index 000000000..a8066cb40
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_tx.c
@@ -0,0 +1,461 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx HDCP Transmitter Interface driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Lakshmi Prasanna Eachuri <lakshmi.prasanna.eachuri@amd.com>
+ *
+ * This driver acts like an interface layer between HDCP1X and HDCP2X protocols
+ * for Xilinx transmitter subsystem devices.
+ *
+ * This driver initializes the HDCP IP and its internal modules based on
+ * downstream capabilities and starts Authentication.
+ *
+ * Currently HDCP2X protocol and its functionalities only enabled in this driver.
+ */
+
+#include <linux/xlnx/xlnx_hdcp_rng.h>
+#include <linux/xlnx/xlnx_hdcp_common.h>
+#include "xlnx_hdcp_tx.h"
+#include "xlnx_hdcp1x_tx.h"
+#include "xlnx_hdcp2x_tx.h"
+
+#define XDPTX_TIMER_CLOCK_FREQ_HZ 99999001U
+
+void xlnx_hdcptx_read_ds_sink_capability(struct xlnx_hdcptx *xtxhdcp)
+{
+	int status = 0;
+
+	if (xtxhdcp->hdcp2xenable) {
+		if (xlnx_hdcp2x_downstream_capbility(xtxhdcp->xhdcp2x)) {
+			xtxhdcp->hdcp_protocol = XHDCPTX_HDCP_2X;
+			status = true;
+		}
+	}
+	if (xtxhdcp->hdcp1xenable && !status) {
+		if (xlnx_hdcp1x_downstream_capbility(xtxhdcp->xhdcp1x)) {
+			xtxhdcp->hdcp_protocol = XHDCPTX_HDCP_1X;
+			status = true;
+		}
+	}
+	if (!status) {
+		xtxhdcp->hdcp_protocol = XHDCPTX_HDCP_NONE;
+
+		if (xtxhdcp->hdcp1xenable)
+			xlnx_hdcp1x_tx_start_timer(xtxhdcp->xhdcp1x,
+						   XHDMI_HDCP1X_WAIT_FOR_ACTIVE_RECEIVER, 0);
+	}
+}
+EXPORT_SYMBOL_GPL(xlnx_hdcptx_read_ds_sink_capability);
+
+static void hdcp_task_monitor_fun(struct work_struct *work)
+{
+	struct xlnx_hdcptx *xtxhdcp;
+
+	xtxhdcp = container_of(work, struct xlnx_hdcptx, hdcp_task_monitor.work);
+
+	if (xtxhdcp->hdcp_protocol == XHDCPTX_HDCP_NONE)
+		xlnx_hdcptx_read_ds_sink_capability(xtxhdcp);
+	if (xtxhdcp->hdcp_protocol == XHDCPTX_HDCP_2X) {
+		struct xlnx_hdcp2x_config  *xhdcp2x = xtxhdcp->xhdcp2x;
+
+		mutex_lock(&xtxhdcp->hdcptx_mutex);
+		xtxhdcp->auth_status = xlnx_hdcp2x_task_monitor(xhdcp2x);
+		if (xhdcp2x->handlers.notify_handler)
+			xhdcp2x->handlers.notify_handler(xhdcp2x->interface_ref,
+							 xtxhdcp->auth_status);
+		schedule_delayed_work(&xtxhdcp->hdcp_task_monitor, 0);
+		mutex_unlock(&xtxhdcp->hdcptx_mutex);
+	} else if (xtxhdcp->hdcp_protocol == XHDCPTX_HDCP_1X) {
+		struct xlnx_hdcp1x_config  *xhdcp1x = xtxhdcp->xhdcp1x;
+
+		mutex_lock(&xtxhdcp->hdcptx_mutex);
+		xtxhdcp->auth_status = xlnx_hdcp1x_task_monitor(xhdcp1x);
+		if (xhdcp1x->handlers.notify_handler)
+			xhdcp1x->handlers.notify_handler(xhdcp1x->interface_ref,
+							  xtxhdcp->auth_status);
+		schedule_delayed_work(&xtxhdcp->hdcp_task_monitor, 0);
+		mutex_unlock(&xtxhdcp->hdcptx_mutex);
+	} else {
+		dev_dbg(xtxhdcp->dev, "Task Monitor is Failed\n");
+		dev_dbg(xtxhdcp->dev, "Unsupported protocol\n");
+	}
+}
+
+void xlnx_hdcp_tx_process_cp_irq(struct xlnx_hdcptx *xtxhdcp)
+{
+	if (xtxhdcp->hdcp2xenable) {
+		struct xlnx_hdcp2x_config  *xhdcp2x = xtxhdcp->xhdcp2x;
+
+		if (xtxhdcp->hdcp_protocol == XHDCPTX_HDCP_2X)
+			xlnx_hdcp2x_tx_process_cp_irq(xhdcp2x);
+	}
+}
+EXPORT_SYMBOL_GPL(xlnx_hdcp_tx_process_cp_irq);
+
+/**
+ * xlnx_hdcp_tx_init - Initialize HDCP transmitter based on hardware selection
+ * and downstream capability
+ * @dev: device structure
+ * @protocol_ref: DP/HDMI structure reference
+ * @xtxhdcp: Xilinx HDCP core driver structure
+ * @hdcp_base_address: HDCP core address
+ * @is_repeater: Repeater selection
+ * @hdcp_type: HDCP protocol selection
+ * @lane_count: Number of lanes data to be encrypted
+ * @hw_protocol: Interface type HDMI or DP
+ * @key_base_address: HDCP Key Management base address
+ * return: HDCP 1x/2x driver structure if success or return memory allocation error
+ */
+void *xlnx_hdcp_tx_init(struct device *dev, void *protocol_ref,
+			struct xlnx_hdcptx *xtxhdcp, void __iomem *hdcp_base_address,
+			u8 is_repeater,	enum xlnx_hdcptx_protocol_type hdcp_type, u8 lane_count,
+			int hw_protocol, struct regmap *key_base_address)
+{
+	struct xlnx_hdcp2x_config  *xhdcp2x;
+	struct xlnx_hdcp1x_config  *xhdcp1x;
+	void *hdcp_drv_address;
+	int ret;
+
+	if (hdcp_type == XHDCPTX_HDCP_2X) {
+		xhdcp2x = devm_kzalloc(dev, sizeof(*xhdcp2x), GFP_KERNEL);
+		if (!xhdcp2x)
+			return ERR_PTR(-ENOMEM);
+
+		hdcp_drv_address = xhdcp2x;
+		xhdcp2x->xhdcp2x_hw.hdcp2xcore_address =
+					(void __iomem *)hdcp_base_address;
+
+		xhdcp2x->xhdcp2x_hw.protocol = hw_protocol;
+		xhdcp2x->dev = dev;
+		xhdcp2x->interface_ref = protocol_ref;
+		xhdcp2x->interface_base = hdcp_base_address;
+		xhdcp2x->is_repeater = is_repeater ? 1 : 0;
+		xhdcp2x->lane_count = lane_count;
+
+		ret = xlnx_hdcp2x_tx_init(xhdcp2x, xhdcp2x->is_repeater);
+		if (ret < 0) {
+			dev_err(xhdcp2x->dev, "Failed to initialize HDCP2X engine\n");
+			goto hdcp2x_error;
+		}
+	}
+	if (hdcp_type == XHDCPTX_HDCP_1X) {
+		xhdcp1x = devm_kzalloc(dev, sizeof(*xhdcp1x), GFP_KERNEL);
+		if (!xhdcp1x)
+			return ERR_PTR(-ENOMEM);
+
+		hdcp_drv_address = xhdcp1x;
+		xhdcp1x->protocol = hw_protocol;
+		xhdcp1x->dev = dev;
+		xhdcp1x->interface_ref = protocol_ref;
+		xhdcp1x->interface_base = hdcp_base_address;
+		xhdcp1x->is_repeater = is_repeater ? 1 : 0;
+		xhdcp1x->lane_count = lane_count;
+		xhdcp1x->hdcp1x_keymgmt_base = key_base_address;
+		ret = xlnx_hdcp1x_tx_init(xhdcp1x, xhdcp1x->is_repeater);
+		if (ret < 0) {
+			dev_err(xhdcp1x->dev, "Failed to initialize HDCP1X engine\n");
+			goto hdcp1x_error;
+		}
+	}
+	if (hdcp_type == XHDCPTX_HDCP_NONE)
+		return ERR_PTR(-ENOMEM);
+
+	mutex_init(&xtxhdcp->hdcptx_mutex);
+	INIT_DELAYED_WORK(&xtxhdcp->hdcp_task_monitor, hdcp_task_monitor_fun);
+
+	return (void *)hdcp_drv_address;
+
+hdcp1x_error:
+	devm_kfree(dev, xhdcp1x);
+
+hdcp2x_error:
+	devm_kfree(dev, xhdcp2x);
+
+	return ERR_PTR(-ENOMEM);
+}
+EXPORT_SYMBOL_GPL(xlnx_hdcp_tx_init);
+
+/**
+ * xlnx_hdcp_timer_init - This function initializes timer submodule
+ * and driver structure parameters
+ * @dev: device structure
+ * @timer_base_address: Xilinx timer core address
+ * return: timer driver structure address if success or return memory
+ * allocation error
+ */
+void *xlnx_hdcp_timer_init(struct device *dev, void __iomem *timer_base_address)
+{
+	struct xlnx_hdcp_timer_config  *xhdcptmr;
+	int ret;
+
+	xhdcptmr = devm_kzalloc(dev, sizeof(*xhdcptmr), GFP_KERNEL);
+	if (!xhdcptmr)
+		return ERR_PTR(-ENOMEM);
+
+	xhdcptmr->hw_config.coreaddress = (void __iomem *)timer_base_address;
+	xhdcptmr->hw_config.sys_clock_freq = XDPTX_TIMER_CLOCK_FREQ_HZ;
+
+	ret = xlnx_hdcp_tmrcntr_init(xhdcptmr);
+	if (ret < 0)
+		goto error;
+
+	return xhdcptmr;
+
+error:
+	devm_kfree(dev, xhdcptmr);
+
+	return ERR_PTR(-ENOMEM);
+}
+EXPORT_SYMBOL_GPL(xlnx_hdcp_timer_init);
+
+int xlnx_hdcp_tx_exit(struct xlnx_hdcptx *xtxhdcp)
+{
+	struct xlnx_hdcp2x_config  *xhdcp2x = xtxhdcp->xhdcp2x;
+	struct xlnx_hdcp1x_config  *xhdcp1x = xtxhdcp->xhdcp1x;
+
+	if (xtxhdcp->hdcp2xenable) {
+		if (xtxhdcp->xhdcp2x) {
+			devm_kfree(xtxhdcp->dev, xhdcp2x);
+		} else {
+			dev_err(xtxhdcp->dev, "HDCP2X is not initialized\n");
+			goto hdcp_error;
+		}
+	}
+	if (xtxhdcp->hdcp1xenable) {
+		if (xtxhdcp->xhdcp1x) {
+			devm_kfree(xtxhdcp->dev, xhdcp1x);
+		} else {
+			dev_err(xtxhdcp->dev, "Hdcp1x is not initialized\n");
+			goto hdcp_error;
+		}
+	}
+	return 0;
+
+hdcp_error:
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(xlnx_hdcp_tx_exit);
+
+void xlnx_hdcp_tx_timer_exit(struct xlnx_hdcptx *xtxhdcp)
+{
+	struct xlnx_hdcp_timer_config  *xhdcptmr = xtxhdcp->xhdcptmr;
+
+	if (xtxhdcp->xhdcptmr)
+		devm_kfree(xtxhdcp->dev, xhdcptmr);
+}
+EXPORT_SYMBOL_GPL(xlnx_hdcp_tx_timer_exit);
+
+int xlnx_hdcp_tx_set_keys(struct xlnx_hdcptx *xtxhdcp, const u8 *data)
+{
+	int ret = 0;
+	struct xlnx_hdcp2x_config  *xhdcp2x = xtxhdcp->xhdcp2x;
+	struct xlnx_hdcp1x_config  *xhdcp1x = xtxhdcp->xhdcp1x;
+	u8 local_srm[XHDCP2X_TX_SRM_SIZE];
+	u8 local_lc128[XHDCP2X_TX_LC128_SIZE];
+	u8 local_buf[XHDCP1X_TX_ENCRYPTION_KEY_SIZE];
+
+	memcpy(local_buf, data, XHDCP1X_TX_ENCRYPTION_KEY_SIZE);
+	memcpy(local_lc128, data + XHDCP1X_TX_ENCRYPTION_KEY_SIZE, XHDCP2X_TX_LC128_SIZE);
+	memcpy(local_srm,
+	       data + XHDCP1X_TX_ENCRYPTION_KEY_SIZE + XHDCP2X_TX_LC128_SIZE, XHDCP2X_TX_SRM_SIZE);
+
+	if (xtxhdcp->hdcp2xenable) {
+		ret = xlnx_hdcp2x_loadkeys(xhdcp2x, local_srm, local_lc128);
+		if (ret < 0)
+			return -EINVAL;
+	}
+	if (xtxhdcp->hdcp1xenable) {
+		ret = xlnx_hdcp1x_set_keys(xhdcp1x, local_buf);
+		if (ret < 0)
+			return -EINVAL;
+	}
+
+	xtxhdcp->is_enckey_available = true;
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(xlnx_hdcp_tx_set_keys);
+
+int xlnx_hdcp_tx_reset(struct xlnx_hdcptx *xtxhdcp)
+{
+	int ret;
+
+	if (!(xtxhdcp->hdcp2xenable || xtxhdcp->hdcp1xenable))
+		return -EINVAL;
+
+	if (xtxhdcp->hdcp2xenable) {
+		struct xlnx_hdcp2x_config  *xhdcp2x = xtxhdcp->xhdcp2x;
+
+		cancel_delayed_work_sync(&xtxhdcp->hdcp_task_monitor);
+		xtxhdcp->hdcp_protocol = XHDCPTX_HDCP_NONE;
+		mutex_lock(&xtxhdcp->hdcptx_mutex);
+
+		ret = xlnx_hdcp2x_tx_reset(xhdcp2x);
+		if (ret < 0) {
+			mutex_unlock(&xtxhdcp->hdcptx_mutex);
+			return -EINVAL;
+		}
+		mutex_unlock(&xtxhdcp->hdcptx_mutex);
+	}
+	if (xtxhdcp->hdcp1xenable) {
+		struct xlnx_hdcp1x_config  *xhdcp1x = xtxhdcp->xhdcp1x;
+
+		cancel_delayed_work_sync(&xtxhdcp->hdcp_task_monitor);
+		xtxhdcp->hdcp_protocol = XHDCPTX_HDCP_NONE;
+		mutex_lock(&xtxhdcp->hdcptx_mutex);
+
+		ret = xlnx_hdcp1x_tx_reset(xhdcp1x);
+		if (ret < 0) {
+			mutex_unlock(&xtxhdcp->hdcptx_mutex);
+			return -EINVAL;
+		}
+		mutex_unlock(&xtxhdcp->hdcptx_mutex);
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(xlnx_hdcp_tx_reset);
+
+static void xlnx_hcdp_tx_timer_callback(void *xtxhdcptr, u8 tmrcntr_number)
+{
+	struct xlnx_hdcptx *xtxhdcp = xtxhdcptr;
+	struct xlnx_hdcp2x_config  *xhdcp2x = xtxhdcp->xhdcp2x;
+	struct xlnx_hdcp1x_config  *xhdcp1x = xtxhdcp->xhdcp1x;
+
+	if (xtxhdcp->hdcp2xenable) {
+		if (xtxhdcp->hdcp_protocol == XHDCPTX_HDCP_2X) {
+			mutex_lock(&xtxhdcp->hdcptx_mutex);
+			xlnx_hdcp2x_tx_timer_handler((void *)xhdcp2x,
+						     tmrcntr_number);
+			mutex_unlock(&xtxhdcp->hdcptx_mutex);
+
+			return;
+		}
+	}
+	if (xtxhdcp->hdcp1xenable) {
+		if (xtxhdcp->hdcp_protocol == XHDCPTX_HDCP_NONE) {
+			schedule_delayed_work(&xtxhdcp->hdcp_task_monitor, 0);
+		} else if (xtxhdcp->hdcp_protocol == XHDCPTX_HDCP_1X) {
+			mutex_lock(&xtxhdcp->hdcptx_mutex);
+			xlnx_hdcp1x_tx_timer_handler((void *)xhdcp1x, tmrcntr_number);
+			mutex_unlock(&xtxhdcp->hdcptx_mutex);
+		}
+
+		return;
+	}
+}
+
+int xlnx_start_hdcp_engine(struct xlnx_hdcptx *xtxhdcp, u8 lanecount)
+{
+	if (!(xtxhdcp->hdcp2xenable || xtxhdcp->hdcp1xenable))
+		return -EINVAL;
+
+	if (!xtxhdcp->is_enckey_available)
+		return -EINVAL;
+
+	if (xtxhdcp->hdcp2xenable) {
+		struct xlnx_hdcp2x_config  *xhdcp2x = xtxhdcp->xhdcp2x;
+
+		xlnx_hdcptx_read_ds_sink_capability(xtxhdcp);
+
+		if (xtxhdcp->hdcp_protocol == XHDCPTX_HDCP_2X) {
+			xlnx_hdcp2x_tx_timer_init(xhdcp2x, xtxhdcp->xhdcptmr);
+			xlnx_hdcp_tmrcntr_set_handler(xtxhdcp->xhdcptmr,
+						      xlnx_hcdp_tx_timer_callback,
+						      (void *)xtxhdcp);
+			xhdcp2x->lane_count = lanecount;
+			xlnx_start_hdcp2x_engine(xhdcp2x);
+			schedule_delayed_work(&xtxhdcp->hdcp_task_monitor, 0);
+
+			return 0;
+		}
+	}
+	if (xtxhdcp->hdcp1xenable) {
+		struct xlnx_hdcp1x_config *xhdcp1x = xtxhdcp->xhdcp1x;
+
+		xlnx_hdcp1x_tx_timer_init(xhdcp1x, xtxhdcp->xhdcptmr);
+		xlnx_hdcp_tmrcntr_set_handler(xtxhdcp->xhdcptmr,
+					      xlnx_hcdp_tx_timer_callback,
+					      (void *)xtxhdcp);
+		xhdcp1x->lane_count = lanecount;
+		xlnx_hdcptx_read_ds_sink_capability(xtxhdcp);
+		if (xtxhdcp->hdcp_protocol == XHDCPTX_HDCP_1X) {
+			xhdcp1x->lane_count = lanecount;
+			xlnx_start_hdcp1x_engine(xhdcp1x);
+			schedule_delayed_work(&xtxhdcp->hdcp_task_monitor, 0);
+
+			return 0;
+		}
+	} else {
+		dev_err(xtxhdcp->dev, "Downstream is not a HDCP complaint Device\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(xlnx_start_hdcp_engine);
+
+int xlnx_hdcp_tx_set_callback(void *ref,
+			      enum xlnx_hdcptx_callback_type callback_type,
+			      void *callbackfunc)
+{
+	int ret = 0;
+	struct xlnx_hdcptx *xtxhdcp = (struct xlnx_hdcptx *)ref;
+
+	if (xtxhdcp->hdcp2xenable) {
+		struct xlnx_hdcp2x_config  *xhdcp2x = xtxhdcp->xhdcp2x;
+
+		switch (callback_type) {
+		case XHDCPTX_HANDLER_AUX_READ:
+			xhdcp2x->handlers.rd_handler = callbackfunc;
+			break;
+		case XHDCPTX_HANDLER_AUX_WRITE:
+			xhdcp2x->handlers.wr_handler = callbackfunc;
+			break;
+		case XHDCPTX_HANDLER_HDCP_STATUS:
+			xhdcp2x->handlers.notify_handler = callbackfunc;
+			break;
+		default:
+			dev_err(xtxhdcp->dev, "Invalid handler type\n");
+			ret = -EINVAL;
+			break;
+		}
+	}
+	if (xtxhdcp->hdcp1xenable) {
+		struct xlnx_hdcp1x_config  *xhdcp1x = xtxhdcp->xhdcp1x;
+
+		switch (callback_type) {
+		case XHDCPTX_HANDLER_AUX_READ:
+			xhdcp1x->handlers.rd_handler = callbackfunc;
+			break;
+		case XHDCPTX_HANDLER_AUX_WRITE:
+			xhdcp1x->handlers.wr_handler = callbackfunc;
+			break;
+		case XHDCPTX_HANDLER_HDCP_STATUS:
+			xhdcp1x->handlers.notify_handler = callbackfunc;
+			break;
+		default:
+			dev_err(xtxhdcp->dev, "Invalid handler type\n");
+			ret = -EINVAL;
+			break;
+		}
+	}
+	return ret;
+}
+EXPORT_SYMBOL_GPL(xlnx_hdcp_tx_set_callback);
+
+void xlnx_hdcp1x_interrupt_handler(struct xlnx_hdcptx *xtxhdcp)
+{
+	if (xtxhdcp->hdcp1xenable) {
+		u32 interrupts;
+		struct xlnx_hdcp1x_config  *xhdcp1x = xtxhdcp->xhdcp1x;
+
+		if (xhdcp1x_cipher_get_interrupts(xhdcp1x->cipher, &interrupts))
+			return;
+
+		xlnx_hdcp1x_tx_process_ri_event(xhdcp1x);
+	}
+}
+EXPORT_SYMBOL_GPL(xlnx_hdcp1x_interrupt_handler);
diff --git a/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_tx.h b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_tx.h
new file mode 100644
index 000000000..40d865f8b
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/hdcp/xlnx_hdcp_tx.h
@@ -0,0 +1,97 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * HDCP Interface driver
+ *
+ * Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
+ *
+ * Author: Lakshmi Prasanna Eachuri <lakshmi.prasanna.eachuri@amd.com>
+ */
+
+#ifndef _XLNX_HDCP_TX_H_
+#define _XLNX_HDCP_TX_H_
+
+#include <linux/device.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/regmap.h>
+#include <linux/types.h>
+#include <linux/xlnx/xlnx_timer.h>
+#include <linux/xlnx/xilinx-hdcp1x-cipher.h>
+#include "xlnx_hdcp2x_tx.h"
+
+#define XHDCP_KEY_WRITE_PERMISSION 0220
+
+enum xlnx_hdcptx_callback_type {
+	XHDCPTX_HANDLER_AUX_READ = 0,
+	XHDCPTX_HANDLER_AUX_WRITE = 1,
+	XHDCPTX_HANDLER_HDCP_STATUS = 2,
+	XHDCPTX_HANDLER_INVALID = 3
+};
+
+enum xlnx_hdcptx_protocol_type {
+	XHDCPTX_HDCP_NONE = 0,
+	XHDCPTX_HDCP_1X = 1,
+	XHDCPTX_HDCP_2X = 2,
+	XHDCPTX_HDCP_BOTH = 3
+};
+
+enum xlnx_hdcptx_authstatus {
+	XHDCPTX_INCOMPATIBLE_RX = 0,
+	XHDCPTX_AUTHENTICATION_BUSY = 1,
+	XHDCPTX_AUTHENTICATED = 2,
+	XHDCPTX_UNAUTHENTICATED = 3,
+	XHDCPTX_REAUTHENTICATE_REQUESTED = 4,
+	XHDCPTX_DEVICE_IS_REVOKED = 5,
+	XHDCPTX_NO_SRM_LOADED = 6
+};
+
+/**
+ * struct xlnx_hdcptx - This structure contains hardware subcore configuration
+ * information about HDCP protocol hardware engine.
+ * @dev: platform device
+ * @xhdcp2x: HDCP2X configuration structure
+ * @xhdcp1x: HDCP1X configuration structure
+ * @xhdcptmr: Axi timer for HDCP module
+ * @hdcptx_mutex: Mutex for HDCP state machine
+ * @hdcp_task_monitor: Work function for HDCP
+ * @hdcp_protocol: Protocol type, HDCP1x, HDCP2X or supports both
+ * @auth_status: Authentication status
+ * @hdcp2xenable: HDCP2X protocol is enabled
+ * @hdcp1xenable: HDCP1X protocol is enabled
+ * @is_enckey_available: Availability of encryption keys
+ * @is_hdcp_initialized: Flag to check whether HDCP driver is initialized or not
+ */
+struct xlnx_hdcptx {
+	struct device *dev;
+	struct xlnx_hdcp2x_config	*xhdcp2x;
+	struct xlnx_hdcp1x_config	*xhdcp1x;
+	struct xlnx_hdcp_timer_config	*xhdcptmr;
+	struct mutex hdcptx_mutex; /* Mutex for HDCP state machine */
+	struct delayed_work  hdcp_task_monitor;
+	enum xlnx_hdcptx_protocol_type hdcp_protocol;
+	enum xlnx_hdcptx_authstatus auth_status;
+	bool hdcp2xenable;
+	bool hdcp1xenable;
+	bool is_enckey_available;
+	bool is_hdcp_initialized;
+};
+
+int xlnx_hdcp_tx_reset(struct xlnx_hdcptx *xtxhdcp);
+int xlnx_start_hdcp_engine(struct xlnx_hdcptx *xtxhdcp, u8 lanecount);
+int xlnx_hdcp_tx_exit(struct xlnx_hdcptx *xtxhdcp);
+int xlnx_hdcp_tx_set_callback(void *ref,
+			      enum xlnx_hdcptx_callback_type callback_type,
+			      void *callbackfunc);
+int xlnx_hdcp_tx_set_keys(struct xlnx_hdcptx *xtxhdcp, const u8 *data);
+
+void xlnx_hdcp1x_interrupt_handler(struct xlnx_hdcptx *xtxhdcp);
+void *xlnx_hdcp_tx_init(struct device *dev, void *protocol_ref,
+			struct xlnx_hdcptx *xtxhdcp, void __iomem *hdcp_base_address,
+			u8 is_repeater,	enum xlnx_hdcptx_protocol_type, u8 lane_count,
+			int hw_protocol, struct regmap *key_base_address);
+void *xlnx_hdcp_timer_init(struct device *dev, void __iomem *interface_base);
+void xlnx_hdcp_tx_process_cp_irq(struct xlnx_hdcptx *xhdcptx);
+void xlnx_hdcp_tx_timer_exit(struct xlnx_hdcptx *xtxhdcp);
+void xlnx_hdcptx_read_ds_sink_capability(struct xlnx_hdcptx *xtxhdcp);
+
+#endif
diff --git a/drivers/gpu/drm/xlnx/mmi_dc.c b/drivers/gpu/drm/xlnx/mmi_dc.c
new file mode 100644
index 000000000..85afa7a14
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/mmi_dc.c
@@ -0,0 +1,452 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Multimedia Integrated Display Controller Driver
+ *
+ * Copyright (C) 2025, Advanced Micro Devices, Inc. All rights reserved.
+ */
+
+#include <linux/delay.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/reset.h>
+
+#include "mmi_dc.h"
+
+/* DC DP Stream Registers */
+#define MMI_DC_DP_MAIN_STREAM_HTOTAL	(0x0000)
+#define MMI_DC_DP_MAIN_STREAM_VTOTAL	(0x0004)
+#define MMI_DC_DP_MAIN_STREAM_HSWIDTH	(0x000c)
+#define MMI_DC_DP_MAIN_STREAM_VSWIDTH	(0x0010)
+#define MMI_DC_DP_MAIN_STREAM_HRES	(0x0014)
+#define MMI_DC_DP_MAIN_STREAM_VRES	(0x0018)
+#define MMI_DC_DP_MAIN_STREAM_HSTART	(0x001c)
+#define MMI_DC_DP_MAIN_STREAM_VSTART	(0x0020)
+#define MMI_DC_DP_MAIN_STREAM_MISC0	(0x0024)
+
+#define MMI_DC_DP_MAIN_STREAM_BPC_MASK	GENMASK(7, 5)
+#define MMI_DC_DP_MAIN_STREAM_BPC_SHIFT	(5)
+#define MMI_DC_DP_MAIN_STREAM_BPC_12	(3 << MMI_DC_DP_MAIN_STREAM_BPC_SHIFT)
+
+/* Blender Registers */
+#define MMI_DC_V_BLEND_BG_CLR(cc)		(0x0000 + 4 * (cc))
+#define MMI_BG_CLR_MIN				(0)
+#define MMI_BG_CLR_MAX				GENMASK(11, 0)
+#define MMI_DC_V_BLEND_GLOBAL_ALPHA		(0x000c)
+#define MMI_DC_V_BLEND_OUTPUT_VID_FORMAT	(0x0014)
+#define MMI_DC_V_BLEND_RGB2YCBCR_COEFF(coeff)	(0x0020 + 4 * (coeff))
+#define MMI_DC_V_BLEND_CC_OUTCSC_OFFSET(cc)	(0x0074 + 4 * (cc))
+
+#define MMI_DC_V_BLEND_ALPHA_VALUE(alpha)	((u32)(alpha) << 1)
+#define MMI_DC_V_BLEND_EN_DOWNSAMPLE		BIT(4)
+
+/* AV Buffer Registers */
+#define MMI_DC_AV_BUF_NON_LIVE_LATENCY		(0x0008)
+#define MMI_DC_AV_BUF_NON_LIVE_LATENCY_VAL	(0x20138)
+#define MMI_DC_AV_BUF_SRST			(0x0124)
+
+#define MMI_DC_AV_BUF_RESET_SHIFT		(1)
+#define MMI_DC_AV_BUF_AUD_VID_CLK_SOURCE	(0x0120)
+#define MMI_DC_AV_BUF_AUD_VID_TIMING_SRC_INT	BIT(2)
+
+/* Misc Registers */
+#define MMI_DC_MISC_VID_CLK			(0x0c5c)
+#define MMI_DC_MISC_WPROTS			(0x0c70)
+#define MMI_DC_VIDEO_FRAME_SWITCH		(0x0d80)
+#define MMI_DC_VIDEO_FRAME_SWITCH_DP_VID0_IMM	BIT(5)
+#define MMI_DC_VIDEO_FRAME_SWITCH_DP_VID0_EN	BIT(4)
+#define MMI_DC_VIDEO_FRAME_SWITCH_PL_VID1_IMM	BIT(3)
+#define MMI_DC_VIDEO_FRAME_SWITCH_PL_VID1_EN	BIT(2)
+#define MMI_DC_VIDEO_FRAME_SWITCH_PL_VID0_IMM	BIT(1)
+#define MMI_DC_VIDEO_FRAME_SWITCH_PL_VID0_EN	BIT(0)
+#define MMI_DC_VIDEO_FRAME_SWITCH_EN_ALL	(MMI_DC_VIDEO_FRAME_SWITCH_DP_VID0_IMM	| \
+						MMI_DC_VIDEO_FRAME_SWITCH_DP_VID0_EN	| \
+						MMI_DC_VIDEO_FRAME_SWITCH_PL_VID1_IMM	| \
+						MMI_DC_VIDEO_FRAME_SWITCH_PL_VID1_EN	| \
+						MMI_DC_VIDEO_FRAME_SWITCH_PL_VID0_IMM	| \
+						MMI_DC_VIDEO_FRAME_SWITCH_PL_VID0_EN)
+
+#define MMI_DC_MISC_VID_CLK_PS			BIT(1)
+#define MMI_DC_MISC_VID_CLK_PL			0
+
+/* IRQ Registers */
+#define MMI_DC_INT_STATUS			(0x0000)
+#define MMI_DC_INT_MASK				(0x0004)
+#define MMI_DC_INT_EN				(0x0008)
+#define MMI_DC_INT_DS				(0x000c)
+
+#define MMI_DC_INT_VBLANK			BIT(3)
+#define MMI_DC_INT_PIXEL_MATCH			(BIT(4) | BIT(5))
+#define MMI_DC_MSLEEP_50MS			(50)
+
+/* ----------------------------------------------------------------------------
+ * CSC Data
+ */
+
+const u16 csc_zero_matrix[MMI_DC_CSC_NUM_COEFFS] = {
+	0x0000, 0x0000, 0x0000,
+	0x0000, 0x0000, 0x0000,
+	0x0000, 0x0000, 0x0000,
+};
+
+const u16 csc_identity_matrix[MMI_DC_CSC_NUM_COEFFS] = {
+	0x1000, 0x0000, 0x0000,
+	0x0000, 0x1000, 0x0000,
+	0x0000, 0x0000, 0x1000,
+};
+
+const u16 csc_rgb_to_sdtv_matrix[MMI_DC_CSC_NUM_COEFFS] = {
+	0x04c9, 0x0864, 0x01d3,
+	0x7d4d, 0x7ab3, 0x0800,
+	0x0800, 0x794d, 0x7eb3,
+};
+
+const u16 csc_sdtv_to_rgb_matrix[MMI_DC_CSC_NUM_COEFFS] = {
+	0x1000, 0x166f, 0x0000,
+	0x1000, 0x7483, 0x7a7f,
+	0x1000, 0x0000, 0x1c5a,
+};
+
+const u32 csc_zero_offsets[MMI_DC_CSC_NUM_OFFSETS] = {
+	0x00000000, 0x00000000, 0x00000000,
+};
+
+const u32 csc_rgb_to_sdtv_offsets[MMI_DC_CSC_NUM_OFFSETS] = {
+	0x00000000, 0x08000000, 0x08000000,
+};
+
+const u32 csc_sdtv_to_rgb_offsets[MMI_DC_CSC_NUM_OFFSETS] = {
+	0x00000000, 0x00001800, 0x00001800,
+};
+
+/**
+ * mmi_dc_set_stream - Set DC output video stream
+ * @dc: MMI DC device
+ * @mode: requested DRM display mode or NULL to disable output to DP Tx
+ */
+static void mmi_dc_set_stream(struct mmi_dc *dc,
+			      struct drm_display_mode *mode)
+{
+	dc_write_dp(dc, MMI_DC_DP_MAIN_STREAM_HTOTAL, mode ? mode->htotal : 0);
+	dc_write_dp(dc, MMI_DC_DP_MAIN_STREAM_VTOTAL, mode ? mode->vtotal : 0);
+	dc_write_dp(dc, MMI_DC_DP_MAIN_STREAM_HSWIDTH,
+		    mode ? mode->hsync_end - mode->hsync_start : 0);
+	dc_write_dp(dc, MMI_DC_DP_MAIN_STREAM_VSWIDTH,
+		    mode ? mode->vsync_end - mode->vsync_start : 0);
+	dc_write_dp(dc, MMI_DC_DP_MAIN_STREAM_HRES, mode ? mode->hdisplay : 0);
+	dc_write_dp(dc, MMI_DC_DP_MAIN_STREAM_VRES, mode ? mode->vdisplay : 0);
+	dc_write_dp(dc, MMI_DC_DP_MAIN_STREAM_HSTART,
+		    mode ? mode->htotal - mode->hsync_start : 0);
+	dc_write_dp(dc, MMI_DC_DP_MAIN_STREAM_VSTART,
+		    mode ? mode->vtotal - mode->vsync_start : 0);
+	dc_write_dp(dc, MMI_DC_DP_MAIN_STREAM_MISC0,
+		    mode ? MMI_DC_DP_MAIN_STREAM_BPC_12 &
+		    MMI_DC_DP_MAIN_STREAM_BPC_MASK : 0);
+}
+
+/**
+ * mmi_dc_set_global_alpha - Set DC global alpha
+ * @dc: MMI DC device
+ * @alpha: requested alpha value
+ * @enable: enable alpha blending
+ */
+void mmi_dc_set_global_alpha(struct mmi_dc *dc, u8 alpha, bool enable)
+{
+	dc_write_blend(dc, MMI_DC_V_BLEND_GLOBAL_ALPHA,
+		       MMI_DC_V_BLEND_ALPHA_VALUE(alpha) | enable);
+}
+
+/**
+ * mmi_dc_blend_set_bg_color - Set blender background color
+ * @dc: MMI DC device
+ * @rcr: R/Cr component value (12 bit)
+ * @gy: G/Y component value (12 bit)
+ * @bcb: B/Cb component value (12 bit)
+ */
+static void mmi_dc_blend_set_bg_color(struct mmi_dc *dc,
+				      u32 rcr, u32 gy, u32 bcb)
+{
+	dc_write_blend(dc, MMI_DC_V_BLEND_BG_CLR(0), rcr);
+	dc_write_blend(dc, MMI_DC_V_BLEND_BG_CLR(1), gy);
+	dc_write_blend(dc, MMI_DC_V_BLEND_BG_CLR(2), bcb);
+}
+
+/**
+ * mmi_dc_blend_set_output_format - Set blender output format
+ * @dc: MMI DC device
+ * @format: requested blender output format
+ */
+static void mmi_dc_blend_set_output_format(struct mmi_dc *dc,
+					   enum mmi_dc_out_format format)
+{
+	u32 blend_format = format;
+	const u16 *coeffs;
+	const u32 *offsets;
+	unsigned int i;
+
+	if (blend_format == MMI_DC_FORMAT_YCBCR422)
+		blend_format |= MMI_DC_V_BLEND_EN_DOWNSAMPLE;
+
+	dc_write_blend(dc, MMI_DC_V_BLEND_OUTPUT_VID_FORMAT, blend_format);
+	if (blend_format == MMI_DC_FORMAT_RGB) {
+		coeffs = csc_identity_matrix;
+		offsets = csc_zero_offsets;
+	} else {
+		coeffs = csc_rgb_to_sdtv_matrix;
+		offsets = csc_rgb_to_sdtv_offsets;
+	}
+
+	for (i = 0; i < MMI_DC_CSC_NUM_COEFFS; ++i)
+		dc_write_blend(dc, MMI_DC_V_BLEND_RGB2YCBCR_COEFF(i),
+			       coeffs[i]);
+
+	for (i = 0; i < MMI_DC_CSC_NUM_OFFSETS; ++i)
+		dc_write_blend(dc, MMI_DC_V_BLEND_CC_OUTCSC_OFFSET(i),
+			       offsets[i]);
+}
+
+/**
+ * mmi_dc_blend_enable - Enable DC blender
+ * @dc: MMI DC device
+ */
+static void mmi_dc_blend_enable(struct mmi_dc *dc)
+{
+	/* Set background color as blue */
+	mmi_dc_blend_set_bg_color(dc, MMI_BG_CLR_MIN, MMI_BG_CLR_MIN,
+				  MMI_BG_CLR_MAX);
+	/* TODO: Support YUV formats */
+	mmi_dc_blend_set_output_format(dc, MMI_DC_FORMAT_RGB);
+}
+
+/**
+ * mmi_dc_blend_disable - Disable DC blender
+ * @dc: MMI DC device
+ */
+static void mmi_dc_blend_disable(struct mmi_dc *dc)
+{
+	/* TODO: probably make sense to reset blender to default state */
+}
+
+/**
+ * mmi_dc_reset - Soft reset DC hardware
+ * @dc: MMI DC device
+ * @reset: assert or deassert
+ */
+static void mmi_dc_reset(struct mmi_dc *dc, bool reset)
+{
+	dc_write_avbuf(dc, MMI_DC_AV_BUF_SRST,
+		       reset << MMI_DC_AV_BUF_RESET_SHIFT);
+}
+
+/**
+ * mmi_dc_toggle_ext_reset - Reset DC hardware with external reset
+ * @dc: MMI DC device
+ */
+void mmi_dc_toggle_ext_reset(struct mmi_dc *dc)
+{
+	reset_control_assert(dc->rst);
+	reset_control_deassert(dc->rst);
+}
+
+/**
+ * mmi_dc_avbuf_enable - Enable AV buffer manager
+ * @dc: MMI DC device
+ */
+static void mmi_dc_avbuf_enable(struct mmi_dc *dc)
+{
+	/* TODO: check if any global state need to be initialized */
+}
+
+/**
+ * mmi_dc_avbuf_disable - Disable AV buffer manager
+ * @dc: MMI DC device
+ */
+static void mmi_dc_avbuf_disable(struct mmi_dc *dc)
+{
+	/* TODO: reset AV buffer to default state */
+}
+
+/**
+ * mmi_dc_enable - Enable MMI DC
+ * @dc: MMI DC device
+ * @mode: the display mode requested
+ */
+void mmi_dc_enable(struct mmi_dc *dc, struct drm_display_mode *mode)
+{
+	mmi_dc_blend_enable(dc);
+	mmi_dc_avbuf_enable(dc);
+	mmi_dc_set_stream(dc, mode);
+}
+
+/**
+ * mmi_dc_disable - Disable MMI DC
+ * @dc: MMI DC device
+ */
+void mmi_dc_disable(struct mmi_dc *dc)
+{
+	mmi_dc_avbuf_disable(dc);
+	mmi_dc_blend_disable(dc);
+	mmi_dc_set_stream(dc, NULL);
+	mmi_dc_toggle_ext_reset(dc);
+}
+
+/**
+ * mmi_dc_set_dma_align - Set DC DMA align
+ * @dc: MMI DC device
+ */
+static void mmi_dc_set_dma_align(struct mmi_dc *dc)
+{
+	dc->dma_align = mmi_dc_planes_get_dma_align(dc);
+}
+
+/**
+ * mmi_dc_enable_vblank - Enable VBLANK notifications
+ * @dc: MMI DC device
+ */
+void mmi_dc_enable_vblank(struct mmi_dc *dc)
+{
+	dc_write_irq(dc, MMI_DC_INT_EN, MMI_DC_INT_VBLANK);
+}
+
+/**
+ * mmi_dc_disable_vblank - Disable VBLANK notifications
+ * @dc: MMI DC device
+ */
+void mmi_dc_disable_vblank(struct mmi_dc *dc)
+{
+	dc_write_irq(dc, MMI_DC_INT_DS, MMI_DC_INT_VBLANK);
+}
+
+/**
+ * mmi_dc_irq_handler - MMI DC interrupt handler
+ * @irq: IRQ lane number
+ * @data: struct mmi_dc pointer bound to this handler
+ *
+ * Return: IRQ handling result.
+ */
+static irqreturn_t mmi_dc_irq_handler(int irq, void *data)
+{
+	struct mmi_dc *dc = data;
+	u32 status, mask;
+
+	status = dc_read_irq(dc, MMI_DC_INT_STATUS);
+	/* clear status register as soon as we read it */
+	dc_write_irq(dc, MMI_DC_INT_STATUS, status & ~MMI_DC_INT_PIXEL_MATCH);
+	mask = dc_read_irq(dc, MMI_DC_INT_MASK);
+
+	/*
+	 * Status register may report some events, which corresponding
+	 * interrupts have been disabled. Filter out those events against
+	 * interrupts' mask.
+	 */
+	status &= ~mask;
+
+	if (!status)
+		return IRQ_NONE;
+
+	/* TODO: handle errors */
+
+	if (status & MMI_DC_INT_VBLANK)
+		mmi_dc_drm_handle_vblank(dc->drm);
+
+	return IRQ_HANDLED;
+}
+
+/**
+ * mmi_dc_init - Initialize MMI DC hardware
+ * @dc: MMI DC device
+ * @drm: DRM device
+ *
+ * Return: 0 on success or error code otherwise.
+ */
+int mmi_dc_init(struct mmi_dc *dc, struct drm_device *drm)
+{
+	struct platform_device *pdev = to_platform_device(dc->dev);
+	int ret;
+
+	dc->dp = devm_platform_ioremap_resource_byname(pdev, "dp");
+	if (IS_ERR(dc->dp))
+		return PTR_ERR(dc->dp);
+
+	dc->blend = devm_platform_ioremap_resource_byname(pdev, "blend");
+	if (IS_ERR(dc->blend))
+		return PTR_ERR(dc->blend);
+
+	dc->avbuf = devm_platform_ioremap_resource_byname(pdev, "avbuf");
+	if (IS_ERR(dc->avbuf))
+		return PTR_ERR(dc->avbuf);
+
+	dc->misc = devm_platform_ioremap_resource_byname(pdev, "misc");
+	if (IS_ERR(dc->misc))
+		return PTR_ERR(dc->misc);
+
+	dc->irq = devm_platform_ioremap_resource_byname(pdev, "irq");
+	if (IS_ERR(dc->irq))
+		return PTR_ERR(dc->irq);
+
+	dc->rst = devm_reset_control_get(dc->dev, NULL);
+	if (IS_ERR(dc->rst))
+		return dev_err_probe(dc->dev, PTR_ERR(dc->rst),
+				     "failed to get reset control\n");
+
+	mmi_dc_toggle_ext_reset(dc);
+
+	dc_write_misc(dc, MMI_DC_MISC_WPROTS, 0);
+	dc_write_misc(dc, MMI_DC_VIDEO_FRAME_SWITCH,
+		      MMI_DC_VIDEO_FRAME_SWITCH_EN_ALL);
+
+	dc->irq_num = platform_get_irq(pdev, 0);
+	if (dc->irq_num < 0)
+		return dc->irq_num;
+
+	ret = mmi_dc_create_planes(dc, drm);
+	if (ret < 0) {
+		mmi_dc_destroy_planes(dc);
+		return ret;
+	}
+
+	mmi_dc_set_dma_align(dc);
+
+	/* Set video clock source */
+	if (dc->is_ps_clk)
+		dc_write_misc(dc, MMI_DC_MISC_VID_CLK, MMI_DC_MISC_VID_CLK_PS);
+	else
+		dc_write_misc(dc, MMI_DC_MISC_VID_CLK, MMI_DC_MISC_VID_CLK_PL);
+
+	mmi_dc_reset(dc, true);
+	msleep(MMI_DC_MSLEEP_50MS);
+	mmi_dc_reset(dc, false);
+
+	/* Set another video clock source */
+	dc_write_avbuf(dc, MMI_DC_AV_BUF_AUD_VID_CLK_SOURCE, MMI_DC_AV_BUF_AUD_VID_TIMING_SRC_INT);
+
+	/* Set non live video latency */
+	dc_write_avbuf(dc, MMI_DC_AV_BUF_NON_LIVE_LATENCY, MMI_DC_AV_BUF_NON_LIVE_LATENCY_VAL);
+
+	/* Set blender background and alpha */
+	mmi_dc_set_global_alpha(dc, 0, true);
+	mmi_dc_blend_set_bg_color(dc, MMI_BG_CLR_MIN, MMI_BG_CLR_MIN,
+				  MMI_BG_CLR_MAX);
+
+	ret = devm_request_threaded_irq(dc->dev, dc->irq_num, NULL,
+					mmi_dc_irq_handler,
+					IRQF_ONESHOT | IRQF_SHARED,
+					dev_name(dc->dev), dc);
+	if (ret < 0) {
+		dev_err(dc->dev, "failed to setup irq handler: %d\n", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+/**
+ * mmi_dc_fini - Deinit MMI DC device
+ * @dc: MMI DC device
+ */
+void mmi_dc_fini(struct mmi_dc *dc)
+{
+	mmi_dc_destroy_planes(dc);
+	mmi_dc_reset(dc, true);
+	dc_write_misc(dc, MMI_DC_MISC_WPROTS, 1);
+}
diff --git a/drivers/gpu/drm/xlnx/mmi_dc.h b/drivers/gpu/drm/xlnx/mmi_dc.h
new file mode 100644
index 000000000..44996a640
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/mmi_dc.h
@@ -0,0 +1,168 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Multimedia Integrated Display Controller Driver
+ *
+ * Copyright (C) 2025, Advanced Micro Devices, Inc. All rights reserved.
+ */
+
+#ifndef __MMI_DC_H__
+#define __MMI_DC_H__
+
+#include <linux/device.h>
+#include <drm/drm_modes.h>
+#include <drm/drm_plane.h>
+
+#define MMI_DC_NUM_PLANES		(2)
+#define MMI_DC_MAX_NUM_SUB_PLANES	(3)
+#define MMI_DC_VBLANKS			(3)
+#define MMI_DC_DPTX_PORT_0		(12)
+#define MMI_DC_MAX_WIDTH		(4096)
+#define MMI_DC_MAX_HEIGHT		(4096)
+
+/* ----------------------------------------------------------------------------
+ * CSC Data
+ */
+
+#define MMI_DC_CSC_NUM_COEFFS		(9)
+#define MMI_DC_CSC_NUM_OFFSETS		(3)
+
+/* ----------------------------------------------------------------------------
+ * MMI DC Plane Interface
+ */
+
+/* Blender Registers */
+#define MMI_DC_V_BLEND_LAYER_CONTROL(layer)		(0x0018 + 4 * (layer))
+#define MMI_DC_V_BLEND_INCSC_COEFF(layer, coeff)	(0x0044 + 0x3c * \
+							(layer) + 4 * (coeff))
+#define MMI_DC_V_BLEND_CC_INCSC_OFFSET(layer, cc)	(0x0068 + 0x3c * \
+							(layer) + 4 * (cc))
+
+#define MMI_DC_V_BLEND_RGB_MODE				BIT(1)
+#define MMI_DC_V_BLEND_EN_US				BIT(0)
+
+/* AV Buffer Registers */
+#define MMI_DC_AV_BUF_FORMAT				(0)
+#define MMI_DC_AV_CHBUF(channel)			(0x0010 + 4 * (channel))
+#define MMI_DC_AV_BUF_OUTPUT_AUDIO_VIDEO_SELECT		(0x0070)
+#define MMI_DC_AV_BUF_PLANE_CC_SCALE_FACTOR(layer, cc)	(0x0200 + 0x0c * \
+							(layer) + 4 * (cc))
+
+#define MMI_DC_AV_CHBUF_BURST				(0x000f << 2)
+#define MMI_DC_AV_CHBUF_FLUSH				BIT(1)
+#define MMI_DC_AV_CHBUF_EN				BIT(0)
+
+#define MMI_DC_AV_BUF_FMT_CR_Y0_CB_Y1			(1)
+#define MMI_DC_AV_BUF_FMT_Y0_CB_Y1_CR			(3)
+#define MMI_DC_AV_BUF_FMT_YV24				(5)
+
+#define MMI_DC_AV_BUF_FMT_RGB888			(10)
+#define MMI_DC_AV_BUF_FMT_YV16CI_420			(20)
+#define MMI_DC_AV_BUF_FMT_RGBA8888			(32)
+
+#define MMI_DC_AV_BUF_FMT_SHIFT(layer)			(8 * (layer))
+#define MMI_DC_AV_BUF_FMT_MASK(layer)			(0xff << \
+							 MMI_DC_AV_BUF_FMT_SHIFT(layer))
+#define MMI_DC_AV_BUF_VID_STREAM_SEL_MASK(layer)	(0x0003 << 2 * (layer))
+#define MMI_DC_AV_BUF_VID_STREAM_SEL_MEM(layer)		(0x0001 << 2 * (layer))
+#define MMI_DC_AV_BUF_VID_STREAM_SEL_NONE(layer)	(0x0003 << 2 * (layer))
+#define MMI_DC_AV_BUF_8BIT_SF				(0x00010101)
+#define MMI_DC_AV_BUF_NUM_SF				(9)
+
+extern const u16 csc_zero_matrix[MMI_DC_CSC_NUM_COEFFS];
+extern const u16 csc_identity_matrix[MMI_DC_CSC_NUM_COEFFS];
+extern const u16 csc_rgb_to_sdtv_matrix[MMI_DC_CSC_NUM_COEFFS];
+extern const u16 csc_sdtv_to_rgb_matrix[MMI_DC_CSC_NUM_COEFFS];
+
+extern const u32 csc_zero_offsets[MMI_DC_CSC_NUM_OFFSETS];
+extern const u32 csc_rgb_to_sdtv_offsets[MMI_DC_CSC_NUM_OFFSETS];
+extern const u32 csc_sdtv_to_rgb_offsets[MMI_DC_CSC_NUM_OFFSETS];
+
+/**
+ * enum mmi_dc_out_format - MMI DC output formats
+ * @MMI_DC_FORMAT_RGB: RGB output
+ * @MMI_DC_FORMAT_YCBCR444: non-subsampled YCbCr output
+ * @MMI_DC_FORMAT_YCBCR422: 422 subsampled YCbCr output
+ * @MMI_DC_FORMAT_YONLY: luma only (greyscale) output
+ */
+enum mmi_dc_out_format {
+	MMI_DC_FORMAT_RGB,
+	MMI_DC_FORMAT_YCBCR444,
+	MMI_DC_FORMAT_YCBCR422,
+	MMI_DC_FORMAT_YONLY,
+};
+
+struct mmi_dc_drm;
+struct mmi_dc_plane;
+
+/**
+ * struct mmi_dc - MMI DC device
+ * @dev: generic device
+ * @drm: MMI DC specific DRM data
+ * @planes: DC planes
+ * @dma_align: DMA alignment
+ * @reconfig_hw: reset and reconfig HW in crtc flush callback
+ * @dp: output to DP Tx control registers space
+ * @blend: blender control register space
+ * @avbuf: AV buffer manager control register space
+ * @misc: misc control register space
+ * @irq: interrupt control register space
+ * @rst: external reset
+ * @pixel_clk: pixel clock
+ * @is_ps_clk: flag for PS pixel clock source
+ * @irq_num: interrupt lane number
+ */
+struct mmi_dc {
+	struct device		*dev;
+	struct mmi_dc_drm	*drm;
+
+	struct mmi_dc_plane	*planes[MMI_DC_NUM_PLANES];
+	unsigned int		dma_align;
+	bool			reconfig_hw;
+
+	void __iomem		*dp;
+	void __iomem		*blend;
+	void __iomem		*avbuf;
+	void __iomem		*misc;
+	void __iomem		*irq;
+	struct reset_control	*rst;
+	struct clk		*pixel_clk;
+	bool			is_ps_clk;
+	int			irq_num;
+};
+
+#define DEFINE_REGISTER_OPS(iomem)					\
+static inline __maybe_unused u32					\
+dc_read_##iomem(struct mmi_dc *dc, u32 reg)				\
+{									\
+	return readl(dc->iomem + reg);					\
+}									\
+static inline __maybe_unused void					\
+dc_write_##iomem(struct mmi_dc *dc, u32 reg, u32 val)			\
+{									\
+	writel(val, dc->iomem + reg);					\
+}									\
+
+DEFINE_REGISTER_OPS(dp);
+DEFINE_REGISTER_OPS(blend);
+DEFINE_REGISTER_OPS(avbuf);
+DEFINE_REGISTER_OPS(misc);
+DEFINE_REGISTER_OPS(irq);
+
+void mmi_dc_set_global_alpha(struct mmi_dc *dc, u8 alpha, bool enable);
+void mmi_dc_enable_vblank(struct mmi_dc *dc);
+void mmi_dc_disable_vblank(struct mmi_dc *dc);
+void mmi_dc_enable(struct mmi_dc *dc, struct drm_display_mode *mode);
+void mmi_dc_disable(struct mmi_dc *dc);
+int mmi_dc_init(struct mmi_dc *dc, struct drm_device *drm);
+void mmi_dc_fini(struct mmi_dc *dc);
+void mmi_dc_toggle_ext_reset(struct mmi_dc *dc);
+
+void mmi_dc_drm_handle_vblank(struct mmi_dc_drm *drm);
+struct drm_plane *mmi_dc_plane_get_primary(struct mmi_dc *dc);
+void mmi_dc_planes_set_possible_crtc(struct mmi_dc *dc, u32 crtc_mask);
+unsigned int mmi_dc_planes_get_dma_align(struct mmi_dc *dc);
+int mmi_dc_create_planes(struct mmi_dc *dc, struct drm_device *drm);
+void mmi_dc_destroy_planes(struct mmi_dc *dc);
+void mmi_dc_reconfig_planes(struct mmi_dc *dc, struct drm_atomic_state *state);
+
+#endif /* __MMI_DC_H__ */
diff --git a/drivers/gpu/drm/xlnx/mmi_dc_kms.c b/drivers/gpu/drm/xlnx/mmi_dc_kms.c
new file mode 100644
index 000000000..e202461df
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/mmi_dc_kms.c
@@ -0,0 +1,589 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Multimedia Integrated Display Controller Driver
+ *
+ * Copyright (C) 2025, Advanced Micro Devices, Inc. All rights reserved.
+ */
+
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/of.h>
+#include <linux/pm_runtime.h>
+
+#include <drm/drm_atomic.h>
+#include <drm/drm_atomic_helper.h>
+#include <drm/drm_bridge.h>
+#include <drm/drm_bridge_connector.h>
+#include <drm/drm_crtc.h>
+#include <drm/drm_device.h>
+#include <drm/drm_drv.h>
+#include <drm/drm_encoder.h>
+#include <drm/drm_framebuffer.h>
+#include <drm/drm_gem_dma_helper.h>
+#include <drm/drm_gem_framebuffer_helper.h>
+#include <drm/drm_modeset_helper.h>
+#include <drm/drm_module.h>
+#include <drm/drm_plane.h>
+#include <drm/drm_probe_helper.h>
+#include <drm/drm_simple_kms_helper.h>
+#include <drm/drm_vblank.h>
+
+#include "mmi_dc.h"
+
+/**
+ * DOC: wb(bool)
+ * Enable/disable writeback through PL Feedback path.
+ */
+static bool wb;
+module_param(wb, bool, 0600);
+MODULE_PARM_DESC(wb, "Enable writeback through PL feedback path");
+
+/**
+ * struct mmi_dc_drm - MMI DC DRM pipeline
+ * @dc: MMI DC device
+ * @drm: DRM device
+ * @crtc: DRM CRTC
+ * @encoder: DRM encoder
+ * @bridge: DRM chain pointer
+ */
+struct mmi_dc_drm {
+	struct mmi_dc	*dc;
+
+	struct drm_device	drm;
+	struct drm_crtc		crtc;
+	struct drm_encoder	encoder;
+	struct drm_bridge	*bridge;
+};
+
+/**
+ * drm_to_dc - Get DC device pointer from DRM device
+ * @drm: DRM device
+ *
+ * Return: Corresponding MMI DC device
+ */
+static inline struct mmi_dc *drm_to_dc(struct drm_device *drm)
+{
+	return container_of(drm, struct mmi_dc_drm, drm)->dc;
+}
+
+/* ----------------------------------------------------------------------------
+ * Power Management
+ */
+
+static int __maybe_unused mmi_dc_suspend(struct device *dev)
+{
+	struct mmi_dc *dc = dev_get_drvdata(dev);
+
+	return drm_mode_config_helper_suspend(&dc->drm->drm);
+}
+
+static int __maybe_unused mmi_dc_resume(struct device *dev)
+{
+	struct mmi_dc *dc = dev_get_drvdata(dev);
+
+	return drm_mode_config_helper_resume(&dc->drm->drm);
+}
+
+static const struct dev_pm_ops mmi_dc_pm_ops = {
+	SET_SYSTEM_SLEEP_PM_OPS(mmi_dc_suspend, mmi_dc_resume)
+};
+
+/* ----------------------------------------------------------------------------
+ * DRM CRTC
+ */
+
+/**
+ * crtc_to_dc - Get DC device pointer from DRM CRTC
+ * @crtc: DRM CRTC
+ *
+ * Return: Corresponding MMI DC device
+ */
+static inline struct mmi_dc *crtc_to_dc(struct drm_crtc *crtc)
+{
+	return container_of(crtc, struct mmi_dc_drm, crtc)->dc;
+}
+
+/**
+ * mmi_dc_drm_handle_vblank - Handle VBLANK notification
+ * @drm: pointer to MMI DC DRM
+ *
+ * Return: Corresponding MMI DC device
+ */
+void mmi_dc_drm_handle_vblank(struct mmi_dc_drm *drm)
+{
+	drm_crtc_handle_vblank(&drm->crtc);
+}
+
+static void mmi_dc_crtc_atomic_enable(struct drm_crtc *crtc,
+				      struct drm_atomic_state *state)
+{
+	struct mmi_dc *dc = crtc_to_dc(crtc);
+	struct drm_display_mode *adjusted_mode = &crtc->state->adjusted_mode;
+	int vrefresh, ret;
+	unsigned long rate;
+	unsigned long mode_clock = adjusted_mode->clock * 1000;
+
+	pm_runtime_get_sync(dc->dev);
+
+	ret = clk_set_rate(dc->pixel_clk, mode_clock);
+	if (ret) {
+		dev_err(dc->dev, "failed to set pixel clock ret:%d\n", ret);
+		return;
+	}
+
+	ret = clk_prepare_enable(dc->pixel_clk);
+	if (ret) {
+		dev_err(dc->dev, "failed to enable the pixel clock ret:%d\n", ret);
+		return;
+	}
+
+	rate = clk_get_rate(dc->pixel_clk);
+	dev_dbg(dc->dev, "requested pixel rate: %lu actual rate: %lu diff: %lu\n",
+		mode_clock, rate, abs(rate - mode_clock));
+
+	mmi_dc_enable(dc, adjusted_mode);
+
+	/* TODO: Do we need this? */
+	/* Delay of 3 vblank intervals for timing gen to be stable */
+	vrefresh = mode_clock / (adjusted_mode->vtotal * adjusted_mode->htotal);
+	msleep(MMI_DC_VBLANKS * 1000 / vrefresh);
+}
+
+static void mmi_dc_crtc_atomic_disable(struct drm_crtc *crtc,
+				       struct drm_atomic_state *state)
+{
+	struct mmi_dc *dc = crtc_to_dc(crtc);
+
+	mmi_dc_disable(dc);
+
+	drm_crtc_vblank_off(crtc);
+
+	spin_lock_irq(&crtc->dev->event_lock);
+	if (crtc->state->event) {
+		drm_crtc_send_vblank_event(crtc, crtc->state->event);
+		crtc->state->event = NULL;
+	}
+	spin_unlock_irq(&crtc->dev->event_lock);
+
+	clk_disable_unprepare(dc->pixel_clk);
+	pm_runtime_put_sync(dc->dev);
+}
+
+static int mmi_dc_crtc_atomic_check(struct drm_crtc *crtc,
+				    struct drm_atomic_state *state)
+{
+	return drm_atomic_add_affected_planes(state, crtc);
+}
+
+static void mmi_dc_crtc_atomic_begin(struct drm_crtc *crtc,
+				     struct drm_atomic_state *state)
+{
+	drm_crtc_vblank_on(crtc);
+}
+
+static void mmi_dc_crtc_atomic_flush(struct drm_crtc *crtc,
+				     struct drm_atomic_state *state)
+{
+	struct drm_pending_vblank_event *vblank;
+	struct mmi_dc *dc = crtc_to_dc(crtc);
+	struct drm_display_mode *adjusted_mode = &crtc->state->adjusted_mode;
+
+	if (dc->reconfig_hw) {
+		dc->reconfig_hw = false;
+		mmi_dc_toggle_ext_reset(dc);
+		mmi_dc_enable(dc, adjusted_mode);
+		mmi_dc_reconfig_planes(dc, state);
+	}
+
+	if (!crtc->state->event)
+		return;
+
+	/* Consume the flip_done event from atomic helper. */
+	vblank = crtc->state->event;
+	crtc->state->event = NULL;
+
+	vblank->pipe = drm_crtc_index(crtc);
+
+	WARN_ON(drm_crtc_vblank_get(crtc) != 0);
+
+	spin_lock_irq(&crtc->dev->event_lock);
+	drm_crtc_arm_vblank_event(crtc, vblank);
+	spin_unlock_irq(&crtc->dev->event_lock);
+}
+
+static const struct drm_crtc_helper_funcs mmi_dc_crtc_helper_funcs = {
+	.atomic_enable	= mmi_dc_crtc_atomic_enable,
+	.atomic_disable	= mmi_dc_crtc_atomic_disable,
+	.atomic_check	= mmi_dc_crtc_atomic_check,
+	.atomic_begin	= mmi_dc_crtc_atomic_begin,
+	.atomic_flush	= mmi_dc_crtc_atomic_flush,
+};
+
+static int mmi_dc_crtc_enable_vblank(struct drm_crtc *crtc)
+{
+	struct mmi_dc *dc = crtc_to_dc(crtc);
+
+	mmi_dc_enable_vblank(dc);
+
+	return 0;
+}
+
+static void mmi_dc_crtc_disable_vblank(struct drm_crtc *crtc)
+{
+	struct mmi_dc *dc = crtc_to_dc(crtc);
+
+	mmi_dc_disable_vblank(dc);
+}
+
+static const struct drm_crtc_funcs mmi_dc_dpsub_crtc_funcs = {
+	.destroy		= drm_crtc_cleanup,
+	.set_config		= drm_atomic_helper_set_config,
+	.page_flip		= drm_atomic_helper_page_flip,
+	.reset			= drm_atomic_helper_crtc_reset,
+	.atomic_duplicate_state	= drm_atomic_helper_crtc_duplicate_state,
+	.atomic_destroy_state	= drm_atomic_helper_crtc_destroy_state,
+	.enable_vblank		= mmi_dc_crtc_enable_vblank,
+	.disable_vblank		= mmi_dc_crtc_disable_vblank,
+};
+
+/**
+ * mmi_dc_create_crtc - Create DRM CRTC interface for MMI DC
+ * @dc: MMI DC device
+ *
+ * Return: 0 on success or error code otherwise
+ */
+static int mmi_dc_create_crtc(struct mmi_dc *dc)
+{
+	struct drm_plane *plane = mmi_dc_plane_get_primary(dc);
+	struct drm_crtc *crtc = &dc->drm->crtc;
+	int ret;
+
+	/* TODO cursor plane */
+	ret = drm_crtc_init_with_planes(&dc->drm->drm, crtc, plane, NULL,
+					&mmi_dc_dpsub_crtc_funcs, NULL);
+	if (ret < 0) {
+		dev_err(dc->dev, "failed to init DRM CRTC: %d\n", ret);
+		return ret;
+	}
+
+	drm_crtc_helper_add(crtc, &mmi_dc_crtc_helper_funcs);
+
+	drm_crtc_vblank_off(crtc);
+
+	return 0;
+}
+
+/* ----------------------------------------------------------------------------
+ * DRM Encoder
+ */
+
+/**
+ * mmi_create_encoder - Create DRM encoder interface for MMI DC
+ * @dc: MMI DC device
+ *
+ * Return: 0 on success or error code otherwise
+ */
+static int mmi_create_encoder(struct mmi_dc *dc)
+{
+	struct mmi_dc_drm *dc_drm = dc->drm;
+	struct drm_device *drm = &dc_drm->drm;
+	struct drm_encoder *encoder = &dc_drm->encoder;
+	struct drm_bridge *bridge;
+	enum drm_bridge_attach_flags attach_flags = 0;
+	int ret;
+
+	encoder->possible_crtcs |= drm_crtc_mask(&dc_drm->crtc);
+	ret = drm_simple_encoder_init(drm, encoder, DRM_MODE_ENCODER_NONE);
+	if (ret < 0) {
+		dev_err(dc->dev, "failed to init encoder: %d\n", ret);
+		return ret;
+	}
+
+	dc_drm->bridge = devm_drm_of_get_bridge(dc->dev,
+						dc->dev->of_node,
+						MMI_DC_DPTX_PORT_0, 0);
+	if (IS_ERR(dc_drm->bridge))
+		return dev_err_probe(dc->dev, PTR_ERR(dc_drm->bridge),
+				     "failed to find bridge\n");
+
+	bridge = dc_drm->bridge;
+
+	if (!wb)
+		attach_flags = DRM_BRIDGE_ATTACH_NO_CONNECTOR;
+
+	ret = drm_bridge_attach(encoder, bridge, NULL, attach_flags);
+	if (ret < 0) {
+		dev_err(dc->dev, "failed to attach bridge: %d\n", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+/* ----------------------------------------------------------------------------
+ * DRM Connector
+ */
+
+/**
+ * mmi_dc_setup_connector - Setup DRM connector interface for MMI DC
+ * @dc: MMI DC device
+ *
+ * Return: 0 on success or error code otherwise
+ */
+static int mmi_dc_setup_connector(struct mmi_dc *dc)
+{
+	struct mmi_dc_drm *dc_drm = dc->drm;
+	struct drm_device *drm = &dc_drm->drm;
+	struct drm_encoder *encoder = &dc_drm->encoder;
+	struct drm_connector *connector;
+	struct drm_connector_list_iter iter;
+	int ret;
+
+	if (wb) {
+		drm_connector_list_iter_begin(drm, &iter);
+		drm_for_each_connector_iter(connector, &iter) {
+			if (connector->connector_type ==
+				DRM_MODE_CONNECTOR_WRITEBACK) {
+				drm_connector_list_iter_end(&iter);
+				return 0;
+			}
+		}
+		drm_connector_list_iter_end(&iter);
+	}
+
+	connector = drm_bridge_connector_init(drm, encoder);
+	if (IS_ERR(connector)) {
+		ret = PTR_ERR(connector);
+		dev_err(dc->dev, "failed to init connector: %d\n", ret);
+		return ret;
+	}
+
+	return drm_connector_attach_encoder(connector, encoder);
+}
+
+/* ----------------------------------------------------------------------------
+ * Buffers Allocation
+ */
+
+static int mmi_dc_dumb_create(struct drm_file *file_priv,
+			      struct drm_device *drm,
+			      struct drm_mode_create_dumb *args)
+{
+	struct mmi_dc *dc = drm_to_dc(drm);
+	unsigned int pitch = DIV_ROUND_UP(args->width * args->bpp, 8);
+
+	/* Enforce the alignment constraints of the DMA engine. */
+	args->pitch = ALIGN(pitch, dc->dma_align);
+
+	return drm_gem_dma_dumb_create_internal(file_priv, drm, args);
+}
+
+static struct drm_framebuffer *
+mmi_dc_fb_create(struct drm_device *drm, struct drm_file *file_priv,
+		 const struct drm_mode_fb_cmd2 *mode_cmd)
+{
+	struct mmi_dc *dc = drm_to_dc(drm);
+	struct drm_mode_fb_cmd2 cmd = *mode_cmd;
+	unsigned int i;
+
+	/* Enforce the alignment constraints of the DMA engine. */
+	for (i = 0; i < ARRAY_SIZE(cmd.pitches); ++i)
+		cmd.pitches[i] = ALIGN(cmd.pitches[i], dc->dma_align);
+
+	return drm_gem_fb_create(drm, file_priv, &cmd);
+}
+
+static const struct drm_mode_config_funcs mmi_dc_mode_config_funcs = {
+	.fb_create		= mmi_dc_fb_create,
+	.atomic_check		= drm_atomic_helper_check,
+	.atomic_commit		= drm_atomic_helper_commit,
+};
+
+/* ----------------------------------------------------------------------------
+ * DRM Driver
+ */
+
+DEFINE_DRM_GEM_DMA_FOPS(mmi_dc_drm_fops);
+
+static const struct drm_driver mmi_dc_drm_driver = {
+	.driver_features	= DRIVER_MODESET | DRIVER_GEM | DRIVER_ATOMIC,
+	DRM_GEM_DMA_DRIVER_OPS_WITH_DUMB_CREATE(mmi_dc_dumb_create),
+	/* TODO: fbdev emulation */
+	.fops			= &mmi_dc_drm_fops,
+	.name			= "mmi-dc",
+	.desc			= "MMI Display Controller Driver",
+	.date			= "20241226",
+	.major			= 0,
+	.minor			= 1,
+};
+
+/**
+ * mmi_dc_drm_pipeline_init - Initialize DRM pipeline
+ * @dc: MMI DC device
+ *
+ * Return: 0 on success or error code otherwise
+ */
+static int mmi_dc_drm_pipeline_init(struct mmi_dc *dc)
+{
+	struct mmi_dc_drm *dc_drm = dc->drm;
+	struct drm_device *drm = &dc_drm->drm;
+	int ret;
+
+	ret = mmi_dc_create_crtc(dc);
+	if (ret < 0)
+		return ret;
+
+	mmi_dc_planes_set_possible_crtc(dc, drm_crtc_mask(&dc_drm->crtc));
+
+	ret = mmi_create_encoder(dc);
+	if (ret < 0)
+		return ret;
+
+	ret = mmi_dc_setup_connector(dc);
+	if (ret < 0)
+		return ret;
+
+	drm_mode_config_reset(drm);
+
+	ret = drm_dev_register(drm, 0);
+	if (ret < 0) {
+		dev_err(dc->dev, "failed to register DRM device: %d\n", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+/**
+ * mmi_dc_drm_init - Initialize DRM subsystem
+ * @dc: MMI DC device
+ *
+ * Return: 0 on success or error code otherwise
+ */
+static int mmi_dc_drm_init(struct mmi_dc *dc)
+{
+	struct mmi_dc_drm *dc_drm;
+	struct drm_device *drm;
+	int ret;
+
+	dc_drm = devm_drm_dev_alloc(dc->dev, &mmi_dc_drm_driver,
+				    struct mmi_dc_drm, drm);
+	if (IS_ERR(dc_drm)) {
+		ret = PTR_ERR(dc_drm);
+		dev_err(dc->dev, "failed to allocate DRM: %d\n", ret);
+		return ret;
+	}
+	drm = &dc_drm->drm;
+
+	dc_drm->dc = dc;
+	dc->drm = dc_drm;
+
+	ret = drmm_mode_config_init(drm);
+	if (ret < 0) {
+		dev_err(dc->dev, "failed to init mode config: %d\n", ret);
+		return ret;
+	}
+
+	drm->mode_config.funcs = &mmi_dc_mode_config_funcs;
+	drm->mode_config.min_width = 0;
+	drm->mode_config.min_height = 0;
+	drm->mode_config.max_width = MMI_DC_MAX_WIDTH;
+	drm->mode_config.max_height = MMI_DC_MAX_HEIGHT;
+
+	ret = drm_vblank_init(drm, 1);
+	if (ret < 0) {
+		dev_err(dc->dev, "failed to init vblank: %d\n", ret);
+		return ret;
+	}
+
+	drm_kms_helper_poll_init(drm);
+
+	return 0;
+}
+
+/**
+ * mmi_dc_probe - Probe MMI DC device
+ * @pdev: the platform device
+ *
+ * Return: 0 on success or error code otherwise
+ */
+static int mmi_dc_probe(struct platform_device *pdev)
+{
+	struct mmi_dc *dc;
+	int ret;
+
+	dc = devm_kzalloc(&pdev->dev, sizeof(*dc), GFP_KERNEL);
+	if (!dc)
+		return -ENOMEM;
+
+	platform_set_drvdata(pdev, dc);
+	dc->dev = &pdev->dev;
+
+	dc->pixel_clk = devm_clk_get(dc->dev, "pl_vid_func_clk");
+	if (IS_ERR(dc->pixel_clk)) {
+		dev_dbg(dc->dev, "failed to get pl_vid_func_clk %ld\n",
+			PTR_ERR(dc->pixel_clk));
+		dc->pixel_clk = devm_clk_get(dc->dev, "ps_vid_clk");
+		if (IS_ERR(dc->pixel_clk))
+			return dev_err_probe(dc->dev, PTR_ERR(dc->pixel_clk),
+					     "failed to get ps_vid_clk\n");
+		dc->is_ps_clk = true;
+	} else {
+		dc->is_ps_clk = false;
+	}
+
+	ret = mmi_dc_drm_init(dc);
+	if (ret < 0)
+		return ret;
+
+	ret = mmi_dc_init(dc, &dc->drm->drm);
+	if (ret < 0)
+		return ret;
+
+	ret = mmi_dc_drm_pipeline_init(dc);
+	if (ret < 0)
+		return ret;
+
+	return 0;
+}
+
+/**
+ * mmi_dc_remove - Remove MMI DC device
+ * @pdev: the platform device
+ */
+static void mmi_dc_remove(struct platform_device *pdev)
+{
+	struct mmi_dc *dc = dev_get_drvdata(&pdev->dev);
+	struct drm_device *drm = &dc->drm->drm;
+
+	drm_dev_unregister(drm);
+	drm_atomic_helper_shutdown(drm);
+	drm_encoder_cleanup(&dc->drm->encoder);
+	drm_kms_helper_poll_fini(drm);
+
+	mmi_dc_fini(dc);
+}
+
+static const struct of_device_id mmi_dc_of_match[] = {
+	{ .compatible = "amd,mmi-dc-1.0", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, mmi_dc_of_match);
+
+static struct platform_driver mmi_dc_driver = {
+	.probe			= mmi_dc_probe,
+	.remove_new		= mmi_dc_remove,
+	.driver			= {
+		.name		= "mmi-dc",
+		.pm		= &mmi_dc_pm_ops,
+		.of_match_table	= mmi_dc_of_match,
+	},
+};
+
+drm_module_platform_driver(mmi_dc_driver);
+
+MODULE_DESCRIPTION("MMI Display Controller Driver");
+MODULE_AUTHOR("Advanced Micro Devices, Inc");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/mmi_dc_plane.c b/drivers/gpu/drm/xlnx/mmi_dc_plane.c
new file mode 100644
index 000000000..e7ffca484
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/mmi_dc_plane.c
@@ -0,0 +1,807 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * MMI Display Controller Plane Driver
+ *
+ * Copyright (C) 2025, Advanced Micro Devices, Inc. All rights reserved.
+ */
+
+#include <drm/drm_atomic.h>
+#include <drm/drm_atomic_helper.h>
+#include <drm/drm_blend.h>
+#include <drm/drm_fb_dma_helper.h>
+#include <drm/drm_fourcc.h>
+#include <drm/drm_framebuffer.h>
+
+#include <linux/dmaengine.h>
+#include <linux/dma/xilinx_dpdma.h>
+
+#include "mmi_dc.h"
+
+/* ----------------------------------------------------------------------------
+ * DC Plane Data
+ */
+
+/**
+ * enum mmi_dc_plane_id - MMI DC plane id
+ * @MMI_DC_PLANE0: video/graphics plane 0 (zorder based)
+ * @MMI_DC_PLANE1: video/graphics plane 1
+ * @MMI_DC_CURSOR: hardware cursor plane
+ */
+enum mmi_dc_plane_id {
+	MMI_DC_PLANE0,
+	MMI_DC_PLANE1,
+	MMI_DC_CURSOR,
+};
+
+/**
+ * struct mmi_dc_format - DC format
+ * @drm_format: DRM fourcc format
+ * @buf_format: internal DC pixel format
+ * @swap: swap color (U/V or R/B) channels
+ * @sf: CSC scaling factors (4,5,6,8 or 10 bpc to 12 bpc)
+ */
+struct mmi_dc_format {
+	u32		drm_format;
+	u32		buf_format;
+	bool		swap;
+	const u32	*sf;
+};
+
+/* TODO: more scaling factors */
+static const u32 scaling_factors_888[] = {
+	MMI_DC_AV_BUF_8BIT_SF,
+	MMI_DC_AV_BUF_8BIT_SF,
+	MMI_DC_AV_BUF_8BIT_SF,
+};
+
+/* TODO: more formats */
+static const struct mmi_dc_format plane_formats[] = {
+	{
+		.drm_format	= DRM_FORMAT_VYUY,
+		.buf_format	= MMI_DC_AV_BUF_FMT_CR_Y0_CB_Y1,
+		.swap		= true,
+		.sf		= scaling_factors_888,
+	},
+	{
+		.drm_format	= DRM_FORMAT_YUYV,
+		.buf_format	= MMI_DC_AV_BUF_FMT_Y0_CB_Y1_CR,
+		.swap		= true,
+		.sf		= scaling_factors_888,
+	},
+	{
+		.drm_format	= DRM_FORMAT_YUV444,
+		.buf_format	= MMI_DC_AV_BUF_FMT_YV24,
+		.swap		= false,
+		.sf		= scaling_factors_888,
+	},
+	{
+		.drm_format	= DRM_FORMAT_XRGB8888,
+		.buf_format	= MMI_DC_AV_BUF_FMT_RGBA8888,
+		.swap		= true,
+		.sf		= scaling_factors_888,
+	},
+	{
+		.drm_format	= DRM_FORMAT_RGB888,
+		.buf_format	= MMI_DC_AV_BUF_FMT_RGB888,
+		.swap		= true,
+		.sf		= scaling_factors_888,
+	},
+	{
+		.drm_format	= DRM_FORMAT_NV12,
+		.buf_format	= MMI_DC_AV_BUF_FMT_YV16CI_420,
+		.swap		= false,
+		.sf		= scaling_factors_888,
+	},
+};
+
+/**
+ * struct mmi_dc_plane_info - DC plane info
+ * @formats: list of supported pixel formats
+ * @num_formats: number of supported formats
+ * @num_channels: number of DMA channels
+ */
+struct mmi_dc_plane_info {
+	const struct mmi_dc_format	*formats;
+	unsigned int			num_formats;
+	unsigned int			num_channels;
+};
+
+/**
+ * struct mmi_dc_plane - DC plane
+ * @base: generic DRM plane
+ * @dc: back pointer to the display controller device
+ * @id: unique plane id
+ * @info: corresponding plane info
+ * @dc_format: current pixel format
+ * @drm_format: DRM format description
+ * @dmas: DMA channels used
+ * @xt: DMA transfer template
+ */
+struct mmi_dc_plane {
+	struct drm_plane		base;
+	struct mmi_dc			*dc;
+	enum mmi_dc_plane_id		id;
+	const struct mmi_dc_plane_info	*info;
+	const struct mmi_dc_format	*dc_format;
+	const struct drm_format_info	*drm_format;
+	struct dma_chan			*dmas[MMI_DC_MAX_NUM_SUB_PLANES];
+	struct dma_interleaved_template *xt;
+};
+
+/**
+ * drm_to_dc_plane - Convert DRM plane to DC plane
+ * @plane: generic DRM plane
+ *
+ * Return: Corresponding DC plane.
+ */
+static inline struct mmi_dc_plane *drm_to_dc_plane(struct drm_plane *plane)
+{
+	return container_of(plane, struct mmi_dc_plane, base);
+}
+
+/* ----------------------------------------------------------------------------
+ * DC Blender Ops
+ */
+
+/**
+ * mmi_dc_blend_plane_set_csc - Set input CSC
+ * @plane: DC plane
+ * @coeffs: CSC matrix coefficients
+ * @offsets: CSC color offsets
+ *
+ * Setup input color space converter.
+ */
+static void mmi_dc_blend_plane_set_csc(struct mmi_dc_plane *plane,
+				       const u16 *coeffs, const u32 *offsets)
+{
+	struct mmi_dc *dc = plane->dc;
+	unsigned int i, reg, swap[] = { 0, 1, 2 };
+
+	if (plane->dc_format->swap) {
+		if (plane->drm_format->is_yuv) {
+			/* swap U and V */
+			swap[1] = 2;
+			swap[2] = 1;
+		} else {
+			/* swap R and B */
+			swap[0] = 2;
+			swap[2] = 0;
+		}
+	}
+
+	for (i = 0; i < MMI_DC_CSC_NUM_COEFFS; ++i) {
+		reg = MMI_DC_V_BLEND_INCSC_COEFF(plane->id, i);
+		dc_write_blend(dc, reg, coeffs[i - i % 3 + swap[i % 3]]);
+	}
+
+	for (i = 0; i < MMI_DC_CSC_NUM_OFFSETS; ++i) {
+		reg = MMI_DC_V_BLEND_CC_INCSC_OFFSET(plane->id, i);
+		dc_write_blend(dc, reg, offsets[i]);
+	}
+}
+
+/**
+ * mmi_dc_blend_plane_enable - Enable blender input for given DC plane
+ * @plane: DC plane
+ */
+static void mmi_dc_blend_plane_enable(struct mmi_dc_plane *plane)
+{
+	struct mmi_dc *dc = plane->dc;
+	const u16 *coeffs;
+	const u32 *offsets;
+	u32 val;
+
+	val = (plane->drm_format->is_yuv ? 0 : MMI_DC_V_BLEND_RGB_MODE) |
+	      (plane->drm_format->hsub > 1 ? MMI_DC_V_BLEND_EN_US : 0);
+
+	dc_write_blend(dc, MMI_DC_V_BLEND_LAYER_CONTROL(plane->id), val);
+
+	if (plane->drm_format->is_yuv) {
+		coeffs = csc_sdtv_to_rgb_matrix;
+		offsets = csc_sdtv_to_rgb_offsets;
+	} else {
+		coeffs = csc_identity_matrix;
+		offsets = csc_zero_offsets;
+	}
+
+	mmi_dc_blend_plane_set_csc(plane, coeffs, offsets);
+}
+
+/**
+ * mmi_dc_blend_plane_disable - Disable blender input for given DC plane
+ * @plane: DC plane
+ */
+static void mmi_dc_blend_plane_disable(struct mmi_dc_plane *plane)
+{
+	struct mmi_dc *dc = plane->dc;
+
+	dc_write_blend(dc, MMI_DC_V_BLEND_LAYER_CONTROL(plane->id), 0);
+	mmi_dc_blend_plane_set_csc(plane, csc_zero_matrix, csc_zero_offsets);
+}
+
+/* ----------------------------------------------------------------------------
+ * DC AV Buffer Ops
+ */
+
+/**
+ * mmi_dc_avbuf_plane_set_format - Set AVBUF format
+ * @plane: DC plane
+ * @format: format to set
+ *
+ * Configure the audio/video buffer manager according to the given pixel format
+ */
+static void mmi_dc_avbuf_plane_set_format(struct mmi_dc_plane *plane,
+					  const struct mmi_dc_format *format)
+{
+	struct mmi_dc *dc = plane->dc;
+	u32 val, i;
+
+	val = dc_read_avbuf(dc, MMI_DC_AV_BUF_FORMAT);
+	val &= ~MMI_DC_AV_BUF_FMT_MASK(plane->id);
+	val |= format->buf_format << MMI_DC_AV_BUF_FMT_SHIFT(plane->id);
+	dc_write_avbuf(dc, MMI_DC_AV_BUF_FORMAT, val);
+
+	for (i = 0; i < MMI_DC_AV_BUF_NUM_SF; ++i) {
+		u32 reg = MMI_DC_AV_BUF_PLANE_CC_SCALE_FACTOR(plane->id, i);
+
+		dc_write_avbuf(dc, reg, format->sf[i]);
+	}
+}
+
+/**
+ * mmi_dc_avbuf_plane_enable - Enable AV buffer input for the given plane
+ * @plane: DC plane
+ */
+static void mmi_dc_avbuf_plane_enable(struct mmi_dc_plane *plane)
+{
+	struct mmi_dc *dc = plane->dc;
+	u32 val;
+	int ch;
+
+	for (ch = 0; ch < plane->drm_format->num_planes; ++ch)
+		dc_write_avbuf(dc, MMI_DC_AV_CHBUF(plane->id * 3 + ch),
+			       MMI_DC_AV_CHBUF_EN | MMI_DC_AV_CHBUF_BURST);
+
+	val = dc_read_avbuf(dc, MMI_DC_AV_BUF_OUTPUT_AUDIO_VIDEO_SELECT);
+	val &= ~MMI_DC_AV_BUF_VID_STREAM_SEL_MASK(plane->id);
+	val |= MMI_DC_AV_BUF_VID_STREAM_SEL_MEM(plane->id);
+	dc_write_avbuf(dc, MMI_DC_AV_BUF_OUTPUT_AUDIO_VIDEO_SELECT, val);
+}
+
+/**
+ * mmi_dc_avbuf_plane_disable - Disable AV buffer input for the given plane
+ * @plane: DC plane
+ */
+static void mmi_dc_avbuf_plane_disable(struct mmi_dc_plane *plane)
+{
+	struct mmi_dc *dc = plane->dc;
+	u32 val;
+	int ch;
+
+	val = dc_read_avbuf(dc, MMI_DC_AV_BUF_OUTPUT_AUDIO_VIDEO_SELECT);
+	val &= ~MMI_DC_AV_BUF_VID_STREAM_SEL_MASK(plane->id);
+	val |= MMI_DC_AV_BUF_VID_STREAM_SEL_NONE(plane->id);
+	dc_write_avbuf(dc, MMI_DC_AV_BUF_OUTPUT_AUDIO_VIDEO_SELECT, val);
+
+	for (ch = 0; ch < plane->drm_format->num_planes; ++ch)
+		dc_write_avbuf(dc, MMI_DC_AV_CHBUF(plane->id * 3 + ch),
+			       MMI_DC_AV_CHBUF_FLUSH);
+}
+
+/* ----------------------------------------------------------------------------
+ * DC Plane Utils
+ */
+
+/**
+ * mmi_dc_plane_find_format - Find plane format
+ * @plane: DC plane
+ * @drm_format: format to lookup for
+ *
+ * Return: Found DC pixel format corresponding to the given DRM format, or
+ *         NULL.
+ */
+static const struct mmi_dc_format *
+mmi_dc_plane_find_format(struct mmi_dc_plane *plane, u32 drm_format)
+{
+	unsigned int i;
+
+	for (i = 0; i < plane->info->num_formats; ++i) {
+		if (plane->info->formats[i].drm_format == drm_format)
+			return &plane->info->formats[i];
+	}
+
+	return NULL;
+}
+
+/**
+ * mmi_dc_plane_request_dma - Request DMA channels for the plane
+ * @plane: DC plane
+ *
+ * Request DMA channels for each sub-plane.
+ *
+ * Return: 0 on success or error code otherwise.
+ */
+static int mmi_dc_plane_request_dma(struct mmi_dc_plane *plane)
+{
+	struct mmi_dc *dc = plane->dc;
+	unsigned int i;
+
+	for (i = 0; i < plane->info->num_channels; ++i) {
+		struct dma_chan *dma_channel;
+		char dma_channel_name[32];
+
+		snprintf(dma_channel_name, sizeof(dma_channel_name),
+			 "vid.%u.%u", plane->id, i);
+		dma_channel = dma_request_chan(dc->dev, dma_channel_name);
+		if (IS_ERR(dma_channel))
+			return dev_err_probe(dc->dev, PTR_ERR(dma_channel),
+					     "failed to request dma channel");
+		plane->dmas[i] = dma_channel;
+	}
+
+	return 0;
+}
+
+/**
+ * mmi_dc_plane_release_dma - Release assigned DMA channels
+ * @plane: DC plane
+ */
+static void mmi_dc_plane_release_dma(struct mmi_dc_plane *plane)
+{
+	unsigned int i;
+
+	for (i = 0; i < plane->info->num_channels; ++i) {
+		struct dma_chan *dma_channel = plane->dmas[i];
+
+		if (dma_channel) {
+			dmaengine_terminate_sync(dma_channel);
+			dma_release_channel(dma_channel);
+		}
+	}
+}
+
+/**
+ * mmi_dc_plane_drm_formats - Get the list of supported DRM formats
+ * @info: DC plane info
+ * @num_formats: number of supported formats
+ *
+ * Allocate and fill an array of supported DRM formats. Assign supported format
+ * numbers in @num_formats. The caller is expected to free the list.
+ *
+ * Return: Pointer to the supported format list.
+ */
+static u32 *mmi_dc_plane_drm_formats(const struct mmi_dc_plane_info *info,
+				     unsigned int *num_formats)
+{
+	unsigned int i;
+	u32 *formats;
+
+	formats = kcalloc(info->num_formats, sizeof(*formats), GFP_KERNEL);
+
+	if (!formats) {
+		*num_formats = 0;
+		return NULL;
+	}
+
+	for (i = 0; i < info->num_formats; ++i)
+		formats[i] = info->formats[i].drm_format;
+
+	*num_formats = info->num_formats;
+
+	return formats;
+}
+
+/**
+ * mmi_dc_plane_set_format - Set plane DRM format
+ * @plane: DC plane
+ * @info: DRM format description
+ *
+ * Set DRM format, program blender, and AV buffer manager accordingly.
+ */
+static void mmi_dc_plane_set_format(struct mmi_dc_plane *plane,
+				    const struct drm_format_info *info)
+{
+	unsigned int i;
+
+	plane->dc_format = mmi_dc_plane_find_format(plane, info->format);
+	if (WARN_ON(!plane->dc_format))
+		return;
+	plane->drm_format = info;
+
+	mmi_dc_avbuf_plane_set_format(plane, plane->dc_format);
+
+	for (i = 0; i < info->num_planes; ++i) {
+		struct dma_chan *dma_channel = plane->dmas[i];
+		struct xilinx_dpdma_peripheral_config pconfig = {
+			.video_group = true,
+		};
+		struct dma_slave_config sconfig = {
+			.direction = DMA_MEM_TO_DEV,
+			.peripheral_config = &pconfig,
+			.peripheral_size = sizeof(pconfig),
+		};
+
+		dmaengine_slave_config(dma_channel, &sconfig);
+	}
+}
+
+/**
+ * mmi_dc_plane_update - Update DC plane
+ * @plane: DC plane
+ * @state: DRM plane state to update to
+ *
+ * Update DC plane buffer. Prepare and submit DMA transfers.
+ */
+static void mmi_dc_plane_update(struct mmi_dc_plane *plane,
+				struct drm_plane_state *state)
+{
+	struct mmi_dc *dc = plane->dc;
+	const struct drm_format_info *info = plane->drm_format;
+	unsigned int i;
+
+	for (i = 0; i < info->num_planes; ++i) {
+		unsigned int width = state->crtc_w / (i ? info->hsub : 1);
+		unsigned int height = state->crtc_h / (i ? info->vsub : 1);
+		struct dma_chan *dma_channel = plane->dmas[i];
+		struct dma_async_tx_descriptor *desc;
+
+		plane->xt->numf = height;
+		plane->xt->src_start = drm_fb_dma_get_gem_addr(state->fb,
+							       state, i);
+		plane->xt->sgl[0].size = width * info->cpp[i];
+		plane->xt->sgl[0].icg = state->fb->pitches[i] -
+					plane->xt->sgl[0].size;
+
+		desc = dmaengine_prep_interleaved_dma(dma_channel, plane->xt,
+						      DMA_CTRL_ACK |
+						      DMA_PREP_REPEAT |
+						      DMA_PREP_LOAD_EOT);
+		if (!desc) {
+			dev_err(dc->dev, "failed to prepare DMA descriptor\n");
+			return;
+		}
+
+		dmaengine_submit(desc);
+		dma_async_issue_pending(dma_channel);
+	}
+}
+
+/**
+ * mmi_dc_plane_enable - Enable DC plane
+ * @plane: DC plane
+ */
+static void mmi_dc_plane_enable(struct mmi_dc_plane *plane)
+{
+	mmi_dc_avbuf_plane_enable(plane);
+	mmi_dc_blend_plane_enable(plane);
+}
+
+/**
+ * mmi_dc_plane_disable - Disable DC plane
+ * @plane: DC plane
+ */
+static void mmi_dc_plane_disable(struct mmi_dc_plane *plane)
+{
+	unsigned int i;
+
+	for (i = 0; i < plane->drm_format->num_planes; ++i)
+		dmaengine_terminate_sync(plane->dmas[i]);
+
+	mmi_dc_avbuf_plane_disable(plane);
+	mmi_dc_blend_plane_disable(plane);
+}
+
+/* ----------------------------------------------------------------------------
+ * DRM Plane
+ */
+
+static int mmi_dc_plane_atomic_check(struct drm_plane *plane,
+				     struct drm_atomic_state *state)
+{
+	struct drm_plane_state *new_plane_state =
+		drm_atomic_get_new_plane_state(state, plane);
+	struct drm_crtc_state *crtc_state;
+
+	if (!new_plane_state->crtc)
+		return 0;
+
+	crtc_state = drm_atomic_get_crtc_state(state, new_plane_state->crtc);
+	if (IS_ERR(crtc_state))
+		return PTR_ERR(crtc_state);
+
+	return drm_atomic_helper_check_plane_state(new_plane_state, crtc_state,
+						   DRM_PLANE_NO_SCALING,
+						   DRM_PLANE_NO_SCALING,
+						   false, false);
+}
+
+static void mmi_dc_plane_atomic_update(struct drm_plane *plane,
+				       struct drm_atomic_state *state)
+{
+	struct drm_plane_state *old_state =
+		drm_atomic_get_old_plane_state(state, plane);
+	struct drm_plane_state *new_state =
+		drm_atomic_get_new_plane_state(state, plane);
+	struct mmi_dc_plane *dc_plane = drm_to_dc_plane(plane);
+	struct mmi_dc *dc = dc_plane->dc;
+
+	if (!old_state->fb ||
+	    old_state->fb->format->format != new_state->fb->format->format)
+		dc->reconfig_hw = true;
+
+	if (plane->type == DRM_PLANE_TYPE_PRIMARY)
+		mmi_dc_set_global_alpha(dc_plane->dc, new_state->alpha >> 8,
+					true);
+
+	if (!dc->reconfig_hw)
+		mmi_dc_plane_update(dc_plane, new_state);
+}
+
+static void mmi_dc_plane_atomic_disable(struct drm_plane *plane,
+					struct drm_atomic_state *state)
+{
+	struct drm_plane_state *old_state =
+		drm_atomic_get_old_plane_state(state, plane);
+	struct mmi_dc_plane *dc_plane = drm_to_dc_plane(plane);
+
+	if (!old_state->fb)
+		return;
+
+	mmi_dc_plane_disable(dc_plane);
+
+	if (plane->type == DRM_PLANE_TYPE_PRIMARY)
+		mmi_dc_set_global_alpha(dc_plane->dc, plane->state->alpha >> 8,
+					false);
+}
+
+static const struct drm_plane_helper_funcs mmi_dc_plane_helper_funcs = {
+	.atomic_check		= mmi_dc_plane_atomic_check,
+	.atomic_update		= mmi_dc_plane_atomic_update,
+	.atomic_disable		= mmi_dc_plane_atomic_disable,
+};
+
+static const struct drm_plane_funcs mmi_dc_plane_funcs = {
+	.update_plane		= drm_atomic_helper_update_plane,
+	.disable_plane		= drm_atomic_helper_disable_plane,
+	.reset			= drm_atomic_helper_plane_reset,
+	.atomic_duplicate_state	= drm_atomic_helper_plane_duplicate_state,
+	.atomic_destroy_state	= drm_atomic_helper_plane_destroy_state,
+};
+
+/**
+ * mmi_dc_drm_plane_init - Allocate and initialize the DC plane
+ * @drm: DRM device
+ * @info: DC plane info
+ * @type: DRM plane type
+ * @id: DC plane id
+ *
+ * Return: New DC plane on success or error pointer otherwise.
+ */
+static struct mmi_dc_plane *
+mmi_dc_drm_plane_init(struct drm_device *drm,
+		      const struct mmi_dc_plane_info *info,
+		      enum drm_plane_type type,
+		      enum mmi_dc_plane_id id)
+{
+	unsigned int num_formats;
+	u32 *formats = mmi_dc_plane_drm_formats(info, &num_formats);
+	struct mmi_dc_plane *plane;
+
+	plane = drmm_universal_plane_alloc(drm, struct mmi_dc_plane,
+					   base, 0, &mmi_dc_plane_funcs,
+					   formats, num_formats, NULL, type,
+					   NULL);
+	if (IS_ERR(plane))
+		return plane;
+
+	drm_plane_helper_add(&plane->base, &mmi_dc_plane_helper_funcs);
+
+	drm_plane_create_zpos_immutable_property(&plane->base, id);
+	if (type == DRM_PLANE_TYPE_PRIMARY)
+		drm_plane_create_alpha_property(&plane->base);
+
+	return plane;
+}
+
+/* ----------------------------------------------------------------------------
+ * DC Plane Interface
+ */
+
+/**
+ * mmi_dc_plane_get_primary - Get DC primary plane
+ * @dc: DC device
+ *
+ * Return: Primary DC plane.
+ */
+struct drm_plane *mmi_dc_plane_get_primary(struct mmi_dc *dc)
+{
+	return &dc->planes[MMI_DC_PLANE1]->base;
+}
+
+/**
+ * mmi_dc_planes_set_possible_crtc - Set possible CRTC for all planes
+ * @dc: DC device
+ * @crtc_mask: CRTC mask to assign
+ */
+void mmi_dc_planes_set_possible_crtc(struct mmi_dc *dc, u32 crtc_mask)
+{
+	unsigned int i;
+
+	for (i = 0; i < ARRAY_SIZE(dc->planes); ++i)
+		dc->planes[i]->base.possible_crtcs = crtc_mask;
+}
+
+/**
+ * mmi_dc_planes_get_dma_align - Get DMA align
+ * @dc: DC device
+ *
+ * Return: DC DMA alignment constraint.
+ */
+unsigned int mmi_dc_planes_get_dma_align(struct mmi_dc *dc)
+{
+	struct mmi_dc_plane *plane = dc->planes[MMI_DC_PLANE1];
+	struct dma_chan *dma_channel = plane->dmas[0];
+
+	return 1 << dma_channel->device->copy_align;
+}
+
+/**
+ * mmi_dc_create_planes - Create all DC planes.
+ * @dc: DC device
+ * @drm: DRM device
+ *
+ * Return: 0 on success or error code otherwise.
+ */
+int mmi_dc_create_planes(struct mmi_dc *dc, struct drm_device *drm)
+{
+	static const struct mmi_dc_plane_info plane_info[] = {
+		[MMI_DC_PLANE0] = {
+			.formats = plane_formats,
+			.num_formats = ARRAY_SIZE(plane_formats),
+			.num_channels = MMI_DC_MAX_NUM_SUB_PLANES,
+		},
+		[MMI_DC_PLANE1] = {
+			.formats = plane_formats,
+			.num_formats = ARRAY_SIZE(plane_formats),
+			.num_channels = MMI_DC_MAX_NUM_SUB_PLANES,
+		},
+	};
+	unsigned int i;
+
+	for (i = 0; i < ARRAY_SIZE(dc->planes); ++i) {
+		int ret;
+		size_t xt_alloc_size;
+		enum drm_plane_type type = i == MMI_DC_PLANE1 ?
+						DRM_PLANE_TYPE_PRIMARY :
+						DRM_PLANE_TYPE_OVERLAY;
+		const struct mmi_dc_plane_info *info = &plane_info[i];
+		struct mmi_dc_plane *plane = mmi_dc_drm_plane_init(drm, info,
+								   type, i);
+		if (IS_ERR(plane)) {
+			ret = PTR_ERR(plane);
+			dev_err(dc->dev, "failed to create DRM plane: %d\n",
+				ret);
+			return ret;
+		}
+
+		dc->planes[i] = plane;
+		plane->id = i;
+		plane->dc = dc;
+		plane->info = info;
+
+		ret = mmi_dc_plane_request_dma(plane);
+		if (ret < 0)
+			return ret;
+
+		xt_alloc_size = sizeof(struct dma_interleaved_template) +
+				sizeof(struct data_chunk);
+		plane->xt = devm_kzalloc(dc->dev, xt_alloc_size, GFP_KERNEL);
+		if (!plane->xt)
+			return -ENOMEM;
+
+		plane->xt->dir = DMA_MEM_TO_DEV;
+		plane->xt->src_sgl = true;
+		plane->xt->frame_size = 1;
+	}
+
+	/* Reset video / audio select */
+	dc_write_avbuf(dc, MMI_DC_AV_BUF_OUTPUT_AUDIO_VIDEO_SELECT, 0x1F);
+
+	return 0;
+}
+
+/**
+ * mmi_dc_destroy_planes - Destroy all DC planes.
+ * @dc: DC device
+ */
+void mmi_dc_destroy_planes(struct mmi_dc *dc)
+{
+	unsigned int i;
+
+	for (i = 0; i < ARRAY_SIZE(dc->planes); i++) {
+		if (dc->planes[i])
+			mmi_dc_plane_release_dma(dc->planes[i]);
+	}
+}
+
+/**
+ * mmi_dc_disable_planes - Stop DMA transfers and disable all planes.
+ * @dc: DC device
+ * @state: New atomic state to apply
+ */
+static void mmi_dc_disable_planes(struct mmi_dc *dc,
+				  struct drm_atomic_state *state)
+{
+	unsigned int i;
+
+	for (i = 0; i < MMI_DC_NUM_PLANES; ++i) {
+		struct mmi_dc_plane *dc_plane = dc->planes[i];
+		struct drm_plane *plane = &dc_plane->base;
+		struct drm_plane_state *old_state =
+			drm_atomic_get_old_plane_state(state, plane);
+
+		if (old_state && old_state->fb)
+			mmi_dc_plane_disable(dc_plane);
+	}
+}
+
+/**
+ * mmi_dc_enable_planes - Set formats and enable planes.
+ * @dc: DC device
+ * @state: New atomic state to apply
+ */
+static void mmi_dc_enable_planes(struct mmi_dc *dc,
+				 struct drm_atomic_state *state)
+{
+	unsigned int i;
+
+	for (i = 0; i < MMI_DC_NUM_PLANES; ++i) {
+		struct mmi_dc_plane *dc_plane = dc->planes[i];
+		struct drm_plane *plane = &dc_plane->base;
+		struct drm_plane_state *new_state =
+			drm_atomic_get_new_plane_state(state, plane);
+
+		if (new_state && new_state->fb) {
+			mmi_dc_plane_set_format(dc_plane,
+						new_state->fb->format);
+			mmi_dc_plane_enable(dc_plane);
+			if (plane->type == DRM_PLANE_TYPE_PRIMARY)
+				mmi_dc_set_global_alpha(dc_plane->dc,
+							new_state->alpha >> 8,
+							true);
+		}
+	}
+}
+
+/**
+ * mmi_dc_update_planes - Start DMA transfers to flush FBs.
+ * @dc: DC device
+ * @state: New atomic state to apply
+ */
+static void mmi_dc_update_planes(struct mmi_dc *dc,
+				 struct drm_atomic_state *state)
+{
+	unsigned int i;
+
+	for (i = 0; i < MMI_DC_NUM_PLANES; ++i) {
+		struct mmi_dc_plane *dc_plane = dc->planes[i];
+		struct drm_plane *plane = &dc_plane->base;
+		struct drm_plane_state *new_state =
+			drm_atomic_get_new_plane_state(state, plane);
+
+		if (new_state && new_state->fb)
+			mmi_dc_plane_update(dc_plane, new_state);
+	}
+}
+
+/**
+ * mmi_dc_reconfig_planes - Reset and reconfigure DC planes.
+ * @dc: DC device
+ * @state: New atomic state to apply
+ */
+void mmi_dc_reconfig_planes(struct mmi_dc *dc, struct drm_atomic_state *state)
+{
+	mmi_dc_disable_planes(dc, state);
+	mmi_dc_enable_planes(dc, state);
+	mmi_dc_update_planes(dc, state);
+}
diff --git a/drivers/gpu/drm/xlnx/xlnx_bridge.c b/drivers/gpu/drm/xlnx/xlnx_bridge.c
new file mode 100644
index 000000000..4fdec0a1a
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_bridge.c
@@ -0,0 +1,575 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx DRM bridge driver
+ *
+ *  Copyright (C) 2017 Xilinx, Inc.
+ *
+ *  Author: Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/slab.h>
+#include <linux/of.h>
+#include <linux/list.h>
+
+#include "xlnx_bridge.h"
+#include "xlnx_drv.h"
+
+/*
+ * Overview
+ * --------
+ *
+ * Similar to drm bridge, but this can be used by any DRM driver. There
+ * is no limitation to be used by non DRM drivers as well. No complex topology
+ * is modeled, thus it's assumed that the Xilinx bridge device is directly
+ * attached to client. The client should call Xilinx bridge functions explicitly
+ * where it's needed, as opposed to drm bridge functions which are called
+ * implicitly by DRM core.
+ * One Xlnx bridge can be owned by one driver at a time.
+ */
+
+/**
+ * struct xlnx_bridge_helper - Xilinx bridge helper
+ * @xlnx_bridges: list of Xilinx bridges
+ * @lock: lock to protect @xlnx_crtcs
+ * @refcnt: reference count
+ * @error: flag if in error state
+ */
+struct xlnx_bridge_helper {
+	struct list_head xlnx_bridges;
+	struct mutex lock; /* lock for @xlnx_bridges */
+	unsigned int refcnt;
+	bool error;
+};
+
+static struct xlnx_bridge_helper helper;
+
+struct videomode;
+/*
+ * Client functions
+ */
+
+/**
+ * xlnx_bridge_enable - Enable the bridge
+ * @bridge: bridge to enable
+ *
+ * Enable bridge.
+ *
+ * Return: 0 on success. -ENOENT if no callback, -EFAULT in error state,
+ * or return code from callback.
+ */
+int xlnx_bridge_enable(struct xlnx_bridge *bridge)
+{
+	if (!bridge)
+		return 0;
+
+	if (helper.error)
+		return -EFAULT;
+
+	if (bridge->enable)
+		return bridge->enable(bridge);
+
+	return -ENOENT;
+}
+EXPORT_SYMBOL(xlnx_bridge_enable);
+
+/**
+ * xlnx_bridge_disable - Disable the bridge
+ * @bridge: bridge to disable
+ *
+ * Disable bridge.
+ */
+void xlnx_bridge_disable(struct xlnx_bridge *bridge)
+{
+	if (!bridge)
+		return;
+
+	if (helper.error)
+		return;
+
+	if (bridge->disable)
+		bridge->disable(bridge);
+}
+EXPORT_SYMBOL(xlnx_bridge_disable);
+
+/**
+ * xlnx_bridge_set_input - Set the input of @bridge
+ * @bridge: bridge to set
+ * @width: width
+ * @height: height
+ * @bus_fmt: bus format (ex, MEDIA_BUS_FMT_*);
+ *
+ * Set the bridge input with height / width / format.
+ *
+ * Return: 0 on success. -ENOENT if no callback, -EFAULT if in error state,
+ * or return code from callback.
+ */
+int xlnx_bridge_set_input(struct xlnx_bridge *bridge,
+			  u32 width, u32 height, u32 bus_fmt)
+{
+	if (!bridge)
+		return 0;
+
+	if (helper.error)
+		return -EFAULT;
+
+	if (bridge->set_input)
+		return bridge->set_input(bridge, width, height, bus_fmt);
+
+	return -ENOENT;
+}
+EXPORT_SYMBOL(xlnx_bridge_set_input);
+
+/**
+ * xlnx_bridge_get_input_fmts - Get the supported input formats
+ * @bridge: bridge to set
+ * @fmts: pointer to formats
+ * @count: pointer to format count
+ *
+ * Get the list of supported input bus formats.
+ *
+ * Return: 0 on success. -ENOENT if no callback, -EFAULT if in error state,
+ * or return code from callback.
+ */
+int xlnx_bridge_get_input_fmts(struct xlnx_bridge *bridge,
+			       const u32 **fmts, u32 *count)
+{
+	if (!bridge)
+		return 0;
+
+	if (helper.error)
+		return -EFAULT;
+
+	if (bridge->get_input_fmts)
+		return bridge->get_input_fmts(bridge, fmts, count);
+
+	return -ENOENT;
+}
+EXPORT_SYMBOL(xlnx_bridge_get_input_fmts);
+
+/**
+ * xlnx_bridge_set_output - Set the output of @bridge
+ * @bridge: bridge to set
+ * @width: width
+ * @height: height
+ * @bus_fmt: bus format (ex, MEDIA_BUS_FMT_*);
+ *
+ * Set the bridge output with height / width / format.
+ *
+ * Return: 0 on success. -ENOENT if no callback, -EFAULT if in error state,
+ * or return code from callback.
+ */
+int xlnx_bridge_set_output(struct xlnx_bridge *bridge,
+			   u32 width, u32 height, u32 bus_fmt)
+{
+	if (!bridge)
+		return 0;
+
+	if (helper.error)
+		return -EFAULT;
+
+	if (bridge->set_output)
+		return bridge->set_output(bridge, width, height, bus_fmt);
+
+	return -ENOENT;
+}
+EXPORT_SYMBOL(xlnx_bridge_set_output);
+
+/**
+ * xlnx_bridge_get_output_fmts - Get the supported output formats
+ * @bridge: bridge to set
+ * @fmts: pointer to formats
+ * @count: pointer to format count
+ *
+ * Get the list of supported output bus formats.
+ *
+ * Return: 0 on success. -ENOENT if no callback, -EFAULT if in error state,
+ * or return code from callback.
+ */
+int xlnx_bridge_get_output_fmts(struct xlnx_bridge *bridge,
+				const u32 **fmts, u32 *count)
+{
+	if (!bridge)
+		return 0;
+
+	if (helper.error)
+		return -EFAULT;
+
+	if (bridge->get_output_fmts)
+		return bridge->get_output_fmts(bridge, fmts, count);
+
+	return -ENOENT;
+}
+EXPORT_SYMBOL(xlnx_bridge_get_output_fmts);
+
+/**
+ * xlnx_bridge_set_timing - Set the video timing
+ * @bridge: bridge to set
+ * @vm: Videomode
+ *
+ * Set the video mode so that timing can be generated using this
+ * by the video timing controller.
+ *
+ * Return: 0 on success. -ENOENT if no callback, -EFAULT if in error state,
+ * or return code from callback.
+ */
+int xlnx_bridge_set_timing(struct xlnx_bridge *bridge, struct videomode *vm)
+{
+	if (!bridge)
+		return 0;
+
+	if (helper.error)
+		return -EFAULT;
+
+	if (bridge->set_timing) {
+		bridge->set_timing(bridge, vm);
+		return 0;
+	}
+
+	return -ENOENT;
+}
+EXPORT_SYMBOL(xlnx_bridge_set_timing);
+
+/**
+ * of_xlnx_bridge_get - Get the corresponding Xlnx bridge instance
+ * @bridge_np: The device node of the bridge device
+ *
+ * The function walks through the Xlnx bridge list of @drm, and return
+ * if any registered bridge matches the device node. The returned
+ * bridge will not be accesible by others.
+ *
+ * Return: the matching Xlnx bridge instance, or NULL
+ */
+struct xlnx_bridge *of_xlnx_bridge_get(struct device_node *bridge_np)
+{
+	struct xlnx_bridge *found = NULL;
+	struct xlnx_bridge *bridge;
+
+	if (helper.error)
+		return NULL;
+
+	mutex_lock(&helper.lock);
+	list_for_each_entry(bridge, &helper.xlnx_bridges, list) {
+		if (bridge->of_node == bridge_np && !bridge->owned) {
+			found = bridge;
+			bridge->owned = true;
+			break;
+		}
+	}
+	mutex_unlock(&helper.lock);
+
+	return found;
+}
+EXPORT_SYMBOL_GPL(of_xlnx_bridge_get);
+
+/**
+ * of_xlnx_bridge_put - Put the Xlnx bridge instance
+ * @bridge: Xlnx bridge instance to release
+ *
+ * Return the @bridge. After this, the bridge will be available for
+ * other drivers to use.
+ */
+void of_xlnx_bridge_put(struct xlnx_bridge *bridge)
+{
+	if (WARN_ON(helper.error))
+		return;
+
+	mutex_lock(&helper.lock);
+	WARN_ON(!bridge->owned);
+	bridge->owned = false;
+	mutex_unlock(&helper.lock);
+}
+EXPORT_SYMBOL_GPL(of_xlnx_bridge_put);
+
+#ifdef CONFIG_DRM_XLNX_BRIDGE_DEBUG_FS
+
+#include <linux/debugfs.h>
+
+struct xlnx_bridge_debugfs_dir {
+	struct dentry *dir;
+	int ref_cnt;
+};
+
+static struct xlnx_bridge_debugfs_dir *dir;
+
+struct xlnx_bridge_debugfs_file {
+	struct dentry *file;
+	const char *status;
+};
+
+#define XLNX_BRIDGE_DEBUGFS_MAX_BYTES	16
+
+static ssize_t xlnx_bridge_debugfs_read(struct file *f, char __user *buf,
+					size_t size, loff_t *pos)
+{
+	struct xlnx_bridge *bridge = f->f_inode->i_private;
+	int ret, count = 0;
+
+	if (size <= 0)
+		return -EINVAL;
+
+	if (*pos != 0)
+		return 0;
+
+	if (bridge->debugfs_file->status) {
+		count = min(size, strlen(bridge->debugfs_file->status));
+		ret = copy_to_user(buf, bridge->debugfs_file->status, count);
+		if (ret)
+			count = -EFAULT;
+	}
+
+	return count;
+}
+
+static ssize_t xlnx_bridge_debugfs_write(struct file *f, const char __user *buf,
+					 size_t size, loff_t *pos)
+{
+	struct xlnx_bridge *bridge = f->f_inode->i_private;
+
+	if (*pos != 0 || size <= 0)
+		return -EINVAL;
+
+	if (!strncmp(buf, "enable", 5)) {
+		xlnx_bridge_enable(bridge);
+	} else if (!strncmp(buf, "disable", 6)) {
+		xlnx_bridge_disable(bridge);
+	} else if (!strncmp(buf, "set_input", 3)) {
+		char *cmd, **tmp;
+		char *w, *h, *bus_fmt;
+		u32 width = 0, height = 0, fmt = 0;
+		int ret;
+
+		cmd = kzalloc(size, GFP_KERNEL);
+		if (!cmd)
+			return -ENOMEM;
+
+		ret = strncpy_from_user(cmd, buf, size);
+		if (ret < 0) {
+			pr_err("%s %d failed to copy the command  %s\n",
+			       __func__, __LINE__, buf);
+			kfree(cmd);
+			return ret;
+		}
+
+		tmp = &cmd;
+		strsep(tmp, " ");
+		w = strsep(tmp, " ");
+		h = strsep(tmp, " ");
+		bus_fmt = strsep(tmp, " ");
+		if (w && h && bus_fmt) {
+			ret = kstrtouint(w, 0, &width);
+			ret |= kstrtouint(h, 0, &height);
+			ret |= kstrtouint(bus_fmt, 0, &fmt);
+		}
+
+		kfree(cmd);
+		if (ret) {
+			pr_err("%s %d invalid command: %s\n",
+			       __func__, __LINE__, buf);
+			return -EINVAL;
+		}
+		xlnx_bridge_set_input(bridge, width, height, fmt);
+	}
+
+	return size;
+}
+
+static const struct file_operations xlnx_bridge_debugfs_fops = {
+	.owner	= THIS_MODULE,
+	.read	= xlnx_bridge_debugfs_read,
+	.write	= xlnx_bridge_debugfs_write,
+};
+
+static int xlnx_bridge_debugfs_register(struct xlnx_bridge *bridge)
+{
+	struct xlnx_bridge_debugfs_file *file;
+	char file_name[32];
+
+	file = kzalloc(sizeof(*file), GFP_KERNEL);
+	if (!file)
+		return -ENOMEM;
+
+	if (bridge->extra_name)
+		snprintf(file_name, sizeof(file_name), "xlnx_bridge-%s%s",
+			 bridge->of_node->name, bridge->extra_name);
+	else
+		snprintf(file_name, sizeof(file_name), "xlnx_bridge-%s",
+			 bridge->of_node->name);
+	file->file = debugfs_create_file(file_name, 0444, dir->dir, bridge,
+					 &xlnx_bridge_debugfs_fops);
+	bridge->debugfs_file = file;
+
+	return 0;
+}
+
+static void xlnx_bridge_debugfs_unregister(struct xlnx_bridge *bridge)
+{
+	if (!bridge->debugfs_file) {
+		pr_err("bridge %s debugfs file is NULL\n", bridge->of_node->name);
+		return;
+	}
+	debugfs_remove(bridge->debugfs_file->file);
+	kfree(bridge->debugfs_file);
+}
+
+static int xlnx_bridge_debugfs_init(void)
+{
+	if (dir) {
+		dir->ref_cnt++;
+		return 0;
+	}
+
+	dir = kzalloc(sizeof(*dir), GFP_KERNEL);
+	if (!dir)
+		return -ENOMEM;
+
+	dir->dir = debugfs_create_dir("xlnx-bridge", NULL);
+	if (!dir->dir)
+		return -ENODEV;
+	dir->ref_cnt++;
+
+	return 0;
+}
+
+static void xlnx_bridge_debugfs_fini(void)
+{
+	if (--dir->ref_cnt)
+		return;
+
+	debugfs_remove_recursive(dir->dir);
+	dir = NULL;
+}
+
+#else
+
+static int xlnx_bridge_debugfs_register(struct xlnx_bridge *bridge)
+{
+	return 0;
+}
+
+static void xlnx_bridge_debugfs_unregister(struct xlnx_bridge *bridge)
+{
+}
+
+static int xlnx_bridge_debugfs_init(void)
+{
+	return 0;
+}
+
+static void xlnx_bridge_debugfs_fini(void)
+{
+}
+
+#endif
+
+/*
+ * Provider functions
+ */
+
+/**
+ * xlnx_bridge_register - Register the bridge instance
+ * @bridge: Xlnx bridge instance to register
+ *
+ * Register @bridge to be available for clients.
+ *
+ * Return: 0 on success. -EPROBE_DEFER if helper is not initialized, or
+ * -EFAULT if in error state.
+ */
+int xlnx_bridge_register(struct xlnx_bridge *bridge)
+{
+	if (!helper.refcnt)
+		return -EPROBE_DEFER;
+
+	if (helper.error)
+		return -EFAULT;
+
+	mutex_lock(&helper.lock);
+	WARN_ON(!bridge->of_node);
+	bridge->owned = false;
+	xlnx_bridge_debugfs_register(bridge);
+	list_add_tail(&bridge->list, &helper.xlnx_bridges);
+	mutex_unlock(&helper.lock);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(xlnx_bridge_register);
+
+/**
+ * xlnx_bridge_unregister - Unregister the bridge instance
+ * @bridge: Xlnx bridge instance to unregister
+ *
+ * Unregister @bridge. The bridge shouldn't be owned by any client
+ * at this point.
+ */
+void xlnx_bridge_unregister(struct xlnx_bridge *bridge)
+{
+	if (helper.error)
+		return;
+
+	mutex_lock(&helper.lock);
+	pr_warn("unregister bridge %s which is owned by other component\n",
+		bridge->of_node->name);
+	xlnx_bridge_debugfs_unregister(bridge);
+	list_del(&bridge->list);
+	mutex_unlock(&helper.lock);
+}
+EXPORT_SYMBOL_GPL(xlnx_bridge_unregister);
+
+/*
+ * Internal functions: used by Xlnx DRM
+ */
+
+/**
+ * xlnx_bridge_helper_init - Initialize the bridge helper
+ * @void: No arg
+ *
+ * Initialize the bridge helper or increment the reference count
+ * if already initialized.
+ *
+ * Return: 0 on success, or -EFAULT if in error state.
+ */
+int xlnx_bridge_helper_init(void)
+{
+	if (helper.refcnt++ > 0) {
+		if (helper.error)
+			return -EFAULT;
+		return 0;
+	}
+
+	INIT_LIST_HEAD(&helper.xlnx_bridges);
+	mutex_init(&helper.lock);
+	helper.error = false;
+
+	if (xlnx_bridge_debugfs_init())
+		pr_err("failed to init xlnx bridge debugfs\n");
+
+	return 0;
+}
+
+/**
+ * xlnx_bridge_helper_fini - Release the bridge helper
+ *
+ * Clean up or decrement the reference of the bridge helper.
+ */
+void xlnx_bridge_helper_fini(void)
+{
+	if (--helper.refcnt > 0)
+		return;
+
+	xlnx_bridge_debugfs_fini();
+
+	if (WARN_ON(!list_empty(&helper.xlnx_bridges))) {
+		helper.error = true;
+		pr_err("any further xlnx bridge call will fail\n");
+	}
+
+	mutex_destroy(&helper.lock);
+}
diff --git a/drivers/gpu/drm/xlnx/xlnx_bridge.h b/drivers/gpu/drm/xlnx/xlnx_bridge.h
new file mode 100644
index 000000000..74fe9cb5f
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_bridge.h
@@ -0,0 +1,180 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx DRM bridge header
+ *
+ *  Copyright (C) 2017 Xilinx, Inc.
+ *
+ *  Author: Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _XLNX_BRIDGE_H_
+#define _XLNX_BRIDGE_H_
+
+struct videomode;
+
+struct xlnx_bridge_debugfs_file;
+
+/**
+ * struct xlnx_bridge - Xilinx bridge device
+ * @list: list node for Xilinx bridge device list
+ * @of_node: OF node for the bridge
+ * @owned: flag if the bridge is owned
+ * @enable: callback to enable the bridge
+ * @disable: callback to disable the bridge
+ * @set_input: callback to set the input
+ * @get_input_fmts: callback to get supported input formats.
+ * @set_output: callback to set the output
+ * @get_output_fmts: callback to get supported output formats.
+ * @set_timing: callback to set timing in connected video timing controller.
+ * @debugfs_file: for debugfs support
+ * @extra_name: name to distinguish the bridges which share the same of_node
+ */
+struct xlnx_bridge {
+	struct list_head list;
+	struct device_node *of_node;
+	bool owned;
+	int (*enable)(struct xlnx_bridge *bridge);
+	void (*disable)(struct xlnx_bridge *bridge);
+	int (*set_input)(struct xlnx_bridge *bridge,
+			 u32 width, u32 height, u32 bus_fmt);
+	int (*get_input_fmts)(struct xlnx_bridge *bridge,
+			      const u32 **fmts, u32 *count);
+	int (*set_output)(struct xlnx_bridge *bridge,
+			  u32 width, u32 height, u32 bus_fmt);
+	int (*get_output_fmts)(struct xlnx_bridge *bridge,
+			       const u32 **fmts, u32 *count);
+	int (*set_timing)(struct xlnx_bridge *bridge, struct videomode *vm);
+	struct xlnx_bridge_debugfs_file *debugfs_file;
+	char *extra_name;
+};
+
+#if IS_ENABLED(CONFIG_DRM_XLNX_BRIDGE)
+/*
+ * Helper functions: used within Xlnx DRM
+ */
+
+struct xlnx_bridge_helper;
+
+int xlnx_bridge_helper_init(void);
+void xlnx_bridge_helper_fini(void);
+
+/*
+ * Helper functions: used by client driver
+ */
+
+int xlnx_bridge_enable(struct xlnx_bridge *bridge);
+void xlnx_bridge_disable(struct xlnx_bridge *bridge);
+int xlnx_bridge_set_input(struct xlnx_bridge *bridge,
+			  u32 width, u32 height, u32 bus_fmt);
+int xlnx_bridge_get_input_fmts(struct xlnx_bridge *bridge,
+			       const u32 **fmts, u32 *count);
+int xlnx_bridge_set_output(struct xlnx_bridge *bridge,
+			   u32 width, u32 height, u32 bus_fmt);
+int xlnx_bridge_get_output_fmts(struct xlnx_bridge *bridge,
+				const u32 **fmts, u32 *count);
+int xlnx_bridge_set_timing(struct xlnx_bridge *bridge, struct videomode *vm);
+struct xlnx_bridge *of_xlnx_bridge_get(struct device_node *bridge_np);
+void of_xlnx_bridge_put(struct xlnx_bridge *bridge);
+
+/*
+ * Bridge registration: used by bridge driver
+ */
+
+int xlnx_bridge_register(struct xlnx_bridge *bridge);
+void xlnx_bridge_unregister(struct xlnx_bridge *bridge);
+
+#else /* CONFIG_DRM_XLNX_BRIDGE */
+
+struct xlnx_bridge_helper;
+
+static inline int xlnx_bridge_helper_init(void)
+{
+	return 0;
+}
+
+static inline void xlnx_bridge_helper_fini(void)
+{
+}
+
+static inline int xlnx_bridge_enable(struct xlnx_bridge *bridge)
+{
+	if (bridge)
+		return -ENODEV;
+	return 0;
+}
+
+static inline void xlnx_bridge_disable(struct xlnx_bridge *bridge)
+{
+}
+
+static inline int xlnx_bridge_set_input(struct xlnx_bridge *bridge,
+					u32 width, u32 height, u32 bus_fmt)
+{
+	if (bridge)
+		return -ENODEV;
+	return 0;
+}
+
+static inline int xlnx_bridge_get_input_fmts(struct xlnx_bridge *bridge,
+					     const u32 **fmts, u32 *count)
+{
+	if (bridge)
+		return -ENODEV;
+	return 0;
+}
+
+static inline int xlnx_bridge_set_output(struct xlnx_bridge *bridge,
+					 u32 width, u32 height, u32 bus_fmt)
+{
+	if (bridge)
+		return -ENODEV;
+	return 0;
+}
+
+static inline int xlnx_bridge_get_output_fmts(struct xlnx_bridge *bridge,
+					      const u32 **fmts, u32 *count)
+{
+	if (bridge)
+		return -ENODEV;
+	return 0;
+}
+
+static inline int xlnx_bridge_set_timing(struct xlnx_bridge *bridge,
+					 struct videomode *vm)
+{
+	if (bridge)
+		return -ENODEV;
+	return 0;
+}
+
+static inline struct xlnx_bridge *
+of_xlnx_bridge_get(struct device_node *bridge_np)
+{
+	return NULL;
+}
+
+static inline void of_xlnx_bridge_put(struct xlnx_bridge *bridge)
+{
+}
+
+static inline int xlnx_bridge_register(struct xlnx_bridge *bridge)
+{
+	return 0;
+}
+
+static inline void xlnx_bridge_unregister(struct xlnx_bridge *bridge)
+{
+}
+
+#endif /* CONFIG_DRM_XLNX_BRIDGE */
+
+#endif /* _XLNX_BRIDGE_H_ */
diff --git a/drivers/gpu/drm/xlnx/xlnx_crtc.c b/drivers/gpu/drm/xlnx/xlnx_crtc.c
new file mode 100644
index 000000000..fd718ca5b
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_crtc.c
@@ -0,0 +1,208 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx DRM crtc driver
+ *
+ *  Copyright (C) 2017 - 2018 Xilinx, Inc.
+ *
+ *  Author: Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <drm/drm_drv.h>
+#include <drm/drm_crtc.h>
+
+#include <linux/list.h>
+#include <linux/dma-mapping.h>
+
+#include "xlnx_crtc.h"
+#include "xlnx_drv.h"
+
+/*
+ * Overview
+ * --------
+ *
+ * The Xilinx CRTC layer is to enable the custom interface to CRTC drivers.
+ * The interface is used by Xilinx DRM driver where it needs CRTC
+ * functionailty. CRTC drivers should attach the desired callbacks
+ * to struct xlnx_crtc and register the xlnx_crtc with correcsponding
+ * drm_device. It's highly recommended CRTC drivers register all callbacks
+ * even though many of them are optional.
+ * The CRTC helper simply walks through the registered CRTC device,
+ * and call the callbacks.
+ */
+
+/**
+ * struct xlnx_crtc_helper - Xilinx CRTC helper
+ * @xlnx_crtcs: list of Xilinx CRTC devices
+ * @lock: lock to protect @xlnx_crtcs
+ * @drm: back pointer to DRM core
+ */
+struct xlnx_crtc_helper {
+	struct list_head xlnx_crtcs;
+	struct mutex lock; /* lock for @xlnx_crtcs */
+	struct drm_device *drm;
+};
+
+#define XLNX_CRTC_MAX_HEIGHT_WIDTH	INT_MAX
+
+unsigned int xlnx_crtc_helper_get_align(struct xlnx_crtc_helper *helper)
+{
+	struct xlnx_crtc *crtc;
+	unsigned int align = 1, tmp;
+
+	list_for_each_entry(crtc, &helper->xlnx_crtcs, list) {
+		if (crtc->get_align) {
+			tmp = crtc->get_align(crtc);
+			align = ALIGN(align, tmp);
+		}
+	}
+
+	return align;
+}
+
+u64 xlnx_crtc_helper_get_dma_mask(struct xlnx_crtc_helper *helper)
+{
+	struct xlnx_crtc *crtc;
+	u64 mask = DMA_BIT_MASK(sizeof(dma_addr_t) * 8), tmp;
+
+	list_for_each_entry(crtc, &helper->xlnx_crtcs, list) {
+		if (crtc->get_dma_mask) {
+			tmp = crtc->get_dma_mask(crtc);
+			mask = min(mask, tmp);
+		}
+	}
+
+	return mask;
+}
+
+int xlnx_crtc_helper_get_max_width(struct xlnx_crtc_helper *helper)
+{
+	struct xlnx_crtc *crtc;
+	int width = XLNX_CRTC_MAX_HEIGHT_WIDTH, tmp;
+
+	list_for_each_entry(crtc, &helper->xlnx_crtcs, list) {
+		if (crtc->get_max_width) {
+			tmp = crtc->get_max_width(crtc);
+			width = min(width, tmp);
+		}
+	}
+
+	return width;
+}
+
+int xlnx_crtc_helper_get_max_height(struct xlnx_crtc_helper *helper)
+{
+	struct xlnx_crtc *crtc;
+	int height = XLNX_CRTC_MAX_HEIGHT_WIDTH, tmp;
+
+	list_for_each_entry(crtc, &helper->xlnx_crtcs, list) {
+		if (crtc->get_max_height) {
+			tmp = crtc->get_max_height(crtc);
+			height = min(height, tmp);
+		}
+	}
+
+	return height;
+}
+
+uint32_t xlnx_crtc_helper_get_format(struct xlnx_crtc_helper *helper)
+{
+	struct xlnx_crtc *crtc;
+	u32 format = 0, tmp;
+
+	list_for_each_entry(crtc, &helper->xlnx_crtcs, list) {
+		if (crtc->get_format) {
+			tmp = crtc->get_format(crtc);
+			if (format && format != tmp)
+				return 0;
+			format = tmp;
+		}
+	}
+
+	return format;
+}
+
+u32 xlnx_crtc_helper_get_cursor_width(struct xlnx_crtc_helper *helper)
+{
+	struct xlnx_crtc *crtc;
+	u32 width = XLNX_CRTC_MAX_HEIGHT_WIDTH, tmp;
+
+	list_for_each_entry(crtc, &helper->xlnx_crtcs, list) {
+		if (crtc->get_cursor_width) {
+			tmp = crtc->get_cursor_width(crtc);
+			width = min(width, tmp);
+		}
+	}
+
+	return width;
+}
+
+u32 xlnx_crtc_helper_get_cursor_height(struct xlnx_crtc_helper *helper)
+{
+	struct xlnx_crtc *crtc;
+	u32 height = XLNX_CRTC_MAX_HEIGHT_WIDTH, tmp;
+
+	list_for_each_entry(crtc, &helper->xlnx_crtcs, list) {
+		if (crtc->get_cursor_height) {
+			tmp = crtc->get_cursor_height(crtc);
+			height = min(height, tmp);
+		}
+	}
+
+	return height;
+}
+struct xlnx_crtc_helper *xlnx_crtc_helper_init(struct drm_device *drm)
+{
+	struct xlnx_crtc_helper *helper;
+
+	helper = devm_kzalloc(drm->dev, sizeof(*helper), GFP_KERNEL);
+	if (!helper)
+		return ERR_PTR(-ENOMEM);
+
+	INIT_LIST_HEAD(&helper->xlnx_crtcs);
+	mutex_init(&helper->lock);
+	helper->drm = drm;
+
+	return helper;
+}
+
+void xlnx_crtc_helper_fini(struct drm_device *drm,
+			   struct xlnx_crtc_helper *helper)
+{
+	if (WARN_ON(helper->drm != drm))
+		return;
+
+	if (WARN_ON(!list_empty(&helper->xlnx_crtcs)))
+		return;
+
+	mutex_destroy(&helper->lock);
+	devm_kfree(drm->dev, helper);
+}
+
+void xlnx_crtc_register(struct drm_device *drm, struct xlnx_crtc *crtc)
+{
+	struct xlnx_crtc_helper *helper = xlnx_get_crtc_helper(drm);
+
+	mutex_lock(&helper->lock);
+	list_add_tail(&crtc->list, &helper->xlnx_crtcs);
+	mutex_unlock(&helper->lock);
+}
+EXPORT_SYMBOL_GPL(xlnx_crtc_register);
+
+void xlnx_crtc_unregister(struct drm_device *drm, struct xlnx_crtc *crtc)
+{
+	struct xlnx_crtc_helper *helper = xlnx_get_crtc_helper(drm);
+
+	mutex_lock(&helper->lock);
+	list_del(&crtc->list);
+	mutex_unlock(&helper->lock);
+}
+EXPORT_SYMBOL_GPL(xlnx_crtc_unregister);
diff --git a/drivers/gpu/drm/xlnx/xlnx_crtc.h b/drivers/gpu/drm/xlnx/xlnx_crtc.h
new file mode 100644
index 000000000..c8762ab1e
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_crtc.h
@@ -0,0 +1,76 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx DRM crtc header
+ *
+ *  Copyright (C) 2017 - 2018 Xilinx, Inc.
+ *
+ *  Author: Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _XLNX_CRTC_H_
+#define _XLNX_CRTC_H_
+
+/**
+ * struct xlnx_crtc - Xilinx CRTC device
+ * @crtc: DRM CRTC device
+ * @list: list node for Xilinx CRTC device list
+ * @get_align: Get the alignment requirement of CRTC device
+ * @get_dma_mask: Get the dma mask of CRTC device
+ * @get_max_width: Get the maximum supported width
+ * @get_max_height: Get the maximum supported height
+ * @get_format: Get the current format of CRTC device
+ * @get_cursor_width: Get the cursor width
+ * @get_cursor_height: Get the cursor height
+ */
+struct xlnx_crtc {
+	struct drm_crtc crtc;
+	struct list_head list;
+	unsigned int (*get_align)(struct xlnx_crtc *crtc);
+	u64 (*get_dma_mask)(struct xlnx_crtc *crtc);
+	int (*get_max_width)(struct xlnx_crtc *crtc);
+	int (*get_max_height)(struct xlnx_crtc *crtc);
+	uint32_t (*get_format)(struct xlnx_crtc *crtc);
+	uint32_t (*get_cursor_width)(struct xlnx_crtc *crtc);
+	uint32_t (*get_cursor_height)(struct xlnx_crtc *crtc);
+};
+
+/*
+ * Helper functions: used within Xlnx DRM
+ */
+
+struct xlnx_crtc_helper;
+
+unsigned int xlnx_crtc_helper_get_align(struct xlnx_crtc_helper *helper);
+u64 xlnx_crtc_helper_get_dma_mask(struct xlnx_crtc_helper *helper);
+int xlnx_crtc_helper_get_max_width(struct xlnx_crtc_helper *helper);
+int xlnx_crtc_helper_get_max_height(struct xlnx_crtc_helper *helper);
+uint32_t xlnx_crtc_helper_get_format(struct xlnx_crtc_helper *helper);
+u32 xlnx_crtc_helper_get_cursor_width(struct xlnx_crtc_helper *helper);
+u32 xlnx_crtc_helper_get_cursor_height(struct xlnx_crtc_helper *helper);
+
+struct xlnx_crtc_helper *xlnx_crtc_helper_init(struct drm_device *drm);
+void xlnx_crtc_helper_fini(struct drm_device *drm,
+			   struct xlnx_crtc_helper *helper);
+
+/*
+ * CRTC registration: used by other sub-driver modules
+ */
+
+static inline struct xlnx_crtc *to_xlnx_crtc(struct drm_crtc *crtc)
+{
+	return container_of(crtc, struct xlnx_crtc, crtc);
+}
+
+void xlnx_crtc_register(struct drm_device *drm, struct xlnx_crtc *crtc);
+void xlnx_crtc_unregister(struct drm_device *drm, struct xlnx_crtc *crtc);
+
+#endif /* _XLNX_CRTC_H_ */
diff --git a/drivers/gpu/drm/xlnx/xlnx_csc.c b/drivers/gpu/drm/xlnx/xlnx_csc.c
new file mode 100644
index 000000000..41ad4283a
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_csc.c
@@ -0,0 +1,571 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * VPSS CSC DRM bridge driver
+ *
+ * Copyright (C) 2017-2018 Xilinx, Inc.
+ *
+ * Author: Venkateshwar rao G <vgannava@xilinx.com>
+ */
+
+/*
+ * Overview:
+ * This experimentatl driver works as a bridge driver and
+ * reused the code from V4L2.
+ * TODO:
+ * Need to implement in a modular approach to share driver code between
+ * V4L2 and DRM frameworks.
+ * Should be integrated with plane
+ */
+
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/err.h>
+#include <linux/gpio/consumer.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <uapi/linux/media-bus-format.h>
+
+#include "xlnx_bridge.h"
+
+/* Register offset */
+#define XV_CSC_AP_CTRL			(0x000)
+#define XV_CSC_INVIDEOFORMAT		(0x010)
+#define XV_CSC_OUTVIDEOFORMAT		(0x018)
+#define XV_CSC_WIDTH			(0x020)
+#define XV_CSC_HEIGHT			(0x028)
+#define XV_CSC_K11			(0x050)
+#define XV_CSC_K12			(0x058)
+#define XV_CSC_K13			(0x060)
+#define XV_CSC_K21			(0x068)
+#define XV_CSC_K22			(0x070)
+#define XV_CSC_K23			(0x078)
+#define XV_CSC_K31			(0x080)
+#define XV_CSC_K32			(0x088)
+#define XV_CSC_K33			(0x090)
+#define XV_CSC_ROFFSET			(0x098)
+#define XV_CSC_GOFFSET			(0x0a0)
+#define XV_CSC_BOFFSET			(0x0a8)
+#define XV_CSC_CLAMPMIN			(0x0b0)
+#define XV_CSC_CLIPMAX			(0x0b8)
+#define XV_CSC_SCALE_FACTOR		(4096)
+#define XV_CSC_DIVISOR			(10000)
+/* Streaming Macros */
+#define XCSC_CLAMP_MIN_ZERO		(0)
+#define XCSC_AP_START			BIT(0)
+#define XCSC_AP_AUTO_RESTART		BIT(7)
+#define XCSC_STREAM_ON			(XCSC_AP_START | XCSC_AP_AUTO_RESTART)
+#define XCSC_STREAM_OFF			(0)
+/* GPIO Reset Assert/De-assert */
+#define XCSC_RESET_ASSERT		(1)
+#define XCSC_RESET_DEASSERT		(0)
+
+#define XCSC_MIN_WIDTH			(64)
+#define XCSC_MAX_WIDTH			(8192)
+#define XCSC_MIN_HEIGHT			(64)
+#define XCSC_MAX_HEIGHT			(4320)
+
+static const u32 xilinx_csc_video_fmts[] = {
+	MEDIA_BUS_FMT_RGB888_1X24,
+	MEDIA_BUS_FMT_VUY8_1X24,
+	MEDIA_BUS_FMT_UYVY8_1X16,
+	MEDIA_BUS_FMT_VYYUYY8_1X24,
+};
+
+/* vpss_csc_color_fmt - Color format type */
+enum vpss_csc_color_fmt {
+	XVIDC_CSF_RGB = 0,
+	XVIDC_CSF_YCRCB_444,
+	XVIDC_CSF_YCRCB_422,
+	XVIDC_CSF_YCRCB_420,
+};
+
+/**
+ * struct xilinx_csc - Core configuration of csc device structure
+ * @base: pointer to register base address
+ * @dev: device structure
+ * @bridge: xilinx bridge
+ * @cft_in: input color format
+ * @cft_out: output color format
+ * @color_depth: color depth
+ * @k_hw: array of hardware values
+ * @clip_max: clipping maximum value
+ * @width: width of the video
+ * @height: height of video
+ * @max_width: maximum number of pixels in a line
+ * @max_height: maximum number of lines per frame
+ * @rst_gpio: Handle to GPIO specifier to assert/de-assert the reset line
+ * @aclk: IP clock struct
+ */
+struct xilinx_csc {
+	void __iomem *base;
+	struct device *dev;
+	struct xlnx_bridge bridge;
+	enum vpss_csc_color_fmt cft_in;
+	enum vpss_csc_color_fmt cft_out;
+	u32 color_depth;
+	s32 k_hw[3][4];
+	s32 clip_max;
+	u32 width;
+	u32 height;
+	u32 max_width;
+	u32 max_height;
+	struct gpio_desc *rst_gpio;
+	struct clk *aclk;
+};
+
+static inline void xilinx_csc_write(void __iomem *base, u32 offset, u32 val)
+{
+	writel(val, base + offset);
+}
+
+static inline u32 xilinx_csc_read(void __iomem *base, u32 offset)
+{
+	return readl(base + offset);
+}
+
+/**
+ * bridge_to_layer - Gets the parent structure
+ * @bridge: pointer to the member.
+ *
+ * Return: parent structure pointer
+ */
+static inline struct xilinx_csc *bridge_to_layer(struct xlnx_bridge *bridge)
+{
+	return container_of(bridge, struct xilinx_csc, bridge);
+}
+
+static void xilinx_csc_write_rgb_3x3(struct xilinx_csc *csc)
+{
+	xilinx_csc_write(csc->base, XV_CSC_K11, csc->k_hw[0][0]);
+	xilinx_csc_write(csc->base, XV_CSC_K12, csc->k_hw[0][1]);
+	xilinx_csc_write(csc->base, XV_CSC_K13, csc->k_hw[0][2]);
+	xilinx_csc_write(csc->base, XV_CSC_K21, csc->k_hw[1][0]);
+	xilinx_csc_write(csc->base, XV_CSC_K22, csc->k_hw[1][1]);
+	xilinx_csc_write(csc->base, XV_CSC_K23, csc->k_hw[1][2]);
+	xilinx_csc_write(csc->base, XV_CSC_K31, csc->k_hw[2][0]);
+	xilinx_csc_write(csc->base, XV_CSC_K32, csc->k_hw[2][1]);
+	xilinx_csc_write(csc->base, XV_CSC_K33, csc->k_hw[2][2]);
+}
+
+static void xilinx_csc_write_rgb_offset(struct xilinx_csc *csc)
+{
+	xilinx_csc_write(csc->base, XV_CSC_ROFFSET, csc->k_hw[0][3]);
+	xilinx_csc_write(csc->base, XV_CSC_GOFFSET, csc->k_hw[1][3]);
+	xilinx_csc_write(csc->base, XV_CSC_BOFFSET, csc->k_hw[2][3]);
+}
+
+static void xilinx_csc_write_coeff(struct xilinx_csc *csc)
+{
+	xilinx_csc_write_rgb_3x3(csc);
+	xilinx_csc_write_rgb_offset(csc);
+}
+
+static void xcsc_set_default_state(struct xilinx_csc *csc)
+{
+	csc->cft_in = XVIDC_CSF_YCRCB_422;
+	csc->cft_out = XVIDC_CSF_YCRCB_422;
+
+	/* This represents an identity matrix mutliped by 2^12 */
+	csc->k_hw[0][0] = XV_CSC_SCALE_FACTOR;
+	csc->k_hw[0][1] = 0;
+	csc->k_hw[0][2] = 0;
+	csc->k_hw[1][0] = 0;
+	csc->k_hw[1][1] = XV_CSC_SCALE_FACTOR;
+	csc->k_hw[1][2] = 0;
+	csc->k_hw[2][0] = 0;
+	csc->k_hw[2][1] = 0;
+	csc->k_hw[2][2] = XV_CSC_SCALE_FACTOR;
+	csc->k_hw[0][3] = 0;
+	csc->k_hw[1][3] = 0;
+	csc->k_hw[2][3] = 0;
+	csc->clip_max = ((1 << csc->color_depth) - 1);
+	xilinx_csc_write(csc->base, XV_CSC_INVIDEOFORMAT, csc->cft_in);
+	xilinx_csc_write(csc->base, XV_CSC_OUTVIDEOFORMAT, csc->cft_out);
+	xilinx_csc_write_coeff(csc);
+	xilinx_csc_write(csc->base, XV_CSC_CLIPMAX, csc->clip_max);
+	xilinx_csc_write(csc->base, XV_CSC_CLAMPMIN, XCSC_CLAMP_MIN_ZERO);
+}
+
+static void xcsc_ycrcb_to_rgb(struct xilinx_csc *csc, s32 *clip_max)
+{
+	u16 bpc_scale = (1 << (csc->color_depth - 8));
+	/*
+	 * See http://graficaobscura.com/matrix/index.html for
+	 * how these numbers are derived. The VPSS CSC IP is
+	 * derived from this Matrix style algorithm. And the
+	 * 'magic' numbers here are derived from the algorithm.
+	 *
+	 * XV_CSC_DIVISOR is used to help with floating constants
+	 * while performing multiplicative operations.
+	 *
+	 * Coefficients valid only for BT 709
+	 */
+	csc->k_hw[0][0] = 11644 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[0][1] = 0;
+	csc->k_hw[0][2] = 17927 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[1][0] = 11644 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[1][1] = -2132 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[1][2] = -5329 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[2][0] = 11644 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[2][1] = 21124 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[2][2] = 0;
+	csc->k_hw[0][3] = -248 * bpc_scale;
+	csc->k_hw[1][3] = 77 * bpc_scale;
+	csc->k_hw[2][3] = -289 * bpc_scale;
+	*clip_max = ((1 << csc->color_depth) - 1);
+}
+
+static void xcsc_rgb_to_ycrcb(struct xilinx_csc *csc, s32 *clip_max)
+{
+	u16 bpc_scale = (1 << (csc->color_depth - 8));
+	/*
+	 * See http://graficaobscura.com/matrix/index.html for
+	 * how these numbers are derived. The VPSS CSC
+	 * derived from this Matrix style algorithm. And the
+	 * 'magic' numbers here are derived from the algorithm.
+	 *
+	 * XV_CSC_DIVISOR is used to help with floating constants
+	 * while performing multiplicative operations.
+	 *
+	 * Coefficients valid only for BT 709
+	 */
+	csc->k_hw[0][0] = 1826 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[0][1] = 6142 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[0][2] = 620 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[1][0] = -1006 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[1][1] = -3386 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[1][2] = 4392 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[2][0] = 4392 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[2][1] = -3989 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[2][2] = -403 * XV_CSC_SCALE_FACTOR / XV_CSC_DIVISOR;
+	csc->k_hw[0][3] = 16 * bpc_scale;
+	csc->k_hw[1][3] = 128 * bpc_scale;
+	csc->k_hw[2][3] = 128 * bpc_scale;
+	*clip_max = ((1 << csc->color_depth) - 1);
+}
+
+/**
+ * xcsc_set_coeff- Sets the coefficients
+ * @csc: Pointer to csc device structure
+ *
+ * This function set the coefficients
+ *
+ */
+static void xcsc_set_coeff(struct xilinx_csc *csc)
+{
+	xilinx_csc_write(csc->base, XV_CSC_INVIDEOFORMAT, csc->cft_in);
+	xilinx_csc_write(csc->base, XV_CSC_OUTVIDEOFORMAT, csc->cft_out);
+	xilinx_csc_write_coeff(csc);
+	xilinx_csc_write(csc->base, XV_CSC_CLIPMAX, csc->clip_max);
+	xilinx_csc_write(csc->base, XV_CSC_CLAMPMIN, XCSC_CLAMP_MIN_ZERO);
+}
+
+/**
+ * xilinx_csc_bridge_enable - enabes csc core
+ * @bridge: bridge instance
+ *
+ * This function enables the csc core
+ *
+ * Return: 0 on success.
+ *
+ */
+static int xilinx_csc_bridge_enable(struct xlnx_bridge *bridge)
+{
+	struct xilinx_csc *csc = bridge_to_layer(bridge);
+
+	xilinx_csc_write(csc->base, XV_CSC_AP_CTRL, XCSC_STREAM_ON);
+
+	return 0;
+}
+
+/**
+ * xilinx_csc_bridge_disable - disables csc core
+ * @bridge: bridge instance
+ *
+ * This function disables the csc core
+ */
+static void xilinx_csc_bridge_disable(struct xlnx_bridge *bridge)
+{
+	struct xilinx_csc *csc = bridge_to_layer(bridge);
+
+	xilinx_csc_write(csc->base, XV_CSC_AP_CTRL, XCSC_STREAM_OFF);
+	/* Reset the Global IP Reset through GPIO */
+	gpiod_set_value_cansleep(csc->rst_gpio, XCSC_RESET_ASSERT);
+	gpiod_set_value_cansleep(csc->rst_gpio, XCSC_RESET_DEASSERT);
+}
+
+/**
+ * xilinx_csc_bridge_set_input - Sets the input parameters of csc
+ * @bridge: bridge instance
+ * @width: width of video
+ * @height: height of video
+ * @bus_fmt: video bus format
+ *
+ * This function sets the input parameters of csc
+ * Return: 0 on success. -EINVAL for invalid parameters.
+ */
+static int xilinx_csc_bridge_set_input(struct xlnx_bridge *bridge, u32 width,
+				       u32 height, u32 bus_fmt)
+{
+	struct xilinx_csc *csc = bridge_to_layer(bridge);
+
+	xcsc_set_default_state(csc);
+
+	if (height > csc->max_height || height < XCSC_MIN_HEIGHT)
+		return -EINVAL;
+
+	if (width > csc->max_width || width < XCSC_MIN_WIDTH)
+		return -EINVAL;
+
+	csc->height = height;
+	csc->width = width;
+
+	switch (bus_fmt) {
+	case MEDIA_BUS_FMT_RGB888_1X24:
+		csc->cft_in = XVIDC_CSF_RGB;
+		break;
+	case MEDIA_BUS_FMT_VUY8_1X24:
+		csc->cft_in = XVIDC_CSF_YCRCB_444;
+		break;
+	case MEDIA_BUS_FMT_UYVY8_1X16:
+		csc->cft_in = XVIDC_CSF_YCRCB_422;
+		break;
+	case MEDIA_BUS_FMT_VYYUYY8_1X24:
+		csc->cft_in = XVIDC_CSF_YCRCB_420;
+		break;
+	default:
+		dev_dbg(csc->dev, "unsupported input video format\n");
+		return -EINVAL;
+	}
+
+	xilinx_csc_write(csc->base, XV_CSC_WIDTH, width);
+	xilinx_csc_write(csc->base, XV_CSC_HEIGHT, height);
+
+	return 0;
+}
+
+/**
+ * xilinx_csc_bridge_get_input_fmts - input formats supported by csc
+ * @bridge: bridge instance
+ * @fmts: Pointer to be updated with formats information
+ * @count: count of video bus formats
+ *
+ * This function provides the input video formats information csc
+ * Return: 0 on success.
+ */
+static int xilinx_csc_bridge_get_input_fmts(struct xlnx_bridge *bridge,
+					    const u32 **fmts, u32 *count)
+{
+	*fmts = xilinx_csc_video_fmts;
+	*count = ARRAY_SIZE(xilinx_csc_video_fmts);
+
+	return 0;
+}
+
+/**
+ * xilinx_csc_bridge_set_output - Sets the output parameters of csc
+ * @bridge: bridge instance
+ * @width: width of video
+ * @height: height of video
+ * @bus_fmt: video bus format
+ *
+ * This function sets the output parameters of csc
+ * Return: 0 on success. -EINVAL for invalid parameters.
+ */
+static int xilinx_csc_bridge_set_output(struct xlnx_bridge *bridge, u32 width,
+					u32 height, u32 bus_fmt)
+{
+	struct xilinx_csc *csc = bridge_to_layer(bridge);
+
+	if (width != csc->width || height != csc->height)
+		return -EINVAL;
+
+	switch (bus_fmt) {
+	case MEDIA_BUS_FMT_RGB888_1X24:
+		csc->cft_out = XVIDC_CSF_RGB;
+		dev_dbg(csc->dev, "Media Format Out : RGB");
+		if (csc->cft_in != MEDIA_BUS_FMT_RBG888_1X24)
+			xcsc_ycrcb_to_rgb(csc, &csc->clip_max);
+		break;
+	case MEDIA_BUS_FMT_VUY8_1X24:
+		csc->cft_out = XVIDC_CSF_YCRCB_444;
+		dev_dbg(csc->dev, "Media Format Out : YUV 444");
+		if (csc->cft_in == MEDIA_BUS_FMT_RBG888_1X24)
+			xcsc_rgb_to_ycrcb(csc, &csc->clip_max);
+		break;
+	case MEDIA_BUS_FMT_UYVY8_1X16:
+		csc->cft_out = XVIDC_CSF_YCRCB_422;
+		dev_dbg(csc->dev, "Media Format Out : YUV 422");
+		if (csc->cft_in == MEDIA_BUS_FMT_RBG888_1X24)
+			xcsc_rgb_to_ycrcb(csc, &csc->clip_max);
+		break;
+	case MEDIA_BUS_FMT_VYYUYY8_1X24:
+		csc->cft_out = XVIDC_CSF_YCRCB_420;
+		dev_dbg(csc->dev, "Media Format Out : YUV 420");
+		if (csc->cft_in == MEDIA_BUS_FMT_RBG888_1X24)
+			xcsc_rgb_to_ycrcb(csc, &csc->clip_max);
+		break;
+	default:
+		dev_info(csc->dev, "unsupported output video format\n");
+		return -EINVAL;
+	}
+	xcsc_set_coeff(csc);
+
+	return 0;
+}
+
+/**
+ * xilinx_csc_bridge_get_output_fmts - output formats supported by csc
+ * @bridge: bridge instance
+ * @fmts: Pointer to be updated with formats information
+ * @count: count of video bus formats
+ *
+ * This function provides the output video formats information csc
+ * Return: 0 on success.
+ */
+static int xilinx_csc_bridge_get_output_fmts(struct xlnx_bridge *bridge,
+					     const u32 **fmts, u32 *count)
+{
+	*fmts = xilinx_csc_video_fmts;
+	*count = ARRAY_SIZE(xilinx_csc_video_fmts);
+	return 0;
+}
+
+static int xcsc_parse_of(struct xilinx_csc *csc)
+{
+	int ret;
+	struct device_node *node = csc->dev->of_node;
+
+	csc->aclk = devm_clk_get(csc->dev, NULL);
+	if (IS_ERR(csc->aclk)) {
+		ret = PTR_ERR(csc->aclk);
+		dev_err(csc->dev, "failed to get aclk %d\n", ret);
+		return ret;
+	}
+
+	ret = of_property_read_u32(node, "xlnx,video-width",
+				   &csc->color_depth);
+	if (ret < 0) {
+		dev_info(csc->dev, "video width not present in DT\n");
+		return ret;
+	}
+	if (csc->color_depth != 8 && csc->color_depth != 10 &&
+	    csc->color_depth != 12 && csc->color_depth != 16) {
+		dev_err(csc->dev, "Invalid video width in DT\n");
+		return -EINVAL;
+	}
+	/* Reset GPIO */
+	csc->rst_gpio = devm_gpiod_get(csc->dev, "reset", GPIOD_OUT_HIGH);
+	if (IS_ERR(csc->rst_gpio)) {
+		if (PTR_ERR(csc->rst_gpio) != -EPROBE_DEFER)
+			dev_err(csc->dev, "Reset GPIO not setup in DT");
+		return PTR_ERR(csc->rst_gpio);
+	}
+
+	ret = of_property_read_u32(node, "xlnx,max-height", &csc->max_height);
+	if (ret < 0) {
+		dev_err(csc->dev, "xlnx,max-height is missing!");
+		return -EINVAL;
+	} else if (csc->max_height > XCSC_MAX_HEIGHT ||
+		   csc->max_height < XCSC_MIN_HEIGHT) {
+		dev_err(csc->dev, "Invalid height in dt");
+		return -EINVAL;
+	}
+
+	ret = of_property_read_u32(node, "xlnx,max-width", &csc->max_width);
+	if (ret < 0) {
+		dev_err(csc->dev, "xlnx,max-width is missing!");
+		return -EINVAL;
+	} else if (csc->max_width > XCSC_MAX_WIDTH ||
+		   csc->max_width < XCSC_MIN_WIDTH) {
+		dev_err(csc->dev, "Invalid width in dt");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int xilinx_csc_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct xilinx_csc *csc;
+	int ret;
+
+	csc = devm_kzalloc(dev, sizeof(*csc), GFP_KERNEL);
+	if (!csc)
+		return -ENOMEM;
+
+	csc->dev = dev;
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	csc->base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(csc->base))
+		return -ENOMEM;
+
+	platform_set_drvdata(pdev, csc);
+	ret = xcsc_parse_of(csc);
+	if (ret < 0)
+		return ret;
+
+	ret = clk_prepare_enable(csc->aclk);
+	if (ret) {
+		dev_err(csc->dev, "failed to enable clock %d\n", ret);
+		return ret;
+	}
+
+	gpiod_set_value_cansleep(csc->rst_gpio, XCSC_RESET_DEASSERT);
+	csc->bridge.enable = &xilinx_csc_bridge_enable;
+	csc->bridge.disable = &xilinx_csc_bridge_disable;
+	csc->bridge.set_input = &xilinx_csc_bridge_set_input;
+	csc->bridge.get_input_fmts = &xilinx_csc_bridge_get_input_fmts;
+	csc->bridge.set_output = &xilinx_csc_bridge_set_output;
+	csc->bridge.get_output_fmts = &xilinx_csc_bridge_get_output_fmts;
+	csc->bridge.of_node = dev->of_node;
+
+	ret = xlnx_bridge_register(&csc->bridge);
+	if (ret) {
+		dev_info(csc->dev, "Bridge registration failed\n");
+		goto err_clk;
+	}
+
+	dev_info(csc->dev, "Xilinx VPSS CSC DRM experimental driver probed\n");
+
+	return 0;
+
+err_clk:
+	clk_disable_unprepare(csc->aclk);
+	return ret;
+}
+
+static void xilinx_csc_remove(struct platform_device *pdev)
+{
+	struct xilinx_csc *csc = platform_get_drvdata(pdev);
+
+	xlnx_bridge_unregister(&csc->bridge);
+	clk_disable_unprepare(csc->aclk);
+}
+
+static const struct of_device_id xilinx_csc_of_match[] = {
+	{ .compatible = "xlnx,vpss-csc"},
+	{ }
+};
+MODULE_DEVICE_TABLE(of, xilinx_csc_of_match);
+
+static struct platform_driver csc_bridge_driver = {
+	.probe = xilinx_csc_probe,
+	.remove = xilinx_csc_remove,
+	.driver = {
+		.name = "xlnx,csc-bridge",
+		.of_match_table = xilinx_csc_of_match,
+	},
+};
+
+module_platform_driver(csc_bridge_driver);
+
+MODULE_AUTHOR("Venkateshwar Rao <vgannava@xilinx.com>");
+MODULE_DESCRIPTION("Xilinx FPGA CSC Bridge Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/xlnx_dptx.c b/drivers/gpu/drm/xlnx/xlnx_dptx.c
new file mode 100644
index 000000000..5824c5c78
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_dptx.c
@@ -0,0 +1,4085 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx FPGA DisplayPort TX Subsystem Driver
+ *
+ *  Copyright (C) 2020 Xilinx, Inc.
+ *
+ * Author: Rajesh Gugulothu <gugulothu.rajesh@xilinx.com>
+ *	 : Venkateshwar Rao G <vgannava.xilinx.com>
+ *
+ */
+#include <linux/bitfield.h>
+#include <linux/clk.h>
+#include <linux/component.h>
+#include <linux/delay.h>
+#include <linux/device.h>
+#include <linux/gpio/consumer.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_device.h>
+#include <linux/of_platform.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/phy/phy.h>
+#include <linux/phy/phy-dp.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <media/hdr-ctrls.h>
+#include <uapi/linux/videodev2.h>
+
+#include <drm/drm_atomic_helper.h>
+#include <drm/drm_connector.h>
+#include <drm/drm_framebuffer.h>
+#include <drm/drm_crtc.h>
+#include <drm/drm_crtc_helper.h>
+#include <drm/drm_eld.h>
+#include <drm/display/drm_dp_helper.h>
+#include <drm/display/drm_hdmi_helper.h>
+#include <drm/drm_edid.h>
+#include <drm/drm_fourcc.h>
+#include <drm/drm_of.h>
+#include <drm/drm_probe_helper.h>
+
+#include <linux/hdmi.h>
+#include <sound/soc.h>
+#include <sound/pcm_drm_eld.h>
+
+#include <linux/mfd/syscon.h>
+#include "hdcp/xlnx_hdcp_tx.h"
+
+#define XDPTX_HDCP			0
+#define XDPTX_HDCP2X_OFFSET		0x4000
+#define XDPTX_HDCP_TIMER_OFFSET		0x6000
+#define XDPTX_HDCP1X_OFFSET		0x2000
+#define XDP_TX_HDCP1X_ENABLE		0x400
+#define XDP_TX_HDCP1X_ENABLE_BYPASS_DISABLE_MASK 0x0001
+/* Link configuration registers */
+#define XDPTX_LINKBW_SET_REG			0x0
+#define XDPTX_LANECNT_SET_REG			0x4
+#define XDPTX_DPCD_LANECNT_SET_MASK		GENMASK(4, 0)
+#define XDPTX_EFRAME_EN_REG			0x8
+#define XDPTX_TRNGPAT_SET_REG			0xc
+#define XDPTX_SCRAMBLING_DIS_REG		0x14
+#define XDPTX_DOWNSPREAD_CTL_REG		0x18
+#define XDPTX_DPCD_SPREAD_AMP_MASK		BIT(4)
+#define XDPTX_SOFT_RST				0x1c
+#define XDPTX_SOFT_RST_VIDEO_STREAM_ALL_MASK	GENMASK(3, 0)
+#define XDPTX_SOFT_RST_HDCP_MASK		BIT(8)
+
+/* GtCtrl Registers */
+#define XDPTX_GTCTL_REG				0x4c
+#define XDPTX_GTCTL_VSWING_MASK			GENMASK(12, 8)
+#define XDPTX_GTCTL_POST_CUR_MASK		GENMASK(22, 18)
+#define XDPTX_GTCTL_LINE_RATE_MASK		GENMASK(2, 1)
+#define XDPTX_GTCTL_LINE_RATE_810G		0x03
+#define XDPTX_GTCTL_LINE_RATE_540G		0x02
+#define XDPTX_GTCTL_LINE_RATE_270G		0x01
+#define XDPTX_GTCTL_LINE_RATE_162G		0x00
+
+/* GTHE4 */
+#define XVPHY_GTHE4_DIFF_SWING_DP_V0P0		0x01
+#define XVPHY_GTHE4_DIFF_SWING_DP_V0P1		0x02
+#define XVPHY_GTHE4_DIFF_SWING_DP_V0P2		0x05
+#define XVPHY_GTHE4_DIFF_SWING_DP_V0P3		0x0b
+#define XVPHY_GTHE4_DIFF_SWING_DP_V1P0		0x02
+#define XVPHY_GTHE4_DIFF_SWING_DP_V1P1		0x05
+#define XVPHY_GTHE4_DIFF_SWING_DP_V1P2		0x07
+#define XVPHY_GTHE4_DIFF_SWING_DP_V2P0		0x04
+#define XVPHY_GTHE4_DIFF_SWING_DP_V2P1		0x07
+#define XVPHY_GTHE4_DIFF_SWING_DP_V3P0		0x08
+#define XVPHY_GTHE4_PREEMP_DP_L0		0x03
+#define XVPHY_GTHE4_PREEMP_DP_L1		0x0d
+#define XVPHY_GTHE4_PREEMP_DP_L2		0x16
+#define XVPHY_GTHE4_PREEMP_DP_L3		0x1d
+
+/* DPTX Core enable registers */
+#define XDPTX_ENABLE_REG			0x80
+#define XDPTX_MAINSTRM_ENABLE_REG		0x84
+#define XDPTX_SCRAMBLER_RESET			0xc0
+#define XDPTX_SCRAMBLER_RESET_MASK		BIT(0)
+#define XDPTX_MST_CONFIG			0xd0
+
+/* AUX channel interface registers */
+#define XDPTX_AUXCMD_REG			0x100
+#define XDPTX_AUX_WRITEFIFO_REG			0x104
+#define XDPTX_AUX_ADDR_REG			0x108
+#define XDPTX_AUXCMD_ADDRONLY_MASK		BIT(12)
+#define XDPTX_AUXCMD_SHIFT			0x8
+#define XDPTX_AUXCMD_BYTES_SHIFT		0x0
+#define XDPTX_AUX_READ_BIT				0x1
+
+#define XDPTX_CLKDIV_REG			0x10c
+#define XDPTX_CLKDIV_MHZ			1000000
+#define XDPTX_CLKDIV_AUXFILTER_SHIFT		0x8
+
+#define XDPTX_INTR_SIGSTATE_REG			0x130
+#define XDPTX_INTR_SIGHPDSTATE			BIT(0)
+#define XDPTX_INTR_SIGREQSTATE			BIT(1)
+#define XDPTX_INTR_SIGRPLYSTATE			BIT(2)
+#define XDPTX_INTR_RPLYTIMEOUT			BIT(3)
+
+#define XDPTX_AUXREPLY_DATA_REG			0x134
+#define XDPTX_AUXREPLY_CODE_REG			0x138
+#define XDPTX_AUXREPLYCODE_AUXACK_MASK		(0)
+#define XDPTX_AUXREPLYCODE_I2CACK_MASK		(0)
+
+#define XDPTX_AUXREPLY_DATACNT_REG		0x148
+#define XDPTX_AUXREPLY_DATACNT_MASK		GENMASK(7, 0)
+#define XDPTX_INTR_STATUS_REG			0x140
+#define XDPTX_INTR_MASK_REG			0x144
+#define XDPTX_INTR_HPDEVENT_MASK		BIT(1)
+#define XDPTX_INTR_HPDPULSE_MASK		BIT(4)
+#define XDPTX_INTR_CHBUFUNDFW_MASK		GENMASK(21, 16)
+#define XDPTX_INTR_CHBUFOVFW_MASK		GENMASK(27, 22)
+#define XDPTX_INTR_VBLANK_MASK			BIT(10)
+#define XDPTX_INTR_EXTPKT_TXD_MASK		BIT(5)
+#define XDPTX_HPD_DURATION_REG			0x150
+
+/* Main stream attribute registers */
+#define XDPTX_MAINSTRM_HTOTAL_REG		0x180
+#define XDPTX_MAINSTRM_VTOTAL_REG		0x184
+#define XDPTX_MAINSTRM_POL_REG			0x188
+#define XDPTX_MAINSTRM_POLHSYNC_SHIFT		0x0
+#define XDPTX_MAINSTRM_POLVSYNC_SHIFT		0x1
+#define XDPTX_MAINSTRM_HSWIDTH_REG		0x18c
+#define XDPTX_MAINSTRM_VSWIDTH_REG		0x190
+#define XDPTX_MAINSTRM_HRES_REG			0x194
+#define XDPTX_MAINSTRM_VRES_REG			0x198
+#define XDPTX_MAINSTRM_HSTART_REG		0x19c
+#define XDPTX_MAINSTRM_VSTART_REG		0x1a0
+#define XDPTX_MAINSTRM_MISC0_REG		0x1a4
+#define XDPTX_MAINSTRM_MISC0_MASK		BIT(0)
+#define XDPTX_MAINSTRM_MISC0_EXT_VSYNC_MASK	BIT(12)
+#define XDPTX_MAINSTRM_MISC1_REG		0x1a8
+#define XDPTX_MAINSTRM_MISC1_TIMING_IGNORED_MASK BIT(6)
+
+#define XDPTX_M_VID_REG				0x1ac
+#define XDPTX_TRANSFER_UNITSIZE_REG		0x1b0
+#define XDPTX_DEF_TRANSFER_UNITSIZE		0x40
+#define XDPTX_N_VID_REG				0x1b4
+#define XDPTX_USER_PIXELWIDTH_REG		0x1b8
+#define XDPTX_USER_DATACNTPERLANE_REG		0x1bc
+#define XDPTX_MINBYTES_PERTU_REG		0x1c4
+#define XDPTX_FRACBYTES_PERTU_REG		0x1c8
+#define XDPTX_INIT_WAIT_REG			0x1cc
+
+/* PHY configuration and status registers */
+#define XDPTX_PHYCONFIG_REG			0x200
+#define XDPTX_PHYCONFIG_RESET_MASK		BIT(0)
+#define XDPTX_PHYCONFIG_GTTXRESET_MASK		BIT(1)
+#define XDPTX_PHYCONFIG_PMARESET_MASK		BIT(8)
+#define XDPTX_PHYCONFIG_PCSRESET_MASK		BIT(9)
+#define XDPTX_PHYCONFIG_ALLRESET_MASK	(XDPTX_PHYCONFIG_RESET_MASK | \
+					 XDPTX_PHYCONFIG_GTTXRESET_MASK | \
+					 XDPTX_PHYCONFIG_PMARESET_MASK | \
+					 XDPTX_PHYCONFIG_PCSRESET_MASK)
+
+#define XDPTX_PHYCLOCK_FBSETTING_REG		0x234
+#define XDPTX_PHYCLOCK_FBSETTING162_MASK	0x1
+#define XDPTX_PHYCLOCK_FBSETTING270_MASK	0x3
+#define XDPTX_PHYCLOCK_FBSETTING810_MASK	0x5
+
+#define XDPTX_VS_PE_LEVEL_MAXCOUNT		3
+#define XDPTX_VS_LEVEL_MAXCOUNT			0x5
+
+#define XDPTX_PHYSTATUS_REG			0x280
+#define XDPTX_PHYSTATUS_FPGAPLLLOCK_MASK	BIT(6)
+#define XDPTX_MAX_RATE(bw, lanecnt, bpp)	((bw) * (lanecnt) * 8 / (bpp))
+
+#define XDPTX_MISC0_RGB_MASK			(0)
+#define XDPTX_MISC0_YCRCB422_MASK		(5 << 1)
+#define XDPTX_MISC0_YCRCB444_MASK		GENMASK(3, 2)
+#define XDPTX_MISC0_FORMAT_MASK			GENMASK(3, 1)
+#define XDPTX_MISC0_BPC6_MASK			(0 << 5)
+#define XDPTX_MISC0_BPC8_MASK			BIT(5)
+#define XDPTX_MISC0_BPC10_MASK			BIT(6)
+#define XDPTX_MISC0_BPC12_MASK			GENMASK(6, 5)
+#define XDPTX_MISC0_BPC16_MASK			BIT(7)
+#define XDPTX_MISC0_BPC_MASK			GENMASK(7, 5)
+#define XDPTX_MISC1_YONLY_MASK			BIT(7)
+
+#define XDPTX_MAX_LANES				0x4
+#define XDPTX_MAX_FREQ				3000000
+#define XDPTX_SINK_PWR_CYCLES			3
+
+#define XDPTX_REDUCED_BIT_RATE			162000
+#define XDPTX_HIGH_BIT_RATE_1			270000
+#define XDPTX_HIGH_BIT_RATE_2			540000
+#define XDPTX_HIGH_BIT_RATE_3			810000
+
+#define XDPTX_V1_2				0x12
+#define XDPTX_V1_4				0x14
+
+#define XDP_TRAIN_MAX_SWING_REACHED			BIT(2)
+#define XDP_TRAIN_PRE_EMPHASIS_SHIFT			GENMASK(1, 0)
+#define XDP_DPCD_TRAINING_LANEX_SET_MAX_PE_MASK		BIT(5)
+
+#define XDPTX_PHYPRECURSOR_LANE0_REG			0x23c
+#define XDPTX_PHYPOSTCURSOR_LANE0_REG			0x24c
+
+/* Transceiver PHY reset and Differential voltage swing */
+#define XDPTX_PHYVOLTAGE_DIFFLANE0_REG			0x220
+#define XDPTX_VS_LEVEL_OFFSET				0x4
+
+#define XDPTX_VTC_BASE					0x1000
+
+/* VTC register offsets and bit masks */
+#define XDPTX_VTC_CTL					0x000
+#define XDPTX_VTC_CTL_MASK				GENMASK(18, 8)
+#define XDPTX_VTC_CTL_GE				BIT(2)
+#define XDPTX_VTC_CTL_RU				BIT(1)
+
+#define XDPTX_VTC_GASIZE_F0				0x060
+#define XDPTX_VTC_ACTIVE_SIZE_MASK			GENMASK(12, 0)
+
+#define XDPTX_VTC_GFENC					0x068
+#define XDPTX_VTC_GFENC_MASK				BIT(6)
+
+#define XDPTX_VTC_GPOL					0x06c
+#define XDPTX_VTC_GPOL_FIELD_ID_POL			BIT(6)
+#define XDPTX_VTC_ACTIVE_CHROMA_POL			BIT(5)
+#define	XDPTX_VTC_ACTIVE_VIDEO_POL			BIT(4)
+#define XDPTX_VTC_HSYNC_POL				BIT(3)
+#define XDPTX_VTC_VSYNC_POL				BIT(2)
+#define XDPTX_VTC_HBLANK_POL				BIT(1)
+#define XDPTX_VTC_VBLANK_POL				BIT(0)
+#define XDPTX_VTC_GPOL_MASK		(XDPTX_VTC_VBLANK_POL |\
+					 XDPTX_VTC_HBLANK_POL |\
+					 XDPTX_VTC_VSYNC_POL |\
+					 XDPTX_VTC_HSYNC_POL |\
+					 XDPTX_VTC_ACTIVE_VIDEO_POL |\
+					 XDPTX_VTC_ACTIVE_CHROMA_POL)
+
+#define XDPTX_VTC_INT_GPOL_MASK		(XDPTX_VTC_GPOL_FIELD_ID_POL |\
+					 XDPTX_VTC_ACTIVE_CHROMA_POL |\
+					 XDPTX_VTC_ACTIVE_VIDEO_POL)
+
+#define XDPTX_VTC_GHSIZE				0x070
+#define XDPTX_VTC_GHSIZE_FRAME_HSIZE			GENMASK(12, 0)
+
+#define XDPTX_VTC_GVSIZE				0x074
+#define XDPTX_VTC_FIELD1_VSIZE_SHIFT			16
+#define XDPTX_VTC_GVSIZE_FRAME_VSIZE			GENMASK(12, 0)
+
+#define XDPTX_VTC_GHSYNC				0x078
+#define XDPTX_VTC_GH1BPSTART_SHIFT			16
+#define XDPTX_VTC_GHSYNC_END_MASK			GENMASK(28, 16)
+#define XDPTX_VTC_GHSYNC_START_MASK			GENMASK(12, 0)
+
+#define XDPTX_VTC_GVBHOFF				0x07c
+#define XDPTX_VTC_F0VSYNC_HEND_SHIFT			16
+#define XDPTX_VTC_F0VBLANK_HEND_MASK			GENMASK(28, 16)
+#define XDPTX_VTC_F0VBLANK_HSTART_MASK			GENMASK(12, 0)
+
+#define XDPTX_VTC_GVSYNC				0x080
+#define XDPTX_VTC_F0_VSYNC_VEND_MASK			GENMASK(28, 16)
+#define XDPTX_VTC_F0_VSYNC_VSTART_MASK			GENMASK(12, 0)
+
+#define XDPTX_VTC_GVSHOFF				0x084
+#define XDPTX_VTC_GVBHOFF_F1				0x088
+#define XDPTX_VTC_GVSYNC_F1				0x08c
+#define XDPTX_VTC_GVSHOFF_F1				0x090
+#define XDPTX_VTC_GASIZE_F1				0x094
+/*
+ * This is sleep time in milliseconds before start training and it can be
+ * modified as per the monitor
+ */
+#define XDPTX_POWERON_DELAY_MS				4
+#define XDPTX_AUDIO_CTRL_REG				0x300
+#define XDPTX_AUDIO_EN_MASK				BIT(0)
+#define XDPTX_AUDIO_MUTE_MASK				BIT(16)
+#define XDPTX_AUDIO_CHANNELS_REG			0x304
+#define XDPTX_AUDIO_INFO_DATA_REG			0x308
+#define XDPTX_AUDIO_MAUD_REG				0x328
+#define XDPTX_AUDIO_NAUD_REG				0x32C
+#define XDP_TX_HDCP2x_ENABLE				0x404
+#define XDP_TX_HDCP2x_ENABLE_BYPASS_DISABLE_MASK	BIT(0)
+#define XDPTX_AUDIO_INFO_BUFF_STATUS			0x6A0
+#define XDPTX_AUDIO_INFO_BUFF_FULL			BIT(0)
+#define XDPTX_AUDIO_INFO_BUFF_OVERFLOW			BIT(1)
+
+#define DP_INFOFRAME_FIFO_SIZE_WORDS	8
+#define DP_INFOFRAME_FIFO_SIZE		(DP_INFOFRAME_FIFO_SIZE_WORDS * 4)
+#define DP_INFOFRAME_HEADER_SIZE	4
+#define DP_AUDIO_INFOFRAME_SIZE		10
+/* infoframe SDP header byte. Please refer section 2.2.5.1.2 in DP1.4 spec */
+#define NON_AUDIOIF_PKT_ID		0x00
+#define NON_AUDIOIF_TYPE		0x07
+#define NON_AUDIOIF_LDATA_BYTECOUNT	0x1d
+#define NON_AUDIOIF_SDP_VERSION		0x4c
+#define NON_AUDIOIF_DRM_TYPE		(0x80 + NON_AUDIOIF_TYPE)
+/* DRM infoframe. Please refer section 6.9 in CTA-861G */
+#define CTA_DRMIF_VERSION_NUMBER	0x01
+#define CTA_DRMIF_LENGHT		0x1a
+
+#define DP_INFOFRAME_SIZE(type)	\
+	(DP_INFOFRAME_HEADER_SIZE + DP_ ## type ## _INFOFRAME_SIZE)
+#define XDPTX_AUDIO_EXT_DATA(NUM)	(0x330 + 4 * ((NUM) - 1))
+#define XDPTX_AUDIO_EXT_DATA_2ND_TO_9TH_WORD		8
+#define XDPTX_VSC_SDP_PIXELENC_HEADER_MASK		0x13050700
+#define XDPTX_VSC_SDP_DYNAMIC_RANGE_SHIFT		15
+#define XDPTX_VSC_SDP_BPC_SHIFT				8
+#define XDPTX_VSC_SDP_BPC_MASK				GENMASK(2, 0)
+#define XDPTX_VSC_SDP_FMT_SHIFT				4
+
+#define DP_LINK_BW_SET_MASK			GENMASK(4, 0)
+#define DP_MAX_TRAINING_TRIES				5
+
+#define XDPTX_DP_LANE_COUNT_1				0x01
+#define XDPTX_DP_LANE_COUNT_2				0x02
+#define XDPTX_DP_LANE_COUNT_4				0x04
+
+#define XDPTX_DPCD_LANE02_CRDONE_MASK			0x01
+#define XDPTX_DPCD_LANE13_CRDONE_MASK			0x10
+
+#define XDPTX_LANE0_CRDONE_MASK				0x0
+#define XDPTX_LANE1_CRDONE_MASK				0x1
+#define XDPTX_LANE2_CRDONE_MASK				0x2
+#define XDPTX_LANE3_CRDONE_MASK				0x3
+
+#define XDPTX_HDCP_DPCD_READ				0x00
+#define XDPTX_HDCP_DPCD_WRITE				BIT(0)
+#define XDPTX_HDCP_STATUS				BIT(1)
+
+#define I2S_FORMATS	(SNDRV_PCM_FMTBIT_S16_LE | SNDRV_PCM_FMTBIT_S16_BE |\
+			 SNDRV_PCM_FMTBIT_S20_3LE | SNDRV_PCM_FMTBIT_S20_3BE |\
+			 SNDRV_PCM_FMTBIT_S24_3LE | SNDRV_PCM_FMTBIT_S24_3BE |\
+			 SNDRV_PCM_FMTBIT_S24_LE | SNDRV_PCM_FMTBIT_S24_BE |\
+			 SNDRV_PCM_FMTBIT_S32_LE | SNDRV_PCM_FMTBIT_S32_BE |\
+			 SNDRV_PCM_FMTBIT_IEC958_SUBFRAME_LE)
+#define DP_RATES	(SNDRV_PCM_RATE_32000 | SNDRV_PCM_RATE_44100 |\
+			 SNDRV_PCM_RATE_48000 | SNDRV_PCM_RATE_88200 |\
+			 SNDRV_PCM_RATE_96000 | SNDRV_PCM_RATE_176400 |\
+			 SNDRV_PCM_RATE_192000)
+
+/* Flag to get VTC offset from device tree */
+#define XDPTX_VTC_OFFSET_CHANGE		BIT(0)
+
+/*
+ * CEA speaker placement
+ *
+ *  FL  FLC   FC   FRC   FR   FRW
+ *
+ *                                  LFE
+ *
+ *  RL  RLC   RC   RRC   RR
+ */
+enum dp_codec_cea_spk_placement {
+	FL  = BIT(0),	/* Front Left           */
+	FC  = BIT(1),	/* Front Center         */
+	FR  = BIT(2),	/* Front Right          */
+	FLC = BIT(3),	/* Front Left Center    */
+	FRC = BIT(4),	/* Front Right Center   */
+	RL  = BIT(5),	/* Rear Left            */
+	RC  = BIT(6),	/* Rear Center          */
+	RR  = BIT(7),	/* Rear Right           */
+	RLC = BIT(8),	/* Rear Left Center     */
+	RRC = BIT(9),	/* Rear Right Center    */
+	LFE = BIT(10),	/* Low Frequency Effect */
+};
+
+/*
+ * cea Speaker allocation structure
+ */
+struct dp_codec_cea_spk_alloc {
+	const int ca_id;
+	unsigned int n_ch;
+	unsigned long mask;
+};
+
+/**
+ * struct xlnx_dptx_audio_data - Audio data structure
+ * @buffer: Audio infoframe data buffer
+ */
+struct xlnx_dptx_audio_data {
+	u32 buffer[DP_INFOFRAME_FIFO_SIZE_WORDS];
+};
+
+union xlnx_dp_iframe_header {
+	u32 data;
+	u8 byte[4];
+};
+
+union xlnx_dp_iframe_payload {
+	u32 data[8];
+	u8 byte[32];
+};
+
+struct xlnx_dp_infoframe {
+	union xlnx_dp_iframe_header header;
+	union xlnx_dp_iframe_payload payload;
+};
+
+/**
+ * struct xlnx_dp_vscpkt: VSC extended packet structure
+ * @payload: VSC packet payload bytes from DB0 to DB28
+ * @header: VSC packet header
+ * @bpc: Number of bits per color component
+ * @fmt: The color format currenctly in use by the video stream
+ * @dynamic_range: The dynamic range colorimetry currenctly in use by te video stream
+ * @ycbcr_colorimetry: The ycbcr colorimetry currently in use by te video stream
+ */
+struct xlnx_dp_vscpkt {
+	u32 payload[8];
+	u32 header;
+	u32 bpc;
+	u8 fmt;
+	u8 dynamic_range;
+	u8 ycbcr_colorimetry;
+};
+
+/*
+ * struct xlnx_dp_link_config - Common link config between source and sink
+ * @max_rate: Miaximum link rate
+ * @max_lanes: Maximum number of lanes
+ */
+struct xlnx_dp_link_config {
+	int max_rate;
+	u8 max_lanes;
+	int link_rate;
+	u8 lane_count;
+	u8 cr_done_cnt;
+	u8 cr_done_oldstate;
+};
+
+/**
+ * struct xlnx_dp_tx_link_config - configuration information of the source
+ * @vs_level: voltage swing level
+ * @pe_level: pre emphasis level
+ */
+struct xlnx_dp_tx_link_config {
+	u8 vs_level;
+	u8 pe_level;
+};
+
+/**
+ * struct xlnx_dp_mode - Configured mode of DisplayPort
+ * @pclock: pixel clock frequency of current mode
+ * @bw_code: code for bandwidth(link rate)
+ * @lane_cnt: number of lanes
+ */
+struct xlnx_dp_mode {
+	int pclock;
+	u8 bw_code;
+	u8 lane_cnt;
+};
+
+/**
+ * struct xlnx_dp_config - Configuration of DisplayPort from DTS
+ * @max_lanes: Maximum number of lanes
+ * @max_link_rate: Maximum supported link rate
+ * @misc0: Misc0 configuration
+ * @bpp: Bits per pixel
+ * @bpc: Bits per component
+ * @num_colors: Number of color components
+ * @ppc: Pixels per component
+ * @fmt: Color format
+ * @audio_enabled: flag to indicate audio is enabled in device tree
+ * @versal_gt_present: flag to indicate versal-gt property in device tree
+ * @hdcp2x_enable: flag to indicate hdcp22-enable property in device tree
+ * @hdcp1x_enable: flag to indicate hdcp-enable property in device tree
+ */
+struct xlnx_dp_config {
+	u32 max_lanes;
+	u32 max_link_rate;
+	u8 misc0;
+	u8 bpp;
+	u8 bpc;
+	u8 num_colors;
+	u8 ppc;
+	u8 fmt;
+	bool audio_enabled;
+	bool versal_gt_present;
+	bool hdcp2x_enable;
+	bool hdcp1x_enable;
+};
+
+enum xlnx_dp_train_state {
+	XLNX_DP_TRAIN_CR = 0,
+	XLNX_DP_TRAIN_CE = 1,
+	XLNX_DP_ADJUST_LINKRATE = 2,
+	XLNX_DP_ADJUST_LANECOUNT = 3,
+	XLNX_DP_TRAIN_FAILURE = 4,
+	XLNX_DP_TRAIN_SUCCESS = 5
+};
+
+/**
+ * struct xlnx_dp - Xilinx DisplayPort core
+ * @dev: device structure
+ * @encoder: the drm encoder structure
+ * @connector: the drm connector structure
+ * @sync_prop: synchronous mode property
+ * @bpc_prop: bpc mode property
+ * @aux: aux channel
+ * @config: IP core configuration from DTS
+ * @tx_link_config: source configuration
+ * @tx_hdcp: HDCP configuration
+ * @hdcpx_keymgmt_base: HDCP key management base address
+ * @link_config: common link configuration between IP core and sink device
+ * @drm: DRM core
+ * @mode: current mode between IP core and sink device
+ * @phy: PHY handles for DP lanes
+ * @axi_lite_clk: axi lite clock
+ * @tx_vid_clk: tx video clock
+ * @reset_gpio: reset gpio
+ * @hpd_work: hot plug detection worker
+ * @hpd_pulse_work: hot plug pulse detection worker
+ * @hdcp_cp_irq_work: HDCP content protection message indication worker
+ * @tx_audio_data: audio data
+ * @infoframe : IP infoframe data
+ * @vscpkt: VSC extended packet data
+ * @cfg: Pointer to DP Feature config struct
+ * @phy_opts: Opaque generic phy configuration
+ * @status: connection status
+ * @dp_base: Base address of DisplayPort Tx subsystem
+ * @dpms: current dpms state
+ * @hdcptx_timer_irq: HDCP TX timer interrupt
+ * @vtc_off: VTC sub-core offset address
+ * @dpcd: DP configuration data from currently connected sink device
+ * @train_set: set of training data
+ * @num_lanes: number of enabled phy lanes
+ * @enabled: flag to indicate if the device is enabled
+ * @audio_init: flag to indicate audio is initialized
+ * @have_edid: flag to indicate if edid is available
+ * @colorimetry_through_vsc: colorimetry information through vsc packets
+ *
+ */
+struct xlnx_dp {
+	struct device *dev;
+	struct drm_encoder encoder;
+	struct drm_connector connector;
+	struct drm_property *sync_prop;
+	struct drm_property *bpc_prop;
+	struct drm_dp_aux aux;
+	struct xlnx_dp_config config;
+	struct xlnx_dp_tx_link_config tx_link_config;
+	struct xlnx_hdcptx tx_hdcp;
+	struct regmap *hdcpx_keymgmt_base;
+	struct xlnx_dp_link_config link_config;
+	struct drm_device *drm;
+	struct xlnx_dp_mode mode;
+	struct phy *phy[XDPTX_MAX_LANES];
+	struct clk *axi_lite_clk;
+	struct clk *tx_vid_clk;
+	struct gpio_desc *reset_gpio;
+	struct delayed_work hpd_work;
+	struct delayed_work hpd_pulse_work;
+	struct delayed_work hdcp_cp_irq_work;
+	struct xlnx_dptx_audio_data *tx_audio_data;
+	struct xlnx_dp_infoframe infoframe;
+	struct xlnx_dp_vscpkt vscpkt;
+	const struct xlnx_dp_feature *cfg;
+	union phy_configure_opts phy_opts;
+	enum drm_connector_status status;
+	void __iomem *dp_base;
+	int dpms;
+	int hdcptx_timer_irq;
+	u32 vtc_off;
+	u8 dpcd[DP_RECEIVER_CAP_SIZE];
+	u8 train_set[XDPTX_MAX_LANES];
+	u8 num_lanes;
+	unsigned int enabled : 1;
+	bool audio_init;
+	bool have_edid;
+	unsigned int colorimetry_through_vsc : 1;
+};
+
+/**
+ * struct xlnx_dp_feature - dt or IP property structure
+ * @flags: Bitmask of properties enabled in IP or dt
+ */
+struct xlnx_dp_feature {
+	u32 flags;
+};
+
+static const struct xlnx_dp_feature xlnx_dp_cfg_v31 = {
+	.flags = XDPTX_VTC_OFFSET_CHANGE,
+};
+
+static const struct xlnx_dp_feature xlnx_dp_cfg_v30 = {
+	.flags = 0,
+};
+
+static const struct of_device_id xlnx_dp_of_match[] = {
+	{ .compatible = "xlnx,v-dp-txss-3.0",
+		.data = (void *)&xlnx_dp_cfg_v30},
+	{ .compatible = "xlnx,v-dp-txss-3.1",
+		.data = (void *)&xlnx_dp_cfg_v31},
+	{ /* end of table */ }
+};
+
+/*
+ * dp_codec_channel_alloc: speaker configuration available for CEA
+ *
+ * This is an ordered list that must match with dp_codec_8ch_chmaps struct
+ * The preceding ones have better chances to be selected by
+ * dp_codec_get_ch_alloc_table_idx().
+ */
+static const struct dp_codec_cea_spk_alloc dp_codec_channel_alloc[] = {
+	{ .ca_id = 0x00, .n_ch = 2,
+	  .mask = FL | FR},
+	/* 2.1 */
+	{ .ca_id = 0x01, .n_ch = 4,
+	  .mask = FL | FR | LFE},
+	/* Dolby Surround */
+	{ .ca_id = 0x02, .n_ch = 4,
+	  .mask = FL | FR | FC },
+	/* surround51 */
+	{ .ca_id = 0x0b, .n_ch = 6,
+	  .mask = FL | FR | LFE | FC | RL | RR},
+	/* surround40 */
+	{ .ca_id = 0x08, .n_ch = 6,
+	  .mask = FL | FR | RL | RR },
+	/* surround41 */
+	{ .ca_id = 0x09, .n_ch = 6,
+	  .mask = FL | FR | LFE | RL | RR },
+	/* surround50 */
+	{ .ca_id = 0x0a, .n_ch = 6,
+	  .mask = FL | FR | FC | RL | RR },
+	/* 6.1 */
+	{ .ca_id = 0x0f, .n_ch = 8,
+	  .mask = FL | FR | LFE | FC | RL | RR | RC },
+	/* surround71 */
+	{ .ca_id = 0x13, .n_ch = 8,
+	  .mask = FL | FR | LFE | FC | RL | RR | RLC | RRC },
+	/* others */
+	{ .ca_id = 0x03, .n_ch = 8,
+	  .mask = FL | FR | LFE | FC },
+	{ .ca_id = 0x04, .n_ch = 8,
+	  .mask = FL | FR | RC},
+	{ .ca_id = 0x05, .n_ch = 8,
+	  .mask = FL | FR | LFE | RC },
+	{ .ca_id = 0x06, .n_ch = 8,
+	  .mask = FL | FR | FC | RC },
+	{ .ca_id = 0x07, .n_ch = 8,
+	  .mask = FL | FR | LFE | FC | RC },
+	{ .ca_id = 0x0c, .n_ch = 8,
+	  .mask = FL | FR | RC | RL | RR },
+	{ .ca_id = 0x0d, .n_ch = 8,
+	  .mask = FL | FR | LFE | RL | RR | RC },
+	{ .ca_id = 0x0e, .n_ch = 8,
+	  .mask = FL | FR | FC | RL | RR | RC },
+	{ .ca_id = 0x10, .n_ch = 8,
+	  .mask = FL | FR | RL | RR | RLC | RRC },
+	{ .ca_id = 0x11, .n_ch = 8,
+	  .mask = FL | FR | LFE | RL | RR | RLC | RRC },
+	{ .ca_id = 0x12, .n_ch = 8,
+	  .mask = FL | FR | FC | RL | RR | RLC | RRC },
+	{ .ca_id = 0x14, .n_ch = 8,
+	  .mask = FL | FR | FLC | FRC },
+	{ .ca_id = 0x15, .n_ch = 8,
+	  .mask = FL | FR | LFE | FLC | FRC },
+	{ .ca_id = 0x16, .n_ch = 8,
+	  .mask = FL | FR | FC | FLC | FRC },
+	{ .ca_id = 0x17, .n_ch = 8,
+	  .mask = FL | FR | LFE | FC | FLC | FRC },
+	{ .ca_id = 0x18, .n_ch = 8,
+	  .mask = FL | FR | RC | FLC | FRC },
+	{ .ca_id = 0x19, .n_ch = 8,
+	  .mask = FL | FR | LFE | RC | FLC | FRC },
+	{ .ca_id = 0x1a, .n_ch = 8,
+	  .mask = FL | FR | RC | FC | FLC | FRC },
+	{ .ca_id = 0x1b, .n_ch = 8,
+	  .mask = FL | FR | LFE | RC | FC | FLC | FRC },
+	{ .ca_id = 0x1c, .n_ch = 8,
+	  .mask = FL | FR | RL | RR | FLC | FRC },
+	{ .ca_id = 0x1d, .n_ch = 8,
+	  .mask = FL | FR | LFE | RL | RR | FLC | FRC },
+	{ .ca_id = 0x1e, .n_ch = 8,
+	  .mask = FL | FR | FC | RL | RR | FLC | FRC },
+	{ .ca_id = 0x1f, .n_ch = 8,
+	  .mask = FL | FR | LFE | FC | RL | RR | FLC | FRC },
+};
+
+static void xlnx_dp_hpd_pulse_work_func(struct work_struct *work);
+static int xlnx_dp_txconnected(struct xlnx_dp *dp);
+
+static inline struct xlnx_dp *encoder_to_dp(struct drm_encoder *encoder)
+{
+	return container_of(encoder, struct xlnx_dp, encoder);
+}
+
+static inline struct xlnx_dp *connector_to_dp(struct drm_connector *connector)
+{
+	return container_of(connector, struct xlnx_dp, connector);
+}
+
+static void xlnx_dp_write(void __iomem *base, int offset, u32 val)
+{
+	writel(val, base + offset);
+}
+
+static u32 xlnx_dp_read(void __iomem *base, int offset)
+{
+	return readl(base + offset);
+}
+
+static void xlnx_dp_set(void __iomem *base, int offset, u32 set)
+{
+	xlnx_dp_write(base, offset, xlnx_dp_read(base, offset) | set);
+}
+
+static void xlnx_dp_clr(void __iomem *base, int offset, u32 clr)
+{
+	xlnx_dp_write(base, offset, xlnx_dp_read(base, offset) & ~clr);
+}
+
+static void xlnx_dp_vtc_set_timing(struct xlnx_dp *dp,
+				   struct drm_display_mode *mode)
+{
+	u32 reg;
+	u32 htotal, hactive, hsync_start, hbackporch_start;
+	u32 vtotal, vactive, vsync_start, vbackporch_start;
+	u32 hsync_len, hfront_porch, hback_porch;
+	u32 vsync_len, vfront_porch, vback_porch;
+
+	/*
+	 * TODO : For now driver does not support interlace mode
+	 * In future  driver may add interlace support
+	 */
+
+	/*
+	 * Note that pixels-per-clock for video data and timing is non-existent
+	 * in the Video Timing Controller. There is only a single set of timing
+	 * signals for the video data bus. This means that horizontal (acive
+	 * pixles, hsync, hblank) timing settings can be detected and generated
+	 * only for a multiple of the pixels-per-clock configured in the system.
+	 */
+	hactive = mode->hdisplay / dp->config.ppc;
+	hfront_porch = (mode->hsync_start - mode->hdisplay) / dp->config.ppc;
+	hback_porch = (mode->htotal - mode->hsync_end) / dp->config.ppc;
+	hsync_len = (mode->hsync_end - mode->hsync_start) / dp->config.ppc;
+	htotal = hactive + hfront_porch + hsync_len + hback_porch;
+	hsync_start = hactive + hfront_porch;
+	hbackporch_start = hsync_start + hsync_len;
+
+	vactive = mode->vdisplay;
+	vfront_porch = mode->vsync_start - mode->vdisplay;
+	vback_porch = mode->vtotal - mode->vsync_end;
+	vsync_len = mode->vsync_end - mode->vsync_start;
+	vtotal = vactive + vfront_porch + vsync_len + vback_porch;
+	vsync_start = vactive + vfront_porch;
+	vbackporch_start = vsync_start + vsync_len;
+
+	reg = htotal & XDPTX_VTC_GHSIZE_FRAME_HSIZE;
+	xlnx_dp_write(dp->dp_base, dp->vtc_off + XDPTX_VTC_GHSIZE, reg);
+
+	reg = vtotal & XDPTX_VTC_GVSIZE_FRAME_VSIZE;
+	reg |= reg << XDPTX_VTC_FIELD1_VSIZE_SHIFT;
+	xlnx_dp_write(dp->dp_base, dp->vtc_off + XDPTX_VTC_GVSIZE, reg);
+
+	reg = hactive & XDPTX_VTC_ACTIVE_SIZE_MASK;
+	reg |= (vactive & XDPTX_VTC_ACTIVE_SIZE_MASK) <<
+		XDPTX_VTC_FIELD1_VSIZE_SHIFT;
+	xlnx_dp_write(dp->dp_base, dp->vtc_off + XDPTX_VTC_GASIZE_F0, reg);
+
+	reg = hsync_start & XDPTX_VTC_GHSYNC_START_MASK;
+	reg |= (hbackporch_start << XDPTX_VTC_GH1BPSTART_SHIFT) &
+		XDPTX_VTC_GHSYNC_END_MASK;
+	xlnx_dp_write(dp->dp_base, dp->vtc_off + XDPTX_VTC_GHSYNC, reg);
+
+	reg = vsync_start & XDPTX_VTC_F0_VSYNC_VSTART_MASK;
+	reg |= (vbackporch_start << XDPTX_VTC_FIELD1_VSIZE_SHIFT) &
+		XDPTX_VTC_F0_VSYNC_VEND_MASK;
+	xlnx_dp_write(dp->dp_base, dp->vtc_off + XDPTX_VTC_GVSYNC, reg);
+	xlnx_dp_clr(dp->dp_base, dp->vtc_off + XDPTX_VTC_GFENC,
+		    XDPTX_VTC_GFENC_MASK);
+
+	/* Calculate and update Generator VBlank Hori field 0 */
+	reg = hactive & XDPTX_VTC_F0VBLANK_HSTART_MASK;
+	reg |= (hactive << XDPTX_VTC_F0VSYNC_HEND_SHIFT) &
+		XDPTX_VTC_F0VBLANK_HEND_MASK;
+	xlnx_dp_write(dp->dp_base, dp->vtc_off + XDPTX_VTC_GVBHOFF, reg);
+
+	/* Calculate and update Generator VSync Hori field 0 */
+	reg = hsync_start & XDPTX_VTC_F0VBLANK_HSTART_MASK;
+	reg |= (hsync_start << XDPTX_VTC_F0VSYNC_HEND_SHIFT) &
+		XDPTX_VTC_F0VBLANK_HEND_MASK;
+	xlnx_dp_write(dp->dp_base, dp->vtc_off + XDPTX_VTC_GVSHOFF, reg);
+
+	/* sets all polarities as active high */
+	xlnx_dp_write(dp->dp_base, dp->vtc_off + XDPTX_VTC_GPOL,
+		      XDPTX_VTC_GPOL_MASK);
+
+	/* configure timing source */
+	xlnx_dp_set(dp->dp_base, dp->vtc_off + XDPTX_VTC_CTL,
+		    XDPTX_VTC_CTL_MASK);
+	xlnx_dp_set(dp->dp_base, dp->vtc_off + XDPTX_VTC_CTL,
+		    XDPTX_VTC_CTL_RU);
+}
+
+/**
+ * xlnx_dp_update_bpp - Update the current bpp config
+ * @dp: DisplayPort IP core structure
+ *
+ * Update the current bpp based on the color format: bpc & num_colors.
+ * Any function that changes bpc or num_colors should call this
+ * to keep the bpp value in sync.
+ */
+static void xlnx_dp_update_bpp(struct xlnx_dp *dp)
+{
+	struct xlnx_dp_config *config = &dp->config;
+
+	config->bpp = dp->config.bpc * dp->config.num_colors;
+}
+
+/**
+ * xlnx_dp_set_color - Set the color format
+ * @dp: DisplayPort IP core structure
+ * @drm_fourcc: Color string, from xlnx_disp_color_enum
+ *
+ * This function updates misc register values based on color string.
+ */
+static void xlnx_dp_set_color(struct xlnx_dp *dp, u32 drm_fourcc)
+{
+	struct xlnx_dp_config *config = &dp->config;
+
+	config->misc0 &= ~XDPTX_MISC0_FORMAT_MASK;
+
+	switch (drm_fourcc) {
+	case DRM_FORMAT_XBGR8888:
+		fallthrough;
+	case DRM_FORMAT_XRGB8888:
+		fallthrough;
+	case DRM_FORMAT_BGR888:
+		fallthrough;
+	case DRM_FORMAT_RGB888:
+		fallthrough;
+	case DRM_FORMAT_XBGR2101010:
+		config->misc0 |= XDPTX_MISC0_RGB_MASK;
+		config->num_colors = 3;
+		config->fmt = 0x0;
+		break;
+	case DRM_FORMAT_VUY888:
+		fallthrough;
+	case DRM_FORMAT_XVUY8888:
+		fallthrough;
+	case DRM_FORMAT_Y8:
+		fallthrough;
+	case DRM_FORMAT_XVUY2101010:
+		fallthrough;
+	case DRM_FORMAT_Y10:
+		config->misc0 |= XDPTX_MISC0_YCRCB444_MASK;
+		config->num_colors = 3;
+		config->fmt = 0x1;
+		break;
+	case DRM_FORMAT_YUYV:
+		fallthrough;
+	case DRM_FORMAT_UYVY:
+		fallthrough;
+	case DRM_FORMAT_NV16:
+		fallthrough;
+	case DRM_FORMAT_XV20:
+		config->misc0 |= XDPTX_MISC0_YCRCB422_MASK;
+		config->num_colors = 2;
+		config->fmt = 0x2;
+		break;
+	default:
+		dev_dbg(dp->dev, "Warning: Unknown drm_fourcc format :%d\n",
+			drm_fourcc);
+		config->misc0 |= XDPTX_MISC0_RGB_MASK;
+	}
+	xlnx_dp_update_bpp(dp);
+}
+
+/**
+ * xlnx_dp_init_phy - Initialize the phy
+ * @dp: DisplayPort IP core structure
+ *
+ * Initialize the phy.
+ *
+ * Return: 0 if the phy instances are initialized correctly, or the error code
+ * returned from the callee functions.
+ */
+static int xlnx_dp_init_phy(struct xlnx_dp *dp)
+{
+	unsigned int i;
+	int ret;
+
+	xlnx_dp_clr(dp->dp_base, XDPTX_PHYCONFIG_REG,
+		    XDPTX_PHYCONFIG_ALLRESET_MASK);
+
+	for (i = 0; i < XDPTX_MAX_LANES; i++) {
+		ret = phy_init(dp->phy[i]);
+		if (ret) {
+			dev_err(dp->dev,
+				"failed to init phy lane %d\n", i);
+			return ret;
+		}
+	}
+
+	return ret;
+}
+
+/**
+ * xlnx_dp_exit_phy - Exit the phy
+ * @dp: DisplayPort IP core structure
+ *
+ * Exit the phy.
+ */
+static void xlnx_dp_exit_phy(struct xlnx_dp *dp)
+{
+	unsigned int i;
+	int ret;
+
+	for (i = 0; i < XDPTX_MAX_LANES; i++) {
+		ret = phy_exit(dp->phy[i]);
+		if (ret)
+			dev_err(dp->dev, "fail to exit phy(%d) %d\n", i, ret);
+		dp->phy[i] = NULL;
+	}
+}
+
+/**
+ * xlnx_dp_phy_ready - check if PHY is ready
+ * @dp: DisplayPort IP core structure
+ *
+ * check if PHY is ready. If PHY is not ready, wait 1ms to check for 100 times.
+ * This amount of delay was suggested by IP designer.
+ *
+ * Return: 0 if PHY is ready, or -ENODEV if PHY is not ready.
+ */
+static int xlnx_dp_phy_ready(struct xlnx_dp *dp)
+{
+	u32 i, reg, ready;
+
+	ready = (1 << XDPTX_MAX_LANES) - 1;
+	ready |= XDPTX_PHYSTATUS_FPGAPLLLOCK_MASK;
+
+	/* Wait for 100ms. This should be enough time for PHY to be ready */
+	for (i = 0; ; i++) {
+		reg = xlnx_dp_read(dp->dp_base, XDPTX_PHYSTATUS_REG);
+		if ((reg & ready) == ready)
+			return 0;
+		if (i == 100) {
+			dev_err(dp->dev, "PHY isn't ready\n");
+			return -ENODEV;
+		}
+		usleep_range(1000, 1100);
+	}
+
+	return 0;
+}
+
+/**
+ * xlnx_dp_tx_set_vswing_preemp - This function sets current voltage swing and
+ * pre-emphasis level settings from the link_config structure to hardware.
+ * @dp: DisplayPort IP core structure
+ * @aux_data: Aux_data is a pointer to the array used for preparing a burst
+ * write over the AUX channel.
+ */
+static void xlnx_dp_tx_set_vswing_preemp(struct xlnx_dp *dp, u8 *aux_data)
+{
+	static const u32 tx_pe_levels[] = { 0x00, 0x0e, 0x14, 0x1b };
+	static const u8 tx_vs_levels[] = { 0x2, 0x5, 0x8, 0xf };
+	u32 pe_level, vs_level;
+	u8 data, i;
+
+	u8 vs_level_rx = dp->tx_link_config.vs_level;
+	u8 pe_level_rx = dp->tx_link_config.pe_level;
+
+	pe_level = tx_pe_levels[pe_level_rx];
+	vs_level = tx_vs_levels[vs_level_rx];
+
+	/*
+	 * Redriver in path requires different voltage-swing and pre-emphasis
+	 * values. Below case assumes there is no redriver in the path so
+	 * voltage-swing compensation offset is used when pre-emphasis is used.
+	 * See the VESA DisplayPort v1.4 Specification, section 3.6.1.1.
+	 */
+	if (!pe_level_rx)
+		vs_level += XDPTX_VS_LEVEL_OFFSET;
+
+	data = (pe_level_rx << XDP_TRAIN_PRE_EMPHASIS_SHIFT) |
+		vs_level_rx;
+
+	if (vs_level_rx == XDPTX_VS_PE_LEVEL_MAXCOUNT)
+		data |= XDP_TRAIN_MAX_SWING_REACHED;
+	if (pe_level_rx == XDPTX_VS_PE_LEVEL_MAXCOUNT)
+		data |= XDP_DPCD_TRAINING_LANEX_SET_MAX_PE_MASK;
+
+	memset(aux_data, data, XDPTX_MAX_LANES);
+
+	for (i = 0; i < dp->mode.lane_cnt; i++) {
+		xlnx_dp_write(dp->dp_base,
+			      XDPTX_PHYPRECURSOR_LANE0_REG + 4 * i, 0x0);
+		xlnx_dp_write(dp->dp_base,
+			      XDPTX_PHYVOLTAGE_DIFFLANE0_REG + 4 * i, vs_level);
+		xlnx_dp_write(dp->dp_base,
+			      XDPTX_PHYPOSTCURSOR_LANE0_REG + 4 * i, pe_level);
+	}
+}
+
+static int config_gt_control_linerate(struct xlnx_dp *dp, int bw_code)
+{
+	u32 data, regval;
+
+	switch (bw_code) {
+	case DP_LINK_BW_1_62:
+		data = XDPTX_GTCTL_LINE_RATE_162G;
+		break;
+	case DP_LINK_BW_2_7:
+		data = XDPTX_GTCTL_LINE_RATE_270G;
+		break;
+	case DP_LINK_BW_5_4:
+		data = XDPTX_GTCTL_LINE_RATE_540G;
+		break;
+	case DP_LINK_BW_8_1:
+		data = XDPTX_GTCTL_LINE_RATE_810G;
+		break;
+	default:
+		data = XDPTX_GTCTL_LINE_RATE_810G;
+	}
+
+	regval = xlnx_dp_read(dp->dp_base, XDPTX_GTCTL_REG);
+	regval &= ~XDPTX_GTCTL_LINE_RATE_MASK;
+	regval |= FIELD_PREP(XDPTX_GTCTL_LINE_RATE_MASK, data);
+	xlnx_dp_write(dp->dp_base, XDPTX_GTCTL_REG, regval);
+
+	/* Wait for PHY ready */
+	return xlnx_dp_phy_ready(dp);
+}
+
+static int xlnx_dp_tx_gt_control_init(struct xlnx_dp *dp)
+{
+	u32 data;
+	int ret;
+
+	/* Setting initial vswing */
+	data = xlnx_dp_read(dp->dp_base, XDPTX_GTCTL_REG);
+	data &= ~XDPTX_GTCTL_VSWING_MASK;
+	data |= FIELD_PREP(XDPTX_GTCTL_VSWING_MASK, 0x05);
+	xlnx_dp_write(dp->dp_base, XDPTX_GTCTL_REG, data);
+
+	xlnx_dp_clr(dp->dp_base, XDPTX_GTCTL_REG, 0x01);
+	ret = xlnx_dp_phy_ready(dp);
+	if (ret < 0)
+		return ret;
+
+	/* Setting initial link rate */
+	ret = config_gt_control_linerate(dp, DP_LINK_BW_5_4);
+	if (ret) {
+		dev_err(dp->dev, "Default Line Rate setting Failed\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+/**
+ * xlnx_dp_set_train_patttern - This function sets the training pattern to be
+ * used during link training for both the DisplayPort TX core and Rx core.
+ * @dp: DisplayPort IP core structure
+ * @pattern: pattern selects the pattern to be used. One of the following
+ *	- DP_TRAINING_PATTERN_DISABLE
+ *	- DP_TRAINING_PATTERN_1
+ *	- DP_TRAINING_PATTERN_2
+ *	- DP_TRAINING_PATTERN_3
+ *	- DP_TRAINING_PATTERN_4
+ *
+ * Returns:
+ *	- 0 on success or negative error code on failure
+ */
+static int xlnx_dp_set_train_patttern(struct xlnx_dp *dp, u32 pattern)
+{
+	int ret;
+	u8 aux_data[5];
+
+	xlnx_dp_write(dp->dp_base, XDPTX_TRNGPAT_SET_REG, pattern);
+	aux_data[0] = pattern;
+
+	/* write scrambler disable to DisplayPort TX core */
+	switch (pattern) {
+	case DP_TRAINING_PATTERN_DISABLE:
+		xlnx_dp_write(dp->dp_base, XDPTX_SCRAMBLING_DIS_REG, 0);
+		break;
+	case DP_TRAINING_PATTERN_1:
+	case DP_TRAINING_PATTERN_2:
+	case DP_TRAINING_PATTERN_3:
+		aux_data[0] |= DP_LINK_SCRAMBLING_DISABLE;
+		xlnx_dp_write(dp->dp_base, XDPTX_SCRAMBLING_DIS_REG, 1);
+		break;
+	case DP_TRAINING_PATTERN_4:
+		xlnx_dp_write(dp->dp_base, XDPTX_SCRAMBLING_DIS_REG, 0);
+		break;
+	default:
+		break;
+	}
+
+	/* Make the adjustment to both the DisplayPort TX core and the RX */
+	xlnx_dp_tx_set_vswing_preemp(dp, &aux_data[1]);
+
+	if (pattern == DP_TRAINING_PATTERN_DISABLE)
+		ret = drm_dp_dpcd_write(&dp->aux, DP_TRAINING_PATTERN_SET,
+					aux_data, 1);
+	else
+		ret = drm_dp_dpcd_write(&dp->aux, DP_TRAINING_PATTERN_SET,
+					aux_data, 5);
+
+	return ret;
+}
+
+/**
+ * xlnx_dp_tx_pe_vs_adjust_handler - Calculate and configure pe and vs values
+ * @dp: DisplayPort IP core structure
+ * @dp_phy_opts: phy configuration structure
+ *
+ * This function adjusts the pre emphasis and voltage swing values of phy.
+ */
+static void xlnx_dp_tx_pe_vs_adjust_handler(struct xlnx_dp *dp,
+					    struct phy_configure_opts_dp *dp_phy_opts)
+{
+	u8 preemp = 0, diff_swing = 0;
+	u32 data;
+
+	switch (dp_phy_opts->pre[0]) {
+	case 0:
+		preemp = XVPHY_GTHE4_PREEMP_DP_L0;
+		break;
+	case 1:
+		preemp = XVPHY_GTHE4_PREEMP_DP_L1;
+		break;
+	case 2:
+		preemp = XVPHY_GTHE4_PREEMP_DP_L2;
+		break;
+	case 3:
+		preemp = XVPHY_GTHE4_PREEMP_DP_L3;
+		break;
+	}
+
+	switch (dp_phy_opts->voltage[0]) {
+	case 0:
+		switch (dp_phy_opts->pre[0]) {
+		case 0:
+			diff_swing = XVPHY_GTHE4_DIFF_SWING_DP_V0P0;
+			break;
+		case 1:
+			diff_swing = XVPHY_GTHE4_DIFF_SWING_DP_V0P1;
+			break;
+		case 2:
+			diff_swing = XVPHY_GTHE4_DIFF_SWING_DP_V0P2;
+			break;
+		case 3:
+			diff_swing = XVPHY_GTHE4_DIFF_SWING_DP_V0P3;
+			break;
+		}
+		break;
+	case 1:
+		switch (dp_phy_opts->pre[0]) {
+		case 0:
+			diff_swing = XVPHY_GTHE4_DIFF_SWING_DP_V1P0;
+			break;
+		case 1:
+			diff_swing = XVPHY_GTHE4_DIFF_SWING_DP_V1P1;
+			break;
+		case 2:
+			fallthrough;
+		case 3:
+			diff_swing = XVPHY_GTHE4_DIFF_SWING_DP_V1P2;
+			break;
+		}
+		break;
+	case 2:
+		switch (dp_phy_opts->pre[0]) {
+		case 0:
+			diff_swing = XVPHY_GTHE4_DIFF_SWING_DP_V2P0;
+			break;
+		case 1:
+			fallthrough;
+		case 2:
+			fallthrough;
+		case 3:
+			diff_swing = XVPHY_GTHE4_DIFF_SWING_DP_V2P1;
+			break;
+		}
+		break;
+	case 3:
+		diff_swing = XVPHY_GTHE4_DIFF_SWING_DP_V3P0;
+		break;
+	}
+
+	data = xlnx_dp_read(dp->dp_base, XDPTX_GTCTL_REG);
+	data &= ~(XDPTX_GTCTL_POST_CUR_MASK | XDPTX_GTCTL_VSWING_MASK);
+	data |= FIELD_PREP(XDPTX_GTCTL_VSWING_MASK, diff_swing) |
+		FIELD_PREP(XDPTX_GTCTL_POST_CUR_MASK, preemp);
+	xlnx_dp_write(dp->dp_base, XDPTX_GTCTL_REG, data);
+
+	dp_phy_opts->set_voltages = 0;
+}
+
+/**
+ * xlnx_dp_tx_adj_vswing_preemp - Sets voltage swing and pre-emphasis levels
+ * using the adjustment requests obtained from the RX device
+ * @dp:Pointer to xlnx_dp structure
+ * @link_status: An array of link status register
+ *
+ * This function sets new voltage swing and pre-emphasis levels using the
+ * adjustment requests obtained from the sink.
+ *
+ * Return: 0 if the new levels were written successfully.
+ * error value on failure.
+ */
+static int xlnx_dp_tx_adj_vswing_preemp(struct xlnx_dp *dp, u8 link_status[6])
+{
+	struct phy_configure_opts_dp *phy_cfg = &dp->phy_opts.dp;
+	int ret;
+	u8 i, aux_data[4];
+	u8 vs_level_adj_req[4];
+	u8 pe_level_adj_req[4];
+	u8 max_lanes = dp->link_config.max_lanes;
+
+	/*
+	 * Analyze the adjustment requests for changes in voltage swing and
+	 * pre-emphasis levels.
+	 */
+	vs_level_adj_req[0] = FIELD_GET(DP_ADJUST_VOLTAGE_SWING_LANE0_MASK,
+					link_status[4]);
+	vs_level_adj_req[1] = FIELD_GET(DP_ADJUST_VOLTAGE_SWING_LANE1_MASK,
+					link_status[4]);
+	vs_level_adj_req[2] = FIELD_GET(DP_ADJUST_VOLTAGE_SWING_LANE0_MASK,
+					link_status[5]);
+	vs_level_adj_req[3] = FIELD_GET(DP_ADJUST_VOLTAGE_SWING_LANE1_MASK,
+					link_status[5]);
+	pe_level_adj_req[0] = FIELD_GET(DP_ADJUST_PRE_EMPHASIS_LANE0_MASK,
+					link_status[4]);
+	pe_level_adj_req[1] = FIELD_GET(DP_ADJUST_PRE_EMPHASIS_LANE1_MASK,
+					link_status[4]);
+	pe_level_adj_req[2] = FIELD_GET(DP_ADJUST_PRE_EMPHASIS_LANE0_MASK,
+					link_status[5]);
+	pe_level_adj_req[3] = FIELD_GET(DP_ADJUST_PRE_EMPHASIS_LANE1_MASK,
+					link_status[5]);
+
+	/*
+	 * change the drive settings to match the adjustment requests. Use the
+	 * greatest level requested.
+	 */
+	dp->tx_link_config.vs_level = 0;
+	dp->tx_link_config.pe_level = 0;
+	for (i = 0; i < dp->mode.lane_cnt ; i++) {
+		if (vs_level_adj_req[i] > dp->tx_link_config.vs_level)
+			dp->tx_link_config.vs_level = vs_level_adj_req[i];
+		if (pe_level_adj_req[i] > dp->tx_link_config.pe_level)
+			dp->tx_link_config.pe_level = pe_level_adj_req[i];
+	}
+
+	/*
+	 * Verify that the voltage swing and pre-emphasis combination is
+	 * allowed. Some combinations will result in differential peak-to-peak
+	 * voltage that is outside the permissible range. See the VESA
+	 * DisplayPort v1.4 Specification, section 3.1.5.2.
+	 * The valid combinations are:
+	 *      PE=0    PE=1    PE=2    PE=3
+	 * VS=0 Valid   Valid   Valid   Valid
+	 * VS=1 Valid   Valid   Valid
+	 * VS=2 Valid   Valid
+	 * VS=3 Valid
+	 */
+	if (dp->tx_link_config.pe_level > (4 - dp->tx_link_config.vs_level))
+		dp->tx_link_config.pe_level = 4 - dp->tx_link_config.vs_level;
+
+	/*
+	 * Make the adjustments to both the DisplayPort TX core and the RX
+	 * device.
+	 */
+	xlnx_dp_tx_set_vswing_preemp(dp, aux_data);
+	/*
+	 * Write the voltage swing and pre-emphasis levels for each lane to the
+	 * RX device.
+	 */
+	ret = drm_dp_dpcd_write(&dp->aux, DP_TRAINING_LANE0_SET,
+				&aux_data[0], 4);
+	if (ret < 0)
+		return ret;
+
+	phy_cfg->lanes = max_lanes;
+	phy_cfg->pre[0] = dp->tx_link_config.pe_level;
+	phy_cfg->voltage[0] = dp->tx_link_config.vs_level;
+	phy_cfg->set_voltages = 1;
+
+	if (!dp->config.versal_gt_present)
+		phy_configure(dp->phy[0], &dp->phy_opts);
+	else
+		xlnx_dp_tx_pe_vs_adjust_handler(dp, &dp->phy_opts.dp);
+
+	return 0;
+}
+
+/**
+ * xlnx_dp_check_clock_recovery - This function checks if the RX device's DPCD
+ * indicates that the clock recovery sequence during link training was
+ * successful - the RX device's link clock and data recovery unit has realized
+ * and maintained the frequency lock for all the lanes currently in use.
+ * @dp: DisplayPort IP core structure
+ * @lane_cnt: Number of lanes in use
+ *
+ * Return: 0 if the RX device's clock recovery PLL has achieved frequency lock
+ * for all the lanes in use.Othewise returns error value.
+ */
+static int xlnx_dp_check_clock_recovery(struct xlnx_dp *dp, u8 lane_cnt)
+{
+	struct xlnx_dp_link_config *link_config = &dp->link_config;
+	int ret;
+	u8 link_status[DP_LINK_STATUS_SIZE];
+
+	ret = drm_dp_dpcd_read_link_status(&dp->aux, link_status);
+	if (ret < 0)
+		return ret;
+
+	switch (lane_cnt) {
+	case XDPTX_DP_LANE_COUNT_4:
+		if (!(link_status[0] & XDPTX_DPCD_LANE02_CRDONE_MASK)) {
+			link_config->cr_done_cnt = XDPTX_LANE0_CRDONE_MASK;
+			return 1;
+		}
+		if (!(link_status[0] & XDPTX_DPCD_LANE13_CRDONE_MASK)) {
+			link_config->cr_done_cnt = XDPTX_LANE1_CRDONE_MASK;
+			return 1;
+		}
+		if (!(link_status[1] & XDPTX_DPCD_LANE02_CRDONE_MASK)) {
+			link_config->cr_done_cnt = XDPTX_LANE2_CRDONE_MASK;
+			return 1;
+		}
+		if (!(link_status[1] & XDPTX_DPCD_LANE13_CRDONE_MASK)) {
+			link_config->cr_done_cnt = XDPTX_LANE3_CRDONE_MASK;
+			return 1;
+		}
+		link_config->cr_done_cnt = 0x4;
+		fallthrough;
+	case XDPTX_DP_LANE_COUNT_2:
+		if (!(link_status[0] & XDPTX_DPCD_LANE02_CRDONE_MASK)) {
+			link_config->cr_done_cnt = 0x0;
+			return 1;
+		}
+		if (!(link_status[0] & XDPTX_DPCD_LANE13_CRDONE_MASK)) {
+			link_config->cr_done_cnt = 0x1;
+			return 1;
+		}
+		link_config->cr_done_cnt = 0x2;
+		fallthrough;
+	case XDPTX_DP_LANE_COUNT_1:
+		if (!(link_status[0] & XDPTX_DPCD_LANE02_CRDONE_MASK)) {
+			link_config->cr_done_cnt = 0x0;
+			return 1;
+		}
+		link_config->cr_done_cnt = 0x1;
+		break;
+	default:
+		break;
+	}
+
+	return 0;
+}
+
+static int xlnx_dp_set_linkrate(struct xlnx_dp *dp, u8 bw_code)
+{
+	struct phy_configure_opts_dp *phy_cfg = &dp->phy_opts.dp;
+	int ret;
+	u32 reg, lrate_val = 0, val;
+	u8 lane_count = dp->mode.lane_cnt;
+
+	if (!xlnx_dp_txconnected(dp)) {
+		dev_dbg(dp->dev, "display is not connected");
+		return connector_status_disconnected;
+	}
+
+	dp->mode.bw_code = bw_code;
+
+	switch (bw_code) {
+	case DP_LINK_BW_1_62:
+		reg = XDPTX_PHYCLOCK_FBSETTING162_MASK;
+		phy_cfg->link_rate = XDPTX_REDUCED_BIT_RATE / 100;
+		if (dp->config.versal_gt_present)
+			lrate_val = XDPTX_GTCTL_LINE_RATE_162G;
+		break;
+	case DP_LINK_BW_2_7:
+		reg = XDPTX_PHYCLOCK_FBSETTING270_MASK;
+		phy_cfg->link_rate = XDPTX_HIGH_BIT_RATE_1 / 100;
+		if (dp->config.versal_gt_present)
+			lrate_val = XDPTX_GTCTL_LINE_RATE_270G;
+		break;
+	case DP_LINK_BW_5_4:
+		reg = XDPTX_PHYCLOCK_FBSETTING810_MASK;
+		phy_cfg->link_rate = XDPTX_HIGH_BIT_RATE_2 / 100;
+		if (dp->config.versal_gt_present)
+			lrate_val = XDPTX_GTCTL_LINE_RATE_540G;
+		break;
+	case DP_LINK_BW_8_1:
+		reg = XDPTX_PHYCLOCK_FBSETTING810_MASK;
+		phy_cfg->link_rate = XDPTX_HIGH_BIT_RATE_3 / 100;
+		if (dp->config.versal_gt_present)
+			lrate_val = XDPTX_GTCTL_LINE_RATE_810G;
+		break;
+	default:
+		reg = XDPTX_PHYCLOCK_FBSETTING810_MASK;
+		phy_cfg->link_rate = XDPTX_HIGH_BIT_RATE_3 / 100;
+		if (dp->config.versal_gt_present)
+			lrate_val = XDPTX_GTCTL_LINE_RATE_810G;
+	}
+
+	/*
+	 * set the clock frequency for the DisplayPort PHY corresponding
+	 * to a desired link rate
+	 */
+	val = xlnx_dp_read(dp->dp_base, XDPTX_ENABLE_REG);
+	xlnx_dp_write(dp->dp_base, XDPTX_ENABLE_REG, 0);
+	xlnx_dp_write(dp->dp_base, XDPTX_PHYCLOCK_FBSETTING_REG, reg);
+	if (val)
+		xlnx_dp_write(dp->dp_base, XDPTX_ENABLE_REG, 1);
+	/* Wait for PHY ready */
+	ret = xlnx_dp_phy_ready(dp);
+	if (ret < 0)
+		return ret;
+
+	/* write new link rate to the DisplayPort TX core */
+	xlnx_dp_write(dp->dp_base, XDPTX_LINKBW_SET_REG, bw_code);
+	/* write new link rate to the RX device */
+	ret = drm_dp_dpcd_writeb(&dp->aux, DP_LINK_BW_SET, bw_code);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to set DP bandwidth\n");
+		return ret;
+	}
+	/* configure video phy controller to new link rate */
+	phy_cfg->set_rate = 1;
+	phy_cfg->lanes = lane_count;
+	if (!dp->config.versal_gt_present)
+		phy_configure(dp->phy[0], &dp->phy_opts);
+
+	if (dp->config.versal_gt_present) {
+		val = xlnx_dp_read(dp->dp_base, XDPTX_GTCTL_REG);
+		val &= ~XDPTX_GTCTL_LINE_RATE_MASK;
+		val |= FIELD_PREP(XDPTX_GTCTL_LINE_RATE_MASK, lrate_val);
+		xlnx_dp_write(dp->dp_base, XDPTX_GTCTL_REG, val);
+	}
+
+	return 0;
+}
+
+static int xlnx_dp_set_lanecount(struct xlnx_dp *dp, u8 lane_cnt)
+{
+	int ret;
+	u8 data;
+
+	dp->mode.lane_cnt = lane_cnt;
+	xlnx_dp_write(dp->dp_base, XDPTX_LANECNT_SET_REG, lane_cnt);
+
+	ret = drm_dp_dpcd_readb(&dp->aux, DP_LANE_COUNT_SET, &data);
+	if (ret < 0) {
+		dev_err(dp->dev, "DPCD read retry fails");
+		return ret;
+	}
+
+	data &= ~XDPTX_DPCD_LANECNT_SET_MASK;
+	data |= dp->mode.lane_cnt;
+	ret = drm_dp_dpcd_writeb(&dp->aux, DP_LANE_COUNT_SET, data);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to set lane count\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+/**
+ * xlnx_dp_check_link_status - This function checks if the receiver has
+ * achieved and maintained clock recovery, channel equalization, symbol lock, and
+ * interlane alignment for all lanes currently in use
+ * @dp: DisplayPort IP core structure
+ *
+ * Return: 0 if link status is successfully.
+ * error value on failure.
+ */
+static int xlnx_dp_check_link_status(struct xlnx_dp *dp)
+{
+	int ret;
+	u8 link_status[DP_LINK_STATUS_SIZE];
+	u8 retry = 0;
+
+	memset(link_status, 0, sizeof(link_status));
+
+	if (!xlnx_dp_txconnected(dp)) {
+		dev_dbg(dp->dev, "display is not connected");
+		return connector_status_disconnected;
+	}
+
+	for (retry = 0; retry < 5; retry++) {
+		ret = drm_dp_dpcd_read_link_status(&dp->aux, link_status);
+		if (ret < 0)
+			return ret;
+
+		if (drm_dp_clock_recovery_ok(link_status, dp->mode.lane_cnt) ||
+		    drm_dp_channel_eq_ok(link_status, dp->mode.lane_cnt))
+			return 0;
+	}
+
+	return -EINVAL;
+}
+
+static int xlnx_dp_post_training(struct xlnx_dp *dp)
+{
+	int ret;
+	u8 data;
+
+	if (dp->dpcd[DP_DPCD_REV] == XDPTX_V1_4) {
+		ret = drm_dp_dpcd_readb(&dp->aux, DP_LANE_COUNT_SET, &data);
+		if (ret < 0) {
+			dev_dbg(dp->dev, "DPCD read first try fails");
+			ret = drm_dp_dpcd_readb(&dp->aux,
+						DP_LANE_COUNT_SET, &data);
+			if (ret < 0) {
+				dev_err(dp->dev, "DPCD read retry fails");
+				return ret;
+			}
+		}
+
+		/*
+		 * Post Link Training ; An upstream device with a DPTX sets
+		 * this bit to 1 to grant the POST_LT_ADJ_REQ sequence by the
+		 * downstream DPRX if the downstream DPRX supports
+		 * POST_LT_ADJ_REQ
+		 */
+		data |= 0x20;
+		ret = drm_dp_dpcd_writeb(&dp->aux, DP_LANE_COUNT_SET, data);
+		if (ret < 0) {
+			dev_dbg(dp->dev, "DPCD write first try fails");
+			ret = drm_dp_dpcd_writeb(&dp->aux,
+						 DP_LANE_COUNT_SET, data);
+			if (ret < 0) {
+				dev_err(dp->dev, "DPCD write retry fails");
+				return ret;
+			}
+		}
+	}
+
+	ret = xlnx_dp_check_link_status(dp);
+	if (ret < 0)
+		return ret;
+
+	ret = xlnx_dp_set_train_patttern(dp, DP_TRAINING_PATTERN_DISABLE);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to disable training pattern\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+/**
+ * xlnx_dp_link_train_cr - Train clock recovery
+ * @dp: DisplayPort IP core structure
+ *
+ * Return: 0 if clock recovery train is done successfully, or corresponding
+ * error code.
+ */
+static int xlnx_dp_link_train_cr(struct xlnx_dp *dp)
+{
+	struct xlnx_dp_tx_link_config *link_config = &dp->tx_link_config;
+	struct xlnx_dp_link_config *config = &dp->link_config;
+	int ret;
+	u16 max_tries;
+	u8 prev_vs_level = 0, same_vs_level_count = 0;
+	u8 link_status[DP_LINK_STATUS_SIZE];
+	u8 lane_cnt = dp->mode.lane_cnt;
+	bool cr_done = 0;
+
+	/* start from minimal vs and pe levels */
+	dp->tx_link_config.vs_level = 0;
+	dp->tx_link_config.pe_level = 0;
+
+	ret = xlnx_dp_set_train_patttern(dp, DP_TRAINING_PATTERN_1);
+	if (ret < 0)
+		return XLNX_DP_TRAIN_FAILURE;
+
+	/*
+	 * 256 loops should be maximum iterations for 4 lanes and 4 values.
+	 * So, This loop should exit before 512 iterations
+	 */
+	for (max_tries = 0; max_tries < 512; max_tries++) {
+		/*
+		 * Obtain the required delay for clock recovery as specified
+		 * by the RX device.
+		 * Wait delay specified in TRAINING_AUX_RD_INTERVAL(0x0E)
+		 */
+		drm_dp_link_train_clock_recovery_delay(&dp->aux, dp->dpcd);
+		/*
+		 * check if all lanes have realized and maintained the
+		 * frequency lock and get adjustment requests.
+		 */
+		ret = drm_dp_dpcd_read_link_status(&dp->aux, link_status);
+		if (ret < 0)
+			return XLNX_DP_TRAIN_FAILURE;
+
+		cr_done = xlnx_dp_check_clock_recovery(dp, lane_cnt);
+		if (!cr_done)
+			return XLNX_DP_TRAIN_CE;
+		/*
+		 * check if the same voltage swing for each lane has been
+		 * used 5 consecutive times.
+		 */
+		if (prev_vs_level == link_config->vs_level) {
+			same_vs_level_count++;
+		} else {
+			same_vs_level_count = 0;
+			prev_vs_level = link_config->vs_level;
+		}
+
+		if (same_vs_level_count >= XDPTX_VS_LEVEL_MAXCOUNT)
+			break;
+
+		if (link_config->vs_level == XDPTX_VS_PE_LEVEL_MAXCOUNT)
+			break;
+		/* Adjust the drive settings as requested by the RX device */
+		ret = xlnx_dp_tx_adj_vswing_preemp(dp, link_status);
+		if (ret < 0)
+			return XLNX_DP_TRAIN_FAILURE;
+	}
+
+	if (dp->mode.bw_code == DP_LINK_BW_1_62) {
+		if (config->cr_done_cnt != 0x4 && config->cr_done_cnt != 0x0) {
+			ret = xlnx_dp_set_train_patttern(dp, DP_TRAINING_PATTERN_DISABLE);
+			if (ret < 0) {
+				dev_err(dp->dev, "failed to disable training pattern\n");
+				return ret;
+			}
+
+			ret = xlnx_dp_set_linkrate(dp, DP_LINK_BW_8_1);
+			if (ret < 0) {
+				dev_err(dp->dev, "failed to set link rate\n");
+				return ret;
+			}
+
+			ret = xlnx_dp_set_lanecount(dp, config->cr_done_cnt);
+			if (ret < 0) {
+				dev_err(dp->dev, "failed to set lane count\n");
+				return ret;
+			}
+			config->cr_done_oldstate = config->cr_done_cnt;
+
+			return XLNX_DP_TRAIN_CR;
+		}
+	}
+
+	return XLNX_DP_ADJUST_LINKRATE;
+}
+
+/**
+ * xlnx_dp_adjust_linkrate - Adjust the link rate
+ * @dp: DisplayPort core structure
+ *
+ * This function is reached if either the clock recovery or the channel
+ * equalization process failed during training. As a result, the data rate will
+ * be downshifted and training will be re-attempted at the reduced data rate. If
+ * the data rate is already at 1.62 Gbps, a downshited in lane count will be
+ * attempted.
+ *
+ * Return: The next training state:
+ *	- XLNX_DP_ADJUST_LANECOUNT if the minimal data rate is already in use.
+ *	re-attempt training at a reduced lane count.
+ *	- XLNX_DP_TRAIN_CR otherwise. Re-attempt training.
+ */
+static int xlnx_dp_adjust_linkrate(struct xlnx_dp *dp)
+{
+	int ret;
+	u8 bw_code;
+
+	switch (dp->mode.bw_code) {
+	case DP_LINK_BW_8_1:
+		bw_code = DP_LINK_BW_5_4;
+		break;
+	case DP_LINK_BW_5_4:
+		bw_code = DP_LINK_BW_2_7;
+		break;
+	case DP_LINK_BW_2_7:
+		bw_code = DP_LINK_BW_1_62;
+		break;
+	default:
+		/*
+		 * Already at the lowest link rate. Try reducing the lane
+		 * count next
+		 */
+		return XLNX_DP_ADJUST_LANECOUNT;
+	}
+
+	ret = xlnx_dp_set_linkrate(dp, bw_code);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to set link rate\n");
+		return XLNX_DP_TRAIN_FAILURE;
+	}
+
+	ret = xlnx_dp_set_lanecount(dp, dp->link_config.cr_done_oldstate);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to set lane count\n");
+		return XLNX_DP_TRAIN_FAILURE;
+	}
+
+	return XLNX_DP_TRAIN_CR;
+}
+
+/**
+ * xlnx_dp_adjust_lanecount - Adjust the lane count
+ * @dp: DisplayPort core structure
+ *
+ * This function is reached if either the clock recovery or the channel
+ * equalization process failed during training. As a result, the number of lanes
+ * will be downshifted and training will be re-attempted at this lower lane
+ * count.
+ *
+ * note: Training will be re-attempted with the maximum data rate being used
+ * with the reduced lane count to train the main link at the maximum bandwidth
+ * possible.
+ *
+ * Return: The next training state:
+ *	- XLNX_DP_TRAIN_FAILURE if only one lane is already in use
+ *	- XLNX_DP_TRAIN_CR otherwise. Re-attempt training
+ */
+static int xlnx_dp_adjust_lanecount(struct xlnx_dp *dp)
+{
+	int max_rate = dp->link_config.max_rate, ret;
+	u8 bw_code = drm_dp_link_rate_to_bw_code(max_rate), lane_cnt;
+
+	switch (dp->mode.lane_cnt) {
+	case XDPTX_DP_LANE_COUNT_4:
+		lane_cnt = XDPTX_DP_LANE_COUNT_2;
+		break;
+	case XDPTX_DP_LANE_COUNT_2:
+		lane_cnt = XDPTX_DP_LANE_COUNT_1;
+		break;
+	default:
+		dev_err(dp->dev, " Training failed at lowest linkrate and lane count\n");
+		return XLNX_DP_TRAIN_FAILURE;
+	}
+
+	ret = xlnx_dp_set_linkrate(dp, bw_code);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to set link rate\n");
+		return XLNX_DP_TRAIN_FAILURE;
+	}
+
+	ret = xlnx_dp_set_lanecount(dp, lane_cnt);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to set lane count\n");
+		return XLNX_DP_TRAIN_FAILURE;
+	}
+
+	return XLNX_DP_TRAIN_CR;
+}
+
+/**
+ * xlnx_dp_link_train_ce - Train channel equalization
+ * @dp: DisplayPort IP core structure
+ *
+ * Return: 0 if channel equalization train is done successfully, or
+ * corresponding error code.
+ */
+
+static int xlnx_dp_link_train_ce(struct xlnx_dp *dp)
+{
+	struct xlnx_dp_link_config *config = &dp->link_config;
+	struct xlnx_dp_mode *mode = &dp->mode;
+	int ret;
+	u32 i;
+	u8 pat, link_status[DP_LINK_STATUS_SIZE];
+	u8 lane_cnt = dp->mode.lane_cnt;
+	bool ce_done, cr_done;
+
+	if (dp->dpcd[DP_DPCD_REV] == XDPTX_V1_4 &&
+	    dp->dpcd[DP_MAX_DOWNSPREAD] & DP_TPS4_SUPPORTED) {
+		pat = DP_TRAINING_PATTERN_4;
+	} else if (dp->dpcd[DP_MAX_LANE_COUNT] & DP_TPS3_SUPPORTED) {
+		pat = DP_TRAINING_PATTERN_3;
+	} else {
+		pat = DP_TRAINING_PATTERN_2;
+	}
+
+	ret = xlnx_dp_set_train_patttern(dp, pat);
+	if (ret < 0)
+		return XLNX_DP_TRAIN_FAILURE;
+
+	for (i = 0; i < DP_MAX_TRAINING_TRIES; i++) {
+		/*
+		 * Obtain the required delay for channel equalization as
+		 * specified by the RX device.
+		 */
+		drm_dp_link_train_channel_eq_delay(&dp->aux, dp->dpcd);
+
+		ret = drm_dp_dpcd_read_link_status(&dp->aux, link_status);
+		if (ret < 0)
+			return XLNX_DP_TRAIN_FAILURE;
+
+		cr_done = drm_dp_clock_recovery_ok(link_status, lane_cnt);
+		if (!cr_done)
+			break;
+		/*
+		 * check if all lanes have accomplished channel equalization,
+		 * symbol lock, and interlane alignment.
+		 */
+		ce_done = drm_dp_channel_eq_ok(link_status, lane_cnt);
+		if (ce_done)
+			return XLNX_DP_TRAIN_SUCCESS;
+
+		ret = drm_dp_dpcd_read_link_status(&dp->aux, link_status);
+		if (ret < 0)
+			return XLNX_DP_TRAIN_FAILURE;
+
+		ret = xlnx_dp_tx_adj_vswing_preemp(dp, link_status);
+		if (ret != 0)
+			return XLNX_DP_TRAIN_FAILURE;
+	}
+	/*
+	 * Tried 5 times with no success. Try a reduced bitrate first, then
+	 * reduce the number of lanes.
+	 */
+
+	if (!cr_done) {
+		/* Down link on CR failure in EQ state */
+		config->cr_done_oldstate = config->max_lanes;
+		return XLNX_DP_ADJUST_LINKRATE;
+	} else if ((mode->lane_cnt == 1) && !ce_done) {
+		/* Need to set lanecount for next iter */
+		mode->lane_cnt = config->max_lanes;
+		config->cr_done_oldstate = config->max_lanes;
+		return XLNX_DP_ADJUST_LINKRATE;
+	} else if ((mode->lane_cnt > 1) && !ce_done) {
+		/* For EQ failure downlink the lane count */
+		return XLNX_DP_ADJUST_LANECOUNT;
+	}
+
+	config->cr_done_oldstate = config->max_lanes;
+
+	return XLNX_DP_ADJUST_LINKRATE;
+}
+
+/**
+ * xlnx_dp_run_training - Run the link training process
+ * @dp: DisplayPort core structure
+ *
+ * This function is implemented as a state machine, with each state returning
+ * the next state. First, the clock recovery sequence will be run; if successful,
+ * the channel equalization sequence will run. If either the clock recovery or
+ * channel equalization sequence failed, the link rate or the number of lanes
+ * used will be reduced and training will be re-attempted. If training fails
+ * at the minimal data rate, 1.62 Gbps with a single lane, training will no
+ * longer re-attempt and fail.
+ *
+ * Return: 0 if the training process succeeded.
+ * error value on training failure.
+ */
+static int xlnx_dp_run_training(struct xlnx_dp *dp)
+{
+	struct xlnx_dp_link_config *config = &dp->link_config;
+	enum xlnx_dp_train_state state = XLNX_DP_TRAIN_CR;
+	int ret;
+
+	while (1) {
+		switch (state) {
+		case XLNX_DP_TRAIN_CR:
+			state = xlnx_dp_link_train_cr(dp);
+			break;
+		case XLNX_DP_TRAIN_CE:
+			state = xlnx_dp_link_train_ce(dp);
+			break;
+		case XLNX_DP_ADJUST_LINKRATE:
+			state = xlnx_dp_adjust_linkrate(dp);
+			break;
+		case XLNX_DP_ADJUST_LANECOUNT:
+			state = xlnx_dp_adjust_lanecount(dp);
+			break;
+		default:
+			break;
+		}
+
+		if (state == XLNX_DP_TRAIN_SUCCESS) {
+			config->cr_done_oldstate = config->max_lanes;
+			config->cr_done_cnt = config->max_lanes;
+			dev_dbg(dp->dev, "dp training is success !!");
+			break;
+		} else if (state == XLNX_DP_TRAIN_FAILURE) {
+			config->cr_done_oldstate = config->max_lanes;
+			config->cr_done_cnt = config->max_lanes;
+			goto err_out;
+		}
+
+		if (state == XLNX_DP_ADJUST_LINKRATE ||
+		    state == XLNX_DP_ADJUST_LANECOUNT) {
+			ret = xlnx_dp_set_train_patttern(dp, DP_TRAINING_PATTERN_DISABLE);
+			if (ret < 0) {
+				dev_err(dp->dev,
+					"failed to disable training pattern\n");
+				goto err_out;
+			}
+		}
+	}
+
+	return 0;
+err_out:
+	dev_err(dp->dev, "failed to train the DP link\n");
+	return -EIO;
+}
+
+static void xlnx_dp_phy_reset(struct xlnx_dp *dp, u32 reset)
+{
+	u32 phy_val, reg_val;
+
+	xlnx_dp_write(dp->dp_base, XDPTX_ENABLE_REG, 0);
+
+	/* Preserve the current PHY settings */
+	phy_val = xlnx_dp_read(dp->dp_base, XDPTX_PHYCONFIG_REG);
+
+	/* Apply reset */
+	reg_val = phy_val | reset;
+	xlnx_dp_write(dp->dp_base, XDPTX_PHYCONFIG_REG, reg_val);
+
+	/* Remove reset */
+	xlnx_dp_write(dp->dp_base, XDPTX_PHYCONFIG_REG, phy_val);
+
+	/* Wait for the PHY to be ready */
+	xlnx_dp_phy_ready(dp);
+
+	xlnx_dp_write(dp->dp_base, XDPTX_ENABLE_REG, 1);
+}
+
+/**
+ * xlnx_dp_aux_cmd_submit - Submit aux command
+ * @dp: DisplayPort IP core structure
+ * @cmd: aux command
+ * @addr: aux address
+ * @buf: buffer for command data
+ * @bytes: number of bytes for @buf
+ * @reply: reply code to be returned
+ *
+ * Submit an aux command. All aux related commands, native or i2c aux
+ * read/write, are submitted through this function. The function is mapped to
+ * the transfer function of struct drm_dp_aux. This function involves in
+ * multiple register reads/writes, thus synchronization is needed, and it is
+ * done by drm_dp_helper using @hw_mutex. The calling thread goes into sleep
+ * if there's no immediate reply to the command submission. The reply code is
+ * returned at @reply if @reply != NULL.
+ *
+ * Return: 0 if the command is submitted properly, or corresponding error code:
+ * -EBUSY when there is any request already being processed
+ * -ETIMEDOUT when receiving reply is timed out
+ * -EIO when received bytes are less than requested
+ */
+static int xlnx_dp_aux_cmd_submit(struct xlnx_dp *dp, u32 cmd, u32 addr,
+				  u8 *buf, u32 bytes, u8 *reply)
+{
+	bool is_read = (cmd & XDPTX_AUX_READ_BIT) ? true : false;
+	void __iomem *dp_base = dp->dp_base;
+	u32 reg, i, bytesleft, address;
+	u8 *data;
+	u8 no_of_bytes;
+
+	bytesleft = bytes;
+	address = addr;
+
+	while (bytesleft > 0) {
+		reg = xlnx_dp_read(dp_base, XDPTX_INTR_SIGSTATE_REG);
+		if (reg & XDPTX_INTR_SIGREQSTATE)
+			return -EBUSY;
+
+		address = addr + (bytes - bytesleft);
+		xlnx_dp_write(dp_base, XDPTX_AUX_ADDR_REG, address);
+
+		/* Increment the pointer to the supplied data buffer. */
+		data = &buf[bytes - bytesleft];
+
+		if (bytesleft > 16)
+			no_of_bytes = 16;
+		else
+			no_of_bytes = bytesleft;
+
+		bytesleft -= no_of_bytes;
+		if (!is_read) {
+			for (i = 0; i < no_of_bytes; i++) {
+				xlnx_dp_write(dp_base, XDPTX_AUX_WRITEFIFO_REG,
+					      data[i]);
+			}
+		}
+
+		reg = cmd << XDPTX_AUXCMD_SHIFT;
+		if (!bytes)
+			reg |= XDPTX_AUXCMD_ADDRONLY_MASK;
+		else
+			reg |= (no_of_bytes - 1) << XDPTX_AUXCMD_BYTES_SHIFT;
+		xlnx_dp_write(dp_base, XDPTX_AUXCMD_REG, reg);
+
+		/* Wait for reply to be delivered upto 2ms */
+		for (i = 0; ; i++) {
+			reg = xlnx_dp_read(dp_base, XDPTX_INTR_SIGSTATE_REG);
+			if (reg & XDPTX_INTR_SIGRPLYSTATE)
+				break;
+
+			if (reg & XDPTX_INTR_RPLYTIMEOUT ||
+			    i == 2)
+				return -ETIMEDOUT;
+
+			usleep_range(1000, 1100);
+		}
+
+		reg = xlnx_dp_read(dp_base, XDPTX_AUXREPLY_CODE_REG);
+		if (reply)
+			*reply = reg;
+
+		if (is_read && !reg) {
+			reg = xlnx_dp_read(dp_base, XDPTX_AUXREPLY_DATACNT_REG);
+			if ((reg & XDPTX_AUXREPLY_DATACNT_MASK) != no_of_bytes)
+				return -EIO;
+
+			for (i = 0; i < no_of_bytes; i++) {
+				data[i] = xlnx_dp_read(dp_base,
+						       XDPTX_AUXREPLY_DATA_REG);
+			}
+		}
+	}
+
+	return 0;
+}
+
+static ssize_t
+xlnx_dp_aux_transfer(struct drm_dp_aux *aux, struct drm_dp_aux_msg *msg)
+{
+	struct xlnx_dp *dp = container_of(aux, struct xlnx_dp, aux);
+	int ret;
+	unsigned int i, iter;
+
+	/* This is to iterate at least 50 msec */
+	iter = 50 * 1000 / 400;
+
+	for (i = 0; i < iter; i++) {
+		ret = xlnx_dp_aux_cmd_submit(dp, msg->request, msg->address,
+					     msg->buffer, msg->size,
+					       &msg->reply);
+		if (!ret) {
+			dev_dbg(dp->dev, "aux %d retries\n", i);
+			return msg->size;
+		}
+
+		if (dp->status == connector_status_disconnected) {
+			dev_info(dp->dev, "no connected aux device\n");
+			return -ENODEV;
+		}
+
+		usleep_range(3200, 3300);
+	}
+
+	dev_info(dp->dev, "failed aux transfer\n");
+
+	return ret;
+}
+
+/**
+ * xlnx_dp_init_aux - Initialize the DP aux
+ * @dp: DisplayPort IP core structure
+ *
+ * Initialize the DP aux. The aux clock is derived from the axi clock, so
+ * this function gets the axi clock frequency and calculates the filter
+ * value. Additionally, the interrupts and transmitter are enabled.
+ *
+ * Return: 0 on success, error value otherwise
+ */
+static int xlnx_dp_init_aux(struct xlnx_dp *dp)
+{
+	unsigned long rate;
+	u32 reg, w;
+
+	rate = clk_get_rate(dp->axi_lite_clk);
+	if (rate < XDPTX_CLKDIV_MHZ) {
+		dev_err(dp->dev, "aclk should be higher than 1MHz\n");
+		return -EINVAL;
+	}
+
+	/* Allowable values for this register are: 8, 16, 24, 32, 40, 48 */
+	for (w = 8; w <= 48; w += 8) {
+		/* AUX pulse width should be between 0.4 to 0.6 usec */
+		if (w >= (4 * rate / 10000000) &&
+		    w <= (6 * rate / 10000000))
+			break;
+	}
+
+	if (w > 48)
+		w = 48;
+
+	reg = w << XDPTX_CLKDIV_AUXFILTER_SHIFT;
+	reg |= rate / XDPTX_CLKDIV_MHZ;
+	xlnx_dp_write(dp->dp_base, XDPTX_CLKDIV_REG, reg);
+
+	xlnx_dp_write(dp->dp_base, XDPTX_ENABLE_REG, 1);
+	return 0;
+}
+
+/**
+ * xlnx_dp_exit_aux - De-initialize the DP aux
+ * @dp: DisplayPort IP core structure
+ *
+ * De-initialize the DP aux. Disable all interrupts which are enabled
+ * through aux initialization, as well as the transmitter.
+ */
+static void xlnx_dp_exit_aux(struct xlnx_dp *dp)
+{
+	xlnx_dp_write(dp->dp_base, XDPTX_ENABLE_REG, 0);
+	xlnx_dp_write(dp->dp_base, XDPTX_INTR_MASK_REG, 0xfff);
+}
+
+/**
+ * xlnx_dp_update_misc - Write the misc registers
+ * @dp: DisplayPort IP core structure
+ *
+ * The misc register values are stored in the structure, and this
+ * function applies the values into the registers.
+ */
+static void xlnx_dp_update_misc(struct xlnx_dp *dp)
+{
+	struct xlnx_dp_config *config = &dp->config;
+
+	if (!dp->colorimetry_through_vsc) {
+		xlnx_dp_write(dp->dp_base, XDPTX_MAINSTRM_MISC0_REG,
+			      config->misc0);
+		xlnx_dp_write(dp->dp_base, XDPTX_MAINSTRM_MISC1_REG, 0x0);
+	} else {
+		xlnx_dp_set(dp->dp_base, XDPTX_MAINSTRM_MISC1_REG,
+			    XDPTX_MAINSTRM_MISC1_TIMING_IGNORED_MASK);
+	}
+}
+
+/**
+ * xlnx_dp_set_sync_mode - Set the sync mode bit in the software misc state
+ * @dp: DisplayPort IP core structure
+ * @mode: flag if the sync mode should be on or off
+ *
+ * Set the bit in software misc state. To apply to hardware,
+ * xlnx_dp_update_misc() should be called.
+ */
+static void xlnx_dp_set_sync_mode(struct xlnx_dp *dp, bool mode)
+{
+	struct xlnx_dp_config *config = &dp->config;
+
+	if (mode)
+		config->misc0 |= XDPTX_MAINSTRM_MISC0_MASK;
+	else
+		config->misc0 &= ~XDPTX_MAINSTRM_MISC0_MASK;
+}
+
+static void xlnx_dp_vsc_pkt_handler(struct xlnx_dp *dp)
+{
+	struct xlnx_dp_vscpkt *vscpkt = &dp->vscpkt;
+	int i;
+
+	if (dp->colorimetry_through_vsc) {
+		xlnx_dp_write(dp->dp_base, XDPTX_AUDIO_EXT_DATA(1),
+			      vscpkt->header);
+		for (i = 0; i < XDPTX_AUDIO_EXT_DATA_2ND_TO_9TH_WORD; i++) {
+			xlnx_dp_write(dp->dp_base, XDPTX_AUDIO_EXT_DATA(i + 2),
+				      vscpkt->payload[i]);
+		}
+	}
+}
+
+static void xlnx_dp_prepare_vsc(struct xlnx_dp *dp)
+{
+	struct xlnx_dp_config *config = &dp->config;
+	struct xlnx_dp_vscpkt *vscpkt = &dp->vscpkt;
+	int i;
+	u32 payload_data = 0, bpc;
+
+	vscpkt->header = XDPTX_VSC_SDP_PIXELENC_HEADER_MASK;
+	payload_data |= config->fmt << XDPTX_VSC_SDP_FMT_SHIFT;
+
+	switch (config->bpc) {
+	case 6:
+		bpc = 0x0;
+		break;
+	case 8:
+		bpc = 0x1;
+		break;
+	case 10:
+		bpc = 0x2;
+		break;
+	case 12:
+		bpc = 0x3;
+		break;
+	case 16:
+		bpc = 0x4;
+		break;
+	default:
+		dev_err(dp->dev, "Not supported bpc (%u). fall back to 8bpc\n",
+			config->bpc);
+		bpc = 0x0;
+	}
+
+	bpc &= XDPTX_VSC_SDP_BPC_MASK;
+	payload_data |= (bpc << XDPTX_VSC_SDP_BPC_SHIFT);
+	/* TODO: it has to be dynamic */
+	payload_data |= (0x1 << XDPTX_VSC_SDP_DYNAMIC_RANGE_SHIFT);
+
+	dev_dbg(dp->dev, "payload_data 0x%x", payload_data);
+
+	/* population vsc payload */
+	for (i = 0; i < 8; i++) {
+		if (i == 4) {
+			vscpkt->payload[i] = payload_data;
+			continue;
+		}
+		vscpkt->payload[i] = 0x0;
+	}
+}
+
+/**
+ * xlnx_dp_set_bpc - Set bpc value in software misc state
+ * @dp: DisplayPort IP core structure
+ * @bpc: bits per component
+ *
+ * Return: 0 on success, or the fallback bpc value
+ */
+static u32 xlnx_dp_set_bpc(struct xlnx_dp *dp, u8 bpc)
+{
+	struct xlnx_dp_config *config = &dp->config;
+	unsigned int ret = 0;
+
+	if (dp->connector.display_info.bpc &&
+	    dp->connector.display_info.bpc != bpc) {
+		dev_err(dp->dev, "requested bpc (%u) != display info (%u)\n",
+			bpc, dp->connector.display_info.bpc);
+		bpc = dp->connector.display_info.bpc;
+	}
+
+	config->misc0 &= ~XDPTX_MISC0_BPC_MASK;
+	switch (bpc) {
+	case 6:
+		config->misc0 |= XDPTX_MISC0_BPC6_MASK;
+		break;
+	case 8:
+		config->misc0 |= XDPTX_MISC0_BPC8_MASK;
+		break;
+	case 10:
+		config->misc0 |= XDPTX_MISC0_BPC10_MASK;
+		break;
+	case 12:
+		config->misc0 |= XDPTX_MISC0_BPC12_MASK;
+		break;
+	case 16:
+		config->misc0 |= XDPTX_MISC0_BPC16_MASK;
+		break;
+	default:
+		dev_err(dp->dev, "Not supported bpc (%u). fall back to 8bpc\n",
+			bpc);
+		config->misc0 |= XDPTX_MISC0_BPC8_MASK;
+		ret = 8;
+	}
+	config->bpc = bpc;
+	xlnx_dp_update_bpp(dp);
+
+	return ret;
+}
+
+/**
+ * xlnx_dp_encoder_mode_set_transfer_unit - Set the transfer unit values
+ * @dp: DisplayPort IP core structure
+ * @mode: requested display mode
+ *
+ * Set the transfer unit, and calculate all transfer unit size related values.
+ * Calculation is based on DP and IP core specification.
+ */
+static void
+xlnx_dp_encoder_mode_set_transfer_unit(struct xlnx_dp *dp,
+				       struct drm_display_mode *mode)
+{
+	struct xlnx_dp_config *config = &dp->config;
+	u32 tu = XDPTX_DEF_TRANSFER_UNITSIZE, temp;
+	u32 bw, vid_kbytes, avg_bytes_per_tu, init_wait, min_bytes_per_tu;
+
+	/* Use the max transfer unit size (default) */
+	xlnx_dp_write(dp->dp_base, XDPTX_TRANSFER_UNITSIZE_REG, tu);
+
+	vid_kbytes = (mode->clock / 1000) * (dp->config.bpp / 8);
+	bw = drm_dp_bw_code_to_link_rate(dp->mode.bw_code);
+	avg_bytes_per_tu = vid_kbytes * tu / (dp->mode.lane_cnt * bw);
+	min_bytes_per_tu = avg_bytes_per_tu / 1000;
+	xlnx_dp_write(dp->dp_base, XDPTX_MINBYTES_PERTU_REG,
+		      min_bytes_per_tu);
+
+	temp = (avg_bytes_per_tu % 1000) * 1024 / 1000;
+	xlnx_dp_write(dp->dp_base, XDPTX_FRACBYTES_PERTU_REG, temp);
+
+	init_wait = tu - min_bytes_per_tu;
+
+	/* Configure the initial wait cycle based on transfer unit size */
+	if (min_bytes_per_tu <= 4)
+		init_wait = tu;
+	else if ((config->misc0 & XDPTX_MISC0_YCRCB422_MASK) ==
+		XDPTX_MISC0_YCRCB422_MASK)
+		init_wait = init_wait / 2;
+
+	xlnx_dp_write(dp->dp_base, XDPTX_INIT_WAIT_REG, init_wait);
+}
+
+/**
+ * xlnx_dp_encoder_mode_set_stream - Configure the main stream
+ * @dp: DisplayPort IP core structure
+ * @mode: requested display mode
+ *
+ * Configure the main stream based on the requested mode @mode. Calculation is
+ * based on IP core specification.
+ */
+static void xlnx_dp_encoder_mode_set_stream(struct xlnx_dp *dp,
+					    struct drm_display_mode *mode)
+{
+	void __iomem *dp_base = dp->dp_base;
+	u32 reg, wpl, ppc;
+	u8 lane_cnt = dp->mode.lane_cnt;
+
+	xlnx_dp_write(dp_base, XDPTX_MAINSTRM_HTOTAL_REG, mode->htotal);
+	xlnx_dp_write(dp_base, XDPTX_MAINSTRM_VTOTAL_REG, mode->vtotal);
+
+	xlnx_dp_write(dp_base, XDPTX_MAINSTRM_POL_REG,
+		      (!!(mode->flags & DRM_MODE_FLAG_PVSYNC) <<
+		      XDPTX_MAINSTRM_POLVSYNC_SHIFT) |
+		      (!!(mode->flags & DRM_MODE_FLAG_PHSYNC) <<
+		      XDPTX_MAINSTRM_POLHSYNC_SHIFT));
+
+	xlnx_dp_write(dp_base, XDPTX_MAINSTRM_HSWIDTH_REG,
+		      mode->hsync_end - mode->hsync_start);
+	xlnx_dp_write(dp_base, XDPTX_MAINSTRM_VSWIDTH_REG,
+		      mode->vsync_end - mode->vsync_start);
+	xlnx_dp_write(dp_base, XDPTX_MAINSTRM_HRES_REG, mode->hdisplay);
+	xlnx_dp_write(dp_base, XDPTX_MAINSTRM_VRES_REG, mode->vdisplay);
+
+	xlnx_dp_write(dp_base, XDPTX_MAINSTRM_HSTART_REG,
+		      mode->htotal - mode->hsync_start);
+	xlnx_dp_write(dp_base, XDPTX_MAINSTRM_VSTART_REG,
+		      mode->vtotal - mode->vsync_start);
+	xlnx_dp_update_misc(dp);
+
+	if (mode->clock > 530000)
+		ppc = 4;
+	else if (mode->clock > 270000)
+		ppc = 2;
+	else
+		ppc = 1;
+
+	xlnx_dp_write(dp_base, XDPTX_USER_PIXELWIDTH_REG, ppc);
+	dp->config.ppc = ppc;
+
+	xlnx_dp_write(dp_base, XDPTX_M_VID_REG, mode->clock);
+	reg = drm_dp_bw_code_to_link_rate(dp->mode.bw_code);
+	xlnx_dp_write(dp_base, XDPTX_N_VID_REG, reg);
+
+	/* In synchronous mode, set the dividers */
+	if (dp->config.misc0 & XDPTX_MAINSTRM_MISC0_MASK) {
+		reg = drm_dp_bw_code_to_link_rate(dp->mode.bw_code);
+		xlnx_dp_write(dp_base, XDPTX_N_VID_REG, reg);
+		xlnx_dp_write(dp_base, XDPTX_M_VID_REG, mode->clock);
+	}
+
+	wpl = (mode->hdisplay * dp->config.bpp + 15) / 16;
+	reg = wpl + wpl % lane_cnt - lane_cnt;
+	xlnx_dp_write(dp_base, XDPTX_USER_DATACNTPERLANE_REG, reg);
+}
+
+static void xlnx_dp_mainlink_en(struct xlnx_dp *dp, u8 enable)
+{
+	xlnx_dp_write(dp->dp_base, XDPTX_SCRAMBLER_RESET,
+		      XDPTX_SCRAMBLER_RESET_MASK);
+	xlnx_dp_write(dp->dp_base, XDPTX_MAINSTRM_ENABLE_REG, enable);
+}
+
+static int xlnx_dp_power_cycle(struct xlnx_dp *dp)
+{
+	int ret = 0, i;
+	u8 value;
+
+	/* sink Power cycle */
+	for (i = 0; i < XDPTX_SINK_PWR_CYCLES; i++) {
+		ret = drm_dp_dpcd_readb(&dp->aux, DP_SET_POWER, &value);
+
+		value &= ~DP_SET_POWER_MASK;
+		value |= DP_SET_POWER_D3;
+		ret = drm_dp_dpcd_writeb(&dp->aux, DP_SET_POWER, value);
+
+		usleep_range(300, 400);
+		value &= ~DP_SET_POWER_MASK;
+		value |= DP_SET_POWER_D0;
+		ret = drm_dp_dpcd_writeb(&dp->aux, DP_SET_POWER, value);
+		usleep_range(300, 400);
+		ret = drm_dp_dpcd_writeb(&dp->aux, DP_SET_POWER, value);
+		if (ret == 1)
+			break;
+		usleep_range(3000, 4000);
+	}
+
+	if (ret < 0) {
+		dev_err(dp->dev, "DP aux failed\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+/**
+ * xlnx_dp_start - start the DisplayPort core
+ * @dp: DisplayPort IP core structure
+ *
+ * This function trains the DisplayPort link based on the sink capabilities and
+ * enables the main link.
+ */
+static void xlnx_dp_start(struct xlnx_dp *dp)
+{
+	struct xlnx_dp_mode *mode = &dp->mode;
+	struct xlnx_hdcptx *dptxhdcp = &dp->tx_hdcp;
+	int link_rate = dp->link_config.link_rate;
+	int ret = 0;
+	u32 val, intr_mask;
+	u8 data;
+	bool enhanced;
+
+	mode->bw_code = drm_dp_link_rate_to_bw_code(link_rate);
+	mode->lane_cnt = dp->link_config.lane_count;
+	dp->link_config.cr_done_oldstate = dp->link_config.max_lanes;
+
+	xlnx_dp_init_aux(dp);
+	if (dp->status != connector_status_connected) {
+		dev_info(dp->dev, "Display not connected\n");
+		return;
+	}
+
+	xlnx_dp_power_cycle(dp);
+	xlnx_dp_write(dp->dp_base, XDPTX_ENABLE_REG, 0);
+	/*
+	 * Give a bit of time for DP IP after monitor came up and starting
+	 * link training
+	 */
+	msleep(100);
+	xlnx_dp_write(dp->dp_base, XDPTX_ENABLE_REG, 1);
+
+	ret = xlnx_dp_set_linkrate(dp, mode->bw_code);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to set link rate\n");
+		return;
+	}
+
+	ret = xlnx_dp_set_lanecount(dp, mode->lane_cnt);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to set lane count\n");
+		return;
+	}
+
+	/* Disable MST mode in both the RX and TX */
+	ret = drm_dp_dpcd_writeb(&dp->aux, DP_MSTM_CTRL, 0);
+	if (ret < 0) {
+		dev_dbg(dp->dev, "DPCD write failed");
+		return;
+	}
+	xlnx_dp_write(dp->dp_base, XDPTX_MST_CONFIG, 0x0);
+
+	/* Disable main link during training. */
+	val = xlnx_dp_read(dp->dp_base, XDPTX_MAINSTRM_ENABLE_REG);
+	if (val)
+		xlnx_dp_mainlink_en(dp, 0x0);
+
+	/* Disable HPD pulse interrupts during link training */
+	intr_mask = xlnx_dp_read(dp->dp_base, XDPTX_INTR_MASK_REG);
+	xlnx_dp_write(dp->dp_base, XDPTX_INTR_MASK_REG,
+		      intr_mask | XDPTX_INTR_HPDPULSE_MASK);
+
+	/* Enable clock spreading for both DP TX and RX device */
+	drm_dp_dpcd_readb(&dp->aux, DP_DOWNSPREAD_CTRL, &data);
+	if (dp->dpcd[DP_MAX_DOWNSPREAD] & 0x1) {
+		xlnx_dp_write(dp->dp_base, XDPTX_DOWNSPREAD_CTL_REG, 1);
+		data |=  XDPTX_DPCD_SPREAD_AMP_MASK;
+	} else {
+		xlnx_dp_write(dp->dp_base, XDPTX_DOWNSPREAD_CTL_REG, 0);
+		data &= ~XDPTX_DPCD_SPREAD_AMP_MASK;
+	}
+	drm_dp_dpcd_writeb(&dp->aux, DP_DOWNSPREAD_CTRL, data);
+
+	/* Enahanced framing model */
+	drm_dp_dpcd_readb(&dp->aux, DP_LANE_COUNT_SET, &data);
+	enhanced = drm_dp_enhanced_frame_cap(dp->dpcd);
+	if (enhanced) {
+		xlnx_dp_write(dp->dp_base, XDPTX_EFRAME_EN_REG, 1);
+		data |= DP_LANE_COUNT_ENHANCED_FRAME_EN;
+	}
+
+	ret = drm_dp_dpcd_writeb(&dp->aux, DP_LANE_COUNT_SET, data);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to set lane count\n");
+		return;
+	}
+	/* set channel encoding */
+	ret = drm_dp_dpcd_writeb(&dp->aux, DP_MAIN_LINK_CHANNEL_CODING_SET,
+				 DP_SET_ANSI_8B10B);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to set ANSI 8B/10B encoding\n");
+		return;
+	}
+	/* Reset PHY */
+	xlnx_dp_phy_reset(dp, XDPTX_PHYCONFIG_RESET_MASK);
+
+	/* Wait for PHY ready */
+	ret = xlnx_dp_phy_ready(dp);
+	if (ret < 0)
+		return;
+
+	memset(dp->train_set, 0, XDPTX_MAX_LANES);
+
+	ret = xlnx_dp_run_training(dp);
+	if (ret < 0) {
+		dev_err(dp->dev, "DP Link Training Failed\n");
+		return;
+	}
+
+	ret = xlnx_dp_post_training(dp);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed post trining settings\n");
+		return;
+	}
+
+	/* re-enable main link after training if required */
+	if (val)
+		xlnx_dp_mainlink_en(dp, 0x1);
+	/* Enable HDP interrupts after link training */
+	xlnx_dp_write(dp->dp_base, XDPTX_INTR_MASK_REG, intr_mask);
+
+	dev_dbg(dp->dev, "Training done:");
+
+	/* reset the transmitter */
+	xlnx_dp_write(dp->dp_base, XDPTX_SOFT_RST,
+		      XDPTX_SOFT_RST_VIDEO_STREAM_ALL_MASK |
+		      XDPTX_SOFT_RST_HDCP_MASK);
+	xlnx_dp_write(dp->dp_base, XDPTX_SOFT_RST, 0x0);
+
+	/* Enable VTC and MainStream */
+	xlnx_dp_set(dp->dp_base, dp->vtc_off + XDPTX_VTC_CTL,
+		    XDPTX_VTC_CTL_GE);
+	xlnx_dp_mainlink_en(dp, 0x1);
+
+	ret = xlnx_dp_check_link_status(dp);
+	if (ret < 0) {
+		dev_err(dp->dev, "Link is DOWN after main link enabled!\n");
+		return;
+	}
+	if (dp->config.hdcp2x_enable || dp->config.hdcp1x_enable) {
+		if (dp->config.hdcp2x_enable) {
+			xlnx_dp_set(dp->dp_base, XDP_TX_HDCP2x_ENABLE,
+				    XDP_TX_HDCP2x_ENABLE_BYPASS_DISABLE_MASK);
+		}
+		if (dp->config.hdcp1x_enable) {
+			val  = xlnx_dp_read(dp->dp_base, XDP_TX_HDCP1X_ENABLE);
+			val |= XDP_TX_HDCP1X_ENABLE_BYPASS_DISABLE_MASK;
+			xlnx_dp_write(dp->dp_base, XDP_TX_HDCP1X_ENABLE, val);
+		}
+		ret = xlnx_start_hdcp_engine(dptxhdcp, mode->lane_cnt);
+		if (ret < 0) {
+			dev_err(dp->dev, "Failed to Start HDCP\n");
+			return;
+		}
+	}
+
+	if (dp->colorimetry_through_vsc) {
+		/* program the VSC extended packet */
+		xlnx_dp_vsc_pkt_handler(dp);
+		/* This ensures that VSC pkt is sent every frame */
+		xlnx_dp_set(dp->dp_base, XDPTX_MAINSTRM_MISC0_REG,
+			    XDPTX_MAINSTRM_MISC0_EXT_VSYNC_MASK);
+	}
+	/* enable audio */
+	xlnx_dp_set(dp->dp_base, XDPTX_AUDIO_CTRL_REG, 0x1);
+	/* Enabling TX interrupts */
+	xlnx_dp_write(dp->dp_base, XDPTX_INTR_MASK_REG, 0);
+}
+
+/**
+ * xlnx_dp_hdcp_reset - Reset HDCP module
+ * @dp: DisplayPort IP core structure
+ *
+ * This function resets HDCP cipher engine,
+ * protocol state machine and its internal parameters.
+ *
+ * Return: 0 on success, or the error code returned
+ * from the callee functions.
+ */
+static int xlnx_dp_hdcp_reset(struct xlnx_dp *dp)
+{
+	struct xlnx_hdcptx *dptxhdcp = &dp->tx_hdcp;
+	int ret;
+
+	cancel_delayed_work(&dp->hdcp_cp_irq_work);
+	ret = xlnx_hdcp_tx_reset(dptxhdcp);
+	if (ret < 0) {
+		dev_dbg(dp->dev, "failed to reset HDCP Cipher Engine");
+		return ret;
+	}
+
+	return 0;
+}
+
+/**
+ * xlnx_dp_stop - stop the DisplayPort core
+ * @dp: DisplayPort IP core structure
+ *
+ * This function disables the DisplayPort main link and VTC.
+ */
+static void xlnx_dp_stop(struct xlnx_dp *dp)
+{
+	struct phy_configure_opts_dp *phy_cfg = &dp->phy_opts.dp;
+
+	xlnx_dp_write(dp->dp_base, XDPTX_MAINSTRM_ENABLE_REG, 0);
+
+	/* Disabling the audio in dp core */
+	xlnx_dp_clr(dp->dp_base, XDPTX_AUDIO_CTRL_REG, 0);
+
+	/* set Vs and Pe to 0, 0 on cable disconnect */
+	phy_cfg->pre[0] = 0;
+	phy_cfg->voltage[0] = 0;
+	phy_cfg->set_voltages = 1;
+
+	if (!dp->config.versal_gt_present)
+		phy_configure(dp->phy[0], &dp->phy_opts);
+	else
+		xlnx_dp_tx_pe_vs_adjust_handler(dp, &dp->phy_opts.dp);
+
+	/* Disable VTC */
+	xlnx_dp_clr(dp->dp_base, dp->vtc_off + XDPTX_VTC_CTL,
+		    XDPTX_VTC_CTL_GE);
+	/* Reset HDCP Engine. */
+	if (dp->config.hdcp2x_enable || dp->config.hdcp1x_enable)
+		xlnx_dp_hdcp_reset(dp);
+}
+
+static int xlnx_dp_txconnected(struct xlnx_dp *dp)
+{
+	u32 status;
+	u8 retries = 0;
+
+	do {
+		status = xlnx_dp_read(dp->dp_base,
+				      XDPTX_INTR_SIGSTATE_REG) & 0x1;
+		if (retries > 5)
+			return false;
+		retries++;
+		usleep_range(1000, 1100);
+	} while (status == 0);
+
+	return true;
+}
+
+/*
+ * DRM connector functions
+ */
+static enum drm_connector_status
+xlnx_dp_connector_detect(struct drm_connector *connector, bool force)
+{
+	struct xlnx_dp *dp = connector_to_dp(connector);
+	struct xlnx_dp_link_config *link_config = &dp->link_config;
+	struct xlnx_dp_mode *mode = &dp->mode;
+	int ret;
+	u8 dpcd_ext[DP_RECEIVER_CAP_SIZE];
+	u8 max_link_rate, ext_cap_rd = 0, data;
+
+	if (!xlnx_dp_txconnected(dp)) {
+		dev_dbg(dp->dev, "Display is not connected");
+		goto disconnected;
+	}
+
+	/* Reading the Ext capability for compliance */
+	ret = drm_dp_dpcd_read(&dp->aux, DP_DP13_DPCD_REV, dpcd_ext,
+			       sizeof(dpcd_ext));
+	if ((dp->dpcd[6] & 0x1) == 0x1) {
+		ret = drm_dp_dpcd_read(&dp->aux, DP_DOWNSTREAM_PORT_0,
+				       dpcd_ext, sizeof(dpcd_ext));
+	}
+
+	ret = drm_dp_dpcd_read(&dp->aux, DP_DPCD_REV, dp->dpcd,
+			       sizeof(dp->dpcd));
+	if (ret < 0) {
+		dev_dbg(dp->dev, "DPCD read first try fails");
+		ret = drm_dp_dpcd_read(&dp->aux, DP_DPCD_REV, dp->dpcd,
+				       sizeof(dp->dpcd));
+		if (ret < 0) {
+			dev_info(dp->dev, "DPCD read failes");
+			goto disconnected;
+		}
+	}
+	/* set MaxLinkRate to TX rate, if sink provides a non-standard value */
+	if (dp->dpcd[DP_MAX_LINK_RATE] != DP_LINK_BW_8_1 &&
+	    dp->dpcd[DP_MAX_LINK_RATE] != DP_LINK_BW_5_4 &&
+	    dp->dpcd[DP_MAX_LINK_RATE] != DP_LINK_BW_2_7 &&
+	    dp->dpcd[DP_MAX_LINK_RATE] != DP_LINK_BW_1_62) {
+		dp->dpcd[DP_MAX_LINK_RATE] = DP_LINK_BW_8_1;
+	}
+
+	if (dp->dpcd[DP_TRAINING_AUX_RD_INTERVAL] &
+	    DP_EXTENDED_RECEIVER_CAP_FIELD_PRESENT) {
+		ret = drm_dp_dpcd_read(&dp->aux, DP_DP13_MAX_LINK_RATE,
+				       &max_link_rate, 1);
+		if (ret < 0) {
+			dev_dbg(dp->dev, "DPCD read failed");
+			goto disconnected;
+		}
+
+		if (max_link_rate == DP_LINK_BW_8_1)
+			dp->dpcd[DP_MAX_LINK_RATE] = DP_LINK_BW_8_1;
+
+		/* compliance: UCD400 required reading these extended registers */
+		ret = drm_dp_dpcd_read(&dp->aux, DP_DP13_MAX_LINK_RATE,
+				       &ext_cap_rd, 1);
+		ret = drm_dp_dpcd_read(&dp->aux, DP_SINK_COUNT_ESI,
+				       &ext_cap_rd, 1);
+		ret = drm_dp_dpcd_read(&dp->aux,
+				       DP_DEVICE_SERVICE_IRQ_VECTOR_ESI0,
+				       &ext_cap_rd, 1);
+		ret = drm_dp_dpcd_read(&dp->aux, DP_LANE0_1_STATUS_ESI,
+				       &ext_cap_rd, 1);
+		ret = drm_dp_dpcd_read(&dp->aux, DP_LANE2_3_STATUS_ESI,
+				       &ext_cap_rd, 1);
+		ret = drm_dp_dpcd_read(&dp->aux,
+				       DP_LANE_ALIGN_STATUS_UPDATED_ESI,
+				       &ext_cap_rd, 1);
+		ret = drm_dp_dpcd_read(&dp->aux, DP_SINK_STATUS_ESI,
+				       &ext_cap_rd, 1);
+		if (ret < 0)
+			dev_dbg(dp->dev, "DPCD read fails");
+	}
+
+	link_config->max_rate = min_t(int,
+				      drm_dp_max_link_rate(dp->dpcd),
+				      dp->config.max_link_rate);
+	link_config->max_lanes = min_t(u8,
+				       drm_dp_max_lane_count(dp->dpcd),
+				       dp->config.max_lanes);
+	link_config->link_rate = link_config->max_rate;
+	link_config->lane_count = link_config->max_lanes;
+	mode->lane_cnt = link_config->max_lanes;
+	mode->bw_code = drm_dp_link_rate_to_bw_code(link_config->link_rate);
+
+	ret = drm_dp_dpcd_readb(&dp->aux, DP_DPRX_FEATURE_ENUMERATION_LIST,
+				&data);
+	if (ret < 0) {
+		dev_dbg(dp->dev, "DPCD read failed");
+		goto disconnected;
+	}
+	dp->status = connector_status_connected;
+
+	if (data & DP_VSC_SDP_EXT_FOR_COLORIMETRY_SUPPORTED)
+		dp->colorimetry_through_vsc = true;
+	else
+		dp->colorimetry_through_vsc = false;
+
+	if (dp->enabled) {
+		xlnx_dp_stop(dp);
+		xlnx_dp_start(dp);
+	}
+
+	return connector_status_connected;
+disconnected:
+	dp->status = connector_status_disconnected;
+	if (dp->enabled)
+		xlnx_dp_stop(dp);
+
+	return connector_status_disconnected;
+}
+
+static int xlnx_dp_connector_get_modes(struct drm_connector *connector)
+{
+	struct xlnx_dp *dp = connector_to_dp(connector);
+	struct edid *edid;
+	int ret;
+
+	edid = drm_get_edid(connector, &dp->aux.ddc);
+	if (!edid) {
+		drm_connector_update_edid_property(connector, NULL);
+		dp->have_edid = false;
+		return 0;
+	}
+
+	drm_connector_update_edid_property(connector, edid);
+	ret = drm_add_edid_modes(connector, edid);
+	dp->have_edid = true;
+	kfree(edid);
+
+	return ret;
+}
+
+static struct drm_encoder *
+xlnx_dp_connector_best_encoder(struct drm_connector *connector)
+{
+	struct xlnx_dp *dp = connector_to_dp(connector);
+
+	return &dp->encoder;
+}
+
+static int xlnx_dp_connector_mode_valid(struct drm_connector *connector,
+					struct drm_display_mode *mode)
+{
+	struct xlnx_dp *dp = connector_to_dp(connector);
+	u8 max_lanes = dp->link_config.max_lanes;
+	u8 bpp = dp->config.bpp;
+	int max_rate = dp->link_config.max_rate;
+	int rate;
+
+	if (mode->clock > XDPTX_MAX_FREQ) {
+		dev_info(dp->dev, "filtered the mode, %s,for high pixel rate\n",
+			 mode->name);
+		drm_mode_debug_printmodeline(mode);
+		return MODE_CLOCK_HIGH;
+	}
+
+	/* check with link rate and lane count */
+	rate = XDPTX_MAX_RATE(max_rate, max_lanes, bpp);
+	if (mode->clock > rate) {
+		dev_dbg(dp->dev, "filtered the mode, %s,for high pixel rate\n",
+			mode->name);
+		drm_mode_debug_printmodeline(mode);
+
+		return MODE_CLOCK_HIGH;
+	}
+
+	return MODE_OK;
+}
+
+static void xlnx_dp_connector_destroy(struct drm_connector *connector)
+{
+	drm_connector_unregister(connector);
+	drm_connector_cleanup(connector);
+}
+
+static int
+xlnx_dp_connector_atomic_set_property(struct drm_connector *connector,
+				      struct drm_connector_state *state,
+				      struct drm_property *property,
+				      uint64_t val)
+{
+	struct xlnx_dp *dp = connector_to_dp(connector);
+	unsigned int bpc;
+
+	if (property == dp->sync_prop) {
+		xlnx_dp_set_sync_mode(dp, val);
+	} else if (property == dp->bpc_prop) {
+		bpc = xlnx_dp_set_bpc(dp, val);
+		if (bpc) {
+			drm_object_property_set_value(&connector->base,
+						      property, bpc);
+			return -EINVAL;
+		}
+	} else {
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int
+xlnx_dp_connector_atomic_get_property(struct drm_connector *connector,
+				      const struct drm_connector_state *state,
+					struct drm_property *property,
+					uint64_t *val)
+{
+	struct xlnx_dp *dp = connector_to_dp(connector);
+
+	if (property == dp->sync_prop)
+		*val = (dp->config.misc0 & XDPTX_MAINSTRM_MISC0_MASK);
+	else if (property == dp->bpc_prop)
+		*val = dp->config.bpc;
+	else
+		return -EINVAL;
+
+	return 0;
+}
+
+static const struct drm_connector_funcs xlnx_dp_connector_funcs = {
+	.detect			= xlnx_dp_connector_detect,
+	.fill_modes		= drm_helper_probe_single_connector_modes,
+	.destroy		= xlnx_dp_connector_destroy,
+	.atomic_duplicate_state	= drm_atomic_helper_connector_duplicate_state,
+	.atomic_destroy_state	= drm_atomic_helper_connector_destroy_state,
+	.reset			= drm_atomic_helper_connector_reset,
+	.atomic_set_property	= xlnx_dp_connector_atomic_set_property,
+	.atomic_get_property	= xlnx_dp_connector_atomic_get_property,
+};
+
+static struct drm_connector_helper_funcs xlnx_dp_connector_helper_funcs = {
+	.get_modes	= xlnx_dp_connector_get_modes,
+	.best_encoder	= xlnx_dp_connector_best_encoder,
+	.mode_valid	= xlnx_dp_connector_mode_valid,
+};
+
+static int xlnx_dp_get_eld(struct device *dev, u8 *buf, size_t len)
+{
+	struct xlnx_dp *dp = dev_get_drvdata(dev);
+	size_t size;
+
+	if (!dp->have_edid)
+		return -EIO;
+
+	size = drm_eld_size(dp->connector.eld);
+	if (!size)
+		return -EINVAL;
+
+	if (len < size)
+		size = len;
+	memcpy(buf, dp->connector.eld, size);
+
+	return 0;
+}
+
+static unsigned long dp_codec_spk_mask_from_alloc(int spk_alloc)
+{
+	int i;
+	static const unsigned long dp_codec_eld_spk_alloc_bits[] = {
+		[0] = FL | FR, [1] = LFE, [2] = FC, [3] = RL | RR,
+		[4] = RC, [5] = FLC | FRC, [6] = RLC | RRC,
+	};
+	unsigned long spk_mask = 0;
+
+	for (i = 0; i < ARRAY_SIZE(dp_codec_eld_spk_alloc_bits); i++) {
+		if (spk_alloc & (1 << i))
+			spk_mask |= dp_codec_eld_spk_alloc_bits[i];
+	}
+
+	return spk_mask;
+}
+
+static int dp_codec_get_ch_alloc_table_idx(u8 *eld, u8 channels)
+{
+	int i;
+	u8 spk_alloc;
+	unsigned long spk_mask;
+	const struct dp_codec_cea_spk_alloc *cap = dp_codec_channel_alloc;
+
+	spk_alloc = drm_eld_get_spk_alloc(eld);
+	spk_mask = dp_codec_spk_mask_from_alloc(spk_alloc);
+
+	for (i = 0; i < ARRAY_SIZE(dp_codec_channel_alloc); i++, cap++) {
+		/* If spk_alloc == 0, DP is unplugged return stereo config */
+		if (!spk_alloc && cap->ca_id == 0)
+			return i;
+		if (cap->n_ch != channels)
+			continue;
+		if (!(cap->mask == (spk_mask & cap->mask)))
+			continue;
+		return i;
+	}
+
+	return -EINVAL;
+}
+
+static int dp_codec_fill_cea_params(struct snd_pcm_substream *substream,
+				    struct snd_soc_dai *dai,
+				    unsigned int channels,
+				    struct hdmi_audio_infoframe *cea)
+{
+	int idx;
+	int ret;
+	u8 eld[MAX_ELD_BYTES];
+
+	ret = xlnx_dp_get_eld(dai->dev, eld, sizeof(eld));
+	if (ret)
+		return ret;
+
+	ret = snd_pcm_hw_constraint_eld(substream->runtime, eld);
+	if (ret)
+		return ret;
+
+	/* Select a channel allocation that matches with ELD and pcm channels */
+	idx = dp_codec_get_ch_alloc_table_idx(eld, channels);
+	if (idx < 0) {
+		dev_err(dai->dev, "Not able to map channels to speakers (%d)\n",
+			idx);
+		return idx;
+	}
+
+	hdmi_audio_infoframe_init(cea);
+	cea->channels = channels;
+	cea->coding_type = HDMI_AUDIO_CODING_TYPE_STREAM;
+	cea->sample_size = HDMI_AUDIO_SAMPLE_SIZE_STREAM;
+	cea->sample_frequency = HDMI_AUDIO_SAMPLE_FREQUENCY_STREAM;
+	cea->channel_allocation = dp_codec_channel_alloc[idx].ca_id;
+
+	return 0;
+}
+
+/**
+ * xlnx_tx_pcm_startup - initialize audio during audio usecase
+ * @substream: PCM substream
+ * @dai: runtime dai data
+ *
+ * This function is called by ALSA framework before audio
+ * playback begins. This callback initializes audio.
+ *
+ * Return: 0 on success
+ */
+static int xlnx_tx_pcm_startup(struct snd_pcm_substream *substream,
+			       struct snd_soc_dai *dai)
+{
+	struct xlnx_dp *dp = dev_get_drvdata(dai->dev);
+
+	/* Enabling the audio in dp core */
+	xlnx_dp_clr(dp->dp_base, XDPTX_AUDIO_CTRL_REG, XDPTX_AUDIO_EN_MASK);
+
+	xlnx_dp_set(dp->dp_base, XDPTX_AUDIO_CTRL_REG, XDPTX_AUDIO_EN_MASK);
+
+	return 0;
+}
+
+/**
+ * xlnx_tx_pcm_hw_params - sets the playback stream properties
+ * @substream: PCM substream
+ * @params: PCM stream hardware parameters
+ * @dai: runtime dai data
+ *
+ * This function is called by ALSA framework after startup callback
+ * packs the audio infoframe from stream paremters and programs ACR
+ * block
+ *
+ * Return: 0 on success
+ */
+static int xlnx_tx_pcm_hw_params(struct snd_pcm_substream *substream,
+				 struct snd_pcm_hw_params *params,
+				 struct snd_soc_dai *dai)
+{
+	struct hdmi_audio_infoframe infoframe;
+	struct xlnx_dp *dp = dev_get_drvdata(dai->dev);
+	int ret;
+	u8 infopckt[DP_INFOFRAME_SIZE(AUDIO)] = {0};
+	u8 *ptr = (u8 *)dp->tx_audio_data->buffer;
+
+	ret = dp_codec_fill_cea_params(substream, dai,
+				       params_channels(params),
+				       &infoframe);
+	if (ret < 0)
+		return ret;
+
+	/* Setting audio channels */
+	xlnx_dp_write(dp->dp_base, XDPTX_AUDIO_CHANNELS_REG,
+		      infoframe.channels - 1);
+
+	hdmi_audio_infoframe_pack(&infoframe, infopckt,
+				  DP_INFOFRAME_SIZE(AUDIO));
+	/* Setting audio infoframe packet header. Please refer to PG 299 */
+	ptr[0] = 0x00;
+	ptr[1] = 0x84;
+	ptr[2] = 0x1B;
+	ptr[3] = 0x44;
+	memcpy((void *)(&ptr[4]), (void *)(&infopckt[4]),
+	       (DP_INFOFRAME_SIZE(AUDIO) - DP_INFOFRAME_HEADER_SIZE));
+
+	return 0;
+}
+
+/**
+ * xlnx_tx_pcm_shutdown - Deinitialze audio when audio usecase is stopped
+ * @substream: PCM substream
+ * @dai: runtime dai data
+ *
+ * This function is called by ALSA framework before audio playback usecase
+ * ends.
+ */
+static void xlnx_tx_pcm_shutdown(struct snd_pcm_substream *substream,
+				 struct snd_soc_dai *dai)
+{
+	struct xlnx_dp *dp = dev_get_drvdata(dai->dev);
+
+	/* Disabling the audio in dp core */
+	xlnx_dp_clr(dp->dp_base, XDPTX_AUDIO_CTRL_REG, XDPTX_AUDIO_EN_MASK);
+}
+
+/**
+ * xlnx_tx_pcm_digital_mute - mute or unmute audio
+ * @dai: runtime dai data
+ * @enable: enable or disable mute
+ * @direction: direction to enable mute (capture/playback)
+ *
+ * This function is called by ALSA framework before audio usecase
+ * starts and before audio usecase ends
+ *
+ * Return: 0 on success
+ */
+static int xlnx_tx_pcm_digital_mute(struct snd_soc_dai *dai, int enable,
+				    int direction)
+{
+	struct xlnx_dp *dp = dev_get_drvdata(dai->dev);
+
+	if (enable)
+		xlnx_dp_set(dp->dp_base, XDPTX_AUDIO_CTRL_REG, XDPTX_AUDIO_MUTE_MASK);
+	else
+		xlnx_dp_clr(dp->dp_base, XDPTX_AUDIO_CTRL_REG, XDPTX_AUDIO_MUTE_MASK);
+
+	return 0;
+}
+
+static const struct snd_soc_dai_ops xlnx_dp_tx_dai_ops = {
+	.startup = xlnx_tx_pcm_startup,
+	.hw_params = xlnx_tx_pcm_hw_params,
+	.shutdown = xlnx_tx_pcm_shutdown,
+	.mute_stream = xlnx_tx_pcm_digital_mute,
+	.no_capture_mute = 1,
+};
+
+static struct snd_soc_dai_driver xlnx_dp_tx_dai = {
+	.name = "xlnx_dp_tx",
+	.playback = {
+		.stream_name = "I2S Playback",
+		.channels_min = 2,
+		.channels_max = 8,
+		.rates = DP_RATES,
+		.formats = I2S_FORMATS,
+		.sig_bits = 24,
+	},
+	.ops = &xlnx_dp_tx_dai_ops,
+};
+
+static int xlnx_tx_codec_probe(struct snd_soc_component *component)
+{
+	return 0;
+}
+
+static void xlnx_tx_codec_remove(struct snd_soc_component *component)
+{
+}
+
+static const struct snd_soc_component_driver xlnx_dp_component = {
+	.probe = xlnx_tx_codec_probe,
+	.remove = xlnx_tx_codec_remove,
+};
+
+static int dptx_register_aud_dev(struct device *dev)
+{
+	return devm_snd_soc_register_component(dev, &xlnx_dp_component,
+			&xlnx_dp_tx_dai, 1);
+}
+
+static void xlnx_dp_encoder_enable(struct drm_encoder *encoder)
+{
+	struct xlnx_dp *dp = encoder_to_dp(encoder);
+
+	pm_runtime_get_sync(dp->dev);
+
+	if (!dp->enabled) {
+		dp->enabled = true;
+		xlnx_dp_start(dp);
+	}
+}
+
+static void xlnx_dp_encoder_disable(struct drm_encoder *encoder)
+{
+	struct xlnx_dp *dp = encoder_to_dp(encoder);
+
+	if (dp->enabled) {
+		dp->enabled = false;
+		cancel_delayed_work(&dp->hpd_work);
+		cancel_delayed_work(&dp->hpd_pulse_work);
+		xlnx_dp_stop(dp);
+	}
+	pm_runtime_put_sync(dp->dev);
+}
+
+static void
+xlnx_dp_encoder_atomic_mode_set(struct drm_encoder *encoder,
+				struct drm_crtc_state *crtc_state,
+				struct drm_connector_state *connector_state)
+{
+	struct xlnx_dp *dp = encoder_to_dp(encoder);
+	struct drm_display_mode *mode = &crtc_state->mode;
+	struct drm_display_mode *adjusted_mode = &crtc_state->adjusted_mode;
+	int rate, max_rate = dp->link_config.max_rate;
+	u32 clock, drm_fourcc;
+	u8 max_lanes = dp->link_config.max_lanes;
+	u8 bpp = dp->config.bpp;
+
+	/*
+	 * This assumes that there is no conversion  between framebuffer
+	 * and DP Tx
+	 */
+	drm_fourcc = encoder->crtc->primary->state->fb->format->format;
+
+	xlnx_dp_set_color(dp, drm_fourcc);
+
+	rate = XDPTX_MAX_RATE(max_rate, max_lanes, bpp);
+	if (mode->clock > rate) {
+		dev_err(dp->dev, "the mode, %s,has too high pixel rate\n",
+			mode->name);
+		drm_mode_debug_printmodeline(mode);
+	}
+
+	/* The timing register should be programmed always */
+	xlnx_dp_encoder_mode_set_stream(dp, adjusted_mode);
+	xlnx_dp_encoder_mode_set_transfer_unit(dp, adjusted_mode);
+	clock = adjusted_mode->clock * 1000;
+	clk_set_rate(dp->tx_vid_clk, clock / dp->config.ppc);
+
+	xlnx_dp_vtc_set_timing(dp, adjusted_mode);
+	/* prepare a vsc packet */
+	xlnx_dp_prepare_vsc(dp);
+}
+
+static const struct drm_encoder_funcs xlnx_dp_encoder_funcs = {
+	.destroy = drm_encoder_cleanup,
+};
+
+static const struct drm_encoder_helper_funcs xlnx_dp_encoder_helper_funcs = {
+	.enable			= xlnx_dp_encoder_enable,
+	.disable		= xlnx_dp_encoder_disable,
+	.atomic_mode_set	= xlnx_dp_encoder_atomic_mode_set,
+};
+
+static void xlnx_dp_hpd_work_func(struct work_struct *work)
+{
+	struct xlnx_dp *dp;
+
+	dp = container_of(work, struct xlnx_dp, hpd_work.work);
+
+	if (dp->drm)
+		drm_helper_hpd_irq_event(dp->drm);
+}
+
+/**
+ * xlnx_dp_hdcp_cp_irq_func - Checks for HDCP information
+ * whenever CP IRQ is detected. HDCP transmitters must process this interrupt when
+ * they are received from receivers/repeaters.
+ * @work: work structure
+ *
+ * This function checks for HDCP authentication information via rxstatus register
+ * as soon as interrupt triggers.
+ */
+static void xlnx_dp_hdcp_cp_irq_func(struct work_struct *work)
+{
+	struct xlnx_dp *dp;
+	struct xlnx_hdcptx *dptxhdcp;
+
+	dp = container_of(work, struct xlnx_dp, hdcp_cp_irq_work.work);
+	dptxhdcp = &dp->tx_hdcp;
+
+	xlnx_hdcp_tx_process_cp_irq(dptxhdcp);
+}
+
+static struct drm_prop_enum_list xlnx_dp_bpc_enum[] = {
+	{ 6, "6BPC" },
+	{ 8, "8BPC" },
+	{ 10, "10BPC" },
+	{ 12, "12BPC" },
+};
+
+static int xlnx_dp_bind(struct device *dev, struct device *master, void *data)
+{
+	struct xlnx_dp *dp = dev_get_drvdata(dev);
+	struct drm_encoder *encoder = &dp->encoder;
+	struct drm_connector *connector = &dp->connector;
+	struct drm_device *drm = data;
+	unsigned int ret;
+
+	encoder->possible_crtcs = 1;
+	drm_encoder_init(drm, encoder, &xlnx_dp_encoder_funcs,
+			 DRM_MODE_ENCODER_TMDS, NULL);
+	drm_encoder_helper_add(encoder, &xlnx_dp_encoder_helper_funcs);
+
+	connector->polled = DRM_CONNECTOR_POLL_HPD;
+	ret = drm_connector_init(encoder->dev, connector,
+				 &xlnx_dp_connector_funcs,
+				 DRM_MODE_CONNECTOR_DisplayPort);
+	if (ret) {
+		dev_err(dp->dev, "failed to initialize the drm connector");
+		goto error_encoder;
+	}
+
+	drm_connector_helper_add(connector, &xlnx_dp_connector_helper_funcs);
+	drm_connector_register(connector);
+	drm_connector_attach_encoder(connector, encoder);
+	connector->dpms = DRM_MODE_DPMS_OFF;
+
+	dp->drm = drm;
+	dp->sync_prop = drm_property_create_bool(drm, 0, "sync");
+	dp->bpc_prop = drm_property_create_enum(drm, 0, "bpc",
+						xlnx_dp_bpc_enum,
+						ARRAY_SIZE(xlnx_dp_bpc_enum));
+	dp->config.misc0 &= ~XDPTX_MAINSTRM_MISC0_MASK;
+	drm_object_attach_property(&connector->base, dp->sync_prop, false);
+	ret = xlnx_dp_set_bpc(dp, 8);
+	drm_object_attach_property(&connector->base, dp->bpc_prop,
+				   ret ? ret : 8);
+	xlnx_dp_update_bpp(dp);
+
+	drm_object_attach_property(&connector->base,
+				   connector->dev->mode_config.gen_hdr_output_metadata_property, 0);
+	/* This enables interrupts, so should be called after DRM init */
+	ret = xlnx_dp_init_aux(dp);
+	if (ret) {
+		dev_err(dp->dev, "failed to initialize DP aux");
+		goto error_prop;
+	}
+	INIT_DELAYED_WORK(&dp->hpd_work, xlnx_dp_hpd_work_func);
+	INIT_DELAYED_WORK(&dp->hpd_pulse_work, xlnx_dp_hpd_pulse_work_func);
+
+	return 0;
+
+error_prop:
+	drm_property_destroy(dp->drm, dp->bpc_prop);
+	drm_property_destroy(dp->drm, dp->sync_prop);
+	xlnx_dp_connector_destroy(&dp->connector);
+error_encoder:
+	drm_encoder_cleanup(&dp->encoder);
+
+	return ret;
+}
+
+static void xlnx_dp_unbind(struct device *dev,
+			   struct device *master, void *data)
+{
+	struct xlnx_dp *dp = dev_get_drvdata(dev);
+
+	cancel_delayed_work_sync(&dp->hpd_work);
+	cancel_delayed_work_sync(&dp->hpd_pulse_work);
+	xlnx_dp_exit_aux(dp);
+	drm_property_destroy(dp->drm, dp->bpc_prop);
+	drm_property_destroy(dp->drm, dp->sync_prop);
+	xlnx_dp_connector_destroy(&dp->connector);
+	drm_encoder_cleanup(&dp->encoder);
+}
+
+static void xlnx_dp_hpd_pulse_work_func(struct work_struct *work)
+{
+	struct xlnx_dp *dp;
+	int ret;
+	u8 link_status[DP_LINK_STATUS_SIZE];
+	u8 bw_set, lane_set;
+
+	dp = container_of(work, struct xlnx_dp, hpd_pulse_work.work);
+
+	if (!dp->enabled)
+		return;
+
+	if (!xlnx_dp_txconnected(dp)) {
+		dev_err(dp->dev, "incorrect HPD pulse received\n");
+		return;
+	}
+
+	/* Read Link information from downstream device */
+	ret = drm_dp_dpcd_read_link_status(&dp->aux, link_status);
+	if (ret < 0)
+		return;
+	ret |= drm_dp_dpcd_read(&dp->aux, DP_LINK_BW_SET, &bw_set, 1);
+	ret |= drm_dp_dpcd_read(&dp->aux, DP_LANE_COUNT_SET, &lane_set, 1);
+	if (ret < 0)
+		return;
+
+	bw_set &= DP_LINK_BW_SET_MASK;
+	if (bw_set != DP_LINK_BW_8_1 &&
+	    bw_set != DP_LINK_BW_5_4 &&
+	    bw_set != DP_LINK_BW_2_7 &&
+	    bw_set != DP_LINK_BW_1_62)
+		goto retrain_link;
+
+	lane_set &= DP_LANE_COUNT_MASK;
+	if (lane_set != 1 && lane_set != 2 && lane_set != 4)
+		goto retrain_link;
+
+	/* Verify the link status */
+	ret = drm_dp_channel_eq_ok(link_status, lane_set);
+	if (!ret)
+		goto retrain_link;
+
+	if (dp->config.hdcp2x_enable || dp->config.hdcp1x_enable)
+		schedule_delayed_work(&dp->hdcp_cp_irq_work, 0);
+
+	return;
+
+retrain_link:
+	xlnx_dp_stop(dp);
+	xlnx_dp_start(dp);
+}
+
+static void xlnx_dp_gen_drmif_pkt(struct xlnx_dp *dp,
+				  struct hdmi_drm_infoframe drmif)
+{
+	struct xlnx_dp_infoframe *iframe = &dp->infoframe;
+
+	memset(iframe, 0, sizeof(struct xlnx_dp_infoframe));
+
+	iframe->header.byte[0] = NON_AUDIOIF_PKT_ID;
+	iframe->header.byte[1] = NON_AUDIOIF_DRM_TYPE;
+	iframe->header.byte[2] = NON_AUDIOIF_LDATA_BYTECOUNT;
+	iframe->header.byte[3] = NON_AUDIOIF_SDP_VERSION;
+	iframe->payload.byte[0] = CTA_DRMIF_VERSION_NUMBER;
+	iframe->payload.byte[1] = CTA_DRMIF_LENGHT;
+
+	iframe->payload.byte[2] = drmif.eotf & 0x7;
+	iframe->payload.byte[3] = drmif.metadata_type & 0x7;
+
+	iframe->payload.byte[4] = drmif.display_primaries[0].x & 0xFF;
+	iframe->payload.byte[5] = drmif.display_primaries[0].x >> 8;
+
+	iframe->payload.byte[6] = drmif.display_primaries[0].y & 0xFF;
+	iframe->payload.byte[7] = drmif.display_primaries[0].y >> 8;
+
+	iframe->payload.byte[8] = drmif.display_primaries[1].x & 0xFF;
+	iframe->payload.byte[9] = drmif.display_primaries[1].x >> 8;
+
+	iframe->payload.byte[10] = drmif.display_primaries[1].y & 0xFF;
+	iframe->payload.byte[11] = drmif.display_primaries[1].y >> 8;
+
+	iframe->payload.byte[12] = drmif.display_primaries[2].x & 0xFF;
+	iframe->payload.byte[13] = drmif.display_primaries[2].x >> 8;
+
+	iframe->payload.byte[14] = drmif.display_primaries[2].y & 0xFF;
+	iframe->payload.byte[15] = drmif.display_primaries[2].y >> 8;
+
+	iframe->payload.byte[16] = drmif.white_point.x & 0xFF;
+	iframe->payload.byte[17] = drmif.white_point.x >> 8;
+
+	iframe->payload.byte[18] = drmif.white_point.y & 0xFF;
+	iframe->payload.byte[19] = drmif.white_point.y >> 8;
+
+	iframe->payload.byte[20] = drmif.max_display_mastering_luminance & 0xFF;
+	iframe->payload.byte[21] = drmif.max_display_mastering_luminance >> 8;
+
+	iframe->payload.byte[22] = drmif.min_display_mastering_luminance & 0xFF;
+	iframe->payload.byte[23] = drmif.min_display_mastering_luminance >> 8;
+
+	iframe->payload.byte[24] = drmif.max_cll & 0xFF;
+	iframe->payload.byte[25] = drmif.max_cll >> 8;
+
+	iframe->payload.byte[26] = drmif.max_fall & 0xFF;
+	iframe->payload.byte[27] = drmif.max_fall >> 8;
+}
+
+static void xlnx_dp_vsync_handler(struct xlnx_dp *dp)
+{
+	struct drm_connector_state *state = dp->connector.state;
+	struct hdmi_drm_infoframe frame;
+	struct xlnx_dp_infoframe *iframe = &dp->infoframe;
+	int i;
+	u32 fifosts = xlnx_dp_read(dp->dp_base, XDPTX_AUDIO_INFO_BUFF_STATUS);
+
+	if (!(fifosts & (XDPTX_AUDIO_INFO_BUFF_FULL |
+					XDPTX_AUDIO_INFO_BUFF_OVERFLOW))) {
+		/* Write new audio info packet */
+		for (i = 0; i < DP_INFOFRAME_FIFO_SIZE_WORDS; i++) {
+			xlnx_dp_write(dp->dp_base,
+				      XDPTX_AUDIO_INFO_DATA_REG,
+				      dp->tx_audio_data->buffer[i]);
+		}
+
+		if (state->gen_hdr_output_metadata) {
+			drm_hdmi_infoframe_set_gen_hdr_metadata(&frame, state);
+			xlnx_dp_gen_drmif_pkt(dp, frame);
+
+			xlnx_dp_write(dp->dp_base, XDPTX_AUDIO_INFO_DATA_REG,
+				      iframe->header.data);
+			/* Write new hdr info packet */
+			for (i = 0; i < (DP_INFOFRAME_FIFO_SIZE_WORDS - 1); i++) {
+				xlnx_dp_write(dp->dp_base,
+					      XDPTX_AUDIO_INFO_DATA_REG,
+					      iframe->payload.data[i]);
+			}
+		}
+	}
+}
+
+static irqreturn_t xlnx_dp_irq_handler(int irq, void *data)
+{
+	struct xlnx_dp *dp = (struct xlnx_dp *)data;
+	u32 intrstatus;
+	u32 hpdduration;
+
+	/* Determine what kind of interrupt occurred. */
+	intrstatus = xlnx_dp_read(dp->dp_base, XDPTX_INTR_STATUS_REG);
+
+	if (!intrstatus)
+		return IRQ_NONE;
+	if (intrstatus & XDPTX_INTR_HPDEVENT_MASK) {
+		dev_dbg_ratelimited(dp->dev, "hpdevent detected\n");
+	} else if (intrstatus & XDPTX_INTR_HPDPULSE_MASK &&
+		   xlnx_dp_txconnected(dp)) {
+		/*
+		 * Some monitors give HPD pulse repeatedly which cause
+		 * HPD pulse function to be executed huge number of times.
+		 * Hence HPD pulse interrupt is disabled if pulse duration
+		 * is longer than 500 microseconds.
+		 */
+		hpdduration = xlnx_dp_read(dp->dp_base, XDPTX_HPD_DURATION_REG);
+		if (hpdduration >= 500)
+			xlnx_dp_write(dp->dp_base, XDPTX_INTR_MASK_REG, 0x10);
+	}
+
+	if (intrstatus & XDPTX_INTR_CHBUFUNDFW_MASK)
+		dev_dbg_ratelimited(dp->dev, "underflow interrupt\n");
+	if (intrstatus & XDPTX_INTR_CHBUFOVFW_MASK)
+		dev_dbg_ratelimited(dp->dev, "overflow interrupt\n");
+
+	if (intrstatus & XDPTX_INTR_HPDEVENT_MASK)
+		schedule_delayed_work(&dp->hpd_work, 0);
+	if (intrstatus & XDPTX_INTR_HPDPULSE_MASK)
+		schedule_delayed_work(&dp->hpd_pulse_work, 0);
+	if (intrstatus & XDPTX_INTR_EXTPKT_TXD_MASK)
+		xlnx_dp_vsc_pkt_handler(dp);
+	if (intrstatus & XDPTX_INTR_VBLANK_MASK)
+		xlnx_dp_vsync_handler(dp);
+
+	return IRQ_HANDLED;
+}
+
+static const struct component_ops xlnx_dp_component_ops = {
+	.bind	= xlnx_dp_bind,
+	.unbind	= xlnx_dp_unbind,
+};
+
+static ssize_t xlnx_hdcp_load_key(struct device *sysfs_dev, struct device_attribute *attr,
+				  const char *buf, size_t count)
+{
+	int ret = 0;
+	struct xlnx_dp *dp = (struct xlnx_dp *)dev_get_drvdata(sysfs_dev);
+	struct xlnx_hdcptx *dptxhdcp = &dp->tx_hdcp;
+
+	ret = xlnx_hdcp_tx_set_keys(dptxhdcp, (u8 *)buf);
+	if (ret) {
+		dev_dbg(dptxhdcp->dev, "failed to send HDCP key from Sysfs to wrapper\n");
+		return ret;
+	}
+	return count;
+}
+
+static DEVICE_ATTR(hdcp_key, XHDCP_KEY_WRITE_PERMISSION, NULL, xlnx_hdcp_load_key);
+
+static struct attribute *attrs[] = {
+	&dev_attr_hdcp_key.attr,
+	NULL,
+};
+
+static struct attribute_group attr_group = {
+	.attrs = attrs,
+};
+
+/**
+ * xlnx_dp_hdcp_dpcd_write - HDCP message write through dpcd interface
+ * @ref: callback reference pointer
+ * @offset: register offset
+ * @buf: write buffer
+ * @buf_size: number of bytes to write
+ *
+ * Return: buffer size on successful write, or the error code returned
+ * from the callee functions.
+ */
+static int xlnx_dp_hdcp_dpcd_write(void *ref, u32 offset,
+				   void *buf, u32 buf_size)
+{
+	struct xlnx_dp *dp = (struct xlnx_dp *)ref;
+	u32 ret = 0;
+
+	ret = drm_dp_dpcd_write(&dp->aux, offset, buf, buf_size);
+	if (ret < 0) {
+		dev_err(dp->dev, "dpcd write failed");
+		return ret;
+	}
+
+	return ret;
+}
+
+/**
+ * xlnx_dp_hdcp_dpcd_read - HDCP message read through dpcd interface
+ * @ref: callback reference pointer
+ * @offset: register offset
+ * @buf: read buffer
+ * @buf_size: number of bytes to read
+ *
+ * Return: buffer size on successful read, or the error code returned
+ * from the callee functions.
+ */
+static int xlnx_dp_hdcp_dpcd_read(void *ref, u32 offset,
+				  void *buf, u32 buf_size)
+{
+	struct xlnx_dp *dp = (struct xlnx_dp *)ref;
+	u32 ret = 0;
+
+	ret = drm_dp_dpcd_read(&dp->aux, offset, buf, buf_size);
+	if (ret < 0) {
+		dev_err(dp->dev, "dpcd read failed");
+		return ret;
+	}
+
+	return ret;
+}
+
+/**
+ * xlnx_dp_hdcp_status_update - HDCP status notification
+ * @ref: callback reference pointer
+ * @notification: HDCP notification
+ */
+static void xlnx_dp_hdcp_status_update(void *ref, u32 notification)
+{
+	struct xlnx_dp *dp = (struct xlnx_dp *)ref;
+
+	switch (notification) {
+	case XHDCPTX_INCOMPATIBLE_RX:
+		dev_dbg(dp->dev, "HDCP TX compatible receiver is not found\n");
+		break;
+	case XHDCPTX_AUTHENTICATION_BUSY:
+		dev_dbg(dp->dev, "HDCP TX Authentication Busy\n");
+		break;
+	case XHDCPTX_AUTHENTICATED:
+		dev_dbg(dp->dev, "HDCP TX Authenticated\n");
+		break;
+	case XHDCPTX_REAUTHENTICATE_REQUESTED:
+		dev_dbg(dp->dev, "HDCP TX Re-authentication Request received\n");
+		break;
+	case XHDCPTX_DEVICE_IS_REVOKED:
+		dev_dbg(dp->dev, "HDCP TX , a device in the HDCP chain is revoked\n");
+		break;
+	case XHDCPTX_NO_SRM_LOADED:
+		dev_dbg(dp->dev, "HDCP TX , no valid srm is loaded\n");
+		break;
+	case XHDCPTX_UNAUTHENTICATED:
+		dev_dbg(dp->dev, "HDCP TX Unauthenticated\n");
+		break;
+	default:
+		dev_dbg(dp->dev, "Error, HDCP is not initialized\n");
+		break;
+	}
+}
+
+/**
+ * xlnx_dp_hdcp_exit - HDCP module de-initialization
+ * @dp: displayPort IP core structure
+ *
+ * Return: 0 on success, or the status from called functions
+ */
+static int xlnx_dp_hdcp_exit(struct xlnx_dp *dp)
+{
+	struct xlnx_hdcptx *dptxhdcp = &dp->tx_hdcp;
+	int ret;
+
+	if (!(dptxhdcp->hdcp1xenable || dptxhdcp->hdcp2xenable)) {
+		dev_info(dp->dev, "HDCP is not enabled in the system");
+		return -EINVAL;
+	}
+
+	ret = xlnx_dp_hdcp_reset(dp);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to reset HDCP");
+		return ret;
+	}
+
+	xlnx_hdcp_tx_timer_exit(dptxhdcp);
+	xlnx_hdcp_tx_exit(dptxhdcp);
+
+	return 0;
+}
+
+/**
+ * xlnx_timer_irq_handler - HDCP timer interrupt handler
+ * @irq: IRQ number of the interrupt being handled
+ * @data: Pointer to device structure
+ *
+ * Return: irq handler status
+ */
+static irqreturn_t xlnx_timer_irq_handler(int irq, void *data)
+{
+	struct xlnx_dp *dp = (struct xlnx_dp *)data;
+	struct xlnx_hdcptx *dptxhdcp = &dp->tx_hdcp;
+
+	xlnx_hdcp_tmrcntr_interrupt_handler(dptxhdcp->xhdcptmr);
+
+	return IRQ_HANDLED;
+}
+
+/**
+ * xlnx_hdcp_init - HDCP module initialization
+ * @dp: displayPort IP core structure
+ * @pdev: platform structure
+ *
+ * Return: 0 on success, or return the error code from the called functions.
+ */
+static int xlnx_hdcp_init(struct xlnx_dp *dp,
+			  struct platform_device *pdev)
+{
+	struct xlnx_hdcptx *dptxhdcp = &dp->tx_hdcp;
+	int ret;
+
+	dptxhdcp->dev = dp->dev;
+	dptxhdcp->hdcp2xenable = dp->config.hdcp2x_enable;
+	dptxhdcp->hdcp1xenable = dp->config.hdcp1x_enable;
+
+	if (dp->config.hdcp2x_enable) {
+		xlnx_dp_set(dp->dp_base, XDP_TX_HDCP2x_ENABLE,
+			    XDP_TX_HDCP2x_ENABLE_BYPASS_DISABLE_MASK);
+
+		dptxhdcp->xhdcp2x = xlnx_hdcp_tx_init(&pdev->dev, dp, dptxhdcp,
+						      dp->dp_base + XDPTX_HDCP2X_OFFSET,
+						      0, XHDCPTX_HDCP_2X, dp->mode.lane_cnt,
+						      XDPTX_HDCP, dp->hdcpx_keymgmt_base);
+
+		if (IS_ERR(dptxhdcp->xhdcp2x)) {
+			dev_err(dp->dev, "failed to initialize HDCP2X module\n");
+			return PTR_ERR(dptxhdcp->xhdcp2x);
+		}
+	}
+	dptxhdcp->xhdcptmr =
+			xlnx_hdcp_timer_init(&pdev->dev, dp->dp_base + XDPTX_HDCP_TIMER_OFFSET);
+	if (IS_ERR(dptxhdcp->xhdcptmr)) {
+		dev_err(dp->dev, "failed to initialize HDCP timer\n");
+		return PTR_ERR(dptxhdcp->xhdcptmr);
+	}
+	dp->hdcptx_timer_irq =
+			 platform_get_irq_byname(pdev, "dptxss_timer_irq");
+	if (dp->hdcptx_timer_irq < 0) {
+		dev_err(dp->dev, "failed to get HDCP timer irq ");
+		return -EINVAL;
+	}
+	ret = devm_request_threaded_irq(dp->dev, dp->hdcptx_timer_irq, NULL,
+					xlnx_timer_irq_handler,
+					IRQF_TRIGGER_HIGH | IRQF_ONESHOT,
+					"dptxss_timer_irq", dp);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to register HDCP timer irq");
+		return ret;
+	}
+	if (dp->config.hdcp1x_enable) {
+		dptxhdcp->xhdcp1x = xlnx_hdcp_tx_init(&pdev->dev, dp, dptxhdcp,
+						      dp->dp_base + XDPTX_HDCP1X_OFFSET,
+						      0, XHDCPTX_HDCP_1X, dp->mode.lane_cnt,
+						      XDPTX_HDCP, dp->hdcpx_keymgmt_base);
+		if (IS_ERR(dptxhdcp->xhdcp1x)) {
+			dev_err(dp->dev, "failed to initialize HDCP1X module\n");
+			return PTR_ERR(dptxhdcp->xhdcp1x);
+		}
+	}
+
+	ret = xlnx_hdcp_tx_set_callback(dptxhdcp, XDPTX_HDCP_DPCD_WRITE,
+					xlnx_dp_hdcp_dpcd_write);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to register HDCP DPCD Write Callback");
+		return ret;
+	}
+
+	ret = xlnx_hdcp_tx_set_callback(dptxhdcp, XDPTX_HDCP_DPCD_READ,
+					xlnx_dp_hdcp_dpcd_read);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to register HDCP DPCD Read Callback");
+		return ret;
+	}
+
+	ret = xlnx_hdcp_tx_set_callback(dptxhdcp, XDPTX_HDCP_STATUS,
+					xlnx_dp_hdcp_status_update);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to register HDCP Status Update Callback");
+		return ret;
+	}
+
+	INIT_DELAYED_WORK(&dp->hdcp_cp_irq_work, xlnx_dp_hdcp_cp_irq_func);
+
+	return 0;
+}
+
+static int xlnx_dp_parse_of(struct xlnx_dp *dp)
+{
+	struct xlnx_dp_config *config = &dp->config;
+	struct device_node *node = dp->dev->of_node;
+	u32 bpc;
+	int ret;
+
+	if (dp->cfg->flags & XDPTX_VTC_OFFSET_CHANGE) {
+		ret = of_property_read_u32(node, "xlnx,vtc-offset",
+					   &dp->vtc_off);
+		if (ret < 0) {
+			dev_err(dp->dev, "No vct offset in DT\n");
+			return ret;
+		}
+	} else {
+		dp->vtc_off = XDPTX_VTC_BASE;
+	}
+
+	config->hdcp1x_enable = of_property_read_bool(node, "xlnx,hdcp-enable");
+	config->hdcp2x_enable =
+			of_property_read_bool(node, "xlnx,hdcp22-enable");
+
+	ret = of_property_read_u32(node, "xlnx,max-lanes", &config->max_lanes);
+	if (ret < 0) {
+		dev_err(dp->dev, "No lane count in DT\n");
+		return ret;
+	}
+	if (config->max_lanes != 1 && config->max_lanes != 2 &&
+	    config->max_lanes != 4) {
+		dev_err(dp->dev, "Invalid max lanes in DT\n");
+		return -EINVAL;
+	}
+
+	ret = of_property_read_u32(node, "xlnx,max-link-rate",
+				   &config->max_link_rate);
+	if (ret < 0) {
+		dev_err(dp->dev, "No link rate in DT\n");
+		return ret;
+	}
+	if (config->max_link_rate != XDPTX_REDUCED_BIT_RATE &&
+	    config->max_link_rate != XDPTX_HIGH_BIT_RATE_1 &&
+	    config->max_link_rate != XDPTX_HIGH_BIT_RATE_2 &&
+	    config->max_link_rate != XDPTX_HIGH_BIT_RATE_3) {
+		dev_err(dp->dev, "Invalid link rate in DT\n");
+		return -EINVAL;
+	}
+
+	xlnx_dp_set_color(dp, DRM_FORMAT_RGB888);
+
+	ret = of_property_read_u32(node, "xlnx,bpc", &bpc);
+	if (ret < 0) {
+		dev_err(dp->dev, "No color depth(bpc) in DT\n");
+		return ret;
+	}
+
+	switch (bpc) {
+	case 6:
+		config->misc0 |= XDPTX_MISC0_BPC6_MASK;
+		break;
+	case 8:
+		config->misc0 |= XDPTX_MISC0_BPC8_MASK;
+		break;
+	case 10:
+		config->misc0 |= XDPTX_MISC0_BPC10_MASK;
+		break;
+	case 12:
+		config->misc0 |= XDPTX_MISC0_BPC12_MASK;
+		break;
+	case 16:
+		config->misc0 |= XDPTX_MISC0_BPC16_MASK;
+		break;
+	default:
+		dev_err(dp->dev, "Not supported color depth in DT\n");
+		return -EINVAL;
+	}
+
+	config->audio_enabled =
+		of_property_read_bool(node, "xlnx,audio-enable");
+
+	config->versal_gt_present =
+		of_property_read_bool(node, "xlnx,versal-gt");
+
+	if (config->hdcp1x_enable) {
+		dp->hdcpx_keymgmt_base = syscon_regmap_lookup_by_phandle(node,
+									 "xlnx,hdcp1x-keymgmt");
+		if (IS_ERR(dp->hdcpx_keymgmt_base)) {
+			dev_err(dp->dev, "couldn't map hdcp1x Keymgmt registers\n");
+			return -ENODEV;
+		}
+	}
+
+	return 0;
+}
+
+static int xlnx_dp_probe(struct platform_device *pdev)
+{
+	struct device_node *pnode = pdev->dev.of_node;
+	struct device_node *fnode;
+	struct platform_device *iface_pdev;
+	struct xlnx_dp *dp;
+	struct resource *res;
+	const struct of_device_id *match;
+	void *ptr;
+	unsigned int i;
+	int irq, ret;
+
+	dp = devm_kzalloc(&pdev->dev, sizeof(*dp), GFP_KERNEL);
+	if (!dp)
+		return -ENOMEM;
+
+	dp->tx_audio_data =
+		devm_kzalloc(&pdev->dev, sizeof(struct xlnx_dptx_audio_data),
+			     GFP_KERNEL);
+	if (!dp->tx_audio_data)
+		return -ENOMEM;
+
+	dp->dpms = DRM_MODE_DPMS_OFF;
+	dp->status = connector_status_disconnected;
+	dp->dev = &pdev->dev;
+
+	match = of_match_node(xlnx_dp_of_match, pnode);
+	if (!match)
+		return -ENODEV;
+
+	dp->cfg = match->data;
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "dp_base");
+	dp->dp_base = devm_ioremap_resource(dp->dev, res);
+	if (IS_ERR(dp->dp_base)) {
+		dev_err(&pdev->dev, "couldn't map DisplayPort registers\n");
+		return -ENODEV;
+	}
+
+	ret = xlnx_dp_parse_of(dp);
+	if (ret < 0)
+		return ret;
+
+	if (dp->config.versal_gt_present) {
+		dp->phy[0] = devm_phy_get(dp->dev, "dp-gtquad");
+		if (IS_ERR(dp->phy[0]))
+			return dev_err_probe(dp->dev, ret, "failed to get phy\n");
+
+		ret = phy_init(dp->phy[0]);
+		if (ret)
+			goto error_phy;
+
+		fnode = of_parse_phandle(pnode, "xlnx,xilinx-vfmc", 0);
+		if (!fnode) {
+			dev_err(&pdev->dev, "platform node not found\n");
+			of_node_put(fnode);
+		} else {
+			iface_pdev = of_find_device_by_node(fnode);
+			if (!iface_pdev) {
+				of_node_put(pnode);
+				return -ENODEV;
+			}
+
+			ptr = dev_get_drvdata(&iface_pdev->dev);
+			if (!ptr) {
+				dev_info(&pdev->dev,
+					 "platform device not found -EPROBE_DEFER\n");
+				of_node_put(fnode);
+				return -EPROBE_DEFER;
+			}
+			of_node_put(fnode);
+		}
+	}
+
+	dp->axi_lite_clk = devm_clk_get(&pdev->dev, "s_axi_aclk");
+	if (IS_ERR(dp->axi_lite_clk))
+		return PTR_ERR(dp->axi_lite_clk);
+
+	dp->tx_vid_clk = devm_clk_get(&pdev->dev, "tx_vid_clk");
+	if (IS_ERR(dp->tx_vid_clk))
+		dev_err(dp->dev, "failed to get vid clk stream1\n");
+
+	platform_set_drvdata(pdev, dp);
+	xlnx_dp_write(dp->dp_base, XDPTX_ENABLE_REG, 0);
+	xlnx_dp_write(dp->dp_base, XDPTX_MAINSTRM_ENABLE_REG, 0);
+
+	dp->tx_link_config.vs_level = 0;
+	dp->tx_link_config.pe_level = 0;
+
+	if (!dp->config.versal_gt_present) {
+		/* acquire vphy lanes */
+		for (i = 0; i < dp->config.max_lanes; i++) {
+			char phy_name[16];
+
+			snprintf(phy_name, sizeof(phy_name), "dp-phy%d", i);
+			dp->phy[i] = devm_phy_get(dp->dev, phy_name);
+			if (IS_ERR(dp->phy[i])) {
+				ret = PTR_ERR(dp->phy[i]);
+				dp->phy[i] = NULL;
+				if (ret == -EPROBE_DEFER) {
+					dev_info(dp->dev,
+						 "xvphy not ready -EPROBE_DEFER\n");
+					return ret;
+				}
+				if (ret != -EPROBE_DEFER)
+					dev_err(dp->dev, "failed to get phy lane %s i %d, error %d\n",
+						phy_name, i, ret);
+				goto error_phy;
+			}
+		}
+
+		ret = xlnx_dp_init_phy(dp);
+		if (ret)
+			goto error_phy;
+	} else {
+		ret = xlnx_dp_tx_gt_control_init(dp);
+		if (ret < 0)
+			return ret;
+	}
+
+	ret = clk_prepare_enable(dp->axi_lite_clk);
+	if (ret) {
+		dev_err(dp->dev, "failed to enable axi_lite_clk (%d)\n", ret);
+		return ret;
+	}
+
+	ret = clk_prepare_enable(dp->tx_vid_clk);
+	if (ret) {
+		dev_err(dp->dev, "failed to enable tx_vid_clk (%d)\n", ret);
+		goto tx_vid_clk_err;
+	}
+
+	dp->aux.name = "Xlnx DP AUX";
+	dp->aux.dev = dp->dev;
+	dp->aux.transfer = xlnx_dp_aux_transfer;
+	ret = drm_dp_aux_register(&dp->aux);
+	if (ret < 0) {
+		dev_err(dp->dev, "failed to initialize DP aux\n");
+		goto error;
+	}
+	irq = platform_get_irq(pdev, 0);
+	if (irq < 0) {
+		ret = irq;
+		goto error;
+	}
+	ret = devm_request_threaded_irq(dp->dev, irq, NULL,
+					xlnx_dp_irq_handler, IRQF_ONESHOT,
+					dev_name(dp->dev), dp);
+
+	if (ret < 0)
+		goto error;
+
+	ret = sysfs_create_group(&dp->dev->kobj, &attr_group);
+	if (ret)
+		dev_err(dp->dev, "sysfs group creation failed to store keys");
+
+	if (dp->config.hdcp2x_enable || dp->config.hdcp1x_enable) {
+		ret = xlnx_hdcp_init(dp, pdev);
+		if (ret < 0)
+			goto error_hdcp;
+	}
+	if (dp->config.audio_enabled) {
+		if (dptx_register_aud_dev(dp->dev)) {
+			dp->audio_init = false;
+			dev_err(dp->dev, "dp tx audio init failed\n");
+			goto error;
+		} else {
+			dp->audio_init = true;
+			dev_info(dp->dev, "dp tx audio initialized\n");
+		}
+	}
+
+	return component_add(&pdev->dev, &xlnx_dp_component_ops);
+
+error_hdcp:
+	xlnx_dp_hdcp_exit(dp);
+tx_vid_clk_err:
+	clk_disable_unprepare(dp->axi_lite_clk);
+error:
+	drm_dp_aux_unregister(&dp->aux);
+error_phy:
+	if (!dp->config.versal_gt_present) {
+		dev_dbg(&pdev->dev, "xdprxss_probe() error_phy:\n");
+		xlnx_dp_exit_phy(dp);
+	} else {
+		phy_exit(dp->phy[0]);
+	}
+
+	return ret;
+}
+
+static void xlnx_dp_remove(struct platform_device *pdev)
+{
+	struct xlnx_dp *dp = platform_get_drvdata(pdev);
+
+	xlnx_dp_write(dp->dp_base, XDPTX_ENABLE_REG, 0);
+	if (dp->config.hdcp2x_enable || dp->config.hdcp1x_enable)
+		xlnx_dp_hdcp_exit(dp);
+	drm_dp_aux_unregister(&dp->aux);
+	if (!dp->config.versal_gt_present)
+		xlnx_dp_exit_phy(dp);
+	else
+		phy_exit(dp->phy[0]);
+	component_del(&pdev->dev, &xlnx_dp_component_ops);
+	sysfs_remove_group(&pdev->dev.kobj, &attr_group);
+}
+
+MODULE_DEVICE_TABLE(of, xlnx_dp_of_match);
+
+static struct platform_driver dp_tx_driver = {
+	.probe = xlnx_dp_probe,
+	.remove = xlnx_dp_remove,
+	.driver = {
+		.name = "xlnx-dp-tx",
+		.of_match_table = xlnx_dp_of_match,
+	},
+};
+
+module_platform_driver(dp_tx_driver);
+
+MODULE_AUTHOR("Rajesh Gugulothu <gugulothu.rajesh@xilinx.com>");
+MODULE_DESCRIPTION("Xilinx FPGA DisplayPort Tx Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/xlnx_drv.c b/drivers/gpu/drm/xlnx/xlnx_drv.c
new file mode 100644
index 000000000..196c78f10
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_drv.c
@@ -0,0 +1,520 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx DRM KMS Driver
+ *
+ *  Copyright (C) 2013 - 2018 Xilinx, Inc.
+ *
+ *  Author: Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <drm/drm_drv.h>
+#include <drm/drm_vblank.h>
+#include <drm/drm_fourcc.h>
+#include <drm/drm_atomic.h>
+#include <drm/drm_atomic_helper.h>
+#include <drm/drm_crtc_helper.h>
+#include <drm/drm_fb_helper.h>
+#include <drm/drm_gem_dma_helper.h>
+#include <drm/drm_of.h>
+#include <drm/drm_probe_helper.h>
+
+#include <linux/component.h>
+#include <linux/device.h>
+#include <linux/dma-buf.h>
+#include <linux/dma-resv.h>
+#include <linux/module.h>
+#include <linux/of_graph.h>
+#include <linux/platform_device.h>
+
+#include "xlnx_bridge.h"
+#include "xlnx_crtc.h"
+#include "xlnx_drv.h"
+#include "xlnx_fb.h"
+#include "xlnx_gem.h"
+
+#define DRIVER_NAME	"xlnx"
+#define DRIVER_DESC	"Xilinx DRM KMS Driver"
+#define DRIVER_DATE	"20130509"
+#define DRIVER_MAJOR	1
+#define DRIVER_MINOR	0
+
+#define MAX_CRTC	3
+
+static uint xlnx_fbdev_vres = 2;
+module_param_named(fbdev_vres, xlnx_fbdev_vres, uint, 0444);
+MODULE_PARM_DESC(fbdev_vres,
+		 "fbdev virtual resolution multiplier for fb (default: 2)");
+
+/**
+ * struct xlnx_drm - Xilinx DRM private data
+ * @drm: DRM core
+ * @crtc: Xilinx DRM CRTC helper
+ * @fb: DRM fb helper
+ * @master: logical master device for pipeline
+ * @suspend_state: atomic state for suspend / resume
+ * @master_count: Counter to track number of fake master instances
+ */
+struct xlnx_drm {
+	struct drm_device *drm;
+	struct xlnx_crtc_helper *crtc;
+	struct drm_fb_helper *fb;
+	struct platform_device *master;
+	struct drm_atomic_state *suspend_state;
+	u32 master_count;
+};
+
+/**
+ * xlnx_get_crtc_helper - Return the crtc helper instance
+ * @drm: DRM device
+ *
+ * Return: the crtc helper instance
+ */
+struct xlnx_crtc_helper *xlnx_get_crtc_helper(struct drm_device *drm)
+{
+	struct xlnx_drm *xlnx_drm = drm->dev_private;
+
+	return xlnx_drm->crtc;
+}
+
+/**
+ * xlnx_get_align - Return the align requirement through CRTC helper
+ * @drm: DRM device
+ *
+ * Return: the alignment requirement
+ */
+unsigned int xlnx_get_align(struct drm_device *drm)
+{
+	struct xlnx_drm *xlnx_drm = drm->dev_private;
+
+	return xlnx_crtc_helper_get_align(xlnx_drm->crtc);
+}
+
+/**
+ * xlnx_get_format - Return the current format of CRTC
+ * @drm: DRM device
+ *
+ * Return: the current CRTC format
+ */
+uint32_t xlnx_get_format(struct drm_device *drm)
+{
+	struct xlnx_drm *xlnx_drm = drm->dev_private;
+
+	return xlnx_crtc_helper_get_format(xlnx_drm->crtc);
+}
+
+static const struct drm_mode_config_funcs xlnx_mode_config_funcs = {
+	.fb_create		= xlnx_fb_create,
+	.atomic_check		= drm_atomic_helper_check,
+	.atomic_commit		= drm_atomic_helper_commit,
+};
+
+static void xlnx_mode_config_init(struct drm_device *drm)
+{
+	struct xlnx_drm *xlnx_drm = drm->dev_private;
+	struct xlnx_crtc_helper *crtc = xlnx_drm->crtc;
+
+	drm->mode_config.min_width = 0;
+	drm->mode_config.min_height = 0;
+	drm->mode_config.max_width = xlnx_crtc_helper_get_max_width(crtc);
+	drm->mode_config.max_height = xlnx_crtc_helper_get_max_height(crtc);
+	drm->mode_config.cursor_width =
+		xlnx_crtc_helper_get_cursor_width(crtc);
+	drm->mode_config.cursor_height =
+		xlnx_crtc_helper_get_cursor_height(crtc);
+}
+
+static int xlnx_drm_open(struct drm_device *dev, struct drm_file *file)
+{
+	struct xlnx_drm *xlnx_drm = dev->dev_private;
+
+	/* This is a hacky way to allow the root user to run as a master */
+	if (!(drm_is_primary_client(file) && !dev->master) &&
+	    !file->is_master && capable(CAP_SYS_ADMIN)) {
+		file->is_master = 1;
+		xlnx_drm->master_count++;
+	}
+
+	return 0;
+}
+
+static int xlnx_drm_release(struct inode *inode, struct file *filp)
+{
+	struct drm_file *file = filp->private_data;
+	struct drm_minor *minor = file->minor;
+	struct drm_device *drm = minor->dev;
+	struct xlnx_drm *xlnx_drm = drm->dev_private;
+
+	if (file->is_master && xlnx_drm->master_count) {
+		xlnx_drm->master_count--;
+		file->is_master = 0;
+	}
+
+	return drm_release(inode, filp);
+}
+
+static const struct file_operations xlnx_fops = {
+	.owner		= THIS_MODULE,
+	.open		= drm_open,
+	.release	= xlnx_drm_release,
+	.unlocked_ioctl	= drm_ioctl,
+	.mmap		= drm_gem_mmap,
+	.poll		= drm_poll,
+	.read		= drm_read,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl	= drm_compat_ioctl,
+#endif
+	.llseek		= noop_llseek,
+	.fop_flags      = FOP_UNSIGNED_OFFSET,
+};
+
+static struct drm_driver xlnx_drm_driver = {
+	.driver_features		= DRIVER_MODESET | DRIVER_GEM |
+					  DRIVER_ATOMIC,
+	.open				= xlnx_drm_open,
+
+	DRM_GEM_DMA_DRIVER_OPS_VMAP_WITH_DUMB_CREATE(xlnx_gem_cma_dumb_create),
+
+	.fops				= &xlnx_fops,
+
+	.name				= DRIVER_NAME,
+	.desc				= DRIVER_DESC,
+	.date				= DRIVER_DATE,
+	.major				= DRIVER_MAJOR,
+	.minor				= DRIVER_MINOR,
+};
+
+static int xlnx_bind(struct device *dev)
+{
+	struct xlnx_drm *xlnx_drm;
+	struct drm_device *drm;
+	const struct drm_format_info *info;
+	struct platform_device *master = to_platform_device(dev);
+	struct platform_device *pdev = to_platform_device(dev->parent);
+	int ret;
+	u32 format;
+
+	drm = drm_dev_alloc(&xlnx_drm_driver, &pdev->dev);
+	if (IS_ERR(drm))
+		return PTR_ERR(drm);
+
+	xlnx_drm = devm_kzalloc(drm->dev, sizeof(*xlnx_drm), GFP_KERNEL);
+	if (!xlnx_drm) {
+		ret = -ENOMEM;
+		goto err_drm;
+	}
+
+	drm_mode_config_init(drm);
+	drm->mode_config.funcs = &xlnx_mode_config_funcs;
+
+	ret = drm_vblank_init(drm, MAX_CRTC);
+	if (ret) {
+		dev_err(&pdev->dev, "failed to initialize vblank\n");
+		goto err_xlnx_drm;
+	}
+
+	drm->dev_private = xlnx_drm;
+	xlnx_drm->drm = drm;
+	xlnx_drm->master = master;
+	drm_kms_helper_poll_init(drm);
+	platform_set_drvdata(master, xlnx_drm);
+
+	xlnx_drm->crtc = xlnx_crtc_helper_init(drm);
+	if (IS_ERR(xlnx_drm->crtc)) {
+		ret = PTR_ERR(xlnx_drm->crtc);
+		goto err_xlnx_drm;
+	}
+
+	ret = component_bind_all(&master->dev, drm);
+	if (ret)
+		goto err_crtc;
+
+	xlnx_mode_config_init(drm);
+	drm_mode_config_reset(drm);
+	dma_set_mask(drm->dev, xlnx_crtc_helper_get_dma_mask(xlnx_drm->crtc));
+
+	format = xlnx_crtc_helper_get_format(xlnx_drm->crtc);
+	info = drm_format_info(format);
+	if (info && info->depth && info->cpp[0]) {
+		unsigned int align;
+
+		align = xlnx_crtc_helper_get_align(xlnx_drm->crtc);
+		xlnx_drm->fb = xlnx_fb_init(drm, info->cpp[0] * 8, 1, align,
+					    xlnx_fbdev_vres);
+		if (IS_ERR(xlnx_drm->fb)) {
+			dev_err(&pdev->dev,
+				"failed to initialize drm fb\n");
+			xlnx_drm->fb = NULL;
+		}
+	} else {
+		/* fbdev emulation is optional */
+		dev_info(&pdev->dev, "fbdev is not initialized\n");
+	}
+
+	ret = drm_dev_register(drm, 0);
+	if (ret < 0)
+		goto err_fb;
+
+	return 0;
+
+err_fb:
+	if (xlnx_drm->fb)
+		xlnx_fb_fini(xlnx_drm->fb);
+	component_unbind_all(drm->dev, drm);
+err_crtc:
+	xlnx_crtc_helper_fini(drm, xlnx_drm->crtc);
+err_xlnx_drm:
+	drm_mode_config_cleanup(drm);
+err_drm:
+	drm_dev_put(drm);
+	return ret;
+}
+
+static void xlnx_unbind(struct device *dev)
+{
+	struct xlnx_drm *xlnx_drm = dev_get_drvdata(dev);
+	struct drm_device *drm = xlnx_drm->drm;
+
+	drm_dev_unregister(drm);
+	component_unbind_all(&xlnx_drm->master->dev, drm);
+	if (xlnx_drm->fb) {
+		xlnx_fb_fini(xlnx_drm->fb);
+		xlnx_drm->fb = NULL;
+	}
+	xlnx_crtc_helper_fini(drm, xlnx_drm->crtc);
+	drm_kms_helper_poll_fini(drm);
+	drm_mode_config_cleanup(drm);
+	drm_dev_put(drm);
+}
+
+static const struct component_master_ops xlnx_master_ops = {
+	.bind	= xlnx_bind,
+	.unbind	= xlnx_unbind,
+};
+
+static int xlnx_of_component_probe(struct device *master_dev,
+				   int (*compare_of)(struct device *, void *),
+				   const struct component_master_ops *m_ops)
+{
+	struct device *dev = master_dev->parent;
+	struct device_node *ep, *port, *remote, *parent;
+	struct component_match *match = NULL;
+	int i;
+
+	if (!dev->of_node)
+		return -EINVAL;
+
+	component_match_add(master_dev, &match, compare_of, dev->of_node);
+
+	for (i = 0; ; i++) {
+		port = of_parse_phandle(dev->of_node, "ports", i);
+		if (!port)
+			break;
+
+		parent = port->parent;
+		if (!of_node_cmp(parent->name, "ports"))
+			parent = parent->parent;
+		parent = of_node_get(parent);
+
+		if (!of_device_is_available(parent)) {
+			of_node_put(parent);
+			of_node_put(port);
+			continue;
+		}
+
+		component_match_add(master_dev, &match, compare_of, parent);
+		of_node_put(parent);
+		of_node_put(port);
+	}
+
+	parent = dev->of_node;
+	for (i = 0; ; i++) {
+		parent = of_node_get(parent);
+		if (!of_device_is_available(parent)) {
+			of_node_put(parent);
+			continue;
+		}
+
+		if (!of_graph_is_present(parent)) {
+			of_node_put(parent);
+			break;
+		}
+
+		for_each_endpoint_of_node(parent, ep) {
+			remote = of_graph_get_remote_port_parent(ep);
+			if (!remote || !of_device_is_available(remote) ||
+			    remote == dev->of_node) {
+				of_node_put(remote);
+				continue;
+			} else if (!of_device_is_available(remote->parent)) {
+				dev_warn(dev, "parent dev of %s unavailable\n",
+					 remote->full_name);
+				of_node_put(remote);
+				continue;
+			}
+			component_match_add(master_dev, &match, compare_of,
+					    remote);
+			of_node_put(remote);
+		}
+		of_node_put(parent);
+
+		port = of_parse_phandle(dev->of_node, "ports", i);
+		if (!port)
+			break;
+
+		parent = port->parent;
+		if (!of_node_cmp(parent->name, "ports"))
+			parent = parent->parent;
+		of_node_put(port);
+	}
+
+	return component_master_add_with_match(master_dev, m_ops, match);
+}
+
+static int xlnx_compare_of(struct device *dev, void *data)
+{
+	return dev->of_node == data;
+}
+
+static int xlnx_platform_probe(struct platform_device *pdev)
+{
+	return xlnx_of_component_probe(&pdev->dev, xlnx_compare_of,
+				       &xlnx_master_ops);
+}
+
+static void xlnx_platform_remove(struct platform_device *pdev)
+{
+	component_master_del(&pdev->dev, &xlnx_master_ops);
+}
+
+static void xlnx_platform_shutdown(struct platform_device *pdev)
+{
+	component_master_del(&pdev->dev, &xlnx_master_ops);
+}
+
+static int __maybe_unused xlnx_pm_suspend(struct device *dev)
+{
+	struct xlnx_drm *xlnx_drm = dev_get_drvdata(dev);
+	struct drm_device *drm = xlnx_drm->drm;
+
+	drm_kms_helper_poll_disable(drm);
+
+	xlnx_drm->suspend_state = drm_atomic_helper_suspend(drm);
+	if (IS_ERR(xlnx_drm->suspend_state)) {
+		drm_kms_helper_poll_enable(drm);
+		return PTR_ERR(xlnx_drm->suspend_state);
+	}
+
+	return 0;
+}
+
+static int __maybe_unused xlnx_pm_resume(struct device *dev)
+{
+	struct xlnx_drm *xlnx_drm = dev_get_drvdata(dev);
+	struct drm_device *drm = xlnx_drm->drm;
+
+	drm_atomic_helper_resume(drm, xlnx_drm->suspend_state);
+	drm_kms_helper_poll_enable(drm);
+
+	return 0;
+}
+
+static const struct dev_pm_ops xlnx_pm_ops = {
+	SET_SYSTEM_SLEEP_PM_OPS(xlnx_pm_suspend, xlnx_pm_resume)
+};
+
+static struct platform_driver xlnx_driver = {
+	.probe			= xlnx_platform_probe,
+	.remove			= xlnx_platform_remove,
+	.shutdown		= xlnx_platform_shutdown,
+	.driver			= {
+		.name		= "xlnx-drm",
+		.pm		= &xlnx_pm_ops,
+	},
+};
+
+/* bitmap for master id */
+static u32 xlnx_master_ids = GENMASK(31, 0);
+
+/**
+ * xlnx_drm_pipeline_init - Initialize the drm pipeline for the device
+ * @pdev: The platform device to initialize the drm pipeline device
+ *
+ * This function initializes the drm pipeline device, struct drm_device,
+ * on @pdev by creating a logical master platform device. The logical platform
+ * device acts as a master device to bind slave devices and represents
+ * the entire pipeline.
+ * The logical master uses the port bindings of the calling device to
+ * figure out the pipeline topology.
+ *
+ * Return: the logical master platform device if the drm device is initialized
+ * on @pdev. Error code otherwise.
+ */
+struct platform_device *xlnx_drm_pipeline_init(struct platform_device *pdev)
+{
+	struct platform_device *master;
+	int id, ret;
+
+	id = ffs(xlnx_master_ids);
+	if (!id)
+		return ERR_PTR(-ENOSPC);
+
+	master = platform_device_alloc("xlnx-drm", id - 1);
+	if (!master)
+		return ERR_PTR(-ENOMEM);
+
+	master->dev.parent = &pdev->dev;
+	ret = platform_device_add(master);
+	if (ret)
+		goto err_out;
+
+	WARN_ON(master->id != id - 1);
+	xlnx_master_ids &= ~BIT(master->id);
+	return master;
+
+err_out:
+	platform_device_unregister(master);
+	return ERR_PTR(ret);
+}
+EXPORT_SYMBOL_GPL(xlnx_drm_pipeline_init);
+
+/**
+ * xlnx_drm_pipeline_exit - Release the drm pipeline for the device
+ * @master: The master pipeline device to release
+ *
+ * Release the logical pipeline device returned by xlnx_drm_pipeline_init().
+ */
+void xlnx_drm_pipeline_exit(struct platform_device *master)
+{
+	xlnx_master_ids |= BIT(master->id);
+	platform_device_unregister(master);
+}
+EXPORT_SYMBOL_GPL(xlnx_drm_pipeline_exit);
+
+static int __init xlnx_drm_drv_init(void)
+{
+	xlnx_bridge_helper_init();
+	platform_driver_register(&xlnx_driver);
+	return 0;
+}
+
+static void __exit xlnx_drm_drv_exit(void)
+{
+	platform_driver_unregister(&xlnx_driver);
+	xlnx_bridge_helper_fini();
+}
+
+module_init(xlnx_drm_drv_init);
+module_exit(xlnx_drm_drv_exit);
+
+MODULE_AUTHOR("Xilinx, Inc.");
+MODULE_DESCRIPTION("Xilinx DRM KMS Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/xlnx_drv.h b/drivers/gpu/drm/xlnx/xlnx_drv.h
new file mode 100644
index 000000000..d016e169f
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_drv.h
@@ -0,0 +1,33 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx DRM KMS Header for Xilinx
+ *
+ *  Copyright (C) 2013 - 2018 Xilinx, Inc.
+ *
+ *  Author: Hyun Woo Kwon <hyunk@xilinx.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _XLNX_DRV_H_
+#define _XLNX_DRV_H_
+
+struct drm_device;
+struct xlnx_crtc_helper;
+
+struct platform_device *xlnx_drm_pipeline_init(struct platform_device *parent);
+void xlnx_drm_pipeline_exit(struct platform_device *pipeline);
+
+uint32_t xlnx_get_format(struct drm_device *drm);
+unsigned int xlnx_get_align(struct drm_device *drm);
+struct xlnx_crtc_helper *xlnx_get_crtc_helper(struct drm_device *drm);
+struct xlnx_bridge_helper *xlnx_get_bridge_helper(struct drm_device *drm);
+
+#endif /* _XLNX_DRV_H_ */
diff --git a/drivers/gpu/drm/xlnx/xlnx_dsi.c b/drivers/gpu/drm/xlnx/xlnx_dsi.c
new file mode 100644
index 000000000..70cc66462
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_dsi.c
@@ -0,0 +1,1034 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx FPGA MIPI DSI Tx Controller driver.
+ *
+ * Copyright (C) 2017 - 2018 Xilinx, Inc.
+ *
+ * Author : Saurabh Sengar <saurabhs@xilinx.com>
+ *        : Siva Rajesh J <siva.rajesh.jarugula@xilinx.com>
+ */
+
+#include <drm/drm_atomic_helper.h>
+#include <drm/drm_crtc.h>
+#include <drm/drm_crtc_helper.h>
+#include <drm/drm_fourcc.h>
+#include <drm/drm_gem_dma_helper.h>
+#include <drm/drm_mipi_dsi.h>
+#include <drm/drm_panel.h>
+#include <drm/drm_probe_helper.h>
+#include <linux/clk.h>
+#include <linux/component.h>
+#include <linux/device.h>
+#include <linux/iopoll.h>
+#include <linux/of_device.h>
+#include <linux/of_graph.h>
+#include <linux/phy/phy.h>
+#include <linux/platform_device.h>
+#include <video/mipi_display.h>
+#include <video/videomode.h>
+
+#include "xlnx_bridge.h"
+
+/* DSI Tx IP registers */
+#define XDSI_CCR			0x00
+#define XDSI_CCR_COREENB		BIT(0)
+#define XDSI_CCR_SOFTRST		BIT(1)
+#define XDSI_CCR_CRREADY		BIT(2)
+#define XDSI_CCR_CMDMODE		BIT(3)
+#define XDSI_CCR_DFIFORST		BIT(4)
+#define XDSI_CCR_CMDFIFORST		BIT(5)
+#define XDSI_PCR			0x04
+#define XDSI_PCR_VIDEOMODE(x)		(((x) & 0x3) << 3)
+#define XDSI_PCR_VIDEOMODE_MASK		(0x3 << 3)
+#define XDSI_PCR_VIDEOMODE_SHIFT	3
+#define XDSI_PCR_BLLPTYPE(x)		((x) << 5)
+#define XDSI_PCR_BLLPMODE(x)		((x) << 6)
+#define XDSI_PCR_EOTPENABLE(x)		((x) << 13)
+#define XDSI_GIER			0x20
+#define XDSI_ISR			0x24
+#define XDSI_IER			0x28
+#define XDSI_STR			0x2C
+#define XDSI_STR_RDY_SHPKT		BIT(6)
+#define XDSI_STR_RDY_LNGPKT		BIT(7)
+#define XDSI_STR_DFIFO_FULL		BIT(8)
+#define XDSI_STR_DFIFO_EMPTY		BIT(9)
+#define XDSI_STR_WAITFR_DATA		BIT(10)
+#define XDSI_STR_CMD_EXE_PGS		BIT(11)
+#define XDSI_STR_CCMD_PROC		BIT(12)
+#define XDSI_STR_LPKT_MASK		(0x5 << 7)
+#define XDSI_CMD			0x30
+#define XDSI_CMD_QUEUE_PACKET(x)	((x) & GENMASK(23, 0))
+#define XDSI_DFR			0x34
+#define XDSI_TIME1			0x50
+#define XDSI_TIME1_BLLP_BURST(x)	((x) & GENMASK(15, 0))
+#define XDSI_TIME1_HSA(x)		(((x) & GENMASK(15, 0)) << 16)
+#define XDSI_TIME2			0x54
+#define XDSI_TIME2_VACT(x)		((x) & GENMASK(15, 0))
+#define XDSI_TIME2_HACT(x)		(((x) & GENMASK(15, 0)) << 16)
+#define XDSI_HACT_MULTIPLIER		GENMASK(1, 0)
+#define XDSI_TIME3			0x58
+#define XDSI_TIME3_HFP(x)		((x) & GENMASK(15, 0))
+#define XDSI_TIME3_HBP(x)		(((x) & GENMASK(15, 0)) << 16)
+#define XDSI_TIME4			0x5c
+#define XDSI_TIME4_VFP(x)		((x) & GENMASK(7, 0))
+#define XDSI_TIME4_VBP(x)		(((x) & GENMASK(7, 0)) << 8)
+#define XDSI_TIME4_VSA(x)		(((x) & GENMASK(7, 0)) << 16)
+#define XDSI_LTIME			0x60
+#define XDSI_BLLP_TIME			0x64
+/*
+ * XDSI_NUM_DATA_T represents number of data types in the
+ * enum mipi_dsi_pixel_format in the MIPI DSI part of DRM framework.
+ */
+#define XDSI_NUM_DATA_T			4
+#define XDSI_VIDEO_MODE_SYNC_PULSE	0x0
+#define XDSI_VIDEO_MODE_SYNC_EVENT	0x1
+#define XDSI_VIDEO_MODE_BURST		0x2
+
+#define XDSI_DPHY_CLK_MIN	197000000UL
+#define XDSI_DPHY_CLK_MAX	203000000UL
+#define XDSI_DPHY_CLK_REQ	200000000UL
+
+/* command timeout in usec */
+#define XDSI_CMD_TIMEOUT_VAL	(3000)
+
+/**
+ * struct xlnx_dsi - Core configuration DSI Tx subsystem device structure
+ * @encoder: DRM encoder structure
+ * @dsi_host: DSI host device
+ * @connector: DRM connector structure
+ * @panel: DRM panel structure
+ * @panel_node: MIPI DSI device panel node
+ * @dev: device structure
+ * @iomem: Base address of DSI subsystem
+ * @vm: videomode data structure
+ * @eotp_prop: configurable EoTP DSI parameter
+ * @bllp_mode_prop: configurable BLLP mode DSI parameter
+ * @bllp_type_prop: configurable BLLP type DSI parameter
+ * @video_mode_prop: configurable Video mode DSI parameter
+ * @bllp_burst_time_prop: Configurable BLLP time for burst mode
+ * @cmd_queue_prop: configurable command queue
+ * @height_out: configurable bridge output height parameter
+ * @width_out: configurable bridge output width parameter
+ * @in_fmt: configurable bridge input media format
+ * @out_fmt: configurable bridge output media format
+ * @bridge: bridge structure
+ * @video_mode_prop_val: configurable Video mode DSI parameter value
+ * @bllp_burst_time_prop_val: Configurable BLLP time for burst mode value
+ * @cmd_queue_prop_val: configurable command queue value
+ * @height_out_prop_val: configurable bridge output height parameter value
+ * @width_out_prop_val: configurable bridge output width parameter value
+ * @in_fmt_prop_val: configurable media bus format value
+ * @out_fmt_prop_val: configurable media bus format value
+ * @lanes: number of active data lanes supported by DSI controller
+ * @mode_flags: DSI operation mode related flags
+ * @mul_factor: multiplication factor for HACT timing parameter
+ * @video_aclk: Video clock
+ * @dphy_clk_200M: 200MHz DPHY clock and AXI Lite clock
+ * @format: pixel format for video mode of DSI controller
+ * @cmdmode: command mode support
+ * @eotp_prop_val: configurable EoTP DSI parameter value
+ * @bllp_mode_prop_val: configurable BLLP mode DSI parameter value
+ * @bllp_type_prop_val: configurable BLLP type DSI parameter value
+ */
+struct xlnx_dsi {
+	struct drm_encoder encoder;
+	struct mipi_dsi_host dsi_host;
+	struct drm_connector connector;
+	struct drm_panel *panel;
+	struct device_node *panel_node;
+	struct device *dev;
+	void __iomem *iomem;
+	struct videomode vm;
+	struct drm_property *eotp_prop;
+	struct drm_property *bllp_mode_prop;
+	struct drm_property *bllp_type_prop;
+	struct drm_property *video_mode_prop;
+	struct drm_property *bllp_burst_time_prop;
+	struct drm_property *cmd_queue_prop;
+	struct drm_property *height_out;
+	struct drm_property *width_out;
+	struct drm_property *in_fmt;
+	struct drm_property *out_fmt;
+	struct xlnx_bridge *bridge;
+	u32 video_mode_prop_val;
+	u32 bllp_burst_time_prop_val;
+	u32 cmd_queue_prop_val;
+	u32 height_out_prop_val;
+	u32 width_out_prop_val;
+	u32 in_fmt_prop_val;
+	u32 out_fmt_prop_val;
+	u32 lanes;
+	u32 mode_flags;
+	u32 mul_factor;
+	struct clk *video_aclk;
+	struct clk *dphy_clk_200M;
+	enum mipi_dsi_pixel_format format;
+	bool cmdmode;
+	bool eotp_prop_val;
+	bool bllp_mode_prop_val;
+	bool bllp_type_prop_val;
+};
+
+#define host_to_dsi(host) container_of(host, struct xlnx_dsi, dsi_host)
+#define connector_to_dsi(c) container_of(c, struct xlnx_dsi, connector)
+#define encoder_to_dsi(e) container_of(e, struct xlnx_dsi, encoder)
+
+static inline void xlnx_dsi_writel(void __iomem *base, int offset, u32 val)
+{
+	writel(val, base + offset);
+}
+
+static inline u32 xlnx_dsi_readl(void __iomem *base, int offset)
+{
+	return readl(base + offset);
+}
+
+/**
+ * xlnx_dsi_set_config_parameters - Configure DSI Tx registers with parameters
+ * given from user application.
+ * @dsi: DSI structure having the updated user parameters
+ *
+ * This function takes the DSI structure having drm_property parameters
+ * configured from  user application and writes them into DSI IP registers.
+ */
+static void xlnx_dsi_set_config_parameters(struct xlnx_dsi *dsi)
+{
+	u32 reg;
+
+	reg = XDSI_PCR_EOTPENABLE(dsi->eotp_prop_val);
+	reg |= XDSI_PCR_VIDEOMODE(dsi->video_mode_prop_val);
+	reg |= XDSI_PCR_BLLPTYPE(dsi->bllp_type_prop_val);
+	reg |= XDSI_PCR_BLLPMODE(dsi->bllp_mode_prop_val);
+
+	xlnx_dsi_writel(dsi->iomem, XDSI_PCR, reg);
+	/*
+	 * Configure the burst time if video mode is burst.
+	 * HSA of TIME1 register is ignored in this mode.
+	 */
+	if (dsi->video_mode_prop_val == XDSI_VIDEO_MODE_BURST) {
+		reg = XDSI_TIME1_BLLP_BURST(dsi->bllp_burst_time_prop_val);
+		xlnx_dsi_writel(dsi->iomem, XDSI_TIME1, reg);
+	}
+
+	reg = XDSI_CMD_QUEUE_PACKET(dsi->cmd_queue_prop_val);
+	xlnx_dsi_writel(dsi->iomem, XDSI_CMD, reg);
+
+	dev_dbg(dsi->dev, "PCR register value is = %x\n",
+		xlnx_dsi_readl(dsi->iomem, XDSI_PCR));
+}
+
+/**
+ * xlnx_dsi_set_display_mode - Configure DSI timing registers
+ * @dsi: DSI structure having the updated user parameters
+ *
+ * This function writes the timing parameters of DSI IP which are
+ * retrieved from panel timing values.
+ */
+static void xlnx_dsi_set_display_mode(struct xlnx_dsi *dsi)
+{
+	struct videomode *vm = &dsi->vm;
+	u32 reg, video_mode;
+
+	reg = xlnx_dsi_readl(dsi->iomem, XDSI_PCR);
+	video_mode = (reg & XDSI_PCR_VIDEOMODE_MASK) >>
+		      XDSI_PCR_VIDEOMODE_SHIFT;
+
+	/* configure the HSA value only if non_burst_sync_pluse video mode */
+	if (!video_mode &&
+	    (dsi->mode_flags & MIPI_DSI_MODE_VIDEO_SYNC_PULSE)) {
+		reg = XDSI_TIME1_HSA(vm->hsync_len);
+		xlnx_dsi_writel(dsi->iomem, XDSI_TIME1, reg);
+	}
+
+	reg = XDSI_TIME4_VFP(vm->vfront_porch) |
+	      XDSI_TIME4_VBP(vm->vback_porch) |
+	      XDSI_TIME4_VSA(vm->vsync_len);
+	xlnx_dsi_writel(dsi->iomem, XDSI_TIME4, reg);
+
+	reg = XDSI_TIME3_HFP(vm->hfront_porch) |
+	      XDSI_TIME3_HBP(vm->hback_porch);
+	xlnx_dsi_writel(dsi->iomem, XDSI_TIME3, reg);
+
+	dev_dbg(dsi->dev, "mul factor for parsed datatype is = %d\n",
+		(dsi->mul_factor) / 100);
+	/*
+	 * The HACT parameter received from panel timing values should be
+	 * divisible by 4. The reason for this is, the word count given as
+	 * input to DSI controller is HACT * mul_factor. The mul_factor is
+	 * 3, 2.25, 2.25, 2 respectively for RGB888, RGB666_L, RGB666_P and
+	 * RGB565.
+	 * e.g. for RGB666_L color format and 1080p, the word count is
+	 * 1920*2.25 = 4320 which is divisible by 4 and it is a valid input
+	 * to DSI controller. Based on this 2.25 mul factor, we come up with
+	 * the division factor of (XDSI_HACT_MULTIPLIER) as 4 for checking
+	 */
+	if ((vm->hactive & XDSI_HACT_MULTIPLIER) != 0)
+		dev_warn(dsi->dev, "Incorrect HACT will be programmed\n");
+
+	reg = XDSI_TIME2_HACT((vm->hactive) * (dsi->mul_factor) / 100) |
+	      XDSI_TIME2_VACT(vm->vactive);
+	xlnx_dsi_writel(dsi->iomem, XDSI_TIME2, reg);
+
+	dev_dbg(dsi->dev, "LCD size = %dx%d\n", vm->hactive, vm->vactive);
+}
+
+/**
+ * xlnx_dsi_set_display_enable - Enables the DSI Tx IP core enable
+ * register bit
+ * @dsi: DSI structure having the updated user parameters
+ *
+ * This function takes the DSI strucure and enables the core enable bit
+ * of core configuration register.
+ */
+static void xlnx_dsi_set_display_enable(struct xlnx_dsi *dsi)
+{
+	u32 reg;
+
+	reg = xlnx_dsi_readl(dsi->iomem, XDSI_CCR);
+	reg |= XDSI_CCR_COREENB;
+
+	xlnx_dsi_writel(dsi->iomem, XDSI_CCR, reg);
+	dev_dbg(dsi->dev, "MIPI DSI Tx controller is enabled.\n");
+}
+
+/**
+ * xlnx_dsi_set_display_disable - Disable the DSI Tx IP core enable
+ * register bit
+ * @dsi: DSI structure having the updated user parameters
+ *
+ * This function takes the DSI strucure and disables the core enable bit
+ * of core configuration register.
+ */
+static void xlnx_dsi_set_display_disable(struct xlnx_dsi *dsi)
+{
+	u32 reg;
+
+	reg = xlnx_dsi_readl(dsi->iomem, XDSI_CCR);
+	reg &= ~XDSI_CCR_COREENB;
+
+	xlnx_dsi_writel(dsi->iomem, XDSI_CCR, reg);
+	dev_dbg(dsi->dev, "DSI Tx is disabled. reset regs to default values\n");
+}
+
+/**
+ * xlnx_dsi_atomic_set_property - implementation of drm_connector_funcs
+ * set_property invoked by IOCTL call to DRM_IOCTL_MODE_OBJ_SETPROPERTY
+ *
+ * @connector: pointer Xilinx DSI connector
+ * @state: DRM connector state
+ * @prop: pointer to the drm_property structure
+ * @val: DSI parameter value that is configured from user application
+ *
+ * This function takes a drm_property name and value given from user application
+ * and update the DSI structure property varabiles with the values.
+ * These values are later used to configure the DSI Rx IP.
+ *
+ * Return: 0 on success OR -EINVAL if setting property fails
+ */
+static int xlnx_dsi_atomic_set_property(struct drm_connector *connector,
+					struct drm_connector_state *state,
+					struct drm_property *prop, u64 val)
+{
+	struct xlnx_dsi *dsi = connector_to_dsi(connector);
+
+	dev_dbg(dsi->dev, "property name = %s, value = %lld\n",
+		prop->name, val);
+
+	if (prop == dsi->eotp_prop)
+		dsi->eotp_prop_val = !!val;
+	else if (prop == dsi->bllp_mode_prop)
+		dsi->bllp_mode_prop_val = !!val;
+	else if (prop == dsi->bllp_type_prop)
+		dsi->bllp_type_prop_val = !!val;
+	else if (prop == dsi->video_mode_prop)
+		dsi->video_mode_prop_val = (unsigned int)val;
+	else if (prop == dsi->bllp_burst_time_prop)
+		dsi->bllp_burst_time_prop_val = (unsigned int)val;
+	else if (prop == dsi->cmd_queue_prop)
+		dsi->cmd_queue_prop_val = (unsigned int)val;
+	else if (prop == dsi->height_out)
+		dsi->height_out_prop_val = (u32)val;
+	else if (prop == dsi->width_out)
+		dsi->width_out_prop_val = (u32)val;
+	else if (prop == dsi->in_fmt)
+		dsi->in_fmt_prop_val = (u32)val;
+	else if (prop == dsi->out_fmt)
+		dsi->out_fmt_prop_val = (u32)val;
+	else
+		return -EINVAL;
+
+	xlnx_dsi_set_config_parameters(dsi);
+
+	return 0;
+}
+
+static int
+xlnx_dsi_atomic_get_property(struct drm_connector *connector,
+			     const struct drm_connector_state *state,
+			     struct drm_property *prop, uint64_t *val)
+{
+	struct xlnx_dsi *dsi = connector_to_dsi(connector);
+
+	if (prop == dsi->eotp_prop)
+		*val = dsi->eotp_prop_val;
+	else if (prop == dsi->bllp_mode_prop)
+		*val = dsi->bllp_mode_prop_val;
+	else if (prop == dsi->bllp_type_prop)
+		*val = dsi->bllp_type_prop_val;
+	else if (prop == dsi->video_mode_prop)
+		*val = dsi->video_mode_prop_val;
+	else if (prop == dsi->bllp_burst_time_prop)
+		*val = dsi->bllp_burst_time_prop_val;
+	else if (prop == dsi->cmd_queue_prop)
+		*val = dsi->cmd_queue_prop_val;
+	else if (prop == dsi->height_out)
+		*val = dsi->height_out_prop_val;
+	else if (prop == dsi->width_out)
+		*val = dsi->width_out_prop_val;
+	else if (prop == dsi->in_fmt)
+		*val = dsi->in_fmt_prop_val;
+	else if (prop == dsi->out_fmt)
+		*val = dsi->out_fmt_prop_val;
+	else
+		return -EINVAL;
+
+	return 0;
+}
+
+/**
+ * xlnx_dsi_host_transfer - transfer command to panel
+ * @host: mipi dsi host structure
+ * @msg: mipi dsi msg with type, length and data
+ *
+ * This function is valid only in command mode.
+ * It checks the command fifo empty status and writes into
+ * data or cmd register and waits for the completion status.
+ *
+ * Return:	number of bytes, on success and error number on failure
+ */
+static ssize_t xlnx_dsi_host_transfer(struct mipi_dsi_host *host,
+				      const struct mipi_dsi_msg *msg)
+{
+	struct xlnx_dsi *dsi = host_to_dsi(host);
+	u32 data0, data1, cmd0, val, offset;
+	int status;
+	const char *tx_buf = msg->tx_buf;
+
+	switch (msg->type) {
+	case MIPI_DSI_DCS_LONG_WRITE:
+		status = readl_poll_timeout(dsi->iomem + XDSI_STR, val,
+					    (val & XDSI_STR_LPKT_MASK) ==
+					     XDSI_STR_LPKT_MASK, 1,
+					    XDSI_CMD_TIMEOUT_VAL);
+		if (status) {
+			dev_err(dsi->dev, "long cmd fifo not empty!\n");
+			return -ETIMEDOUT;
+		}
+		data0 = tx_buf[0] | (tx_buf[1] << 8) | (tx_buf[2] << 16) |
+			(tx_buf[3] << 24);
+		data1 = tx_buf[4] | (tx_buf[5] << 8);
+		cmd0 = msg->type | (MIPI_DSI_DCS_READ << 8);
+
+		xlnx_dsi_writel(dsi->iomem, XDSI_DFR, data0);
+		xlnx_dsi_writel(dsi->iomem, XDSI_DFR, data1);
+		xlnx_dsi_writel(dsi->iomem, XDSI_CMD, cmd0);
+		break;
+	case MIPI_DSI_GENERIC_LONG_WRITE:
+		status = readl_poll_timeout(dsi->iomem + XDSI_STR, val,
+					    (val & XDSI_STR_LPKT_MASK) ==
+					    XDSI_STR_LPKT_MASK, 1,
+					    XDSI_CMD_TIMEOUT_VAL);
+		if (status) {
+			dev_err(dsi->dev, "long cmd fifo not empty!\n");
+			return -EBUSY;
+		}
+		cmd0 = msg->type | (msg->tx_len << 8);
+		xlnx_dsi_writel(dsi->iomem, XDSI_CMD, cmd0);
+
+		for (offset = 0; offset <= msg->tx_len; offset += 4) {
+			data0 = tx_buf[0 + offset] | tx_buf[1 + offset] << 8 |
+				tx_buf[2 + offset] << 16 |
+				tx_buf[3 + offset] << 24;
+			xlnx_dsi_writel(dsi->iomem, XDSI_DFR, data0);
+		}
+		break;
+	case MIPI_DSI_DCS_SHORT_WRITE_PARAM:
+		status = readl_poll_timeout(dsi->iomem + XDSI_STR, val,
+					    (val & XDSI_STR_RDY_SHPKT) ==
+					    XDSI_STR_RDY_SHPKT, 1,
+					    XDSI_CMD_TIMEOUT_VAL);
+		if (status) {
+			dev_err(dsi->dev, "short cmd fifo not empty\n");
+			return -EBUSY;
+		}
+		data0 = MIPI_DSI_DCS_SHORT_WRITE_PARAM |
+			(tx_buf[0] << 8) | (tx_buf[1] << 16);
+		xlnx_dsi_writel(dsi->iomem, XDSI_CMD, data0);
+		break;
+	case MIPI_DSI_DCS_SHORT_WRITE:
+		status = readl_poll_timeout(dsi->iomem + XDSI_STR, val,
+					    (val & XDSI_STR_RDY_SHPKT) ==
+					    XDSI_STR_RDY_SHPKT, 1,
+					    XDSI_CMD_TIMEOUT_VAL);
+		if (status) {
+			dev_err(dsi->dev, "short cmd fifo not empty\n");
+			return -EBUSY;
+		}
+		data0 = MIPI_DSI_DCS_SHORT_WRITE | (tx_buf[0] << 8);
+		xlnx_dsi_writel(dsi->iomem, XDSI_CMD, data0);
+		break;
+	default:
+		dev_err(dsi->dev, "Unsupported command type\n");
+		return -EINVAL;
+	}
+
+	status = readl_poll_timeout(dsi->iomem + XDSI_STR, val,
+				    !(val & XDSI_STR_CMD_EXE_PGS), 1,
+				    XDSI_CMD_TIMEOUT_VAL);
+	if (status) {
+		dev_err(dsi->dev, "cmd timeout\n");
+		return status;
+	}
+
+	return msg->tx_len;
+}
+
+static int xlnx_dsi_host_attach(struct mipi_dsi_host *host,
+				struct mipi_dsi_device *device)
+{
+	u32 panel_lanes;
+	struct xlnx_dsi *dsi = host_to_dsi(host);
+
+	panel_lanes = device->lanes;
+	dsi->mode_flags = device->mode_flags;
+	dsi->panel_node = device->dev.of_node;
+
+	if (panel_lanes != dsi->lanes) {
+		dev_err(dsi->dev, "Mismatch of lanes. panel = %d, DSI = %d\n",
+			panel_lanes, dsi->lanes);
+		return -EINVAL;
+	}
+
+	if (dsi->lanes > 4 || dsi->lanes < 1) {
+		dev_err(dsi->dev, "%d lanes : invalid xlnx,dsi-num-lanes\n",
+			dsi->lanes);
+		return -EINVAL;
+	}
+
+	if (device->format != dsi->format) {
+		dev_err(dsi->dev, "Mismatch of format. panel = %d, DSI = %d\n",
+			device->format, dsi->format);
+		return -EINVAL;
+	}
+
+	if (dsi->connector.dev)
+		drm_helper_hpd_irq_event(dsi->connector.dev);
+
+	return 0;
+}
+
+static int xlnx_dsi_host_detach(struct mipi_dsi_host *host,
+				struct mipi_dsi_device *device)
+{
+	struct xlnx_dsi *dsi = host_to_dsi(host);
+
+	dsi->panel = NULL;
+
+	if (dsi->connector.dev)
+		drm_helper_hpd_irq_event(dsi->connector.dev);
+
+	return 0;
+}
+
+static const struct mipi_dsi_host_ops xlnx_dsi_ops = {
+	.attach = xlnx_dsi_host_attach,
+	.detach = xlnx_dsi_host_detach,
+	.transfer = xlnx_dsi_host_transfer,
+};
+
+static int xlnx_dsi_connector_dpms(struct drm_connector *connector, int mode)
+{
+	struct xlnx_dsi *dsi = connector_to_dsi(connector);
+	int ret;
+
+	dev_dbg(dsi->dev, "connector dpms state: %d\n", mode);
+
+	switch (mode) {
+	case DRM_MODE_DPMS_ON:
+		ret = drm_panel_prepare(dsi->panel);
+		if (ret < 0) {
+			dev_err(dsi->dev, "DRM panel not found\n");
+			return ret;
+		}
+
+		ret = drm_panel_enable(dsi->panel);
+		if (ret < 0) {
+			drm_panel_unprepare(dsi->panel);
+			dev_err(dsi->dev, "DRM panel not enabled\n");
+			return ret;
+		}
+		break;
+	default:
+		drm_panel_disable(dsi->panel);
+		drm_panel_unprepare(dsi->panel);
+		break;
+	}
+
+	return drm_helper_connector_dpms(connector, mode);
+}
+
+static enum drm_connector_status
+xlnx_dsi_detect(struct drm_connector *connector, bool force)
+{
+	struct xlnx_dsi *dsi = connector_to_dsi(connector);
+
+	if (!dsi->panel) {
+		dsi->panel = of_drm_find_panel(dsi->panel_node);
+		if (dsi->panel) {
+			if (dsi->cmdmode) {
+				xlnx_dsi_writel(dsi->iomem, XDSI_CCR,
+						XDSI_CCR_CMDMODE |
+						XDSI_CCR_COREENB);
+				drm_panel_prepare(dsi->panel);
+				xlnx_dsi_writel(dsi->iomem, XDSI_CCR, 0);
+			}
+		}
+	} else if (!dsi->panel_node) {
+		xlnx_dsi_connector_dpms(connector, DRM_MODE_DPMS_OFF);
+		dsi->panel = NULL;
+	}
+
+	if (dsi->panel)
+		return connector_status_connected;
+
+	return connector_status_disconnected;
+}
+
+static void xlnx_dsi_connector_destroy(struct drm_connector *connector)
+{
+	drm_connector_unregister(connector);
+	drm_connector_cleanup(connector);
+	connector->dev = NULL;
+}
+
+static const struct drm_connector_funcs xlnx_dsi_connector_funcs = {
+	.dpms = xlnx_dsi_connector_dpms,
+	.detect = xlnx_dsi_detect,
+	.fill_modes = drm_helper_probe_single_connector_modes,
+	.destroy = xlnx_dsi_connector_destroy,
+	.atomic_set_property = xlnx_dsi_atomic_set_property,
+	.atomic_get_property = xlnx_dsi_atomic_get_property,
+	.atomic_duplicate_state	= drm_atomic_helper_connector_duplicate_state,
+	.atomic_destroy_state	= drm_atomic_helper_connector_destroy_state,
+	.reset			= drm_atomic_helper_connector_reset,
+};
+
+static int xlnx_dsi_get_modes(struct drm_connector *connector)
+{
+	struct xlnx_dsi *dsi = connector_to_dsi(connector);
+
+	if (dsi->panel)
+		return dsi->panel->funcs->get_modes(dsi->panel, connector);
+
+	return 0;
+}
+
+static struct drm_encoder *
+xlnx_dsi_best_encoder(struct drm_connector *connector)
+{
+	return &(connector_to_dsi(connector)->encoder);
+}
+
+static struct drm_connector_helper_funcs xlnx_dsi_connector_helper_funcs = {
+	.get_modes = xlnx_dsi_get_modes,
+	.best_encoder = xlnx_dsi_best_encoder,
+};
+
+/**
+ * xlnx_dsi_connector_create_property -  create DSI connector properties
+ *
+ * @connector: pointer to Xilinx DSI connector
+ *
+ * This function takes the xilinx DSI connector component and defines
+ * the drm_property variables with their default values.
+ */
+static void xlnx_dsi_connector_create_property(struct drm_connector *connector)
+{
+	struct drm_device *dev = connector->dev;
+	struct xlnx_dsi *dsi  = connector_to_dsi(connector);
+
+	dsi->eotp_prop = drm_property_create_bool(dev, 0, "eotp");
+	dsi->video_mode_prop = drm_property_create_range(dev, 0, "video_mode",
+							 0, 2);
+	dsi->bllp_mode_prop = drm_property_create_bool(dev, 0, "bllp_mode");
+	dsi->bllp_type_prop = drm_property_create_bool(dev, 0, "bllp_type");
+	dsi->bllp_burst_time_prop =
+		drm_property_create_range(dev, 0, "bllp_burst_time", 0, 0xFFFF);
+	dsi->cmd_queue_prop = drm_property_create_range(dev, 0, "cmd_queue", 0,
+							0xffffff);
+	dsi->height_out = drm_property_create_range(dev, 0, "height_out",
+						    2, 4096);
+	dsi->width_out = drm_property_create_range(dev, 0, "width_out",
+						   2, 4096);
+	dsi->in_fmt = drm_property_create_range(dev, 0, "in_fmt", 0, 16384);
+	dsi->out_fmt = drm_property_create_range(dev, 0, "out_fmt", 0, 16384);
+}
+
+/**
+ * xlnx_dsi_connector_attach_property -  attach DSI connector
+ * properties
+ *
+ * @connector: pointer to Xilinx DSI connector
+ */
+static void xlnx_dsi_connector_attach_property(struct drm_connector *connector)
+{
+	struct xlnx_dsi *dsi = connector_to_dsi(connector);
+	struct drm_mode_object *obj = &connector->base;
+
+	if (dsi->eotp_prop)
+		drm_object_attach_property(obj, dsi->eotp_prop, 1);
+
+	if (dsi->video_mode_prop)
+		drm_object_attach_property(obj, dsi->video_mode_prop, 0);
+
+	if (dsi->bllp_burst_time_prop)
+		drm_object_attach_property(&connector->base,
+					   dsi->bllp_burst_time_prop, 0);
+
+	if (dsi->bllp_mode_prop)
+		drm_object_attach_property(&connector->base,
+					   dsi->bllp_mode_prop, 0);
+
+	if (dsi->bllp_type_prop)
+		drm_object_attach_property(&connector->base,
+					   dsi->bllp_type_prop, 0);
+
+	if (dsi->cmd_queue_prop)
+		drm_object_attach_property(&connector->base,
+					   dsi->cmd_queue_prop, 0);
+
+	if (dsi->height_out)
+		drm_object_attach_property(obj, dsi->height_out, 0);
+
+	if (dsi->width_out)
+		drm_object_attach_property(obj, dsi->width_out, 0);
+
+	if (dsi->in_fmt)
+		drm_object_attach_property(obj, dsi->in_fmt, 0);
+
+	if (dsi->out_fmt)
+		drm_object_attach_property(obj, dsi->out_fmt, 0);
+}
+
+static int xlnx_dsi_create_connector(struct drm_encoder *encoder)
+{
+	struct xlnx_dsi *dsi = encoder_to_dsi(encoder);
+	struct drm_connector *connector = &dsi->connector;
+	int ret;
+
+	connector->polled = DRM_CONNECTOR_POLL_HPD;
+
+	ret = drm_connector_init(encoder->dev, connector,
+				 &xlnx_dsi_connector_funcs,
+				 DRM_MODE_CONNECTOR_DSI);
+	if (ret) {
+		dev_err(dsi->dev, "Failed to initialize connector with drm\n");
+		return ret;
+	}
+
+	drm_connector_helper_add(connector, &xlnx_dsi_connector_helper_funcs);
+	drm_connector_register(connector);
+	drm_connector_attach_encoder(connector, encoder);
+	xlnx_dsi_connector_create_property(connector);
+	xlnx_dsi_connector_attach_property(connector);
+
+	return 0;
+}
+
+/**
+ * xlnx_dsi_atomic_mode_set -  derive the DSI timing parameters
+ *
+ * @encoder: pointer to Xilinx DRM encoder
+ * @crtc_state: Pointer to drm core crtc state
+ * @connector_state: DSI connector drm state
+ *
+ * This function derives the DSI IP timing parameters from the timing
+ * values given in the attached panel driver.
+ */
+static void
+xlnx_dsi_atomic_mode_set(struct drm_encoder *encoder,
+			 struct drm_crtc_state *crtc_state,
+				 struct drm_connector_state *connector_state)
+{
+	struct xlnx_dsi *dsi = encoder_to_dsi(encoder);
+	struct videomode *vm = &dsi->vm;
+	struct drm_display_mode *m = &crtc_state->adjusted_mode;
+
+	/* Set bridge input and output parameters */
+	xlnx_bridge_set_input(dsi->bridge, m->hdisplay, m->vdisplay,
+			      dsi->in_fmt_prop_val);
+	xlnx_bridge_set_output(dsi->bridge, dsi->width_out_prop_val,
+			       dsi->height_out_prop_val,
+			       dsi->out_fmt_prop_val);
+	xlnx_bridge_enable(dsi->bridge);
+
+	vm->hactive = m->hdisplay;
+	vm->vactive = m->vdisplay;
+	vm->vfront_porch = m->vsync_start - m->vdisplay;
+	vm->vback_porch = m->vtotal - m->vsync_end;
+	vm->vsync_len = m->vsync_end - m->vsync_start;
+	vm->hfront_porch = m->hsync_start - m->hdisplay;
+	vm->hback_porch = m->htotal - m->hsync_end;
+	vm->hsync_len = m->hsync_end - m->hsync_start;
+	xlnx_dsi_set_display_mode(dsi);
+}
+
+static void xlnx_dsi_disable(struct drm_encoder *encoder)
+{
+	struct xlnx_dsi *dsi = encoder_to_dsi(encoder);
+
+	if (dsi->bridge)
+		xlnx_bridge_disable(dsi->bridge);
+
+	xlnx_dsi_set_display_disable(dsi);
+}
+
+static void xlnx_dsi_enable(struct drm_encoder *encoder)
+{
+	struct xlnx_dsi *dsi = encoder_to_dsi(encoder);
+
+	xlnx_dsi_set_display_enable(dsi);
+}
+
+static const struct drm_encoder_helper_funcs xlnx_dsi_encoder_helper_funcs = {
+	.atomic_mode_set = xlnx_dsi_atomic_mode_set,
+	.enable = xlnx_dsi_enable,
+	.disable = xlnx_dsi_disable,
+};
+
+static const struct drm_encoder_funcs xlnx_dsi_encoder_funcs = {
+	.destroy = drm_encoder_cleanup,
+};
+
+static int xlnx_dsi_parse_dt(struct xlnx_dsi *dsi)
+{
+	struct device *dev = dsi->dev;
+	struct device_node *node = dev->of_node;
+	int ret;
+	u32 datatype;
+	static const int xdsi_mul_fact[XDSI_NUM_DATA_T] = {300, 225, 225, 200};
+
+	dsi->dphy_clk_200M = devm_clk_get(dev, "dphy_clk_200M");
+	if (IS_ERR(dsi->dphy_clk_200M)) {
+		ret = PTR_ERR(dsi->dphy_clk_200M);
+		dev_err(dev, "failed to get dphy_clk_200M %d\n", ret);
+		return ret;
+	}
+
+	dsi->video_aclk = devm_clk_get(dev, "s_axis_aclk");
+	if (IS_ERR(dsi->video_aclk)) {
+		ret = PTR_ERR(dsi->video_aclk);
+		dev_err(dev, "failed to get video_clk %d\n", ret);
+		return ret;
+	}
+
+	/*
+	 * Used as a multiplication factor for HACT based on used
+	 * DSI data type.
+	 *
+	 * e.g. for RGB666_L datatype and 1920x1080 resolution,
+	 * the Hact (WC) would be as follows -
+	 * 1920 pixels * 18 bits per pixel / 8 bits per byte
+	 * = 1920 pixels * 2.25 bytes per pixel = 4320 bytes.
+	 *
+	 * Data Type - Multiplication factor
+	 * RGB888    - 3
+	 * RGB666_L  - 2.25
+-	 * RGB666_P  - 2.25
+	 * RGB565    - 2
+	 *
+	 * Since the multiplication factor maybe a floating number,
+	 * a 100x multiplication factor is used.
+	 */
+	ret = of_property_read_u32(node, "xlnx,dsi-num-lanes", &dsi->lanes);
+	if (ret < 0) {
+		dev_err(dsi->dev, "missing xlnx,dsi-num-lanes property\n");
+		return ret;
+	}
+	if (dsi->lanes > 4 || dsi->lanes < 1) {
+		dev_err(dsi->dev, "%d lanes : invalid lanes\n", dsi->lanes);
+		return -EINVAL;
+	}
+	ret = of_property_read_u32(node, "xlnx,dsi-data-type", &datatype);
+	if (ret < 0) {
+		dev_err(dsi->dev, "missing xlnx,dsi-data-type property\n");
+		return ret;
+	}
+	dsi->format = datatype;
+	if (datatype > MIPI_DSI_FMT_RGB565) {
+		dev_err(dsi->dev, "Invalid xlnx,dsi-data-type string\n");
+		return -EINVAL;
+	}
+	dsi->mul_factor = xdsi_mul_fact[datatype];
+
+	dsi->cmdmode = of_property_read_bool(node, "xlnx,dsi-cmd-mode");
+
+	dev_dbg(dsi->dev, "DSI controller num lanes = %d", dsi->lanes);
+	dev_dbg(dsi->dev, "DSI controller datatype = %d\n", datatype);
+	dev_dbg(dsi->dev, "DSI controller cmd mode = %d\n", dsi->cmdmode);
+
+	return 0;
+}
+
+static int xlnx_dsi_bind(struct device *dev, struct device *master,
+			 void *data)
+{
+	struct xlnx_dsi *dsi = dev_get_drvdata(dev);
+	struct drm_encoder *encoder = &dsi->encoder;
+	struct drm_device *drm_dev = data;
+	int ret;
+
+	/*
+	 * TODO: The possible CRTCs are 1 now as per current implementation of
+	 * DSI tx drivers. DRM framework can support more than one CRTCs and
+	 * DSI driver can be enhanced for that.
+	 */
+	encoder->possible_crtcs = 1;
+	drm_encoder_init(drm_dev, encoder, &xlnx_dsi_encoder_funcs,
+			 DRM_MODE_ENCODER_DSI, NULL);
+	drm_encoder_helper_add(encoder, &xlnx_dsi_encoder_helper_funcs);
+	ret = xlnx_dsi_create_connector(encoder);
+	if (ret) {
+		dev_err(dsi->dev, "fail creating connector, ret = %d\n", ret);
+		drm_encoder_cleanup(encoder);
+		return ret;
+	}
+	ret = mipi_dsi_host_register(&dsi->dsi_host);
+	if (ret) {
+		xlnx_dsi_connector_destroy(&dsi->connector);
+		drm_encoder_cleanup(encoder);
+		return ret;
+	}
+	return 0;
+}
+
+static void xlnx_dsi_unbind(struct device *dev, struct device *master,
+			    void *data)
+{
+	struct xlnx_dsi *dsi = dev_get_drvdata(dev);
+
+	xlnx_dsi_disable(&dsi->encoder);
+	mipi_dsi_host_unregister(&dsi->dsi_host);
+	xlnx_bridge_disable(dsi->bridge);
+}
+
+static const struct component_ops xlnx_dsi_component_ops = {
+	.bind	= xlnx_dsi_bind,
+	.unbind	= xlnx_dsi_unbind,
+};
+
+static int xlnx_dsi_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct xlnx_dsi *dsi;
+	struct device_node *vpss_node;
+	int ret;
+	unsigned long rate;
+
+	dsi = devm_kzalloc(dev, sizeof(*dsi), GFP_KERNEL);
+	if (!dsi)
+		return -ENOMEM;
+
+	dsi->dsi_host.ops = &xlnx_dsi_ops;
+	dsi->dsi_host.dev = dev;
+	dsi->dev = dev;
+
+	ret = xlnx_dsi_parse_dt(dsi);
+	if (ret)
+		return ret;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	dsi->iomem = devm_ioremap_resource(dev, res);
+	if (IS_ERR(dsi->iomem))
+		return PTR_ERR(dsi->iomem);
+
+	platform_set_drvdata(pdev, dsi);
+
+	/* Bridge support */
+	vpss_node = of_parse_phandle(dsi->dev->of_node, "xlnx,vpss", 0);
+	if (vpss_node) {
+		dsi->bridge = of_xlnx_bridge_get(vpss_node);
+		if (!dsi->bridge) {
+			dev_info(dsi->dev, "Didn't get bridge instance\n");
+			return -EPROBE_DEFER;
+		}
+	}
+
+	ret = clk_set_rate(dsi->dphy_clk_200M, XDSI_DPHY_CLK_REQ);
+	if (ret) {
+		dev_err(dev, "failed to set dphy clk rate %d\n", ret);
+		return ret;
+	}
+
+	ret = clk_prepare_enable(dsi->dphy_clk_200M);
+	if (ret) {
+		dev_err(dev, "failed to enable dphy clk %d\n", ret);
+		return ret;
+	}
+
+	rate = clk_get_rate(dsi->dphy_clk_200M);
+	if (rate < XDSI_DPHY_CLK_MIN && rate > XDSI_DPHY_CLK_MAX) {
+		dev_err(dev, "Error DPHY clock = %lu\n", rate);
+		ret = -EINVAL;
+		goto err_disable_dphy_clk;
+	}
+
+	ret = clk_prepare_enable(dsi->video_aclk);
+	if (ret) {
+		dev_err(dev, "failed to enable video clk %d\n", ret);
+		goto err_disable_dphy_clk;
+	}
+
+	ret = component_add(dev, &xlnx_dsi_component_ops);
+	if (ret < 0)
+		goto err_disable_video_clk;
+
+	return ret;
+
+err_disable_video_clk:
+	clk_disable_unprepare(dsi->video_aclk);
+err_disable_dphy_clk:
+	clk_disable_unprepare(dsi->dphy_clk_200M);
+	return ret;
+}
+
+static void xlnx_dsi_remove(struct platform_device *pdev)
+{
+	struct xlnx_dsi *dsi = platform_get_drvdata(pdev);
+
+	component_del(&pdev->dev, &xlnx_dsi_component_ops);
+	clk_disable_unprepare(dsi->video_aclk);
+	clk_disable_unprepare(dsi->dphy_clk_200M);
+}
+
+static const struct of_device_id xlnx_dsi_of_match[] = {
+	{ .compatible = "xlnx,dsi"},
+	{ }
+};
+MODULE_DEVICE_TABLE(of, xlnx_dsi_of_match);
+
+static struct platform_driver dsi_driver = {
+	.probe = xlnx_dsi_probe,
+	.remove = xlnx_dsi_remove,
+	.driver = {
+		.name = "xlnx-dsi",
+		.of_match_table = xlnx_dsi_of_match,
+	},
+};
+
+module_platform_driver(dsi_driver);
+
+MODULE_AUTHOR("Siva Rajesh <sivaraj@xilinx.com>");
+MODULE_DESCRIPTION("Xilinx FPGA MIPI DSI Tx Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/xlnx_fb.c b/drivers/gpu/drm/xlnx/xlnx_fb.c
new file mode 100644
index 000000000..12959693c
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_fb.c
@@ -0,0 +1,353 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx DRM KMS Framebuffer helper
+ *
+ *  Copyright (C) 2015 - 2018 Xilinx, Inc.
+ *
+ *  Author: Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ *
+ * Based on drm_fb_cma_helper.c
+ *
+ *  Copyright (C) 2012 Analog Device Inc.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <drm/drm_vblank.h>
+#include <drm/drm_fourcc.h>
+#include <drm/drm_crtc.h>
+#include <drm/drm_crtc_helper.h>
+#include <drm/drm_fb_helper.h>
+#include <drm/drm_framebuffer.h>
+#include <drm/drm_gem_dma_helper.h>
+#include <drm/drm_gem_framebuffer_helper.h>
+#include <drm/drm_modeset_helper.h>
+
+#include "xlnx_crtc.h"
+#include "xlnx_drv.h"
+#include "xlnx_fb.h"
+
+static struct drm_framebuffer_funcs xlnx_fb_funcs = {
+	.destroy	= drm_gem_fb_destroy,
+	.create_handle	= drm_gem_fb_create_handle,
+};
+
+/**
+ * xlnx_fb_create - (struct drm_mode_config_funcs *)->fb_create callback
+ * @drm: DRM device
+ * @file_priv: drm file private data
+ * @mode_cmd: mode command for fb creation
+ *
+ * This functions creates a drm_framebuffer with xlnx_fb_funcs for given mode
+ * @mode_cmd. This functions is intended to be used for the fb_create callback
+ * function of drm_mode_config_funcs.
+ *
+ * Return: a drm_framebuffer object if successful, or
+ * ERR_PTR from drm_gem_fb_create_with_funcs().
+ */
+struct drm_framebuffer *
+xlnx_fb_create(struct drm_device *drm, struct drm_file *file_priv,
+	       const struct drm_mode_fb_cmd2 *mode_cmd)
+{
+	return drm_gem_fb_create_with_funcs(drm, file_priv, mode_cmd,
+					    &xlnx_fb_funcs);
+}
+
+#ifdef CONFIG_DRM_FBDEV_EMULATION
+
+struct xlnx_fbdev {
+	struct drm_fb_helper fb_helper;
+	struct drm_framebuffer *fb;
+	unsigned int align;
+	unsigned int vres_mult;
+};
+
+static inline struct xlnx_fbdev *to_fbdev(struct drm_fb_helper *fb_helper)
+{
+	return container_of(fb_helper, struct xlnx_fbdev, fb_helper);
+}
+
+static int
+xlnx_fb_ioctl(struct fb_info *info, unsigned int cmd, unsigned long arg)
+{
+	struct drm_fb_helper *fb_helper = info->par;
+	struct drm_mode_set *mode_set;
+	int ret = 0;
+
+	switch (cmd) {
+	case FBIO_WAITFORVSYNC:
+		drm_client_for_each_modeset(mode_set, &fb_helper->client) {
+			struct drm_crtc *crtc;
+
+			crtc = mode_set->crtc;
+			ret = drm_crtc_vblank_get(crtc);
+			if (!ret) {
+				drm_crtc_wait_one_vblank(crtc);
+				drm_crtc_vblank_put(crtc);
+			}
+		}
+		return ret;
+	default:
+		return -ENOTTY;
+	}
+
+	return 0;
+}
+
+static struct fb_ops xlnx_fbdev_ops = {
+	.owner		= THIS_MODULE,
+	.fb_fillrect	= sys_fillrect,
+	.fb_copyarea	= sys_copyarea,
+	.fb_imageblit	= sys_imageblit,
+	.fb_check_var	= drm_fb_helper_check_var,
+	.fb_set_par	= drm_fb_helper_set_par,
+	.fb_blank	= drm_fb_helper_blank,
+	.fb_pan_display	= drm_fb_helper_pan_display,
+	.fb_setcmap	= drm_fb_helper_setcmap,
+	.fb_ioctl	= xlnx_fb_ioctl,
+};
+
+static struct drm_framebuffer *
+xlnx_fb_gem_fb_alloc(struct drm_device *drm,
+		     const struct drm_mode_fb_cmd2 *mode_cmd,
+		     struct drm_gem_object **obj, unsigned int num_planes,
+		     const struct drm_framebuffer_funcs *funcs)
+{
+	struct drm_framebuffer *fb;
+	int ret, i;
+
+	fb = kzalloc(sizeof(*fb), GFP_KERNEL);
+	if (!fb)
+		return ERR_PTR(-ENOMEM);
+
+	drm_helper_mode_fill_fb_struct(drm, fb, mode_cmd);
+
+	for (i = 0; i < num_planes; i++)
+		fb->obj[i] = obj[i];
+
+	ret = drm_framebuffer_init(drm, fb, funcs);
+	if (ret) {
+		dev_err(drm->dev, "Failed to init framebuffer: %d\n", ret);
+		kfree(fb);
+		return ERR_PTR(ret);
+	}
+
+	return fb;
+}
+
+static struct drm_framebuffer *
+xlnx_fb_gem_fbdev_fb_create(struct drm_device *drm,
+			struct drm_fb_helper_surface_size *size,
+			unsigned int pitch_align, struct drm_gem_object *obj,
+			const struct drm_framebuffer_funcs *funcs)
+{
+	struct drm_mode_fb_cmd2 mode_cmd = { 0 };
+
+	mode_cmd.width = size->surface_width;
+	mode_cmd.height = size->surface_height;
+	mode_cmd.pitches[0] = size->surface_width *
+			      DIV_ROUND_UP(size->surface_bpp, 8);
+	if (pitch_align)
+		mode_cmd.pitches[0] = roundup(mode_cmd.pitches[0],
+					      pitch_align);
+	mode_cmd.pixel_format = drm_driver_legacy_fb_format(drm,
+							    size->surface_bpp,
+							    size->surface_depth);
+	if (obj->size < (size_t)mode_cmd.pitches[0] * mode_cmd.height)
+		return ERR_PTR(-EINVAL);
+
+	return xlnx_fb_gem_fb_alloc(drm, &mode_cmd, &obj, 1, funcs);
+}
+
+/**
+ * xlnx_fbdev_create - Create the fbdev with a framebuffer
+ * @fb_helper: fb helper structure
+ * @size: framebuffer size info
+ *
+ * This function is based on drm_fbdev_cma_create().
+ *
+ * Return: 0 if successful, or the error code.
+ */
+static int xlnx_fbdev_create(struct drm_fb_helper *fb_helper,
+			     struct drm_fb_helper_surface_size *size)
+{
+	struct xlnx_fbdev *fbdev = to_fbdev(fb_helper);
+	struct drm_device *drm = fb_helper->dev;
+	struct drm_gem_dma_object *obj;
+	struct drm_framebuffer *fb;
+	unsigned int bytes_per_pixel;
+	unsigned long offset;
+	struct fb_info *fbi;
+	u32 format;
+	const struct drm_format_info *info;
+	size_t bytes;
+	int ret;
+
+	dev_dbg(drm->dev, "surface width(%d), height(%d) and bpp(%d)\n",
+		size->surface_width, size->surface_height, size->surface_bpp);
+
+	size->surface_height *= fbdev->vres_mult;
+	bytes_per_pixel = DIV_ROUND_UP(size->surface_bpp, 8);
+	bytes = ALIGN((size_t)size->surface_width * bytes_per_pixel,
+		      fbdev->align);
+	bytes *= size->surface_height;
+
+	obj = drm_gem_dma_create(drm, bytes);
+	if (IS_ERR(obj))
+		return PTR_ERR(obj);
+
+	fbi = framebuffer_alloc(0, drm->dev);
+	if (!fbi) {
+		dev_err(drm->dev, "Failed to allocate framebuffer info.\n");
+		ret = -ENOMEM;
+		goto err_drm_gem_cma_free_object;
+	}
+
+	/* Override the depth given by fb helper with current format value */
+	format = xlnx_get_format(drm);
+	info = drm_format_info(format);
+	if (size->surface_bpp == info->cpp[0] * 8)
+		size->surface_depth = info->depth;
+
+	fbdev->fb = xlnx_fb_gem_fbdev_fb_create(drm, size, fbdev->align,
+						&obj->base, &xlnx_fb_funcs);
+	if (IS_ERR(fbdev->fb)) {
+		dev_err(drm->dev, "Failed to allocate DRM framebuffer.\n");
+		ret = PTR_ERR(fbdev->fb);
+		goto err_framebuffer_release;
+	}
+
+	fb = fbdev->fb;
+	fb_helper->fb = fb;
+	fb_helper->info = fbi;
+	fbi->fbops = &xlnx_fbdev_ops;
+
+	ret = fb_alloc_cmap(&fbi->cmap, 256, 0);
+	if (ret) {
+		dev_err(drm->dev, "Failed to allocate color map.\n");
+		goto err_fb_destroy;
+	}
+
+	drm_fb_helper_fill_info(fbi, fb_helper, size);
+	fbi->var.yres = fb->height / fbdev->vres_mult;
+
+	offset = (unsigned long)fbi->var.xoffset * bytes_per_pixel;
+	offset += fbi->var.yoffset * fb->pitches[0];
+
+	fbi->screen_base = (char __iomem *)(obj->vaddr + offset);
+	fbi->fix.smem_start = (unsigned long)(obj->dma_addr + offset);
+	fbi->screen_size = bytes;
+	fbi->fix.smem_len = bytes;
+
+	return 0;
+
+err_fb_destroy:
+	drm_framebuffer_unregister_private(fb);
+	drm_gem_fb_destroy(fb);
+err_framebuffer_release:
+	framebuffer_release(fbi);
+err_drm_gem_cma_free_object:
+	drm_gem_dma_free(obj);
+	return ret;
+}
+
+static const struct drm_fb_helper_funcs xlnx_fb_helper_funcs = {
+	.fb_probe = xlnx_fbdev_create,
+};
+
+/**
+ * xlnx_fb_init - Allocate and initializes the Xilinx framebuffer
+ * @drm: DRM device
+ * @preferred_bpp: preferred bits per pixel for the device
+ * @max_conn_count: maximum number of connectors
+ * @align: alignment value for pitch
+ * @vres_mult: multiplier for virtual resolution
+ *
+ * This function is based on drm_fbdev_cma_init().
+ *
+ * Return: a newly allocated drm_fb_helper struct or a ERR_PTR.
+ */
+struct drm_fb_helper *
+xlnx_fb_init(struct drm_device *drm, int preferred_bpp,
+	     unsigned int max_conn_count, unsigned int align,
+	     unsigned int vres_mult)
+{
+	struct xlnx_fbdev *fbdev;
+	struct drm_fb_helper *fb_helper;
+	int ret;
+
+	fbdev = kzalloc(sizeof(*fbdev), GFP_KERNEL);
+	if (!fbdev)
+		return ERR_PTR(-ENOMEM);
+
+	fbdev->vres_mult = vres_mult;
+	fbdev->align = align;
+	fb_helper = &fbdev->fb_helper;
+	drm_fb_helper_prepare(drm, fb_helper, preferred_bpp, &xlnx_fb_helper_funcs);
+
+	ret = drm_fb_helper_init(drm, fb_helper);
+	if (ret < 0) {
+		dev_err(drm->dev, "Failed to initialize drm fb helper.\n");
+		goto err_free;
+	}
+
+	ret = drm_fb_helper_initial_config(fb_helper);
+	if (ret < 0) {
+		dev_err(drm->dev, "Failed to set initial hw configuration.\n");
+		goto err_drm_fb_helper_fini;
+	}
+
+	return fb_helper;
+
+err_drm_fb_helper_fini:
+	drm_fb_helper_fini(fb_helper);
+err_free:
+	kfree(fbdev);
+	return ERR_PTR(ret);
+}
+
+/**
+ * xlnx_fbdev_defio_fini - Free the defio fb
+ * @fbi: fb_info struct
+ *
+ * This function is based on drm_fbdev_cma_defio_fini().
+ */
+static void xlnx_fbdev_defio_fini(struct fb_info *fbi)
+{
+	if (!fbi->fbdefio)
+		return;
+
+	fb_deferred_io_cleanup(fbi);
+	kfree(fbi->fbdefio);
+	kfree(fbi->fbops);
+}
+
+/**
+ * xlnx_fb_fini - Free the Xilinx framebuffer
+ * @fb_helper: drm_fb_helper struct
+ *
+ * This function is based on drm_fbdev_cma_fini().
+ */
+void xlnx_fb_fini(struct drm_fb_helper *fb_helper)
+{
+	struct xlnx_fbdev *fbdev = to_fbdev(fb_helper);
+
+	drm_fb_helper_unregister_info(&fbdev->fb_helper);
+	if (fbdev->fb_helper.info)
+		xlnx_fbdev_defio_fini(fbdev->fb_helper.info);
+
+	if (fbdev->fb_helper.fb)
+		drm_framebuffer_remove(fbdev->fb_helper.fb);
+
+	drm_fb_helper_fini(&fbdev->fb_helper);
+	kfree(fbdev);
+}
+
+#endif /* CONFIG_DRM_FBDEV_EMULATION */
diff --git a/drivers/gpu/drm/xlnx/xlnx_fb.h b/drivers/gpu/drm/xlnx/xlnx_fb.h
new file mode 100644
index 000000000..eb0d05920
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_fb.h
@@ -0,0 +1,52 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx DRM KMS Framebuffer helper header
+ *
+ *  Copyright (C) 2015 - 2018 Xilinx, Inc.
+ *
+ *  Author: Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _XLNX_FB_H_
+#define _XLNX_FB_H_
+
+struct drm_fb_helper;
+
+struct drm_framebuffer *
+xlnx_fb_create(struct drm_device *drm, struct drm_file *file_priv,
+	       const struct drm_mode_fb_cmd2 *mode_cmd);
+
+#ifdef CONFIG_DRM_FBDEV_EMULATION
+
+struct drm_fb_helper *
+xlnx_fb_init(struct drm_device *drm, int preferred_bpp,
+	     unsigned int max_conn_count, unsigned int align,
+	     unsigned int vres_mult);
+void xlnx_fb_fini(struct drm_fb_helper *fb_helper);
+
+#else /* CONFIG_DRM_FBDEV_EMULATION */
+
+static inline struct drm_fb_helper *
+xlnx_fb_init(struct drm_device *drm, int preferred_bpp,
+	     unsigned int max_conn_count, unsigned int align,
+	     unsigned int vres_mult)
+{
+	return NULL;
+}
+
+static inline void xlnx_fb_fini(struct drm_fb_helper *fb_helper)
+{
+}
+
+#endif /* CONFIG_DRM_FBDEV_EMULATION */
+
+#endif /* _XLNX_FB_H_ */
diff --git a/drivers/gpu/drm/xlnx/xlnx_gem.c b/drivers/gpu/drm/xlnx/xlnx_gem.c
new file mode 100644
index 000000000..98419cecc
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_gem.c
@@ -0,0 +1,47 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx DRM KMS GEM helper
+ *
+ *  Copyright (C) 2015 - 2018 Xilinx, Inc.
+ *
+ *  Author: Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <drm/drm_drv.h>
+#include <drm/drm_gem_dma_helper.h>
+
+#include "xlnx_drv.h"
+#include "xlnx_gem.h"
+
+/*
+ * xlnx_gem_cma_dumb_create - (struct drm_driver)->dumb_create callback
+ * @file_priv: drm_file object
+ * @drm: DRM object
+ * @args: info for dumb scanout buffer creation
+ *
+ * This function is for dumb_create callback of drm_driver struct. Simply
+ * it wraps around drm_gem_dma_dumb_create() and sets the pitch value
+ * by retrieving the value from the device.
+ *
+ * Return: The return value from drm_gem_dma_dumb_create()
+ */
+int xlnx_gem_cma_dumb_create(struct drm_file *file_priv, struct drm_device *drm,
+			     struct drm_mode_create_dumb *args)
+{
+	int pitch = DIV_ROUND_UP(args->width * args->bpp, 8);
+	unsigned int align = xlnx_get_align(drm);
+
+	if (!args->pitch || !IS_ALIGNED(args->pitch, align))
+		args->pitch = ALIGN(pitch, align);
+
+	return drm_gem_dma_dumb_create_internal(file_priv, drm, args);
+}
diff --git a/drivers/gpu/drm/xlnx/xlnx_gem.h b/drivers/gpu/drm/xlnx/xlnx_gem.h
new file mode 100644
index 000000000..2e178f67d
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_gem.h
@@ -0,0 +1,26 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx DRM KMS GEM helper header
+ *
+ *  Copyright (C) 2015 - 2018 Xilinx, Inc.
+ *
+ *  Author: Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _XLNX_GEM_H_
+#define _XLNX_GEM_H_
+
+int xlnx_gem_cma_dumb_create(struct drm_file *file_priv,
+			     struct drm_device *drm,
+			     struct drm_mode_create_dumb *args);
+
+#endif /* _XLNX_GEM_H_ */
diff --git a/drivers/gpu/drm/xlnx/xlnx_hdmi.c b/drivers/gpu/drm/xlnx/xlnx_hdmi.c
new file mode 100644
index 000000000..21c05b465
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_hdmi.c
@@ -0,0 +1,4079 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx FPGA HDMI TX Subsystem Driver
+ *
+ * Copyright (C) 2021 Xilinx, Inc.
+ *
+ * Author: Venkateshwar Rao G <vgannava.xilinx.com>
+ */
+
+#include <drm/display/drm_dp_helper.h>
+#include <drm/drm_atomic_helper.h>
+#include <drm/drm_connector.h>
+#include <drm/drm_crtc_helper.h>
+#include <drm/drm_framebuffer.h>
+#include <drm/drm_edid.h>
+#include <drm/drm_fourcc.h>
+#include <drm/drm_of.h>
+#include <drm/drm_probe_helper.h>
+#include <drm/drm_sysfs.h>
+
+#include <linux/bitfield.h>
+#include <linux/clk.h>
+#include <linux/component.h>
+#include <linux/delay.h>
+#include <linux/hdmi.h>
+#include <linux/math64.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/mfd/syscon.h>
+#include <linux/of_device.h>
+#include <linux/phy/phy.h>
+#include <linux/platform_device.h>
+#include <linux/pm.h>
+#include <linux/sysfs.h>
+#include <linux/workqueue.h>
+#include <linux/xlnx/xlnx_timer.h>
+#include <uapi/linux/media-bus-format.h>
+
+#include "hdcp/xlnx_hdcp_tx.h"
+#include "xlnx_bridge.h"
+
+/* Parallel Interface registers */
+#define HDMI_TX_PIO_ID				0x40
+#define HDMI_TX_PIO_CTRL			0x44
+#define HDMI_TX_PIO_CTRL_IE			BIT(1)
+#define HDMI_TX_PIO_CTRL_RUN			BIT(0)
+#define HDMI_TX_PIO_CTRL_SET			0x48
+#define HDMI_TX_PIO_CTRL_CLR			0x4c
+#define HDMI_TX_PIO_STA				0x50
+#define HDMI_TX_PIO_STA_EVT			BIT(1)
+#define HDMI_TX_PIO_STA_IRQ			BIT(0)
+#define HDMI_TX_PIO_OUT				0x54
+#define HDMI_TX_PIO_OUT_GCP_AVMUTE		BIT(31)
+#define HDMI_TX_PIO_OUT_BRIDGE_PIXEL		BIT(30)
+#define HDMI_TX_PIO_OUT_BRIDGE_YUV420		BIT(29)
+#define HDMI_TX_PIO_OUT_GCP_CLEARAVMUTE		BIT(28)
+#define HDMI_TX_PIO_OUT_EXT_SYSRST		BIT(22)
+#define HDMI_TX_PIO_OUT_EXT_VRST		BIT(21)
+#define HDMI_TX_PIO_OUT_INT_LRST		BIT(20)
+#define HDMI_TX_PIO_OUT_SCRM			BIT(12)
+#define HDMI_TX_PIO_OUT_CS			GENMASK(11, 10)
+#define HDMI_TX_PIO_OUT_SR			GENMASK(9, 8)
+#define HDMI_TX_PIO_OUT_PR			GENMASK(7, 6)
+#define HDMI_TX_PIO_OUT_CD			GENMASK(5, 4)
+#define HDMI_TX_PIO_OUT_CD_SHIFT		4
+#define HDMI_TX_PIO_OUT_PR_SHIFT		6
+#define HDMI_TX_PIO_OUT_SR_SHIFT		8
+#define HDMI_TX_PIO_OUT_CS_SHIFT		10
+#define HDMI_TX_PIO_OUT_MODE			BIT(3)
+#define HDMI_TX_PIO_OUT_INT_VRST		BIT(0)
+#define HDMI_TX_PIO_OUT_SET			0x58
+#define HDMI_TX_PIO_OUT_CLR			0x5c
+#define HDMI_TX_PIO_OUT_MSK			0x60
+#define HDMI_TX_PIO_IN				0x64
+#define HDMI_TX_PIO_IN_BRIDGE_UFLOW		BIT(11)
+#define HDMI_TX_PIO_IN_BRIDGE_OFLOW		BIT(10)
+#define HDMI_TX_PIO_IN_BRIDGE_LOCKED		BIT(9)
+#define HDMI_TX_PIO_IN_HPD_TOGGLE		BIT(8)
+#define HDMI_TX_PIO_IN_PPP			GENMASK(7, 5)
+#define HDMI_TX_PIO_IN_ERR			BIT(4)
+#define HDMI_TX_PIO_IN_VS			BIT(3)
+#define HDMI_TX_PIO_IN_HPD_CONNECT		BIT(2)
+#define HDMI_TX_PIO_IN_VID_RDY			BIT(1)
+#define HDMI_TX_PIO_IN_LNK_RDY			BIT(0)
+#define HDMI_TX_PIO_LNK_VID_RDY_MASK		(HDMI_TX_PIO_IN_VID_RDY | \
+						HDMI_TX_PIO_IN_LNK_RDY)
+#define HDMI_TX_PIO_IN_EVT			0x68
+#define HDMI_TX_PIO_IN_EVT_RE			0x6c
+#define HDMI_TX_PIO_IN_EVT_FE			0x70
+#define HDMI_TX_HPD_TIMEGRID			0x74
+#define HDMI_TX_HPD_TOGGLE_CONF			0x78
+#define HDMI_TX_HPD_CONNECT_CONF		0x7c
+
+/* Display Data Channel registers */
+#define HDMI_HDCP_DDC_BASE_OFFSET		0x3a
+#define HDMI_TX_DDC_ID				0x80
+#define HDMI_TX_DDC_CTRL			0x84
+#define HDMI_TX_DDC_CTRL_CLK_DIV		GENMASK(31, 16)
+#define HDMI_TX_DDC_CTRL_CLK_DIV_SHIFT		16
+#define HDMI_TX_DDC_CTRL_TO_STOP		BIT(2)
+#define HDMI_TX_DDC_CTRL_IE			BIT(1)
+#define HDMI_TX_DDC_CTRL_RUN			BIT(0)
+#define HDMI_TX_DDC_CTRL_SET			0x88
+#define HDMI_TX_DDC_CTRL_CLR			0x8c
+#define HDMI_TX_DDC_STA				0x90
+#define HDMI_TX_DDC_STA_DAT_USED_WRDS		GENMASK(31, 24)
+#define HDMI_TX_DDC_STA_CMD_FREE_WRDS		GENMASK(23, 16)
+#define HDMI_TX_DDC_STA_DAT_EMPTY		BIT(9)
+#define HDMI_TX_DDC_STA_CMD_FULL		BIT(8)
+#define HDMI_TX_DDC_STA_SDA			BIT(7)
+#define HDMI_TX_DDC_STA_SCL			BIT(6)
+#define HDMI_TX_DDC_STA_ACK			BIT(5)
+#define HDMI_TX_DDC_STA_TO			BIT(4)
+#define HDMI_TX_DDC_STA_DONE			BIT(3)
+#define HDMI_TX_DDC_STA_BUSY			BIT(2)
+#define HDMI_TX_DDC_STA_EVT			BIT(1)
+#define HDMI_TX_DDC_STA_IRQ			BIT(0)
+#define HDMI_TX_DDC_CMD				0x94
+#define HDMI_TX_DDC_DAT				0x98
+
+/* Auxiliary peripheral registers */
+#define HDMI_TX_AUX_ID				0xc0
+#define HDMI_TX_AUX_CTRL			0xc4
+#define HDMI_TX_AUX_CTRL_IE			BIT(1)
+#define HDMI_TX_AUX_CTRL_RUN			BIT(0)
+#define HDMI_TX_AUX_CTRL_SET			0xc8
+#define HDMI_TX_AUX_CTRL_CLR			0xcc
+#define HDMI_TX_AUX_STA				0xd0
+#define HDMI_TX_AUX_STA_FREE_PKTS		GENMASK(7, 4)
+#define HDMI_TX_AUX_STA_PKT_RDY			BIT(3)
+#define HDMI_TX_AUX_STA_FL			BIT(2)
+#define HDMI_TX_AUX_STA_EP			BIT(1)
+#define HDMI_TX_AUX_STA_IRQ			BIT(0)
+#define HDMI_TX_AUX_DAT				0xd4
+
+/* Audio peripheral registers */
+#define HDMI_TX_AUD_ID				0x100
+#define HDMI_TX_AUD_CTRL			0x104
+#define HDMI_TX_AUD_CTRL_AUD_CLK_RATIO		GENMASK(15, 12)
+#define HDMI_TX_AUD_CTRL_TMDS_LNKCLK_RATIO	GENMASK(11, 8)
+#define HDMI_TX_AUD_CTRL_ACR_SEL		BIT(7)
+#define HDMI_TX_AUD_CTRL_ACR_EN			BIT(6)
+#define HDMI_TX_AUD_CTRL_AUD_RESET		BIT(5)
+#define HDMI_TX_AUD_CTRL_AUD_FMT		BIT(4)
+#define HDMI_TX_AUD_CTRL_CH			GENMASK(3, 2)
+#define HDMI_TX_AUD_CTRL_IE			BIT(1)
+#define HDMI_TX_AUD_CTRL_RUN			BIT(0)
+#define HDMI_TX_AUD_CTRL_SET			0x108
+#define HDMI_TX_AUD_CTRL_CLR			0x10c
+#define HDMI_TX_AUD_STA				0x110
+#define HDMI_TX_AUD_ACR_N			0x114
+#define HDMI_TX_AUD_ACR_CTS			0x118
+#define HDMI_TX_AUD_ACR_CTS_ACR_CTS		GENMASK(19, 0)
+#define HDMI_TX_AUD_ACR_CTS_VLD			BIT(31)
+
+/* Video mask peripheral registers */
+#define HDMI_TX_VID_MSK_ID			0x140
+#define HDMI_TX_VID_MSK_CTRL			0x144
+#define HDMI_TX_VID_MSK_CTRL_IE			BIT(1)
+#define HDMI_TX_VID_MSK_CTRL_RUN		BIT(0)
+#define HDMI_TX_VID_MSK_CTRL_SET		0x148
+#define HDMI_TX_VID_MSK_CTRL_CLR		0x14c
+#define HDMI_TX_VID_MSK_STA			0x150
+#define HDMI_TX_VID_MSK_COMP_RED		0x154
+#define HDMI_TX_VID_MSK_COMP_GREEN		0x158
+#define HDMI_TX_VID_MSK_COMP_BLUE		0x15c
+
+/* FRL registers */
+#define HDMI_TX_FRL_ID				0x180
+#define HDMI_TX_FRL_CTRL			0x184
+#define HDMI_TX_FRL_CTRL_FRL_VCKE_EXT		BIT(24)
+#define HDMI_TX_FRL_CTRL_FRL_LTP3_REQ		GENMASK(23, 20)
+#define HDMI_TX_FRL_CTRL_FRL_LTP2_REQ		GENMASK(19, 16)
+#define HDMI_TX_FRL_CTRL_FRL_LTP1_REQ		GENMASK(15, 12)
+#define HDMI_TX_FRL_CTRL_FRL_LTP0_REQ		GENMASK(11, 8)
+#define HDMI_TX_FRL_CTRL_FRL_REQ_MASK		0xF
+#define HDMI_TX_FRL_CTRL_FRL_LTP0_SHIFT		8
+#define HDMI_TX_FRL_CTRL_FRL_LTP1_SHIFT		12
+#define HDMI_TX_FRL_CTRL_FRL_LTP2_SHIFT		16
+#define HDMI_TX_FRL_CTRL_FRL_LTP3_SHIFT		20
+#define HDMI_TX_FRL_CTRL_FRL_ACT		BIT(7)
+#define HDMI_TX_FRL_CTRL_TST_RC_DISABLE		BIT(5)
+#define HDMI_TX_FRL_CTRL_EXEC			BIT(4)
+#define HDMI_TX_FRL_CTRL_FRL_LN_OP		BIT(3)
+#define HDMI_TX_FRL_CTRL_OP_MODE		BIT(2)
+#define HDMI_TX_FRL_CTRL_IE			BIT(1)
+#define HDMI_TX_FRL_CTRL_RST			BIT(0)
+#define HDMI_TX_FRL_CTRL_SET			0x188
+#define HDMI_TX_FRL_CTRL_CLR			0x18c
+#define HDMI_TX_FRL_STA				0x190
+#define HDMI_TX_FRL_STA_GB_SYNC_ERR		BIT(8)
+#define HDMI_TX_FRL_STA_GB_EP			BIT(7)
+#define HDMI_TX_FRL_STA_VID_CLK_OOS		BIT(6)
+#define HDMI_TX_FRL_STA_LNK_CLK_OOS		BIT(5)
+#define HDMI_TX_FRL_STA_TRIB_RST		BIT(4)
+#define HDMI_TX_FRL_STA_FRL_RST			BIT(3)
+#define HDMI_TX_FRL_STA_TMR_ZERO		BIT(2)
+#define HDMI_TX_FRL_STA_TMR_EVT			BIT(1)
+#define HDMI_TX_FRL_STA_IRQ			BIT(0)
+#define HDMI_TX_FRL_TMR				0x194
+#define HDMI_TX_FRL_LNK_CLK			0x198
+#define HDMI_TX_FRL_VID_CLK			0x19c
+#define HDMI_TX_FRL_VP_FIFO_THRD		0x1a0
+#define HDMI_TX_DISP_ERR_INJ			0x1a4
+#define HDMI_TX_DISP_ERR_INJ_NUM_ERR_CB		GENMASK(31, 16)
+#define HDMI_TX_DISP_ERR_INJ_NUM_ERR_CHAR	GENMASK(15, 8)
+#define HDMI_TX_DISP_ERR_INJ_ERR_TYPE		GENMASK(6, 4)
+#define HDMI_TX_DISP_ERR_INJ_DISP_ERR_INJ_EN	BIT(0)
+#define HDMI_TX_FEC_ERR_INJ			0x1a8
+#define HDMI_TX_FEC_ERR_INJ_ERR_CB_LOC		GENMASK(25, 16)
+#define HDMI_TX_FEC_ERR_INJ_NUM_ERR_CB		GENMASK(15, 8)
+#define HDMI_TX_FEC_ERR_INJ_NUM_ERR_CHAR	GENMASK(7, 4)
+#define HDMI_TX_FEC_ERR_INJ_FEC_ERR_INJ_EN	BIT(0)
+/* VTC register offsets and bit masks */
+#define HDMI_TX_VTC_CTL				0x000
+#define HDMI_TX_VTC_CTL_MASK			GENMASK(18, 8)
+#define HDMI_TX_VTC_RST				BIT(31)
+#define HDMI_TX_VTC_CTL_GE			BIT(2)
+#define HDMI_TX_VTC_CTL_RU			BIT(1)
+
+#define HDMI_TX_VTC_GASIZE_F0			0x060
+#define HDMI_TX_VTC_ACTIVE_SIZE_MASK		GENMASK(13, 0)
+
+#define HDMI_TX_VTC_GFENC			0x068
+#define HDMI_TX_VTC_GFENC_MASK			BIT(6)
+
+#define HDMI_TX_VTC_GPOL			0x06c
+#define HDMI_TX_VTC_GPOL_FIELD_ID_POL		BIT(6)
+#define HDMI_TX_VTC_ACTIVE_CHROMA_POL		BIT(5)
+#define HDMI_TX_VTC_ACTIVE_VIDEO_POL		BIT(4)
+#define HDMI_TX_VTC_HSYNC_POL			BIT(3)
+#define HDMI_TX_VTC_VSYNC_POL			BIT(2)
+#define HDMI_TX_VTC_HBLANK_POL			BIT(1)
+#define HDMI_TX_VTC_VBLANK_POL			BIT(0)
+#define HDMI_TX_VTC_GPOL_MASK		(HDMI_TX_VTC_VBLANK_POL |\
+					 HDMI_TX_VTC_HBLANK_POL |\
+					 HDMI_TX_VTC_VSYNC_POL |\
+					 HDMI_TX_VTC_HSYNC_POL |\
+					 HDMI_TX_VTC_ACTIVE_VIDEO_POL |\
+					 HDMI_TX_VTC_ACTIVE_CHROMA_POL)
+
+#define HDMI_TX_VTC_INT_GPOL_MASK	(HDMI_TX_VTC_GPOL_FIELD_ID_POL |\
+					 HDMI_TX_VTC_ACTIVE_CHROMA_POL |\
+					 HDMI_TX_VTC_ACTIVE_VIDEO_POL)
+
+#define HDMI_TX_VTC_GHSIZE			0x070
+#define HDMI_TX_VTC_GHSIZE_FRAME_HSIZE		GENMASK(13, 0)
+
+#define HDMI_TX_VTC_GVSIZE			0x074
+#define HDMI_TX_VTC_FIELD1_VSIZE_SHIFT		16
+#define HDMI_TX_VTC_GVSIZE_FRAME_VSIZE		GENMASK(13, 0)
+
+#define HDMI_TX_VTC_GHSYNC			0x078
+#define HDMI_TX_VTC_GH1BPSTART_SHIFT		16
+#define HDMI_TX_VTC_GHSYNC_END_MASK		GENMASK(29, 16)
+#define HDMI_TX_VTC_GHSYNC_START_MASK		GENMASK(13, 0)
+
+#define HDMI_TX_VTC_GVBHOFF			0x07c
+#define HDMI_TX_VTC_F0VSYNC_HEND_SHIFT		16
+#define HDMI_TX_VTC_F0VBLANK_HEND_MASK		GENMASK(29, 16)
+#define HDMI_TX_VTC_F0VBLANK_HSTART_MASK	GENMASK(13, 0)
+
+#define HDMI_TX_VTC_GVSYNC			0x080
+#define HDMI_TX_VTC_F0_VSYNC_VEND_MASK		GENMASK(29, 16)
+#define HDMI_TX_VTC_F0_VSYNC_VSTART_MASK	GENMASK(13, 0)
+
+#define HDMI_TX_VTC_GVSHOFF			0x084
+#define HDMI_TX_VTC_GVBHOFF_F1			0x088
+#define HDMI_TX_VTC_GVSYNC_F1			0x08c
+#define HDMI_TX_VTC_GVSHOFF_F1			0x090
+#define HDMI_TX_VTC_GASIZE_F1			0x094
+
+#define HDMI_TX_VTC_BASE			0x10000
+#define HDMI_MAX_LANES				4
+
+#define HDMI_TX_3_4_GBPS			340000000
+#define HDMI_TX_SCRAMBLER_OFFSET		0x20
+#define HDMI_TX_TIMEGRID_VAL			0x18696
+#define HDMI_TX_TOGGLE_CONF_VAL			0x630032
+#define HDMI_TX_CONNECT_CONF_VAL		0xA0064
+#define HDMI_TX_DDC_SLAVEADDR			0x54
+#define HDMI_TX_DDC_CLKDIV			100000
+#define HDMI_TX_DDC_EDID_LENGTH			512
+#define HDMI_TX_DDC_EDID_SINK_BW		187
+#define HDMI_TX_DDC_EDID_BW_SHIFT		4
+#define HDMI_TX_DDC_ADDR			0x50
+#define HDMI_TX_DDC_READ_DIR			1
+#define HDMI_TX_DDC_DATA_MSK			0xFF
+#define HDMI_TX_DDC_CMD_MSK			0xFE
+#define HDMI_TX_DDC_CFG_1_FFE_LVLS_MASK		0xF
+#define HDMI_TX_DDC_CFG_1_FFE_LVLS_SHIFT	4
+#define HDMI_TX_DDC_CFG_1_FRL_RATE_MASK		0xF
+#define HDMI_TX_DDC_SINK_VER_REG		0x01
+#define HDMI_TX_DDC_UPDATE_FLGS_REG		0x10
+#define HDMI_TX_DDC_CED_REG			0x50
+#define HDMI_TX_DDC_STCR_REG			0x35
+#define HDMI_TX_DDC_STAT_FLGS_REG		0x40
+#define HDMI_TX_DDC_STAT_FLGS_LN01_REG		0x41
+#define HDMI_TX_DDC_STAT_FLGS_LN23_REG		0x42
+#define HDMI_TX_DDC_UPDATE_FLGS_CED_UPDATE_MASK	0x02
+#define HDMI_TX_DDC_UPDATE_FLGS_STUPDATE_MASK	0x08
+#define HDMI_TX_DDC_UPDATE_FLGS_FRL_START_MASK	0x10
+#define HDMI_TX_DDC_UPDATE_FLGS_FLT_UPDATE_MASK	0x20
+#define HDMI_TX_DDC_STCR_FLT_NO_TIMEOUT_MASK	0x20
+#define HDMI_TX_DDC_STAT_FLGS_FLT_RDY_MASK	0x40
+#define HDMI_TX_DDC_STAT_FLGS_LN01_LN0_MASK	0x0F
+#define HDMI_TX_DDC_STAT_FLGS_LN01_LN1_SHIFT	4
+#define HDMI_TX_DDC_STAT_FLGS_LN23_LN2_MASK	0x0F
+#define HDMI_TX_DDC_STAT_FLGS_LN23_LN3_MASK	0x0F
+#define HDMI_TX_DDC_STAT_FLGS_LN23_LN3_SHIFT	4
+
+#define HDMI_TX_FRL_CLK_CYCLES			0x3E7
+#define HDMI_TX_HDCP2x_ENABLE			0x404
+#define HDMI_TX_HDCP2x_ENABLE_BYPASS_DISABLE_MASK	BIT(0)
+#define HDMI_TX_PIXEL_MAXRATE			2376000
+#define HDMI_TX_PIXELRATE_GBPS			((u64)1e9)
+
+#define HDMI_TX_DDC_CMD_STR_TOKEN		0x100
+#define HDMI_TX_DDC_CMD_STP_TOKEN		0x101
+#define HDMI_TX_DDC_CMD_RD_TOKEN		0x102
+#define HDMI_TX_DDC_CMD_WR_TOKEN		0x103
+
+#define hdmi_mutex_lock(x)	mutex_lock(x)
+#define hdmi_mutex_unlock(x)	mutex_unlock(x)
+
+#define TIMEOUT_2MS		2
+#define TIMEOUT_5MS		5
+#define TIMEOUT_100MS		100
+#define TIMEOUT_200MS		200
+#define TIMEOUT_250MS		250
+#define TIMEOUT_10US		10
+/* TODO: Fix this delay in the future */
+#define HDMI_TX_LNK_VID_RDY_DELAY	10000
+
+#define HDMI_TX_MAX_FRL_RATE	6
+#define HDMI_TX_SCDC_MASK	0xFF
+#define HDMI_TX_DEF_TMDS_CLK	148500000
+
+#define HDMI_HDCP_DPCD_READ	0x00
+#define HDMI_HDCP_DPCD_WRITE	BIT(0)
+#define HDMI_HDCP_STATUS	BIT(1)
+#define HDMI_HDCP_TIMER_OFFSET	0x30000
+#define HDMI_HDCP2X_OFFSET	0x40000
+#define HDMI_HDCP1X_OFFSET	0x20000
+#define HDMI_HDCP_MAX_KEYS	800
+
+#define HDMI_MIN_WIDTH	640
+#define HDMI_MIN_HEIGHT	480
+#define HDMI_MAX_WIDTH	10240
+#define HDMI_MAX_HEIGHT	4320
+
+#define XHDMI_AUX_PKT_HEADER_SIZE	4
+#define XHDMI_AUX_PKT_DATA_SIZE		32
+#define XHDMI_AUX_PKT_SIZE		(XHDMI_AUX_PKT_HEADER_SIZE + \
+					 XHDMI_AUX_PKT_DATA_SIZE)
+
+/**
+ * enum hdmi_state - Stream state
+ * @HDMI_TX_STATE_STREAM_DOWN: stream down
+ * @HDMI_TX_STATE_STREAM_UP: stream up
+ */
+enum hdmi_state {
+	HDMI_TX_STATE_STREAM_DOWN = 0,
+	HDMI_TX_STATE_STREAM_UP = 1
+};
+
+enum color_formats {
+	HDMI_TX_CSF_RGB = 0,
+	HDMI_TX_CSF_YCRCB_444 = 1,
+	HDMI_TX_CSF_YCRCB_422 = 2,
+	HDMI_TX_CSF_YCRCB_420 = 3
+};
+
+enum color_depths {
+	HDMI_TX_BPC_8 = 8,
+	HDMI_TX_BPC_10 = 10,
+	HDMI_TX_BPC_12 = 12,
+	HDMI_TX_BPC_16 = 16
+};
+
+enum config_ppc {
+	HDMI_TX_PPC_1 = 1,
+	HDMI_TX_PPC_2 = 2,
+	HDMI_TX_PPC_4 = 4,
+	HDMI_TX_PPC_8 = 8
+};
+
+enum vid_interface {
+	HDMI_TX_AXI_STREAM = 0,
+	HDMI_TX_NATIVE = 1,
+	HDMI_TX_NATIVE_IDE = 2
+};
+
+/* FRL Training States */
+enum frl_train_state {
+	HDMI_TX_FRLSTATE_LTS_L = 0,
+	HDMI_TX_FRLSTATE_LTS_1 = 1,
+	HDMI_TX_FRLSTATE_LTS_2 = 2,
+	HDMI_TX_FRLSTATE_LTS_3_ARM = 3,
+	HDMI_TX_FRLSTATE_LTS_3 = 4,
+	HDMI_TX_FRLSTATE_LTS_4 = 5,
+	HDMI_TX_FRLSTATE_LTS_P_ARM = 6,
+	HDMI_TX_FRLSTATE_LTS_P = 7,
+	HDMI_TX_FRLSTATE_LTS_P_FRL_RDY = 8
+};
+
+/* LTP type */
+enum frl_ltp_type {
+	HDMI_TX_LTP_NO_LTP = 0,
+	HDMI_TX_LTP_ALL_ONES = 1,
+	HDMI_TX_LTP_ALL_ZEROES = 2,
+	HDMI_TX_LTP_NYQUIST_CLOCK = 3,
+	HDMI_TX_LTP_TXDDE_COMPLIANCE = 4,
+	HDMI_TX_LTP_LFSR0 = 5,
+	HDMI_TX_LTP_LFSR1 = 6,
+	HDMI_TX_LTP_LFSR2 = 7,
+	HDMI_TX_LTP_LFSR3 = 8
+};
+
+enum frl_active_mode {
+	HDMI_TX_FRL_ACTIVE_MODE_GAP_ONLY = 0,
+	HDMI_TX_FRL_ACTIVE_MODE_FULL_STREAM = 1
+};
+
+/* HDMI TX SCDC Fields */
+enum xlnx_hdmi_scdc_fields {
+	HDMI_TX_SCDC_FIELD_SOURCE_VER = 0,
+	HDMI_TX_SCDC_FIELD_SNK_CFG0 = 1,
+	HDMI_TX_SCDC_FIELD_SNK_CFG1 = 2,
+	HDMI_TX_SCDC_FIELD_SNK_STU = 3,
+	HDMI_TX_SCDC_FIELD_CED_UPDATE = 4,
+	HDMI_TX_SCDC_FIELD_FRL_START = 5,
+	HDMI_TX_SCDC_FIELD_FLT_UPDATE = 6,
+	HDMI_TX_SCDC_FIELD_FLT_NO_RETRAIN = 7,
+	HDMI_TX_SCDC_FIELD_SIZE = 8
+};
+
+struct xlnx_hdmi_scdc_field {
+	u8 offset;
+	u8 msk;
+	u8 shift;
+};
+
+static const struct
+xlnx_hdmi_scdc_field scdc_field[HDMI_TX_SCDC_FIELD_SIZE] = {
+	{0x02, 0xFF, 0},/* HDMI_TX_SCDCFIELD_SOURCE_VER */
+	{0x30, 0xFF, 0},/* HDMI_TX_SCDCFIELD_SNK_CFG0 */
+	{0x31, 0xFF, 0},/* HDMI_TX_SCDCFIELD_SNK_CFG1 */
+	{0x10, 0x01, 3},/* HDMI_TX_SCDCFIELD_SNK_STU */
+	{0x10, 0xFF, 1},/* HDMI_TX_SCDCFIELD_CED_UPDATE */
+	{0x10, 0xFF, 4},/* HDMI_TX_SCDCFIELD_FRL_START */
+	{0x10, 0xFF, 5},/* HDMI_TX_SCDCFIELD_FLT_UPDATE */
+	{0x30, 0x01, 1}	/* HDMI_TX_SCDCFIELD_FLT_NO_RETRAIN */
+};
+
+struct xlnx_hdmi_frlrate {
+	u8 lanes;
+	u8 linerate;
+};
+
+static const struct
+xlnx_hdmi_frlrate rate_table[] = {
+	{3, 0},	/* XHDMIC_MAXFRLRATE_NOT_SUPPORTED */
+	{3, 3},	/* XHDMIC_MAXFRLRATE_3X3GBITSPS */
+	{3, 6},	/* XHDMIC_MAXFRLRATE_3X6GBITSPS */
+	{4, 6},	/* XHDMIC_MAXFRLRATE_4X6GBITSPS */
+	{4, 8},	/* XHDMIC_MAXFRLRATE_4X8GBITSPS */
+	{4, 10},/* XHDMIC_MAXFRLRATE_4X10GBITSPS */
+	{4, 12},/* XHDMIC_MAXFRLRATE_4X12GBITSPS */
+};
+
+/**
+ * struct xlnx_hdmi_frl_config - FRL config structure
+ * @max_frl_rate: maximum supported FRL rate
+ * @frl_rate: current FRL rate
+ * @max_linerate: maximum supported linerate
+ * @linerate: current linerate
+ * @max_lanes: maximum supported lanes
+ * @lanes: current lanes
+ * @timer_cnt: frl timer
+ * @timer_event: flag for timer event
+ * @flt_no_timeout: flag for no timeout
+ * @frl_train_states: indicates the frl training state
+ */
+struct xlnx_hdmi_frl_config {
+	u8 max_frl_rate;
+	u8 frl_rate;
+	u8 max_linerate;
+	u8 linerate;
+	u8 max_lanes;
+	u8 lanes;
+	u16 timer_cnt;
+	u8 timer_event;
+	u8 flt_no_timeout;
+	enum frl_train_state frl_train_states;
+};
+
+/**
+ * struct xlnx_hdmi_config - Configuration of HDMI
+ * @bpc: Bits per component
+ * @ppc: Pixels per component
+ * @vid_interface: AXI_stream or Native interface
+ * @max_frl_rate: maximum frl rate supported by hardware
+ * @htiming_div_fact: factor used in calculating htimings
+ * @hdcp2x_enable: flag to indicate hdcp22-enable property in device tree
+ * @hdcp1x_enable: flag to indicate hdcp-enable property in device tree
+ */
+struct xlnx_hdmi_config {
+	enum color_depths bpc;
+	enum config_ppc ppc;
+	enum vid_interface vid_interface;
+	u8 max_frl_rate;
+	u8 htiming_div_fact;
+	bool hdcp2x_enable;
+	bool hdcp1x_enable;
+};
+
+/**
+ * struct xlnx_hdmi_stream - Stream status
+ * @frl_config: frl config structure
+ * @is_frl: flag indicates frl or tmds
+ * @tmds_clock_ratio: tmds clock ratio
+ * @is_hdmi: flag indicates dvi or hdmi
+ * @is_scrambled: scrambled enabled status;
+ * @sink_max_linerate: maximum linerate supported by sink in Gbps
+ * @sink_max_lanes: maximum lanes supported by sink
+ * @state: enum reflects the stream is up or down
+ */
+struct xlnx_hdmi_stream {
+	struct xlnx_hdmi_frl_config frl_config;
+	u8 is_frl;
+	u8 tmds_clock_ratio;
+	u8 is_hdmi;
+	u8 is_scrambled;
+	u8 sink_max_linerate;
+	u8 sink_max_lanes;
+	enum hdmi_state state;
+};
+
+/**
+ * struct xlnx_hdmi - Xilinx HDMI core
+ * @dev: device structure
+ * @encoder: the drm encoder structure
+ * @connector: the drm connector structure
+ * @base: device I/O memory for register access
+ * @irq: hdmi subsystem irq
+ * @phy: PHY handle for hdmi lanes
+ * @hdcp1x_keymgmt_base: HDCP Key management address
+ * @hdmi_mutex: mutex to lock hdmi structure
+ * @irq_lock: to lock irq handler
+ * @cable_connected: flag to indicate cable state
+ * @hdmi_stream_up: flag to inidcate video stream state
+ * @is_hdmi_20_sink: flag to indicate if sink is hdmi2.0 capable
+ * @dpms: current dpms state
+ * @xvidc_colorfmt: hdmi ip internal colorformat representation
+ * @xvidc_colordepth: color depth
+ * @config: IP configuration structure
+ * @stream: stream properties
+ * @intr_status: Flag to indicate irq status
+ * @frl_status: Flag to indicate FRL interrupt status
+ * @wait_for_streamup: Flag for stream up
+ * @tmds_clk: TMDS clock
+ * @wait_event: Wait event
+ * @bridge: bridge structure
+ * @height_out: configurable bridge output height parameter
+ * @saved_adjusted_mode: Copy of @drm_crtc_state.adjusted_mode
+ * @height_out_prop_val: configurable bridge output height parameter value
+ * @width_out: configurable bridge output width parameter
+ * @width_out_prop_val: configurable bridge output width parameter value
+ * @in_fmt: configurable bridge input media format
+ * @in_fmt_prop_val: configurable media bus format value
+ * @out_fmt: configurable bridge output media format
+ * @out_fmt_prop_val: configurable media bus format value
+ * @txhdcp: Hdcp configuration
+ * @hdcp_cp_irq_work: hdcp cp irq interrupt detection worker
+ * @hdcp2x_timer_irq: hdcp2x timer interrupt
+ * @hdcp1x_timer_irq: HDCP1X timer interrupt
+ * @hdcp_irq: HDCP1.4 protocol interrupt
+ * @aux_buffer: Aux packet buffer
+ * @iframe: AVI infroframe structure
+ */
+struct xlnx_hdmi {
+	struct device *dev;
+	struct drm_encoder encoder;
+	struct drm_connector connector;
+	void __iomem *base;
+	int irq;
+	struct phy *phy[HDMI_MAX_LANES];
+	struct regmap *hdcp1x_keymgmt_base;
+	/* to lock hdmi */
+	struct mutex hdmi_mutex;
+	/* to lock irq */
+	spinlock_t irq_lock;
+	bool cable_connected;
+	bool hdmi_stream_up;
+	bool is_hdmi_20_sink;
+	int dpms;
+	enum color_formats xvidc_colorfmt;
+	enum color_depths xvidc_colordepth;
+	struct xlnx_hdmi_config config;
+	struct xlnx_hdmi_stream stream;
+	u32 intr_status;
+	u32 frl_status;
+	u32 wait_for_streamup:1;
+	u64 tmds_clk;
+	wait_queue_head_t wait_event;
+	struct xlnx_bridge *bridge;
+	struct drm_property *height_out;
+	u32 height_out_prop_val;
+	struct drm_property *width_out;
+	struct drm_display_mode saved_adjusted_mode;
+	u32 width_out_prop_val;
+	struct drm_property *in_fmt;
+	u32 in_fmt_prop_val;
+	struct drm_property *out_fmt;
+	u32 out_fmt_prop_val;
+	struct delayed_work hdcp_cp_irq_work;
+	struct xlnx_hdcptx txhdcp;
+	int hdcp2x_timer_irq;
+	int hdcp1x_timer_irq;
+	int hdcp_irq;
+	u32 aux_buffer[XHDMI_AUX_PKT_SIZE / sizeof(u32)];
+	struct hdmi_avi_infoframe iframe;
+};
+
+enum xlnx_hdmitx_clks {
+	S_AXI_CPU_ACLK = 0,
+	LINK_CLK = 1,
+	VIDEO_CLK = 2,
+	FRL_CLK = 3,
+	S_AXIS_VIDEO_ACLK = 4,
+};
+
+static struct clk_bulk_data hdmitx_clks[] = {
+	{ .id = "s_axi_cpu_aclk" },
+	{ .id = "link_clk" },
+	{ .id = "video_clk" },
+	{ .id = "frl_clk" },
+	{ .id = "s_axis_video_aclk" },
+};
+
+/* Parallel Interface */
+#define xlnx_hdmi_piointr_disable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_CTRL_CLR,\
+			 HDMI_TX_PIO_CTRL_IE)
+
+#define xlnx_hdmi_piointr_clear(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_STA,\
+			 HDMI_TX_PIO_STA_IRQ)
+
+#define xlnx_hdmi_piointr_ie_enable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_CTRL_SET,\
+			 HDMI_TX_PIO_CTRL_IE)
+
+#define xlnx_hdmi_piointr_run_enable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_CTRL_SET,\
+			 HDMI_TX_PIO_CTRL_RUN)
+
+#define xlnx_hdmi_pio_set_sr(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_MSK,\
+			 HDMI_TX_PIO_OUT_SR)
+
+#define xlnx_hdmi_pio_set_pr(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_MSK,\
+			 HDMI_TX_PIO_OUT_PR)
+
+#define xlnx_hdmi_pio_set_cs(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_MSK,\
+			 HDMI_TX_PIO_OUT_CS)
+
+#define xlnx_hdmi_pio_set_cd(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_MSK,\
+			 HDMI_TX_PIO_OUT_CD)
+
+#define xlnx_pioout_bridge_yuv_clr(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_CLR,\
+			 HDMI_TX_PIO_OUT_BRIDGE_YUV420)
+
+#define xlnx_pioout_bridge_pixel_clr(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_CLR,\
+			 HDMI_TX_PIO_OUT_BRIDGE_PIXEL)
+
+#define xlnx_pioout_bridge_pixel_set(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_SET,\
+			 HDMI_TX_PIO_OUT_BRIDGE_PIXEL)
+
+#define xlnx_pioout_bridge_yuv_set(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_SET,\
+			 HDMI_TX_PIO_OUT_BRIDGE_YUV420)
+
+#define xlnx_hdmi_auxintr_enable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_AUX_CTRL_SET,\
+			 HDMI_TX_AUD_CTRL_IE)
+
+/* Data Display Channel */
+#define xlnx_hdmi_ddc_disable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_DDC_CTRL_CLR,\
+			 HDMI_TX_DDC_CTRL_RUN)
+
+#define xlnx_hdmi_ddc_intr_clear(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_DDC_STA,\
+			 HDMI_TX_DDC_STA_IRQ)
+
+#define xlnx_hdmi_ddc_set_done(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_DDC_STA,\
+			 HDMI_TX_DDC_STA_DONE)
+
+#define xlnx_hdmi_ddc_set_timeout(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_DDC_STA,\
+			 HDMI_TX_DDC_STA_TO)
+
+#define xlnx_hdmi_ddc_intr_disable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_DDC_CTRL_CLR,\
+			 HDMI_TX_DDC_CTRL_IE)
+
+#define xlnx_hdmi_ddc_intr_enable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_DDC_CTRL_SET,\
+			 HDMI_TX_DDC_CTRL_IE)
+
+#define xlnx_hdmi_ddc_stop_cmd(hdmi) \
+	xlnx_hdmi_ddcwrite_cmd(hdmi, HDMI_TX_DDC_CMD_STP_TOKEN)
+
+#define xlnx_hdmi_ddc_rdtoken_cmd(hdmi) \
+	xlnx_hdmi_ddcwrite_cmd(hdmi, HDMI_TX_DDC_CMD_RD_TOKEN)
+
+#define xlnx_hdmi_ddc_rd_data(hdmi) \
+	xlnx_hdmi_readl(hdmi, HDMI_TX_DDC_DAT)
+
+#define xlnx_hdmi_ddc_run_enable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_DDC_CTRL_SET,\
+			 HDMI_TX_DDC_CTRL_RUN)
+
+/* Audio */
+#define xlnx_hdmi_audio_disable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_AUD_CTRL_CLR,\
+			 HDMI_TX_AUD_CTRL_RUN)
+/* Aux communication */
+#define xlnx_hdmi_aux_disable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_AUX_CTRL_CLR,\
+			 HDMI_TX_AUX_CTRL_RUN)
+
+#define xlnx_hdmi_aux_enable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_AUX_CTRL_SET,\
+			 HDMI_TX_AUX_CTRL_RUN)
+
+#define xlnx_hdmi_auxintr_enable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_AUX_CTRL_SET,\
+			 HDMI_TX_AUD_CTRL_IE)
+
+#define xlnx_hdmi_auxintr_disable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_AUX_CTRL_CLR,\
+			 HDMI_TX_AUD_CTRL_IE)
+
+/* Fixed Rate Link */
+#define xlnx_hdmi_frl_intr_disable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_CLR,\
+			 HDMI_TX_FRL_CTRL_IE)
+
+#define xlnx_hdmi_frl_intr_enable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_SET,\
+			 HDMI_TX_FRL_CTRL_IE)
+
+#define xlnx_hdmi_frl_clear(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_CLR,\
+			 HDMI_TX_FRL_CTRL_RST)
+
+#define xlnx_hdmi_frl_ext_vidsrc(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_SET,\
+			 HDMI_TX_FRL_CTRL_FRL_VCKE_EXT)
+
+#define xlnx_hdmi_frl_reset(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_SET,\
+			 HDMI_TX_FRL_CTRL_RST)
+
+#define xlnx_hdmi_frl_reset_assert(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_CLR,\
+			 HDMI_TX_FRL_CTRL_RST)
+
+#define xlnx_hdmi_frl_reset_deassert(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_SET,\
+			 HDMI_TX_FRL_CTRL_RST)
+
+#define xlnx_hdmi_frl_sleep(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL,\
+			 HDMI_TX_FRL_CTRL_RST |\
+			 HDMI_TX_FRL_CTRL_IE |\
+			 HDMI_TX_FRL_CTRL_EXEC)
+
+#define xlnx_hdmi_frl_mode_enable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_SET,\
+			 HDMI_TX_FRL_CTRL_OP_MODE)
+
+#define xlnx_hdmi_frl_mode_disable(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_CLR,\
+			 HDMI_TX_FRL_CTRL_OP_MODE)
+
+#define xlnx_hdmi_frl_execute(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_SET,\
+			 HDMI_TX_FRL_CTRL_EXEC)
+
+#define xlnx_hdmi_set_hdmi_mode(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_SET,\
+			 HDMI_TX_PIO_OUT_MODE)
+
+/* assert VID_IN bridge resets */
+#define xlnx_hdmi_ext_sysrst_assert(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_CLR,\
+			 HDMI_TX_PIO_OUT_EXT_SYSRST)
+
+#define xlnx_hdmi_ext_vrst_assert(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_CLR,\
+			 HDMI_TX_PIO_OUT_EXT_VRST)
+
+#define xlnx_hdmi_int_lrst_assert(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_CLR,\
+			 HDMI_TX_PIO_OUT_INT_LRST)
+
+#define xlnx_hdmi_int_vrst_assert(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_CLR,\
+			 HDMI_TX_PIO_OUT_INT_VRST)
+
+#define xlnx_hdmi_ext_sysrst_deassert(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_SET,\
+			 HDMI_TX_PIO_OUT_EXT_SYSRST)
+
+#define xlnx_hdmi_ext_vrst_deassert(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_SET,\
+			 HDMI_TX_PIO_OUT_EXT_VRST)
+
+#define xlnx_hdmi_int_lrst_deassert(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_SET,\
+			 HDMI_TX_PIO_OUT_INT_LRST)
+
+#define xlnx_hdmi_int_vrst_deassert(hdmi) \
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_SET,\
+			 HDMI_TX_PIO_OUT_INT_VRST)
+
+/* video timing controller */
+#define xlnx_hdmi_vtc_enable(hdmi) \
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_CTL, HDMI_TX_VTC_CTL_GE)
+
+#define xlnx_hdmi_vtc_disable(hdmi) \
+	xlnx_hdmi_vtc_clr(hdmi, HDMI_TX_VTC_CTL, HDMI_TX_VTC_CTL_GE)
+
+static ssize_t xlnx_hdcp_key_store(struct device *sysfs_dev, struct device_attribute *attr,
+				   const char *buf, size_t count)
+{
+	int ret = -EINVAL;
+	struct xlnx_hdmi *hdmi = (struct xlnx_hdmi *)dev_get_drvdata(sysfs_dev);
+	struct xlnx_hdcptx *xhdcp = &hdmi->txhdcp;
+
+	if (!(hdmi->config.hdcp2x_enable || hdmi->config.hdcp1x_enable))
+		return ret;
+
+	if (IS_ERR(xhdcp->xhdcp2x)) {
+		dev_err(hdmi->dev, "No HDCP2X module is Registered\n");
+		return PTR_ERR(xhdcp->xhdcp2x);
+	}
+
+	ret = xlnx_hdcp_tx_set_keys(xhdcp, (const u8 *)buf);
+	if (ret) {
+		dev_err(xhdcp->dev, "failed to send HDCP key from Sysfs to common layer");
+		return ret;
+	}
+
+	if (hdmi->config.hdcp2x_enable || hdmi->config.hdcp1x_enable) {
+		ret = xlnx_start_hdcp_engine(&hdmi->txhdcp,
+					     HDMI_MAX_LANES);
+		if (ret < 0) {
+			dev_err(hdmi->dev, "Failed to Start HDCP engine\n");
+			return ret;
+		}
+	}
+
+	return count;
+}
+
+static DEVICE_ATTR(xlnx_hdcp_key, 0600/*S_IRUSR | S_IWUSR*/, NULL, xlnx_hdcp_key_store);
+
+static struct attribute *xlnx_hdcp_key_attrs[] = {
+	&dev_attr_xlnx_hdcp_key.attr,
+	NULL,
+};
+
+static struct attribute_group xlnx_hdcp_key_attr_group = {
+	.attrs = xlnx_hdcp_key_attrs,
+};
+
+static inline void
+xlnx_hdmi_writel(struct xlnx_hdmi *hdmi, u32 offset, u32 val)
+{
+	writel(val, hdmi->base + offset);
+}
+
+static inline u32 xlnx_hdmi_readl(struct xlnx_hdmi *hdmi, int offset)
+{
+	return readl(hdmi->base + offset);
+}
+
+static void xlnx_hdmi_clr(struct xlnx_hdmi *hdmi, int offset, u32 clr)
+{
+	xlnx_hdmi_writel(hdmi, offset, xlnx_hdmi_readl(hdmi, offset) & ~clr);
+}
+
+static inline void
+xlnx_hdmi_vtc_writel(struct xlnx_hdmi *hdmi, u32 offset, u32 val)
+{
+	writel(val, hdmi->base + HDMI_TX_VTC_BASE + offset);
+}
+
+static inline u32
+xlnx_hdmi_vtc_readl(struct xlnx_hdmi *hdmi, u32 offset)
+{
+	return readl(hdmi->base + HDMI_TX_VTC_BASE + offset);
+}
+
+static inline void
+xlnx_hdmi_vtc_clr(struct xlnx_hdmi *hdmi, u32 offset, u32 clr)
+{
+	xlnx_hdmi_vtc_writel(hdmi, offset,
+			     xlnx_hdmi_vtc_readl(hdmi, offset) & ~clr);
+}
+
+static inline void
+xlnx_set_frl_link_clk(struct xlnx_hdmi *hdmi, u32 val)
+{
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_LNK_CLK, val);
+}
+
+static inline void
+xlnx_set_frl_vid_clk(struct xlnx_hdmi *hdmi, u32 val)
+{
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_VID_CLK, val);
+}
+
+static inline struct
+xlnx_hdmi *encoder_to_hdmi(struct drm_encoder *encoder)
+{
+	return container_of(encoder, struct xlnx_hdmi, encoder);
+}
+
+static inline
+struct xlnx_hdmi *connector_to_hdmi(struct drm_connector *connector)
+{
+	return container_of(connector, struct xlnx_hdmi, connector);
+}
+
+static bool xlnx_hdmi_is_lnk_vid_rdy(struct xlnx_hdmi *hdmi)
+{
+	u32 reg_val;
+
+	reg_val = xlnx_hdmi_readl(hdmi, HDMI_TX_PIO_IN);
+	reg_val = FIELD_GET(HDMI_TX_PIO_LNK_VID_RDY_MASK, reg_val);
+	if (reg_val == HDMI_TX_PIO_LNK_VID_RDY_MASK)
+		return true;
+
+	return false;
+}
+
+static int xlnx_hdmi_phy_configure(struct xlnx_hdmi *hdmi,
+				   union phy_configure_opts *opts)
+{
+	int ret = 0, i;
+
+	for (i = 0; i < HDMI_MAX_LANES; i++) {
+		ret = phy_configure(hdmi->phy[i], opts);
+		if (ret) {
+			dev_err(hdmi->dev, "phy_configure error %d\n", ret);
+			return ret;
+		}
+	}
+
+	return ret;
+}
+
+/**
+ * xlnx_hdmi_vtc_set_timing - configure video timing parameters
+ * @hdmi: hdmi tx instance
+ * @mode: drm display mode
+ *
+ * Program timing parameters into video timing controller
+ * registers.
+ *
+ * @return: None
+ */
+static void xlnx_hdmi_vtc_set_timing(struct xlnx_hdmi *hdmi,
+				     struct drm_display_mode *mode)
+{
+	u32 reg;
+	u32 htotal, hactive, hsync_start, hbackporch_start;
+	u32 vtotal, vactive, vsync_start, vbackporch_start;
+	u32 hsync_len, hfront_porch, hback_porch;
+	u32 vsync_len, vfront_porch, vback_porch;
+
+	/* vtc reset */
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_CTL, HDMI_TX_VTC_RST);
+	reg = xlnx_hdmi_vtc_readl(hdmi, HDMI_TX_VTC_CTL);
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_CTL, reg | HDMI_TX_VTC_CTL_RU);
+
+	hactive = mode->hdisplay / hdmi->config.htiming_div_fact;
+	hfront_porch = (mode->hsync_start - mode->hdisplay) /
+		hdmi->config.htiming_div_fact;
+	hback_porch = (mode->htotal - mode->hsync_end) /
+		hdmi->config.htiming_div_fact;
+	hsync_len = (mode->hsync_end - mode->hsync_start) /
+		hdmi->config.htiming_div_fact;
+	if (hdmi->xvidc_colorfmt == HDMI_TX_CSF_YCRCB_420) {
+		if (hactive & 0x1 || hfront_porch & 0x1 ||
+		    hback_porch & 0x1 || hsync_len & 0x1)
+			dev_dbg(hdmi->dev, "VTC does not support this timing\n");
+
+		hactive = hactive / 2;
+		hfront_porch = hfront_porch / 2;
+		hback_porch = hback_porch / 2;
+		hsync_len = hsync_len / 2;
+	}
+	htotal = hactive + hfront_porch + hsync_len + hback_porch;
+	hsync_start = hactive + hfront_porch;
+	hbackporch_start = hsync_start + hsync_len;
+
+	vactive = mode->vdisplay;
+	vfront_porch = mode->vsync_start - mode->vdisplay;
+	vback_porch = mode->vtotal - mode->vsync_end;
+	vsync_len = mode->vsync_end - mode->vsync_start;
+	vtotal = vactive + vfront_porch + vsync_len + vback_porch;
+	vsync_start = vactive + vfront_porch;
+	vbackporch_start = vsync_start + vsync_len;
+
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_CTL, reg & ~HDMI_TX_VTC_CTL_RU);
+
+	reg = htotal & HDMI_TX_VTC_GHSIZE_FRAME_HSIZE;
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_GHSIZE, reg);
+
+	reg = vtotal & HDMI_TX_VTC_GVSIZE_FRAME_VSIZE;
+	reg |= reg << HDMI_TX_VTC_FIELD1_VSIZE_SHIFT;
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_GVSIZE, reg);
+
+	reg = hactive & HDMI_TX_VTC_ACTIVE_SIZE_MASK;
+	reg |= (vactive & HDMI_TX_VTC_ACTIVE_SIZE_MASK) <<
+		HDMI_TX_VTC_FIELD1_VSIZE_SHIFT;
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_GASIZE_F0, reg);
+
+	reg = hsync_start & HDMI_TX_VTC_GHSYNC_START_MASK;
+	reg |= (hbackporch_start << HDMI_TX_VTC_GH1BPSTART_SHIFT) &
+		HDMI_TX_VTC_GHSYNC_END_MASK;
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_GHSYNC, reg);
+
+	reg = (vsync_start - 1) & HDMI_TX_VTC_F0_VSYNC_VSTART_MASK;
+	reg |= ((vbackporch_start - 1) << HDMI_TX_VTC_FIELD1_VSIZE_SHIFT) &
+		HDMI_TX_VTC_F0_VSYNC_VEND_MASK;
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_GVSYNC, reg);
+	xlnx_hdmi_clr(hdmi, HDMI_TX_VTC_BASE + HDMI_TX_VTC_GFENC,
+		      HDMI_TX_VTC_GFENC_MASK);
+
+	/* Calculate and uppdate Generator VBlank Hori field 0 */
+	reg = hactive & HDMI_TX_VTC_F0VBLANK_HSTART_MASK;
+	reg |= (hactive << HDMI_TX_VTC_F0VSYNC_HEND_SHIFT) &
+		HDMI_TX_VTC_F0VBLANK_HEND_MASK;
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_GVBHOFF, reg);
+
+	/* Calculate and update Generator VSync Hori field 0 */
+	reg = hsync_start & HDMI_TX_VTC_F0VBLANK_HSTART_MASK;
+	reg |= (hsync_start << HDMI_TX_VTC_F0VSYNC_HEND_SHIFT) &
+		HDMI_TX_VTC_F0VBLANK_HEND_MASK;
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_GVSHOFF, reg);
+
+	/* sets all polarities as active high */
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_GPOL, HDMI_TX_VTC_GPOL_MASK);
+	/* configure timing source */
+	xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_CTL, HDMI_TX_VTC_CTL_MASK |
+			     HDMI_TX_VTC_CTL_RU);
+}
+
+/**
+ * xlnx_hdmi_ddc_getack: get acknowledge
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: ddc transaction acknowledgment
+ */
+static bool xlnx_hdmi_ddc_getack(struct xlnx_hdmi *hdmi)
+{
+	u32 status;
+
+	status = xlnx_hdmi_readl(hdmi, HDMI_TX_DDC_STA);
+
+	return (status & HDMI_TX_DDC_STA_ACK);
+}
+
+/**
+ * xlnx_hdmi_ddcwaitfordone - wait for the ddc done flag to be set
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: 0 on success, 1 on timeout error
+ */
+static bool xlnx_hdmi_ddcwaitfordone(struct xlnx_hdmi *hdmi)
+{
+	u32 data;
+	bool status, val = false;
+
+	do {
+		data = xlnx_hdmi_readl(hdmi, HDMI_TX_DDC_CTRL);
+		if (data & HDMI_TX_DDC_CTRL_RUN) {
+			data = xlnx_hdmi_readl(hdmi, HDMI_TX_DDC_STA);
+			if (data & HDMI_TX_DDC_STA_DONE) {
+				xlnx_hdmi_ddc_set_done(hdmi);
+				val = true;
+				status = false;
+			} else if (data & HDMI_TX_DDC_STA_TO) {
+				xlnx_hdmi_ddc_set_timeout(hdmi);
+				val = true;
+				status = true;
+			}
+		} else {
+			status = true;
+			val = true;
+		}
+	} while (!val);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_ddcwrite_cmd - writes data into FIFO
+ * @hdmi: pointer to HDMI TX core instance
+ * @cmd: command to be written
+ *
+ * Returns: 0 on success, 1 if fifo full error
+ */
+static u32 xlnx_hdmi_ddcwrite_cmd(struct xlnx_hdmi *hdmi, u32 cmd)
+{
+	int tries = 0;
+	u32 status;
+	bool val = false;
+
+	do {
+		status = xlnx_hdmi_readl(hdmi, HDMI_TX_DDC_CTRL);
+		if (status & HDMI_TX_DDC_CTRL_RUN) {
+			status = xlnx_hdmi_readl(hdmi, HDMI_TX_DDC_STA);
+			status &= HDMI_TX_DDC_STA_CMD_FULL;
+			if (!status) {
+				xlnx_hdmi_writel(hdmi, HDMI_TX_DDC_CMD, cmd);
+				status = 0;
+				val = true;
+			} else {
+				usleep_range(100, 200);
+				if (tries++ > 10) {
+					xlnx_hdmi_ddc_disable(hdmi);
+					status = 1;
+					val = true;
+				}
+			}
+		} else {
+			status = 1;
+			val = true;
+		}
+	} while (!val);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_ddcwrite - ddc write
+ * @hdmi: pointer to HDMI TX core instance
+ * @slave: slave address
+ * @length: length of the data to be written
+ * @buffer: data buffer
+ * @stop: stop flag
+ *
+ * Returns: 0 if write is successful, 1 on failure.
+ */
+static u32 xlnx_hdmi_ddcwrite(struct xlnx_hdmi *hdmi, u8 slave,
+			      u16 length, u8 *buffer, u8 stop)
+{
+	u32 data, index, status;
+
+	/* ddc enable */
+	xlnx_hdmi_ddc_run_enable(hdmi);
+	xlnx_hdmi_ddc_intr_disable(hdmi);
+
+	status = xlnx_hdmi_ddcwrite_cmd(hdmi, HDMI_TX_DDC_CMD_STR_TOKEN);
+	if (status)
+		return status;
+
+	status = xlnx_hdmi_ddcwrite_cmd(hdmi, HDMI_TX_DDC_CMD_WR_TOKEN);
+	if (status)
+		return status;
+
+	status = xlnx_hdmi_ddcwrite_cmd(hdmi, 0);
+	if (status)
+		return status;
+
+	status = xlnx_hdmi_ddcwrite_cmd(hdmi, 1);
+	if (status)
+		return status;
+
+	data = slave << 1;
+	data &= HDMI_TX_DDC_CMD_MSK;
+	status = xlnx_hdmi_ddcwrite_cmd(hdmi, data);
+	if (status)
+		return status;
+
+	/* Wait for done flag */
+	if (xlnx_hdmi_ddcwaitfordone(hdmi))
+		return 1;
+
+	if (xlnx_hdmi_ddc_getack(hdmi)) {
+		status = xlnx_hdmi_ddcwrite_cmd(hdmi, HDMI_TX_DDC_CMD_WR_TOKEN);
+		if (status)
+			return status;
+
+		data = (length >> 8) & HDMI_TX_DDC_DATA_MSK;
+		status = xlnx_hdmi_ddcwrite_cmd(hdmi, data);
+		if (status)
+			return status;
+
+		data = length & HDMI_TX_DDC_DATA_MSK;
+		status = xlnx_hdmi_ddcwrite_cmd(hdmi, data);
+		if (status)
+			return status;
+
+		for (index = 0; index < length; index++) {
+			status = xlnx_hdmi_ddcwrite_cmd(hdmi, *buffer++);
+			if (status)
+				return status;
+		}
+		if (!xlnx_hdmi_ddcwaitfordone(hdmi)) {
+			if (xlnx_hdmi_ddc_getack(hdmi)) {
+				if (stop) {
+					status = xlnx_hdmi_ddc_stop_cmd(hdmi);
+					if (status)
+						return status;
+
+					xlnx_hdmi_ddcwaitfordone(hdmi);
+				}
+				status = 0;
+			}
+		}
+	}
+	xlnx_hdmi_ddc_disable(hdmi);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_ddcreaddata - read data
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: Byte data from ddc
+ */
+static u8 xlnx_hdmi_ddcreaddata(struct xlnx_hdmi *hdmi)
+{
+	u32 status;
+	int tries = 0;
+	u8 data;
+	bool val = false;
+
+	do {
+		data = xlnx_hdmi_readl(hdmi, HDMI_TX_DDC_CTRL);
+		if (data & HDMI_TX_DDC_CTRL_RUN) {
+			status = xlnx_hdmi_readl(hdmi, HDMI_TX_DDC_STA);
+			status &= HDMI_TX_DDC_STA_DAT_EMPTY;
+			if (!status) {
+				data = xlnx_hdmi_ddc_rd_data(hdmi);
+				val = true;
+			} else {
+				usleep_range(1000, 1100);
+				if (tries++ > 10) {
+					xlnx_hdmi_ddc_disable(hdmi);
+					val = true;
+					data = 0;
+				}
+			}
+		} else {
+			val = true;
+			data = 0;
+		}
+	} while (!val);
+
+	return data;
+}
+
+/**
+ * xlnx_hdmi_ddcread - read bulk data from ddc
+ * @hdmi: pointer to HDMI TX core instance
+ * @slave: slave address
+ * @length: length of data to be read
+ * @buffer: destination buffer address
+ * @stop: stop flag
+ *
+ * Returns: 0 on success, 1 on timeout errors
+ */
+static u32 xlnx_hdmi_ddcread(struct xlnx_hdmi *hdmi, u8 slave,
+			     u16 length, u8 *buffer, u8 stop)
+{
+	u32 data, index, status;
+
+	/* ddc enable */
+	xlnx_hdmi_ddc_run_enable(hdmi);
+	xlnx_hdmi_ddc_intr_disable(hdmi);
+
+	status = xlnx_hdmi_ddcwrite_cmd(hdmi, HDMI_TX_DDC_CMD_STR_TOKEN);
+	if (status)
+		return status;
+
+	status = xlnx_hdmi_ddcwrite_cmd(hdmi, HDMI_TX_DDC_CMD_WR_TOKEN);
+	if (status)
+		return status;
+
+	status = xlnx_hdmi_ddcwrite_cmd(hdmi, 0);
+	if (status)
+		return status;
+
+	status = xlnx_hdmi_ddcwrite_cmd(hdmi, 1);
+	if (status)
+		return status;
+
+	data = slave << 1;
+	/* set read bit */
+	data |= HDMI_TX_DDC_READ_DIR;
+
+	status = xlnx_hdmi_ddcwrite_cmd(hdmi, data);
+	if (status)
+		return status;
+
+	/* Wait for done flag */
+	if (!xlnx_hdmi_ddcwaitfordone(hdmi)) {
+		if (xlnx_hdmi_ddc_getack(hdmi)) {
+			status = xlnx_hdmi_ddc_rdtoken_cmd(hdmi);
+			if (status)
+				return status;
+
+			data = (length >> 8) & HDMI_TX_DDC_DATA_MSK;
+			status = xlnx_hdmi_ddcwrite_cmd(hdmi, data);
+			if (status)
+				return status;
+
+			data = length & HDMI_TX_DDC_DATA_MSK;
+			status = xlnx_hdmi_ddcwrite_cmd(hdmi, data);
+			if (status)
+				return status;
+
+			/* read data */
+			for (index = 0; index < length; index++)
+				*buffer++ = xlnx_hdmi_ddcreaddata(hdmi);
+			if (!xlnx_hdmi_ddcwaitfordone(hdmi)) {
+				if (stop) {
+					status = xlnx_hdmi_ddc_stop_cmd(hdmi);
+					if (status)
+						return(status);
+
+					xlnx_hdmi_ddcwaitfordone(hdmi);
+				}
+				status = 0;
+			}
+		}
+	}
+	xlnx_hdmi_ddc_disable(hdmi);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_ddc_readreg - read register from ddc
+ * @hdmi: pointer to HDMI TX core instance
+ * @slave: slave address
+ * @length: length of the data to be read
+ * @reg_addr: register address
+ * @buffer: destination buffer address
+ *
+ * Returns: 0 on success, non-zero value if ddc transaction fails.
+ */
+static int
+xlnx_hdmi_ddc_readreg(struct xlnx_hdmi *hdmi, u8 slave, u16 length,
+		      u8 reg_addr, u8 *buffer)
+{
+	int status;
+
+	/* Set the register to be read */
+	status = xlnx_hdmi_ddcwrite(hdmi, slave, 1, (u8 *)&reg_addr, false);
+	if (!status)
+		status = xlnx_hdmi_ddcread(hdmi, slave, length,
+					   (u8 *)buffer, true);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_ddcwrite_field - writes specified SCDC field
+ * @hdmi: HDMI TX core instance structure
+ * @field: field from SCDC channel to be written
+ * @val: value to be written
+ *
+ * Returns: 0 on success, non-zero value if ddc transaction fails.
+ */
+static int xlnx_hdmi_ddcwrite_field(struct xlnx_hdmi *hdmi,
+				    enum xlnx_hdmi_scdc_fields field, u8 val)
+{
+	u32 status;
+	u8 ddc_buf[2] = {0};
+	u8 offset = scdc_field[field].offset;
+
+	if (scdc_field[field].msk != HDMI_TX_SCDC_MASK) {
+		status = xlnx_hdmi_ddcwrite(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+					    (u8 *)&offset, false);
+		if (status)
+			return status;
+
+		status = xlnx_hdmi_ddcread(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+					   (u8 *)&ddc_buf, true);
+		if (status)
+			return status;
+
+		ddc_buf[0] &= ~(scdc_field[field].msk <<
+				scdc_field[field].shift);
+	} else {
+		ddc_buf[0] |= ((val & scdc_field[field].msk) <<
+			       scdc_field[field].shift);
+	}
+
+	ddc_buf[1] = ddc_buf[0];
+	ddc_buf[0] = offset;
+	return xlnx_hdmi_ddcwrite(hdmi, HDMI_TX_DDC_SLAVEADDR, 2,
+				  (u8 *)&ddc_buf, true);
+}
+
+/**
+ * xlnx_hdmi_set_samplerate - set sample rate
+ * @hdmi: pointer to HDMI TX core instance
+ * @samplerate: sample rate value
+ *
+ * Returns: None
+ */
+static void
+xlnx_hdmi_set_samplerate(struct xlnx_hdmi *hdmi, unsigned int samplerate)
+{
+	u32 regvalue;
+
+	xlnx_hdmi_pio_set_sr(hdmi);
+
+	switch (samplerate) {
+	case 2:
+		regvalue = 2;
+		break;
+	case 3:
+		regvalue = 1;
+		break;
+	case 5:
+		regvalue = 3;
+		break;
+	default:
+		regvalue = 0;
+		break;
+	}
+
+	/* set sample rate */
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT,
+			 (regvalue << (HDMI_TX_PIO_OUT_SR_SHIFT)));
+}
+
+/**
+ * xlnx_hdmi_set_ppc - set pixel per clock
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: None
+ */
+static void xlnx_hdmi_set_ppc(struct xlnx_hdmi *hdmi)
+{
+	u32 regvalue;
+
+	/* Mask PIO Out Mask register */
+	xlnx_hdmi_pio_set_pr(hdmi);
+
+	/* Check for pixel width */
+	switch (hdmi->config.ppc) {
+	case HDMI_TX_PPC_2:
+		regvalue = 1;
+		break;
+	case HDMI_TX_PPC_4:
+		regvalue = 2;
+		break;
+	case HDMI_TX_PPC_8:
+		regvalue = 3;
+		break;
+	default:
+		regvalue = 0;
+		break;
+	}
+	/* Write pixel rate into PIO Out register */
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT,
+			 (regvalue << HDMI_TX_PIO_OUT_PR_SHIFT));
+}
+
+/**
+ * xlnx_hdmi_set_colorfmt - set color format
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: None
+ */
+static void xlnx_hdmi_set_colorfmt(struct xlnx_hdmi *hdmi)
+{
+	u32 regvalue;
+
+	/* Mask PIO Out Mask register */
+	xlnx_hdmi_pio_set_cs(hdmi);
+
+	/* Check for color format */
+	switch (hdmi->xvidc_colorfmt) {
+	case HDMI_TX_CSF_YCRCB_444:
+		regvalue = 1;
+		break;
+	case HDMI_TX_CSF_YCRCB_422:
+		regvalue = 2;
+		break;
+	case HDMI_TX_CSF_YCRCB_420:
+		regvalue = 3;
+		break;
+	default:
+		regvalue = 0;
+		break;
+	}
+	/* Write color space into PIO Out register */
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT,
+			 (regvalue << HDMI_TX_PIO_OUT_CS_SHIFT));
+}
+
+/**
+ * xlnx_hdmi_set_colordepth - set color depth
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: None
+ */
+static void xlnx_hdmi_set_colordepth(struct xlnx_hdmi *hdmi)
+{
+	u32 regvalue;
+
+	/* Mask PIO Out Mask register */
+	xlnx_hdmi_pio_set_cd(hdmi);
+	if (hdmi->xvidc_colordepth > hdmi->config.bpc)
+		hdmi->xvidc_colordepth = hdmi->config.bpc;
+
+	switch (hdmi->xvidc_colordepth) {
+	case HDMI_TX_BPC_10:
+		regvalue = 1;
+		break;
+	case HDMI_TX_BPC_12:
+		regvalue = 2;
+		break;
+	case HDMI_TX_BPC_16:
+		regvalue = 3;
+		break;
+	default:
+		regvalue = 0;
+		break;
+	}
+	/* Write color depth into PIO Out register */
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT,
+			 regvalue << HDMI_TX_PIO_OUT_CD_SHIFT);
+}
+
+/**
+ * xlnx_hdmi_clkratio - set clock ratio
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: 0 on success, error if ddc write fails.
+ */
+static u32
+xlnx_hdmi_clkratio(struct xlnx_hdmi *hdmi)
+{
+	u32 status;
+	u8 ddc_buf[2];
+
+	ddc_buf[0] = HDMI_TX_SCRAMBLER_OFFSET;
+	status = xlnx_hdmi_ddcwrite(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+				    (u8 *)&ddc_buf, false);
+	if (status)
+		return status;
+
+	/* Read TMDS configuration */
+	status = xlnx_hdmi_ddcread(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+				   (u8 *)&ddc_buf, true);
+	ddc_buf[0] &= 0xfd;
+
+	if (hdmi->stream.tmds_clock_ratio)
+		ddc_buf[0] |= 0x02;
+	ddc_buf[1] = ddc_buf[0];
+	ddc_buf[0] = HDMI_TX_SCRAMBLER_OFFSET;
+
+	status = xlnx_hdmi_ddcwrite(hdmi, HDMI_TX_DDC_SLAVEADDR, 2,
+				    (u8 *)&ddc_buf, true);
+
+	return status;
+}
+
+static void xlnx_hdmi_avi_infoframe_colorspace(struct hdmi_avi_infoframe *frame,
+					       enum color_formats fmt)
+{
+	switch (fmt) {
+	case HDMI_TX_CSF_RGB:
+		frame->colorspace = HDMI_COLORSPACE_RGB;
+		break;
+	case HDMI_TX_CSF_YCRCB_420:
+		frame->colorspace = HDMI_COLORSPACE_YUV420;
+		break;
+	case HDMI_TX_CSF_YCRCB_422:
+		frame->colorspace = HDMI_COLORSPACE_YUV422;
+		break;
+	case HDMI_TX_CSF_YCRCB_444:
+		frame->colorspace = HDMI_COLORSPACE_YUV444;
+		break;
+	default:
+		break;
+	}
+}
+
+static void xlnx_hdmi_aux_write(struct xlnx_hdmi *hdmi)
+{
+	int index;
+	u32 readval;
+
+	readval = xlnx_hdmi_readl(hdmi, HDMI_TX_AUX_STA);
+
+	if ((readval & (HDMI_TX_AUX_STA_PKT_RDY | HDMI_TX_AUX_STA_FL))) {
+		if (readval & HDMI_TX_AUX_STA_FL) {
+			dev_dbg(hdmi->dev, "HDMI TX AUX FIFO full\n");
+		} else {
+			for (index = 0; index < (XHDMI_AUX_PKT_SIZE / sizeof(u32)); index++) {
+				xlnx_hdmi_writel(hdmi, HDMI_TX_AUX_DAT,
+						 hdmi->aux_buffer[index]);
+			}
+		}
+	}
+}
+
+static ssize_t xlnx_hdmi_send_avi_infoframe(struct xlnx_hdmi *hdmi)
+{
+	struct hdmi_avi_infoframe *frame = &hdmi->iframe;
+	u8 *ptr = (u8 *)hdmi->aux_buffer;
+	u8 buffer[HDMI_INFOFRAME_SIZE(AVI)] = {0};
+	int ret;
+	ssize_t err;
+
+	ret = drm_hdmi_avi_infoframe_from_display_mode(frame,
+						       &hdmi->connector,
+						       &hdmi->saved_adjusted_mode);
+	if (ret < 0) {
+		dev_err(hdmi->dev, "couldn't fill AVI infoframe\n");
+		return ret;
+	}
+
+	xlnx_hdmi_avi_infoframe_colorspace(frame, hdmi->xvidc_colorfmt);
+	err = hdmi_avi_infoframe_pack(frame, buffer, HDMI_INFOFRAME_SIZE(AVI));
+	if (err < 0) {
+		dev_err(hdmi->dev, "Failed to pack AVI infoframe: %zd\n", err);
+		return err;
+	}
+
+	/*
+	 * As per the Table 8-1 in HDMI 1.4b specification, packetization of
+	 * AVI Infoframe is like: HB0 HB1 HB2 PB0 PB1 .....PB27.
+	 */
+
+	/* Setting AVI Infoframe packet header from HB0 to HB2 */
+	ptr[0] = buffer[0];
+	ptr[1] = buffer[1];
+	ptr[2] = buffer[2];
+	/* Checksum (this will be calculated by the HDMI TX IP) */
+	ptr[3] = 0x0;
+
+	/* Copying PB0 - PB27 from offset 4 in the buffer */
+	memcpy((void *)(&ptr[4]), (void *)(&buffer[3]),
+	       (HDMI_INFOFRAME_SIZE(AVI) - HDMI_INFOFRAME_HEADER_SIZE));
+
+	xlnx_hdmi_aux_write(hdmi);
+
+	return 0;
+}
+
+static void xlnx_hdmi_send_infoframes(struct xlnx_hdmi *hdmi)
+{
+	xlnx_hdmi_send_avi_infoframe(hdmi);
+}
+
+static void xlnx_hdmi_vsync_event_handler(struct xlnx_hdmi *hdmi)
+{
+	xlnx_hdmi_send_infoframes(hdmi);
+}
+
+/**
+ * xlnx_hdmi_stream_start - set core parameters
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: 0 on success, 1 if ddc transaction fails
+ */
+static u32 xlnx_hdmi_stream_start(struct xlnx_hdmi *hdmi)
+{
+	u8 ddc_buf[2];
+	int status;
+
+	xlnx_hdmi_set_ppc(hdmi);
+	xlnx_hdmi_set_colorfmt(hdmi);
+	xlnx_hdmi_set_colordepth(hdmi);
+
+	/*
+	 * Set the TMDS clock ratio bit if the data rate is higher
+	 * than 3.4Gb/s
+	 */
+	if (hdmi->tmds_clk > HDMI_TX_3_4_GBPS) {
+		hdmi->stream.is_scrambled = true;
+		hdmi->stream.tmds_clock_ratio = true;
+	} else {
+		hdmi->stream.is_scrambled = false;
+		hdmi->stream.tmds_clock_ratio = false;
+	}
+
+	/* set scrambler */
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_OUT_CLR, HDMI_TX_PIO_OUT_SCRM);
+
+	ddc_buf[0] = HDMI_TX_SCRAMBLER_OFFSET;
+	status = xlnx_hdmi_ddcread(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+				   (u8 *)&ddc_buf, false);
+	if (!status)
+		return status;
+
+	status = xlnx_hdmi_ddcwrite(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+				    (u8 *)&ddc_buf, true);
+	if (status) {
+		ddc_buf[1] = ddc_buf[0] & HDMI_TX_DDC_CMD_MSK;
+		ddc_buf[1] |= hdmi->stream.is_scrambled;
+
+		status = xlnx_hdmi_ddcwrite(hdmi, HDMI_TX_DDC_SLAVEADDR, 2,
+					    (u8 *)&ddc_buf, true);
+	}
+	/* set clock ratio */
+	xlnx_hdmi_clkratio(hdmi);
+	return status;
+}
+
+/**
+ * xlnx_hdmi_set_frl_active: sets active FRL mode.
+ *
+ * @hdmi: HDMI TX core instance
+ * @mode: Mode specifies the active FRL mode.
+ * 0 = FRL transmission only includes GAP characters
+ * 1 = FRL transmission includes video, audio and control packets
+ */
+static void
+xlnx_hdmi_set_frl_active(struct xlnx_hdmi *hdmi, enum frl_active_mode mode)
+{
+	if (mode)
+		xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_SET,
+				 HDMI_TX_FRL_CTRL_FRL_ACT);
+	else
+		xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_CLR,
+				 HDMI_TX_FRL_CTRL_FRL_ACT);
+}
+
+/**
+ * xlnx_hdmi_set_frl_ltp: sets the link training pattern for the selected lane.
+ *
+ * @hdmi: pointer to HDMI TX instance
+ * @lane: lane number
+ * @ltp_type: link training pattern type
+ */
+static void
+xlnx_hdmi_set_frl_ltp(struct xlnx_hdmi *hdmi, u8 lane, u8 ltp_type)
+{
+	u32 value = ltp_type;
+	u32 data;
+
+	data = xlnx_hdmi_readl(hdmi, HDMI_TX_FRL_CTRL);
+
+	switch (lane) {
+	case 0:
+		data = data & ~((u32)(HDMI_TX_FRL_CTRL_FRL_REQ_MASK <<
+				      HDMI_TX_FRL_CTRL_FRL_LTP0_SHIFT));
+		data = data | ((value & HDMI_TX_FRL_CTRL_FRL_REQ_MASK) <<
+			       HDMI_TX_FRL_CTRL_FRL_LTP0_SHIFT);
+		break;
+	case 1:
+		data = data & ~((u32)(HDMI_TX_FRL_CTRL_FRL_REQ_MASK <<
+				      HDMI_TX_FRL_CTRL_FRL_LTP1_SHIFT));
+		data = data | ((value & HDMI_TX_FRL_CTRL_FRL_REQ_MASK) <<
+			       HDMI_TX_FRL_CTRL_FRL_LTP1_SHIFT);
+		break;
+	case 2:
+		data = data & ~((u32)(HDMI_TX_FRL_CTRL_FRL_REQ_MASK <<
+				      HDMI_TX_FRL_CTRL_FRL_LTP2_SHIFT));
+		data = data | ((value & HDMI_TX_FRL_CTRL_FRL_REQ_MASK) <<
+			       HDMI_TX_FRL_CTRL_FRL_LTP2_SHIFT);
+		break;
+	case 3:
+		data = data & ~((u32)(HDMI_TX_FRL_CTRL_FRL_REQ_MASK <<
+				      HDMI_TX_FRL_CTRL_FRL_LTP3_SHIFT));
+		data = data | ((value & HDMI_TX_FRL_CTRL_FRL_REQ_MASK) <<
+			       HDMI_TX_FRL_CTRL_FRL_LTP3_SHIFT);
+		break;
+	default:
+		dev_dbg(hdmi->dev, "Wrong lane is selected!\n");
+		break;
+	}
+
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL, data);
+}
+
+static void xlnx_hdmi_streamup_callback(struct xlnx_hdmi *hdmi)
+{
+	union phy_configure_opts phy_cfg = {0};
+	int ret;
+
+	if (hdmi->stream.is_frl)
+		xlnx_hdmi_frl_mode_enable(hdmi);
+	else
+		xlnx_hdmi_frl_mode_disable(hdmi);
+
+	phy_cfg.hdmi.get_samplerate = 1;
+	ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+	if (ret) {
+		dev_err(hdmi->dev, "phy_cfg: get_samplerate err %d\n", ret);
+		return;
+	}
+	/* Set the sample rate got from HMDI-PHY */
+	xlnx_hdmi_set_samplerate(hdmi,
+				 phy_cfg.hdmi.samplerate);
+	xlnx_hdmi_stream_start(hdmi);
+
+	phy_cfg.hdmi.clkout1_obuftds = 1;
+	phy_cfg.hdmi.clkout1_obuftds_en = true;
+	ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+	if (ret) {
+		dev_err(hdmi->dev, "phy_cfg: obuftds_en err %d\n", ret);
+		return;
+	}
+
+	/* release vid_in bridge resets */
+	xlnx_hdmi_ext_sysrst_deassert(hdmi);
+	xlnx_hdmi_ext_vrst_deassert(hdmi);
+	/* release tx core resets */
+	xlnx_hdmi_int_lrst_deassert(hdmi);
+	xlnx_hdmi_int_vrst_deassert(hdmi);
+
+	if (hdmi->xvidc_colorfmt == HDMI_TX_CSF_YCRCB_420) {
+		xlnx_pioout_bridge_yuv_set(hdmi);
+		xlnx_pioout_bridge_pixel_clr(hdmi);
+	} else {
+		if (hdmi->iframe.pixel_repeat) {
+			xlnx_pioout_bridge_yuv_clr(hdmi);
+			xlnx_pioout_bridge_pixel_set(hdmi);
+		} else {
+			xlnx_pioout_bridge_yuv_clr(hdmi);
+			xlnx_pioout_bridge_pixel_clr(hdmi);
+		}
+	}
+
+	hdmi->wait_for_streamup =
+		xlnx_hdmi_is_lnk_vid_rdy(hdmi) ? 1 : 0;
+	wake_up(&hdmi->wait_event);
+}
+
+/**
+ * xlnx_hdmi_set_frl_timer: sets the frl timer value
+ * @hdmi: pinter to HDMI TX core instance
+ * @timer_val: timer value in milliseconds
+ */
+static void xlnx_hdmi_set_frl_timer(struct xlnx_hdmi *hdmi, u32 timer_val)
+{
+	u32 clk_cycles = 0;
+	unsigned long clkrate;
+
+	clkrate = clk_get_rate(hdmitx_clks[S_AXI_CPU_ACLK].clk);
+	if (timer_val == TIMEOUT_10US)
+		clk_cycles = div_u64(clkrate, 100000);
+	else if (timer_val > 0)
+		clk_cycles = div_u64(clkrate * timer_val, 1000);
+
+	xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_TMR, clk_cycles);
+}
+
+/**
+ * xlnx_hdmi_clear_frl_ltp - stops sending link training patterns
+ * @hdmi: pointer to HDMI TX core instance
+ */
+static void xlnx_hdmi_clear_frl_ltp(struct xlnx_hdmi *hdmi)
+{
+	u32 index;
+
+	for (index = 0; index < HDMI_MAX_LANES; index++)
+		xlnx_hdmi_set_frl_ltp(hdmi, index, HDMI_TX_LTP_NO_LTP);
+}
+
+static int xlnx_hdmi_set_frl_rate(struct xlnx_hdmi *hdmi, u8 frlrate)
+{
+	if (!frlrate) {
+		dev_err(hdmi->dev, "frl_rate %d not supported\n", frlrate);
+		return 1;
+	}
+	hdmi->stream.frl_config.frl_rate = frlrate;
+	hdmi->stream.frl_config.lanes = rate_table[frlrate].lanes;
+	hdmi->stream.frl_config.linerate = rate_table[frlrate].linerate;
+
+	dev_dbg(hdmi->dev, "Setting FRL rate @%d Gbps\n", rate_table[frlrate].linerate);
+	/* Set lanes */
+	if (hdmi->stream.frl_config.lanes == 4)
+		xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_SET,
+				 HDMI_TX_FRL_CTRL_FRL_LN_OP);
+	else
+		xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_CTRL_CLR,
+				 HDMI_TX_FRL_CTRL_FRL_LN_OP);
+	/*TODO: FFE levels needs to set here */
+	return xlnx_hdmi_ddcwrite_field(hdmi, HDMI_TX_SCDC_FIELD_SNK_CFG1,
+					frlrate);
+}
+
+/**
+ * xlnx_hdmi_reset - Reset the core and bridge
+ * @hdmi: HDMI core structure
+ *
+ * Returns: None
+ */
+static void xlnx_hdmi_reset(struct xlnx_hdmi *hdmi)
+{
+	/* hdmi core reset - assert */
+	xlnx_hdmi_int_lrst_assert(hdmi);
+	xlnx_hdmi_int_vrst_assert(hdmi);
+
+	/* vid out bridge reset */
+	xlnx_hdmi_ext_sysrst_assert(hdmi);
+	xlnx_hdmi_ext_vrst_assert(hdmi);
+
+	/* release vid in bridge resets */
+	xlnx_hdmi_ext_sysrst_deassert(hdmi);
+	xlnx_hdmi_ext_vrst_deassert(hdmi);
+
+	/* release hdmi tx core resets */
+	xlnx_hdmi_int_lrst_deassert(hdmi);
+	xlnx_hdmi_int_vrst_deassert(hdmi);
+}
+
+static void xlnx_hdmi_streamdown_callback(struct xlnx_hdmi *hdmi)
+{
+	xlnx_hdmi_reset(hdmi);
+	xlnx_hdmi_ddc_disable(hdmi);
+}
+
+static void xlnx_hdmi_tmdsconfig(struct xlnx_hdmi *hdmi)
+{
+	union phy_configure_opts phy_cfg = {0};
+	int ret;
+
+	phy_cfg.hdmi.ibufds = 1;
+	phy_cfg.hdmi.ibufds_en = true;
+	ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+	if (ret) {
+		dev_err(hdmi->dev, "phy_cfg: Ibufds err %d\n", ret);
+		return;
+	}
+
+	phy_cfg.hdmi.clkout1_obuftds = 1;
+	phy_cfg.hdmi.clkout1_obuftds_en = false;
+	ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+	if (ret) {
+		dev_err(hdmi->dev, "phy_cfg: obuftds_en err %d\n", ret);
+		return;
+	}
+
+	phy_cfg.hdmi.config_hdmi20 = 1;
+	ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+	if (ret) {
+		dev_err(hdmi->dev, "phy_cfg: hdmi20 err %d\n", ret);
+		return;
+	}
+
+	xlnx_set_frl_link_clk(hdmi, 0);
+	xlnx_set_frl_vid_clk(hdmi, 0);
+	xlnx_hdmi_set_hdmi_mode(hdmi);
+}
+
+/**
+ * xlnx_hdmi_hdcp_reset - Reset hdcp module
+ * @hdmi: HDMI IP core structure
+ *
+ * This function resets HDCP cipher engine,
+ * protocol state machine and its internal parameters.
+ *
+ * Return: 0 on success, or the error code returned
+ * from the callee functions.
+ */
+static int xlnx_hdmi_hdcp_reset(struct xlnx_hdmi *hdmi)
+{
+	struct xlnx_hdcptx *xhdcp = &hdmi->txhdcp;
+	int ret;
+
+	cancel_delayed_work(&hdmi->hdcp_cp_irq_work);
+	ret = xlnx_hdcp_tx_reset(xhdcp);
+	if (ret < 0) {
+		dev_err(xhdcp->dev, "failed to reset HDCP");
+		return ret;
+	}
+
+	return 0;
+}
+
+static void xlnx_hdmi_connect_callback(struct xlnx_hdmi *hdmi)
+{
+	union phy_configure_opts phy_cfg = {0};
+	int ret;
+
+	if (hdmi->cable_connected) {
+		xlnx_hdmi_ddc_disable(hdmi);
+
+		hdmi->tmds_clk = HDMI_TX_DEF_TMDS_CLK;
+		xlnx_hdmi_stream_start(hdmi);
+		phy_cfg.hdmi.tx_params = 1;
+		phy_cfg.hdmi.ppc = hdmi->config.ppc;
+		phy_cfg.hdmi.bpc = hdmi->xvidc_colordepth;
+		phy_cfg.hdmi.fmt = hdmi->xvidc_colorfmt;
+		phy_cfg.hdmi.tx_tmdsclk = hdmi->tmds_clk;
+		ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+		if (ret) {
+			dev_err(hdmi->dev, "phy_cfg: txparams error %d\n", ret);
+			return;
+		}
+
+		xlnx_hdmi_tmdsconfig(hdmi);
+	} else {
+		struct xlnx_hdcptx *xhdcp = &hdmi->txhdcp;
+
+		if (xhdcp->hdcp2xenable || xhdcp->hdcp1xenable) {
+			ret = xlnx_hdmi_hdcp_reset(hdmi);
+			if (ret < 0) {
+				dev_err(hdmi->dev, "failed to reset HDCP %d\n", ret);
+				return;
+			}
+		}
+		phy_cfg.hdmi.ibufds = 1;
+		phy_cfg.hdmi.ibufds_en = true;
+		ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+		if (ret) {
+			dev_err(hdmi->dev, "phy_cfg: Ibufds err %d\n", ret);
+			return;
+		}
+	}
+}
+
+static void xlnx_hdmi_frl_config(struct xlnx_hdmi *hdmi)
+{
+	union phy_configure_opts phy_cfg = {0};
+	int ret;
+
+	/* Enable HDMI 2.1 config */
+	phy_cfg.hdmi.linerate =
+		(u64)(hdmi->stream.frl_config.linerate * HDMI_TX_PIXELRATE_GBPS);
+	phy_cfg.hdmi.nchannels = hdmi->stream.frl_config.lanes;
+	phy_cfg.hdmi.config_hdmi21 = 1;
+	ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+	if (ret) {
+		dev_err(hdmi->dev, "phy_cfg: hdmi21 config failed\n");
+		return;
+	}
+
+	/* set FRL mode */
+	hdmi->stream.is_frl = 1;
+}
+
+static int xlnx_hdmi_sink_max_frl(struct xlnx_hdmi *hdmi)
+{
+	struct drm_connector *connector = &hdmi->connector;
+	int max_lanes, rate_per_lane, max_frl_rate;
+	int sink_max_frl_bw;
+
+	max_lanes = connector->display_info.hdmi.max_lanes;
+	rate_per_lane = connector->display_info.hdmi.max_frl_rate_per_lane;
+	max_frl_rate = max_lanes * rate_per_lane;
+
+	switch (max_frl_rate) {
+	case 9:
+		sink_max_frl_bw = DP_PCON_ENABLE_MAX_BW_9GBPS;
+		break;
+	case 18:
+		sink_max_frl_bw = DP_PCON_ENABLE_MAX_BW_18GBPS;
+		break;
+	case 24:
+		sink_max_frl_bw = DP_PCON_ENABLE_MAX_BW_24GBPS;
+		break;
+	case 32:
+		sink_max_frl_bw = DP_PCON_ENABLE_MAX_BW_32GBPS;
+		break;
+	case 40:
+		sink_max_frl_bw = DP_PCON_ENABLE_MAX_BW_40GBPS;
+		break;
+	case 48:
+		sink_max_frl_bw = DP_PCON_ENABLE_MAX_BW_48GBPS;
+		break;
+	case 0:
+		sink_max_frl_bw = DP_PCON_ENABLE_MAX_BW_0GBPS;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return sink_max_frl_bw;
+}
+
+/**
+ * xlnx_hdmi_frl_train_init: Initializes sink's SCDC for training.
+ * @hdmi: Pointer to HDMI TX core instance
+ *
+ * Returns: 0 on success, non-zero value if ddc transaction fails.
+ */
+static int xlnx_hdmi_frl_train_init(struct xlnx_hdmi *hdmi)
+{
+	int status = 1;
+	int source_max_frl_bw, sink_max_frl_bw, max_frl_bw;
+
+	xlnx_hdmi_clear_frl_ltp(hdmi);
+	/*
+	 * Initialize the FRL module to send out GAP characters only for
+	 * link training
+	 */
+	xlnx_hdmi_set_frl_active(hdmi, HDMI_TX_FRL_ACTIVE_MODE_GAP_ONLY);
+
+	source_max_frl_bw = hdmi->config.max_frl_rate;
+	sink_max_frl_bw = xlnx_hdmi_sink_max_frl(hdmi);
+	max_frl_bw = min(sink_max_frl_bw, source_max_frl_bw);
+	if (max_frl_bw <= 0)
+		return 1;
+
+	/* Initialize the core to operate in FRL mode */
+	xlnx_hdmi_frl_mode_enable(hdmi);
+	status = xlnx_hdmi_set_frl_rate(hdmi, max_frl_bw);
+	if (status)
+		return status;
+
+	return xlnx_hdmi_ddcwrite_field(hdmi, HDMI_TX_SCDC_FIELD_SNK_CFG0, 0);
+}
+
+/**
+ * xlnx_hdmi_exec_frl_state_ltsl - executes legacy training state
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: 0 on success, non-zero value if ddc transaction fails.
+ */
+static int xlnx_hdmi_exec_frl_state_ltsl(struct xlnx_hdmi *hdmi)
+{
+	int status;
+	u8 ddc_buf;
+
+	xlnx_hdmi_set_frl_timer(hdmi, 0);
+	xlnx_hdmi_frl_reset_assert(hdmi);
+	xlnx_hdmi_frl_reset_deassert(hdmi);
+	xlnx_hdmi_frl_mode_disable(hdmi);
+	hdmi->stream.is_frl = 0;
+
+	status = xlnx_hdmi_ddc_readreg(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+				       HDMI_TX_DDC_UPDATE_FLGS_REG,
+				       (u8 *)&ddc_buf);
+	if (status)
+		return status;
+
+	if (ddc_buf & HDMI_TX_DDC_UPDATE_FLGS_FLT_UPDATE_MASK)
+		status = xlnx_hdmi_ddcwrite_field(hdmi,
+						  HDMI_TX_SCDC_FIELD_FLT_UPDATE,
+						  1);
+	if (!status)
+		xlnx_hdmi_frl_execute(hdmi);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_exec_frl_state_lts1 - executes FRL LTS1 training state
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: 0 on success, non-zero value if ddc transaction fails.
+ */
+static int xlnx_hdmi_exec_frl_state_lts1(struct xlnx_hdmi *hdmi)
+{
+	int status;
+	u8 ddc_buf;
+
+	/* Read sink version */
+	status = xlnx_hdmi_ddc_readreg(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+				       HDMI_TX_DDC_SINK_VER_REG,
+				       (u8 *)&ddc_buf);
+
+	if (!status && ddc_buf != 0) {
+		status = xlnx_hdmi_ddcwrite_field(hdmi,
+						  HDMI_TX_SCDC_FIELD_SOURCE_VER,
+						  1);
+
+		if (!status) {
+			hdmi->stream.frl_config.frl_train_states =
+					HDMI_TX_FRLSTATE_LTS_2;
+			hdmi->stream.frl_config.timer_cnt = 0;
+		}
+	} else {
+		hdmi->stream.frl_config.frl_train_states =
+			HDMI_TX_FRLSTATE_LTS_L;
+		status = 1;
+	}
+
+	xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_10US);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_exec_frl_state_lts2: executes FRL LTS2 training state
+ * @hdmi: pointer to Hdmi Tx core instance
+ *
+ * Returns: 0 on success, non-zero value if ddc transaction or
+ * phy configure call fails.
+ */
+static int xlnx_hdmi_exec_frl_state_lts2(struct xlnx_hdmi *hdmi)
+{
+	union phy_configure_opts phy_cfg = {0};
+	int status = 1, ret, i;
+	u8 ddc_buf, index;
+
+	hdmi->stream.frl_config.timer_cnt += TIMEOUT_5MS;
+	status = xlnx_hdmi_ddc_readreg(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+				       HDMI_TX_DDC_STCR_REG, (u8 *)&ddc_buf);
+
+	/* Reset GTPLL before starting FRL Training */
+	phy_cfg.hdmi.resetgtpll = 1;
+	for (i = 0; i < HDMI_MAX_LANES; i++) {
+		ret = phy_configure(hdmi->phy[i], &phy_cfg);
+		if (ret) {
+			dev_err(hdmi->dev, "phy_cfg: resetgtpll config failed\n");
+			return ret;
+		}
+	}
+
+	if (!status) {
+		if (ddc_buf & HDMI_TX_DDC_STCR_FLT_NO_TIMEOUT_MASK)
+			hdmi->stream.frl_config.flt_no_timeout = true;
+		else
+			hdmi->stream.frl_config.flt_no_timeout = false;
+
+		xlnx_hdmi_ddcwrite_field(hdmi, HDMI_TX_SCDC_FIELD_SNK_STU, 1);
+	}
+
+	/* Read FLT_NO_UPDATE SCDC Register */
+	if (!status && (hdmi->stream.frl_config.flt_no_timeout ||
+			hdmi->stream.frl_config.timer_cnt < TIMEOUT_100MS)) {
+		status = xlnx_hdmi_ddc_readreg(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+					       HDMI_TX_DDC_STAT_FLGS_REG,
+					       (u8 *)&ddc_buf);
+		if (status)
+			return status;
+
+		if (ddc_buf & HDMI_TX_DDC_STAT_FLGS_FLT_RDY_MASK) {
+			/* Set the training state as LTS_3_ARM */
+			xlnx_hdmi_set_frl_timer(hdmi, 0);
+			hdmi->stream.frl_config.timer_cnt = 0;
+			hdmi->stream.frl_config.frl_train_states =
+					HDMI_TX_FRLSTATE_LTS_3_ARM;
+
+			xlnx_hdmi_frl_config(hdmi);
+
+			/* set Nyquist Clock as link training pattern */
+			for (index = 0; index < HDMI_MAX_LANES; index++) {
+				xlnx_hdmi_set_frl_ltp(hdmi, index,
+						      HDMI_TX_LTP_NYQUIST_CLOCK);
+			}
+
+			xlnx_hdmi_frl_execute(hdmi);
+		}
+	} else {
+		/* Timeout, fallback to LTS:L training state */
+		hdmi->stream.frl_config.frl_train_states =
+			HDMI_TX_FRLSTATE_LTS_L;
+		xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_10US);
+	}
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_exec_frl_state_lts2_ratewr: executes FRL LTS2-wr training state
+ * @hdmi: pointer to Hdmi Tx core instance
+ *
+ * Returns: 0 on success, non zero value on failure
+ */
+static int xlnx_hdmi_exec_frl_state_lts2_ratewr(struct xlnx_hdmi *hdmi)
+{
+	int status;
+
+	status = xlnx_hdmi_frl_train_init(hdmi);
+	if (status) {
+		dev_err(hdmi->dev, "lts2 train init failed\n");
+		hdmi->stream.frl_config.frl_train_states =
+			HDMI_TX_FRLSTATE_LTS_L;
+		return status;
+	}
+
+	xlnx_hdmi_frl_execute(hdmi);
+	hdmi->stream.frl_config.frl_train_states = HDMI_TX_FRLSTATE_LTS_3;
+	xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_10US);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_exec_frl_state_lts3: executes FRL LTS3 training state
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: 0 on success, non-zero value if ddc transaction fails.
+ */
+static int xlnx_hdmi_exec_frl_state_lts3(struct xlnx_hdmi *hdmi)
+{
+	int status;
+	u8 ddc_buf[4], ln;
+
+	/* If timeout is 200ms, fallback to LTS:L */
+	if (hdmi->stream.frl_config.timer_cnt > TIMEOUT_200MS &&
+	    !hdmi->stream.frl_config.flt_no_timeout) {
+		hdmi->stream.frl_config.timer_cnt = 0;
+		hdmi->stream.frl_config.frl_train_states =
+			HDMI_TX_FRLSTATE_LTS_L;
+		xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_10US);
+		return 1;
+	}
+
+	xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_2MS);
+	hdmi->stream.frl_config.timer_cnt += TIMEOUT_2MS;
+
+	status = xlnx_hdmi_ddc_readreg(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+				       HDMI_TX_DDC_UPDATE_FLGS_REG,
+				       (u8 *)&ddc_buf);
+
+	if (status || (ddc_buf[0] & HDMI_TX_DDC_UPDATE_FLGS_FLT_UPDATE_MASK) !=
+	    HDMI_TX_DDC_UPDATE_FLGS_FLT_UPDATE_MASK)
+		return 1;
+
+	if (ddc_buf[0] & HDMI_TX_DDC_UPDATE_FLGS_STUPDATE_MASK) {
+		status = xlnx_hdmi_ddc_readreg(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+					       HDMI_TX_DDC_STCR_REG,
+					       (u8 *)&ddc_buf);
+		if (status)
+			return status;
+
+		if (ddc_buf[0] & HDMI_TX_DDC_STCR_FLT_NO_TIMEOUT_MASK)
+			hdmi->stream.frl_config.flt_no_timeout = true;
+		else
+			hdmi->stream.frl_config.flt_no_timeout = false;
+
+		status = xlnx_hdmi_ddcwrite_field(hdmi,
+						  HDMI_TX_SCDC_FIELD_SNK_STU,
+						  1);
+	}
+
+	status = xlnx_hdmi_ddc_readreg(hdmi, HDMI_TX_DDC_SLAVEADDR, 2,
+				       HDMI_TX_DDC_STAT_FLGS_LN01_REG,
+				       (u8 *)&ddc_buf);
+	if (status)
+		return status;
+
+	ddc_buf[3] = ddc_buf[1] >> HDMI_TX_DDC_STAT_FLGS_LN23_LN3_SHIFT;
+	ddc_buf[2] = ddc_buf[1] & HDMI_TX_DDC_STAT_FLGS_LN23_LN2_MASK;
+	ddc_buf[1] = ddc_buf[0] >> HDMI_TX_DDC_STAT_FLGS_LN01_LN1_SHIFT;
+	ddc_buf[0] = ddc_buf[0] & HDMI_TX_DDC_STAT_FLGS_LN01_LN0_MASK;
+
+	/* link training is successful, if ddc status flag value is 0x0 */
+	if (ddc_buf[0] == 0x0 && ddc_buf[1] == 0x0 &&
+	    ddc_buf[2] == 0x0 && ddc_buf[3] == 0x0) {
+		hdmi->stream.frl_config.timer_cnt = 0;
+		hdmi->stream.frl_config.frl_train_states =
+			HDMI_TX_FRLSTATE_LTS_P_ARM;
+		xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_10US);
+		return 0;
+	} else if (ddc_buf[0] == 0xF && ddc_buf[1] == 0xF &&
+		   ddc_buf[2] == 0xF && ddc_buf[3] == 0xF) {
+		/* 0xF means a request to drop FRL rate */
+		hdmi->config.max_frl_rate = hdmi->config.max_frl_rate - 1;
+		hdmi->stream.frl_config.timer_cnt = 0;
+		hdmi->stream.frl_config.frl_train_states =
+			HDMI_TX_FRLSTATE_LTS_4;
+		xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_10US);
+	} else {
+		for (ln = 0; ln < 4; ln++) {
+			/*
+			 * 0x1 to 0x8 means specific link training pattern is
+			 * requested. Each of the lane need to be set to output
+			 * the link training pattern as requested.
+			 */
+			if (ddc_buf[ln] >= 1 && ddc_buf[ln] <= 8) {
+				if (ddc_buf[ln] != 3 ||
+				    hdmi->stream.frl_config.flt_no_timeout)
+					xlnx_hdmi_set_frl_ltp(hdmi, ln,
+							      ddc_buf[ln]);
+			}
+		}
+		xlnx_hdmi_frl_execute(hdmi);
+	}
+
+	return xlnx_hdmi_ddcwrite_field(hdmi, HDMI_TX_SCDC_FIELD_FLT_UPDATE, 1);
+}
+
+/**
+ * xlnx_hdmi_exec_frl_state_lts4: executes FRL LTS4 training state
+ * @hdmi: Pointer to HDMI TX core instance
+ *
+ * Returns: 0 on success, non-zero value if ddc transaction fails.
+ */
+static int xlnx_hdmi_exec_frl_state_lts4(struct xlnx_hdmi *hdmi)
+{
+	int status = 0;
+
+	xlnx_hdmi_set_frl_timer(hdmi, 0);
+	xlnx_hdmi_clear_frl_ltp(hdmi);
+
+	if (hdmi->stream.frl_config.max_frl_rate > 1) {
+		hdmi->config.max_frl_rate = hdmi->config.max_frl_rate - 1;
+		hdmi->stream.sink_max_linerate =
+			rate_table[hdmi->config.max_frl_rate].linerate;
+		hdmi->stream.sink_max_lanes = rate_table[hdmi->config.max_frl_rate].lanes;
+		status = 0;
+	} else {
+		status = 1;
+	}
+
+	if (!status) {
+		status = xlnx_hdmi_ddcwrite_field(hdmi,
+						HDMI_TX_SCDC_FIELD_FLT_UPDATE, 1);
+		if (!status) {
+			hdmi->stream.frl_config.timer_cnt = 0;
+			hdmi->stream.frl_config.frl_train_states =
+				HDMI_TX_FRLSTATE_LTS_3_ARM;
+			xlnx_hdmi_frl_config(hdmi);
+		}
+	} else {
+		hdmi->stream.frl_config.timer_cnt = 0;
+		hdmi->stream.frl_config.frl_train_states = HDMI_TX_FRLSTATE_LTS_L;
+		xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_10US);
+	}
+
+	xlnx_hdmi_frl_execute(hdmi);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_exec_frl_state_ltsp_arm: executes FRL LTSP-arm training state
+ * @hdmi: pointer to HDMI TX core instance.
+ *
+ * Returns: 0 on success, non-zero value if ddc transaction fails.
+ */
+static int xlnx_hdmi_exec_frl_state_ltsp_arm(struct xlnx_hdmi *hdmi)
+{
+	int status;
+
+	xlnx_hdmi_clear_frl_ltp(hdmi);
+	/* Send GAP characters */
+	xlnx_hdmi_set_frl_active(hdmi, HDMI_TX_FRL_ACTIVE_MODE_GAP_ONLY);
+	status = xlnx_hdmi_ddcwrite_field(hdmi,
+					  HDMI_TX_SCDC_FIELD_FLT_UPDATE, 1);
+	hdmi->stream.frl_config.frl_train_states = HDMI_TX_FRLSTATE_LTS_P;
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_exec_frl_state_ltsp: executes FRL LTS-P training state
+ * @hdmi: pointer to HDMI TX core instance.
+ *
+ * Returns: 0 on success, non-zero value if ddc transaction fails.
+ */
+static int xlnx_hdmi_exec_frl_state_ltsp(struct xlnx_hdmi *hdmi)
+{
+	int status;
+	u8 ddc_buf;
+
+	if (hdmi->stream.frl_config.frl_train_states !=
+	    HDMI_TX_FRLSTATE_LTS_P_FRL_RDY)
+		xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_2MS);
+	else
+		xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_250MS);
+
+	status = xlnx_hdmi_ddc_readreg(hdmi, HDMI_TX_DDC_SLAVEADDR, 1,
+				       HDMI_TX_DDC_UPDATE_FLGS_REG,
+				       (u8 *)&ddc_buf);
+	if (status)
+		return status;
+
+	if (hdmi->stream.frl_config.frl_train_states ==
+	    HDMI_TX_FRLSTATE_LTS_P) {
+		if (ddc_buf & HDMI_TX_DDC_UPDATE_FLGS_FRL_START_MASK) {
+			xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_250MS);
+			status = xlnx_hdmi_ddcwrite_field(hdmi,
+							  HDMI_TX_SCDC_FIELD_FRL_START,
+							  1);
+			if (!status) {
+				hdmi->stream.frl_config.frl_train_states =
+					HDMI_TX_FRLSTATE_LTS_P_FRL_RDY;
+				hdmi->wait_for_streamup =
+					xlnx_hdmi_is_lnk_vid_rdy(hdmi) ? 1 : 0;
+				wake_up(&hdmi->wait_event);
+			}
+		}
+	}
+
+	if (ddc_buf & HDMI_TX_DDC_UPDATE_FLGS_FLT_UPDATE_MASK) {
+		/* Stops transmitting link training pattern */
+		xlnx_hdmi_clear_frl_ltp(hdmi);
+		/* Stops transmitting video, audio and control packets */
+		xlnx_hdmi_set_frl_active(hdmi,
+					 HDMI_TX_FRL_ACTIVE_MODE_GAP_ONLY);
+		hdmi->stream.frl_config.timer_cnt = 0;
+		hdmi->stream.frl_config.frl_train_states =
+			HDMI_TX_FRLSTATE_LTS_3;
+		xlnx_hdmi_set_frl_timer(hdmi, TIMEOUT_10US);
+	} else if (ddc_buf & HDMI_TX_DDC_UPDATE_FLGS_CED_UPDATE_MASK) {
+		xlnx_hdmi_set_frl_timer(hdmi, 0);
+	}
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_exec_frl_state: executes states of FRL.
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: 0 on success, non-zero value on failure
+ */
+static int xlnx_hdmi_exec_frl_state(struct xlnx_hdmi *hdmi)
+{
+	int status = 1;
+
+	xlnx_hdmi_set_frl_timer(hdmi, 0);
+	xlnx_hdmi_frl_intr_enable(hdmi);
+	xlnx_hdmi_frl_execute(hdmi);
+
+	switch (hdmi->stream.frl_config.frl_train_states) {
+	case HDMI_TX_FRLSTATE_LTS_L:
+		status = xlnx_hdmi_exec_frl_state_ltsl(hdmi);
+		break;
+	case HDMI_TX_FRLSTATE_LTS_1:
+		status = xlnx_hdmi_exec_frl_state_lts1(hdmi);
+		break;
+	case HDMI_TX_FRLSTATE_LTS_2:
+		status = xlnx_hdmi_exec_frl_state_lts2(hdmi);
+		break;
+	case HDMI_TX_FRLSTATE_LTS_3_ARM:
+		status = xlnx_hdmi_exec_frl_state_lts2_ratewr(hdmi);
+		break;
+	case HDMI_TX_FRLSTATE_LTS_3:
+		status = xlnx_hdmi_exec_frl_state_lts3(hdmi);
+		break;
+	case HDMI_TX_FRLSTATE_LTS_4:
+		status = xlnx_hdmi_exec_frl_state_lts4(hdmi);
+		break;
+	case HDMI_TX_FRLSTATE_LTS_P_ARM:
+		status = xlnx_hdmi_exec_frl_state_ltsp_arm(hdmi);
+		if (!status)
+			status = xlnx_hdmi_exec_frl_state_ltsp(hdmi);
+		break;
+	case HDMI_TX_FRLSTATE_LTS_P:
+		status = xlnx_hdmi_exec_frl_state_ltsp(hdmi);
+		break;
+	case HDMI_TX_FRLSTATE_LTS_P_FRL_RDY:
+		status = xlnx_hdmi_exec_frl_state_ltsp(hdmi);
+		break;
+	default:
+		dev_dbg(hdmi->dev, "TX:S:FRL_INVALID_STATE!\n");
+		break;
+	}
+	/* Clear timer event flag */
+	hdmi->stream.frl_config.timer_event = false;
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_start_frl_train - starts the Fixed Rate Link Training.
+ * @hdmi: pointer to the HDMI Tx core instance.
+ *
+ * Returns: 0 on success, 1 on failure.
+ */
+static int
+xlnx_hdmi_start_frl_train(struct xlnx_hdmi *hdmi)
+{
+	int status;
+
+	hdmi->stream.frl_config.frl_train_states = HDMI_TX_FRLSTATE_LTS_1;
+	hdmi->stream.frl_config.timer_event = false;
+
+	status = xlnx_hdmi_exec_frl_state(hdmi);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_piointr_handler - HDMI TX peripheral interrupt handler.
+ * @hdmi: pointer to HDMI TX core instance
+ *
+ * Returns: None.
+ *
+ * This handler reads corresponding event interrupt from the PIO_IN_EVT
+ * register. It determines the source of the interrupt
+ */
+static void xlnx_hdmi_piointr_handler(struct xlnx_hdmi *hdmi)
+{
+	u32 event, data;
+
+	/* Read PIO IN Event register */
+	event = xlnx_hdmi_readl(hdmi, HDMI_TX_PIO_IN_EVT);
+
+	/* Clear event flags */
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_IN_EVT, event);
+
+	/* Read data */
+	data = xlnx_hdmi_readl(hdmi, HDMI_TX_PIO_IN);
+
+	/* HPD event has occurred */
+	if (event & HDMI_TX_PIO_IN_HPD_TOGGLE)
+		xlnx_hdmi_stream_start(hdmi);
+
+	/* HPD event has occurred */
+	if (event & HDMI_TX_PIO_IN_HPD_CONNECT) {
+		/* Check the HPD status */
+		if (data & HDMI_TX_PIO_IN_HPD_CONNECT) {
+			hdmi->cable_connected = 1;
+			hdmi->connector.status = connector_status_connected;
+		} else {
+			hdmi->cable_connected = 0;
+			hdmi->connector.status = connector_status_disconnected;
+			xlnx_hdmi_streamdown_callback(hdmi);
+		}
+		xlnx_hdmi_connect_callback(hdmi);
+		if (hdmi->connector.dev)
+			drm_sysfs_hotplug_event(hdmi->connector.dev);
+		else
+			dev_dbg(hdmi->dev, "Not sending HOTPLUG.\n");
+	}
+
+	/* Bridge Unlocked event has occurred */
+	if (event & HDMI_TX_PIO_IN_BRIDGE_LOCKED) {
+		dev_dbg(hdmi->dev, "PIO IN status = 0x%x\n",
+			xlnx_hdmi_readl(hdmi, HDMI_TX_PIO_IN));
+		if (data & HDMI_TX_PIO_IN_BRIDGE_LOCKED) {
+			dev_dbg(hdmi->dev, "Bridge locked\n");
+		} else {
+			dev_dbg(hdmi->dev, "Bridge unlocked\n");
+			/* Clear interrupt and FRL */
+			xlnx_hdmi_set_frl_timer(hdmi, 0);
+			xlnx_hdmi_frl_reset_assert(hdmi);
+			xlnx_hdmi_frl_reset_deassert(hdmi);
+			xlnx_hdmi_frl_mode_disable(hdmi);
+			hdmi->stream.is_frl = 0;
+			xlnx_hdmi_ddcwrite_field(hdmi,
+						 HDMI_TX_SCDC_FIELD_FLT_UPDATE,
+						 1);
+			xlnx_hdmi_piointr_clear(hdmi);
+		}
+	}
+
+	/* Bridge Overflow event has occurred */
+	if (event & HDMI_TX_PIO_IN_BRIDGE_OFLOW)
+		dev_err_ratelimited(hdmi->dev, "Overflow interrupt\n");
+
+	/* Bridge Underflow event has occurred */
+	if (event & HDMI_TX_PIO_IN_BRIDGE_UFLOW)
+		dev_err_ratelimited(hdmi->dev, "Underflow interrupt\n");
+
+	/* vsync event has occurred */
+	if (event & HDMI_TX_PIO_IN_VS) {
+		dev_dbg_ratelimited(hdmi->dev, "Vsync interrupt\n");
+		xlnx_hdmi_vsync_event_handler(hdmi);
+	}
+	/* Link ready event has occurred */
+	if (event & HDMI_TX_PIO_IN_LNK_RDY) {
+		/* Check the link status */
+		if (data & HDMI_TX_PIO_IN_LNK_RDY) {
+			if (hdmi->stream.is_frl) {
+				hdmi->stream.state = HDMI_TX_STATE_STREAM_UP;
+				if (hdmi->stream.frl_config.frl_train_states ==
+				    HDMI_TX_FRLSTATE_LTS_3_ARM) {
+					/* Execute state machine */
+					xlnx_hdmi_exec_frl_state(hdmi);
+				}
+			} else {
+				xlnx_hdmi_streamup_callback(hdmi);
+			}
+			xlnx_hdmi_aux_enable(hdmi);
+			xlnx_hdmi_auxintr_enable(hdmi);
+		} else {
+			/* Set stream status to down */
+			hdmi->stream.state = HDMI_TX_STATE_STREAM_DOWN;
+			/* Disable AUX */
+			xlnx_hdmi_aux_disable(hdmi);
+		}
+	}
+}
+
+/**
+ * xlnx_hdmi_frlintr_handler - HDMI TX FRL interrupt handler.
+ * @hdmi: pointer to HDMI TX core instance
+ */
+static void xlnx_hdmi_frlintr_handler(struct xlnx_hdmi *hdmi)
+{
+	u32 data;
+
+	/* Read FRL Status register */
+	data = xlnx_hdmi_readl(hdmi, HDMI_TX_FRL_STA);
+
+	/* Check FRL timer event */
+	if ((data) & (HDMI_TX_FRL_STA_TMR_EVT)) {
+		xlnx_hdmi_writel(hdmi, HDMI_TX_FRL_STA,
+				 HDMI_TX_FRL_STA_TMR_EVT);
+		/* Set Timer event flag */
+		hdmi->stream.frl_config.timer_event = true;
+
+		/* Execute state machine */
+		xlnx_hdmi_exec_frl_state(hdmi);
+	}
+}
+
+static irqreturn_t hdmitx_irq_handler(int irq, void *dev_id)
+{
+	struct xlnx_hdmi *hdmi = (struct xlnx_hdmi *)dev_id;
+	unsigned long flags;
+
+	/* read status registers */
+	hdmi->intr_status = xlnx_hdmi_readl(hdmi, HDMI_TX_PIO_STA);
+	hdmi->intr_status &= HDMI_TX_PIO_STA_IRQ;
+	if (hdmi->stream.is_frl) {
+		hdmi->frl_status = xlnx_hdmi_readl(hdmi, HDMI_TX_FRL_STA);
+		hdmi->frl_status &= HDMI_TX_FRL_STA_IRQ;
+	}
+
+	spin_lock_irqsave(&hdmi->irq_lock, flags);
+	xlnx_hdmi_piointr_disable(hdmi);
+	if (hdmi->frl_status) {
+		xlnx_hdmi_frl_intr_disable(hdmi);
+		xlnx_hdmi_frl_execute(hdmi);
+	}
+	spin_unlock_irqrestore(&hdmi->irq_lock, flags);
+
+	return IRQ_WAKE_THREAD;
+}
+
+static irqreturn_t hdmitx_irq_thread(int irq, void *data)
+{
+	struct xlnx_hdmi *hdmi = (struct xlnx_hdmi *)data;
+	unsigned long flags;
+
+	if (!hdmi)
+		return IRQ_HANDLED;
+
+	hdmi_mutex_lock(&hdmi->hdmi_mutex);
+
+	if (hdmi->intr_status)
+		xlnx_hdmi_piointr_handler(hdmi);
+
+	if (hdmi->frl_status && hdmi->stream.is_frl)
+		xlnx_hdmi_frlintr_handler(hdmi);
+
+	hdmi_mutex_unlock(&hdmi->hdmi_mutex);
+
+	spin_lock_irqsave(&hdmi->irq_lock, flags);
+	xlnx_hdmi_piointr_ie_enable(hdmi);
+	spin_unlock_irqrestore(&hdmi->irq_lock, flags);
+
+	return IRQ_HANDLED;
+}
+
+/* DRM connector functions */
+static enum drm_connector_status
+xlnx_hdmi_connector_detect(struct drm_connector *connector, bool force)
+{
+	/* it takes HDMI 50 ms to detect connection on init */
+	static int first_time_ms = 50;
+	struct xlnx_hdmi *hdmi = connector_to_hdmi(connector);
+
+	/* first time; wait 50 ms max until cable connected */
+	while (first_time_ms && !hdmi->cable_connected) {
+		msleep(20);
+		first_time_ms--;
+	}
+
+	/* connected in less than 50 ms? */
+	if (first_time_ms) {
+		/* after first time, report immediately */
+		dev_info(hdmi->dev, "detect() waited %d ms until connect.\n",
+			 50 - first_time_ms);
+		first_time_ms = 0;
+	}
+
+	hdmi_mutex_lock(&hdmi->hdmi_mutex);
+	if (hdmi->cable_connected) {
+		hdmi_mutex_unlock(&hdmi->hdmi_mutex);
+		dev_dbg(hdmi->dev, "hdmi_connector_detect() = connected\n");
+		return connector_status_connected;
+	}
+
+	hdmi_mutex_unlock(&hdmi->hdmi_mutex);
+	dev_dbg(hdmi->dev, "hdmi_connector_detect() = disconnected\n");
+
+	return connector_status_disconnected;
+}
+
+static void xlnx_hdmi_connector_destroy(struct drm_connector *connector)
+{
+	drm_connector_unregister(connector);
+	drm_connector_cleanup(connector);
+	connector->dev = NULL;
+}
+
+static int xlnx_hdmi_set_property(struct drm_connector *connector,
+				  struct drm_connector_state *state,
+				  struct drm_property *property,
+				  uint64_t val)
+{
+	struct xlnx_hdmi *hdmi = connector_to_hdmi(connector);
+
+	if (property == hdmi->height_out)
+		hdmi->height_out_prop_val = (u32)val;
+	else if (property == hdmi->width_out)
+		hdmi->width_out_prop_val = (u32)val;
+	else if (property == hdmi->in_fmt)
+		hdmi->in_fmt_prop_val = (u32)val;
+	else if (property == hdmi->out_fmt)
+		hdmi->out_fmt_prop_val = (u32)val;
+	else
+		return -EINVAL;
+
+	return 0;
+}
+
+static int xlnx_hdmi_get_property(struct drm_connector *connector,
+				  const struct drm_connector_state *state,
+				  struct drm_property *property,
+				  uint64_t *val)
+{
+	struct xlnx_hdmi *hdmi = connector_to_hdmi(connector);
+
+	if (property == hdmi->height_out)
+		*val = hdmi->height_out_prop_val;
+	else if (property == hdmi->width_out)
+		*val = hdmi->width_out_prop_val;
+	else if (property == hdmi->in_fmt)
+		*val = hdmi->in_fmt_prop_val;
+	else if (property == hdmi->out_fmt)
+		*val = hdmi->out_fmt_prop_val;
+	else
+		return -EINVAL;
+
+	return 0;
+}
+
+static const struct drm_connector_funcs xlnx_hdmi_connector_funcs = {
+	.dpms			= drm_helper_connector_dpms,
+	.detect			= xlnx_hdmi_connector_detect,
+	.fill_modes		= drm_helper_probe_single_connector_modes,
+	.destroy		= xlnx_hdmi_connector_destroy,
+	.atomic_duplicate_state	= drm_atomic_helper_connector_duplicate_state,
+	.atomic_destroy_state	= drm_atomic_helper_connector_destroy_state,
+	.reset			= drm_atomic_helper_connector_reset,
+	.atomic_set_property	= xlnx_hdmi_set_property,
+	.atomic_get_property	= xlnx_hdmi_get_property,
+};
+
+/* DRM connector helper functions */
+static int
+xlnx_hdmi_connector_mode_valid(struct drm_connector *connector,
+			       struct drm_display_mode *mode)
+{
+	struct xlnx_hdmi *hdmi = connector_to_hdmi(connector);
+	enum drm_mode_status status = MODE_OK;
+
+	if (mode->flags & DRM_MODE_FLAG_INTERLACE) {
+		mode->vdisplay = mode->vdisplay / 2;
+		dev_dbg(hdmi->dev, "INTERLACE, mode->vdisplay %d\n",
+			mode->vdisplay);
+	}
+
+	if ((mode->flags & DRM_MODE_FLAG_DBLCLK) &&
+	    (mode->flags & DRM_MODE_FLAG_INTERLACE)) {
+		mode->clock *= 2;
+		dev_dbg(hdmi->dev, "clock = %d, refresh rate = %d\n",
+			mode->clock, drm_mode_vrefresh(mode));
+	}
+
+	drm_mode_debug_printmodeline(mode);
+	hdmi_mutex_lock(&hdmi->hdmi_mutex);
+
+	/* pixel clock too high for sink? */
+	if (mode->clock > HDMI_TX_PIXEL_MAXRATE)
+		status = MODE_CLOCK_HIGH;
+	hdmi_mutex_unlock(&hdmi->hdmi_mutex);
+
+	return status;
+}
+
+/**
+ * xlnx_hdmi_get_edid_block - callback function for drm_do_get_edid() used in
+ * get_modes through drm_do_get_edid() from drm/drm_edid.c.
+ *
+ * @data: pointer to hdmi instance
+ * @buf: buffer pointer to copy edid data
+ * @block: edid block
+ * @len: length of the data to be read
+ *
+ * @return: 0 on success, error code otherwise
+ */
+static int
+xlnx_hdmi_get_edid_block(void *data, u8 *buf, unsigned int block,
+			 size_t len)
+{
+	u8 *buffer;
+	struct xlnx_hdmi *hdmi = data;
+	int ret = 0;
+
+	/* out of bounds? */
+	if (((block * 128) + len) > HDMI_TX_DDC_EDID_LENGTH)
+		return -EINVAL;
+
+	buffer = kzalloc(HDMI_TX_DDC_EDID_LENGTH, GFP_KERNEL);
+	if (!buffer)
+		return -ENOMEM;
+
+	/* first obtain edid in local buffer */
+	*buffer = 0;
+	ret = xlnx_hdmi_ddcwrite(hdmi, HDMI_TX_DDC_ADDR, 1, buffer, false);
+
+	if (!ret) {
+		ret = xlnx_hdmi_ddcread(hdmi, HDMI_TX_DDC_ADDR,
+					HDMI_TX_DDC_EDID_LENGTH, buffer, true);
+	} else {
+		kfree(buffer);
+		dev_err(hdmi->dev, "failed reading EDID\n");
+		return -EINVAL;
+	}
+
+	memcpy(buf, buffer + block * 128, len);
+
+	kfree(buffer);
+	return 0;
+}
+
+/**
+ * xlnx_hdmi_set_frl_tmds_mode - Function sets the supported mode (FRL/TMDS)
+ * by the connectd sink device. Also gets the max_frl_rate supportd by sink.
+ *
+ * @connector: pointer to drm connector instance
+ */
+static void
+xlnx_hdmi_set_frl_tmds_mode(struct drm_connector *connector)
+{
+	struct xlnx_hdmi *hdmi = connector_to_hdmi(connector);
+
+	if (connector->display_info.hdmi.max_lanes != 0 &&
+	    connector->display_info.hdmi.max_frl_rate_per_lane != 0) {
+		hdmi->stream.is_frl = 1;
+	} else {
+		hdmi->stream.is_frl = 0;
+	}
+}
+
+static int xlnx_hdmi_connector_get_modes(struct drm_connector *connector)
+{
+	struct xlnx_hdmi *hdmi = connector_to_hdmi(connector);
+	const struct drm_edid *drm_edid;
+	const struct edid *edid;
+	int ret;
+	bool is_hdmi_sink;
+
+	hdmi_mutex_lock(&hdmi->hdmi_mutex);
+
+	drm_edid = drm_edid_read_custom(connector, xlnx_hdmi_get_edid_block, hdmi);
+
+	/* Set HDMI FRL or TMDS Mode */
+	xlnx_hdmi_set_frl_tmds_mode(connector);
+
+	hdmi_mutex_unlock(&hdmi->hdmi_mutex);
+	drm_edid_connector_update(connector, drm_edid);
+
+	if (!drm_edid) {
+		dev_info(hdmi->dev, "no edid, assume <= 1024x768 works\n");
+		return 0;
+	}
+
+	/*
+	 * FIXME: This should use connector->display_info.is_hdmi from a
+	 * path that has read the EDID and called
+	 * drm_edid_connector_update().
+	 */
+	edid = drm_edid_raw(drm_edid);
+
+	/* If the sink is non HDMI, set the stream type to DVI else HDMI */
+	is_hdmi_sink = drm_detect_hdmi_monitor(edid);
+	if (is_hdmi_sink) {
+		dev_dbg(hdmi->dev, "setting stream type to HDMI\n");
+		xlnx_hdmi_set_hdmi_mode(hdmi);
+		hdmi->stream.is_hdmi = true;
+		if (hdmi->stream.is_hdmi)
+			xlnx_hdmi_aux_enable(hdmi);
+	} else {
+		dev_dbg(hdmi->dev, "setting stream type to DVI\n");
+	}
+
+	ret = drm_edid_connector_add_modes(connector);
+	kfree(edid);
+
+	return ret;
+}
+
+static struct drm_encoder *
+xlnx_hdmi_connector_best_encoder(struct drm_connector *connector)
+{
+	struct xlnx_hdmi *hdmi = connector_to_hdmi(connector);
+
+	return &hdmi->encoder;
+}
+
+static struct
+drm_connector_helper_funcs xlnx_hdmi_connector_helper_funcs = {
+	.get_modes = xlnx_hdmi_connector_get_modes,
+	.best_encoder = xlnx_hdmi_connector_best_encoder,
+	.mode_valid = xlnx_hdmi_connector_mode_valid,
+};
+
+/* DRM encoder functions */
+static void xlnx_hdmi_encoder_dpms(struct drm_encoder *encoder, int dpms)
+{
+	struct xlnx_hdmi *hdmi = encoder_to_hdmi(encoder);
+
+	hdmi_mutex_lock(&hdmi->hdmi_mutex);
+	hdmi->dpms = dpms;
+	hdmi_mutex_unlock(&hdmi->hdmi_mutex);
+}
+
+static void xlnx_hdmi_encoder_enable(struct drm_encoder *encoder)
+{
+	struct xlnx_hdmi *hdmi = encoder_to_hdmi(encoder);
+	struct xlnx_hdmi_config *config = &hdmi->config;
+
+	xlnx_hdmi_encoder_dpms(encoder, DRM_MODE_DPMS_ON);
+	if (xlnx_hdmi_is_lnk_vid_rdy(hdmi)) {
+		if (!config->vid_interface)
+			xlnx_hdmi_vtc_enable(hdmi);
+	} else {
+		dev_err(hdmi->dev, "No video/link clock! failed to enable vtc\n");
+	}
+
+	xlnx_hdmi_ext_sysrst_deassert(hdmi);
+}
+
+static void xlnx_hdmi_encoder_disable(struct drm_encoder *encoder)
+{
+	struct xlnx_hdmi *hdmi = encoder_to_hdmi(encoder);
+	struct xlnx_hdmi_config *config = &hdmi->config;
+
+	if (hdmi->bridge)
+		xlnx_bridge_disable(hdmi->bridge);
+
+	xlnx_hdmi_encoder_dpms(encoder, DRM_MODE_DPMS_OFF);
+
+	/* Disable the EXT VRST which actually starts the bridge */
+	xlnx_hdmi_ext_sysrst_assert(hdmi);
+	if (xlnx_hdmi_is_lnk_vid_rdy(hdmi)) {
+		if (!config->vid_interface)
+			xlnx_hdmi_vtc_disable(hdmi);
+	} else {
+		dev_err(hdmi->dev, "No video/link clock! failed to disable vtc\n");
+	}
+}
+
+/**
+ * xlnx_hdmi_find_media_bus - finds drm_fourcc equivalent format
+ * @hdmi: pointer to HDMI TX core instance
+ * @drm_fourcc: drm fourcc code
+ *
+ * Returns: equivalent media bus format
+ */
+static enum
+color_formats xlnx_hdmi_find_media_bus(struct xlnx_hdmi *hdmi,
+				       u32 drm_fourcc)
+{
+	switch (drm_fourcc) {
+	case DRM_FORMAT_XBGR8888:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_BGR888:
+	case DRM_FORMAT_RGB888:
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_ABGR8888:
+	case MEDIA_BUS_FMT_RGB888_1X24:
+		hdmi->xvidc_colordepth = HDMI_TX_BPC_8;
+		return HDMI_TX_CSF_RGB;
+	case DRM_FORMAT_XBGR2101010:
+		hdmi->xvidc_colordepth = HDMI_TX_BPC_10;
+		return HDMI_TX_CSF_RGB;
+	case DRM_FORMAT_VUY888:
+	case DRM_FORMAT_XVUY8888:
+	case DRM_FORMAT_Y8:
+	case DRM_FORMAT_YUV444:
+	case MEDIA_BUS_FMT_VUY8_1X24:
+		hdmi->xvidc_colordepth = HDMI_TX_BPC_8;
+		return HDMI_TX_CSF_YCRCB_444;
+	case DRM_FORMAT_XVUY2101010:
+	case DRM_FORMAT_Y10:
+	case DRM_FORMAT_X403:
+	case MEDIA_BUS_FMT_VUY10_1X30:
+		hdmi->xvidc_colordepth = HDMI_TX_BPC_10;
+		return HDMI_TX_CSF_YCRCB_444;
+	/* TODO: Fix using DRM and media formats in same switch case */
+	case DRM_FORMAT_X423:
+	case MEDIA_BUS_FMT_VUY12_1X36:
+		hdmi->xvidc_colordepth = HDMI_TX_BPC_12;
+		return HDMI_TX_CSF_YCRCB_444;
+	case DRM_FORMAT_YUYV:
+	case DRM_FORMAT_UYVY:
+	case DRM_FORMAT_NV16:
+	case MEDIA_BUS_FMT_UYVY8_1X16:
+		hdmi->xvidc_colordepth = HDMI_TX_BPC_8;
+		return HDMI_TX_CSF_YCRCB_422;
+	case DRM_FORMAT_XV20:
+		hdmi->xvidc_colordepth = HDMI_TX_BPC_10;
+		return HDMI_TX_CSF_YCRCB_422;
+	case DRM_FORMAT_NV12:
+	case MEDIA_BUS_FMT_VYYUYY8_1X24:
+		hdmi->xvidc_colordepth = HDMI_TX_BPC_8;
+		return HDMI_TX_CSF_YCRCB_420;
+	case DRM_FORMAT_XV15:
+		hdmi->xvidc_colordepth = HDMI_TX_BPC_10;
+		return HDMI_TX_CSF_YCRCB_420;
+	default:
+		dev_err(hdmi->dev, "Unknown drm fmt: %d\n", drm_fourcc);
+		hdmi->xvidc_colordepth = HDMI_TX_BPC_8;
+		return HDMI_TX_CSF_RGB;
+	}
+}
+
+static u64 xlnx_hdmi_get_tmdsclk(struct xlnx_hdmi *hdmi, struct drm_display_mode *adjusted_mode)
+{
+	u64 tmdsclk;
+
+	tmdsclk = adjusted_mode->clock * 1000;
+	if (hdmi->xvidc_colorfmt == HDMI_TX_CSF_YCRCB_420)
+		tmdsclk = tmdsclk >> 1;
+
+	if (hdmi->xvidc_colorfmt != HDMI_TX_CSF_YCRCB_422) {
+		switch (hdmi->xvidc_colordepth) {
+		case HDMI_TX_BPC_10:
+			tmdsclk = (tmdsclk * 5) >> 2;
+			break;
+		case HDMI_TX_BPC_12:
+			tmdsclk = (tmdsclk * 3) >> 1;
+			break;
+		case HDMI_TX_BPC_16:
+			tmdsclk = tmdsclk << 1;
+			break;
+		default:
+			break;
+		}
+	}
+
+	return tmdsclk;
+}
+
+/**
+ * xlnx_hdmi_encoder_atomic_mode_set - drive the HDMI timing parameters
+ *
+ * @encoder: pointer to Xilinx DRM encoder
+ * @crtc_state: DRM crtc state
+ * @connector_state: DRM connector state
+ *
+ * This function derives the HDMI IP timing parameters from the timing
+ * values given to timing module.
+ */
+static void
+xlnx_hdmi_encoder_atomic_mode_set(struct drm_encoder *encoder,
+				  struct drm_crtc_state *crtc_state,
+				  struct drm_connector_state *connector_state)
+{
+	struct xlnx_hdmi *hdmi = encoder_to_hdmi(encoder);
+	struct drm_connector *connector = &hdmi->connector;
+	struct xlnx_hdmi_config *config = &hdmi->config;
+	struct drm_display_mode *mode = &crtc_state->mode;
+	struct drm_display_mode *adjusted_mode = &crtc_state->adjusted_mode;
+	union phy_configure_opts phy_cfg = {0};
+	int ret;
+	int source_max_frl_bw, sink_max_frl_bw, max_frl_bw;
+	u32 drm_fourcc, pixelrate = 0;
+	u64 lnk_clk = 0, vid_clk = 0;
+
+	drm_mode_copy(&hdmi->saved_adjusted_mode, &crtc_state->adjusted_mode);
+	dev_dbg(hdmi->dev, "mode->clock = %d\n", mode->clock * 1000);
+	dev_dbg(hdmi->dev, "mode->crtc_clock = %d\n", mode->crtc_clock * 1000);
+	dev_dbg(hdmi->dev, "mode->pvsync = %d\n",
+		!!(mode->flags & DRM_MODE_FLAG_PVSYNC));
+	dev_dbg(hdmi->dev, "mode->phsync = %d\n",
+		!!(mode->flags & DRM_MODE_FLAG_PHSYNC));
+	dev_dbg(hdmi->dev, "mode->hsync_end = %d\n", mode->hsync_end);
+	dev_dbg(hdmi->dev, "mode->hsync_start = %d\n", mode->hsync_start);
+	dev_dbg(hdmi->dev, "mode->vsync_end = %d\n", mode->vsync_end);
+	dev_dbg(hdmi->dev, "mode->vsync_start = %d\n", mode->vsync_start);
+	dev_dbg(hdmi->dev, "mode->hdisplay = %d\n", mode->hdisplay);
+	dev_dbg(hdmi->dev, "mode->vdisplay = %d\n", mode->vdisplay);
+	dev_dbg(hdmi->dev, "mode->htotal = %d\n", mode->htotal);
+	dev_dbg(hdmi->dev, "mode->vtotal = %d\n", mode->vtotal);
+	dev_dbg(hdmi->dev, "mode->vrefresh = %d\n", drm_mode_vrefresh(mode));
+	dev_dbg(hdmi->dev, "mode->flags = %d interlace = %d\n", mode->flags,
+		!!(mode->flags & DRM_MODE_FLAG_INTERLACE));
+
+	source_max_frl_bw = hdmi->config.max_frl_rate;
+	sink_max_frl_bw = xlnx_hdmi_sink_max_frl(hdmi);
+	max_frl_bw = min(sink_max_frl_bw, source_max_frl_bw);
+	if (max_frl_bw <= 0) {
+		hdmi->stream.is_frl = 0;
+		dev_dbg(hdmi->dev, "Connected sink supports TMDS mode\n");
+	} else {
+		dev_dbg(hdmi->dev, "Connected sink supports FRL mode\n");
+		hdmi->stream.is_frl = 1;
+	}
+
+	if (hdmi->stream.is_frl) {
+		xlnx_hdmi_frl_reset_deassert(hdmi);
+		xlnx_hdmi_frl_intr_enable(hdmi);
+		xlnx_hdmi_frl_execute(hdmi);
+
+		hdmi->stream.frl_config.lanes = rate_table[max_frl_bw].lanes;
+		hdmi->stream.frl_config.linerate = rate_table[max_frl_bw].linerate;
+	} else {
+		xlnx_hdmi_frl_ext_vidsrc(hdmi);
+		xlnx_hdmi_frl_sleep(hdmi);
+	}
+
+	drm_fourcc = encoder->crtc->primary->state->fb->format->format;
+
+	if (hdmi->bridge) {
+		/*
+		 * TODO: Add a check for valid values of width_out,
+		 * height_out and out_fmt values based on sink
+		 * capabilities.
+		 */
+		xlnx_bridge_set_input(hdmi->bridge, adjusted_mode->hdisplay,
+				      adjusted_mode->vdisplay,
+				      hdmi->in_fmt_prop_val);
+		xlnx_bridge_set_output(hdmi->bridge, hdmi->width_out_prop_val,
+				       hdmi->height_out_prop_val,
+				       hdmi->out_fmt_prop_val);
+		xlnx_bridge_enable(hdmi->bridge);
+
+		drm_fourcc = hdmi->out_fmt_prop_val;
+		adjusted_mode = drm_mode_find_cea(connector->dev,
+						  hdmi->width_out_prop_val,
+						  hdmi->height_out_prop_val,
+						  drm_mode_vrefresh(adjusted_mode),
+						  adjusted_mode->flags & DRM_MODE_FLAG_INTERLACE);
+		if (!adjusted_mode) {
+			dev_err(hdmi->dev, "Invalid CEA mode\n");
+			return;
+		}
+	}
+
+	hdmi->xvidc_colorfmt = xlnx_hdmi_find_media_bus(hdmi, drm_fourcc);
+	dev_dbg(hdmi->dev, "xvidc_colorfmt = %d\n", hdmi->xvidc_colorfmt);
+	dev_dbg(hdmi->dev, "xvidc_colordepth = %d\n", hdmi->xvidc_colordepth);
+
+	hdmi->tmds_clk = xlnx_hdmi_get_tmdsclk(hdmi, adjusted_mode);
+	dev_dbg(hdmi->dev, "tmds_clk = %llu\n", hdmi->tmds_clk);
+
+	if (connector->display_info.is_hdmi)
+		xlnx_hdmi_send_infoframes(hdmi);
+
+	if (hdmi->stream.is_frl) {
+		phy_cfg.hdmi.clkout1_obuftds = 1;
+		phy_cfg.hdmi.clkout1_obuftds_en = false;
+		ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+		if (ret) {
+			dev_err(hdmi->dev, "phy_cfg:10bufds_en err %d\n", ret);
+			return;
+		}
+
+		ret = xlnx_hdmi_start_frl_train(hdmi);
+		if (ret) {
+			dev_err(hdmi->dev, "FRL training is failed.switch to TMDS mode \r\n");
+			xlnx_hdmi_set_hdmi_mode(hdmi);
+			hdmi->stream.is_hdmi = true;
+			hdmi->stream.is_frl = false;
+			xlnx_hdmi_auxintr_enable(hdmi);
+		} else {
+			dev_dbg(hdmi->dev, "FRL training passed !!\n");
+		}
+	}
+
+	xlnx_hdmi_stream_start(hdmi);
+	/* get tmds clock from phy */
+	if (!hdmi->stream.is_frl) {
+		xlnx_hdmi_clkratio(hdmi);
+
+		/* Assert VID_IN bridge resets */
+		xlnx_hdmi_ext_sysrst_assert(hdmi);
+		xlnx_hdmi_ext_vrst_assert(hdmi);
+
+		/* Assert HDMI TXCore resets */
+		xlnx_hdmi_int_lrst_assert(hdmi);
+
+		phy_cfg.hdmi.tx_params = 1;
+		phy_cfg.hdmi.ppc = config->ppc;
+		phy_cfg.hdmi.bpc = hdmi->xvidc_colordepth;
+		phy_cfg.hdmi.fmt = hdmi->xvidc_colorfmt;
+		phy_cfg.hdmi.tx_tmdsclk = hdmi->tmds_clk;
+		ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+		if (ret) {
+			dev_err(hdmi->dev, "phy_config: set txparams error %d\n", ret);
+			return;
+		}
+	} else {
+		if (hdmi->xvidc_colorfmt == HDMI_TX_CSF_YCRCB_422) {
+			vid_clk = div_u64(div_u64(hdmi->tmds_clk, config->ppc),
+					  1000);
+			lnk_clk = vid_clk;
+		} else {
+			pixelrate = div_u64(hdmi->tmds_clk * 8, hdmi->xvidc_colordepth * 1000);
+			vid_clk = div_u64(pixelrate, config->ppc);
+			lnk_clk = div_u64(vid_clk * hdmi->xvidc_colordepth, 8);
+		}
+
+		xlnx_set_frl_link_clk(hdmi, lnk_clk);
+		xlnx_set_frl_vid_clk(hdmi, vid_clk);
+
+		xlnx_hdmi_streamup_callback(hdmi);
+	}
+
+	dev_dbg(hdmi->dev, "tmds_clk = %llu Hz\n", hdmi->tmds_clk);
+
+	hdmi->wait_for_streamup = 0;
+	wait_event_timeout(hdmi->wait_event, hdmi->wait_for_streamup,
+			   msecs_to_jiffies(HDMI_TX_LNK_VID_RDY_DELAY));
+	if (!hdmi->wait_for_streamup)
+		dev_err(hdmi->dev, "wait_for_streamup timeout\n");
+
+	if (xlnx_hdmi_is_lnk_vid_rdy(hdmi)) {
+		dev_dbg(hdmi->dev, "TX: Video ready interrupt received\n");
+		if (!config->vid_interface)
+			xlnx_hdmi_vtc_set_timing(hdmi, adjusted_mode);
+		if (hdmi->stream.is_frl)
+			xlnx_hdmi_vtc_writel(hdmi, HDMI_TX_VTC_CTL,
+					     HDMI_TX_VTC_CTL_GE);
+	} else {
+		dev_dbg(hdmi->dev, "Video/Link clock is not ready\n");
+	}
+	if (hdmi->config.hdcp2x_enable || hdmi->config.hdcp1x_enable) {
+		ret = xlnx_start_hdcp_engine(&hdmi->txhdcp,
+					     HDMI_MAX_LANES);
+		if (ret < 0) {
+			dev_err(hdmi->dev, "Failed to Start HDCP engine\n");
+			return;
+		}
+	}
+	if (hdmi->stream.is_frl)
+		xlnx_hdmi_set_frl_active(hdmi,
+					 HDMI_TX_FRL_ACTIVE_MODE_FULL_STREAM);
+	else
+		xlnx_hdmi_ext_sysrst_assert(hdmi);
+}
+
+static const struct drm_encoder_funcs xlnx_hdmi_encoder_funcs = {
+	.destroy = drm_encoder_cleanup,
+};
+
+static const struct
+drm_encoder_helper_funcs xlnx_hdmi_encoder_helper_funcs = {
+	.dpms = xlnx_hdmi_encoder_dpms,
+	.enable = xlnx_hdmi_encoder_enable,
+	.disable = xlnx_hdmi_encoder_disable,
+	.atomic_mode_set = xlnx_hdmi_encoder_atomic_mode_set,
+};
+
+static void
+xlnx_hdmi_create_connector_property(struct drm_connector *connector)
+{
+	struct drm_device *dev = connector->dev;
+	struct xlnx_hdmi *hdmi = connector_to_hdmi(connector);
+
+	hdmi->height_out = drm_property_create_range(dev, 0, "height_out",
+						     HDMI_MIN_HEIGHT,
+						     HDMI_MAX_HEIGHT);
+	hdmi->width_out = drm_property_create_range(dev, 0, "width_out",
+						    HDMI_MIN_WIDTH,
+						    HDMI_MAX_WIDTH);
+	hdmi->in_fmt = drm_property_create_range(dev, 0, "in_fmt",
+						 MEDIA_BUS_FMT_RGB888_1X24,
+						 MEDIA_BUS_FMT_VYYUYY8_1X24);
+	hdmi->out_fmt = drm_property_create_range(dev, 0, "out_fmt",
+						  MEDIA_BUS_FMT_RGB888_1X24,
+						  MEDIA_BUS_FMT_VYYUYY8_1X24);
+}
+
+static void
+xlnx_hdmi_attach_connector_property(struct drm_connector *connector)
+{
+	struct xlnx_hdmi *hdmi = connector_to_hdmi(connector);
+	struct drm_mode_object *obj = &connector->base;
+
+	if (hdmi->height_out)
+		drm_object_attach_property(obj, hdmi->height_out, 0);
+	if (hdmi->width_out)
+		drm_object_attach_property(obj, hdmi->width_out, 0);
+	if (hdmi->in_fmt)
+		drm_object_attach_property(obj, hdmi->in_fmt, 0);
+	if (hdmi->out_fmt)
+		drm_object_attach_property(obj, hdmi->out_fmt, 0);
+}
+
+static int xlnx_hdmi_create_connector(struct drm_encoder *encoder)
+{
+	struct xlnx_hdmi *hdmi = encoder_to_hdmi(encoder);
+	struct drm_connector *connector = &hdmi->connector;
+	int ret;
+
+	connector->polled = DRM_CONNECTOR_POLL_HPD;
+	connector->interlace_allowed = true;
+
+	ret = drm_connector_init(encoder->dev, connector,
+				 &xlnx_hdmi_connector_funcs,
+				 DRM_MODE_CONNECTOR_HDMIA);
+	if (ret) {
+		dev_err(hdmi->dev, "Failed to initialize connector with drm\n");
+		return ret;
+	}
+
+	drm_connector_helper_add(connector, &xlnx_hdmi_connector_helper_funcs);
+	ret = drm_connector_register(connector);
+	if (ret) {
+		dev_err(hdmi->dev,
+			"Failed to register connector (ret=%d)\n", ret);
+		return ret;
+	}
+	ret = drm_connector_attach_encoder(connector, encoder);
+	if (ret) {
+		dev_err(hdmi->dev,
+			"Failed to attach connector (ret=%d)\n", ret);
+		return ret;
+	}
+
+	xlnx_hdmi_create_connector_property(connector);
+	xlnx_hdmi_attach_connector_property(connector);
+
+	return 0;
+}
+
+static int xlnx_hdmi_bind(struct device *dev, struct device *master,
+			  void *data)
+{
+	struct xlnx_hdmi *hdmi = dev_get_drvdata(dev);
+	struct drm_encoder *encoder = &hdmi->encoder;
+	struct drm_device *drm_dev = data;
+	int ret;
+
+	encoder->possible_crtcs = 1;
+	/* initialize encoder */
+	drm_encoder_init(drm_dev, encoder, &xlnx_hdmi_encoder_funcs,
+			 DRM_MODE_ENCODER_TMDS, NULL);
+	drm_encoder_helper_add(encoder, &xlnx_hdmi_encoder_helper_funcs);
+
+	/* create connector */
+	ret = xlnx_hdmi_create_connector(encoder);
+	if (ret) {
+		dev_err(hdmi->dev, "failed create connector, ret = %d\n", ret);
+		drm_encoder_cleanup(encoder);
+	}
+
+	return ret;
+}
+
+static void xlnx_hdmi_unbind(struct device *dev, struct device *master,
+			     void *data)
+{
+	struct xlnx_hdmi *hdmi = dev_get_drvdata(dev);
+
+	if (hdmi->bridge)
+		xlnx_bridge_disable(hdmi->bridge);
+
+	xlnx_hdmi_encoder_dpms(&hdmi->encoder, DRM_MODE_DPMS_OFF);
+	drm_encoder_cleanup(&hdmi->encoder);
+	drm_connector_cleanup(&hdmi->connector);
+}
+
+static const struct component_ops xlnx_hdmi_component_ops = {
+	.bind	= xlnx_hdmi_bind,
+	.unbind	= xlnx_hdmi_unbind
+};
+
+/**
+ * xlnx_hdmi_exit_phy - Exit the phy
+ * @hdmi: HDMI core structure
+ *
+ * Exit the phy.
+ */
+static void xlnx_hdmi_exit_phy(struct xlnx_hdmi *hdmi)
+{
+	unsigned int i;
+	int ret;
+
+	for (i = 0; i < HDMI_MAX_LANES; i++) {
+		ret = phy_exit(hdmi->phy[i]);
+		if (ret)
+			dev_err(hdmi->dev, "fail to exit phy(%d) %d\n", i, ret);
+		hdmi->phy[i] = NULL;
+	}
+}
+
+/**
+ * xlnx_hdmi_initialize - Initializes the hdmi core
+ * @hdmi: HDMI core strcture
+ *
+ * Return: 0 on success, error code on failure
+ */
+static int xlnx_hdmi_initialize(struct xlnx_hdmi *hdmi)
+{
+	union phy_configure_opts phy_cfg = {0};
+	int ret;
+	unsigned long val, clkrate;
+
+	/* mutex that protects against concurrent access */
+	mutex_init(&hdmi->hdmi_mutex);
+	spin_lock_init(&hdmi->irq_lock);
+	init_waitqueue_head(&hdmi->wait_event);
+
+	/* set default color format to RGB */
+	hdmi->xvidc_colorfmt = HDMI_TX_CSF_RGB;
+	hdmi->xvidc_colordepth = hdmi->config.bpc;
+
+	/* Reset all peripherals */
+	xlnx_hdmi_piointr_disable(hdmi);
+	xlnx_hdmi_ddc_disable(hdmi);
+	xlnx_hdmi_audio_disable(hdmi);
+	xlnx_hdmi_aux_disable(hdmi);
+	xlnx_hdmi_frl_intr_disable(hdmi);
+	xlnx_hdmi_frl_clear(hdmi);
+	xlnx_hdmi_piointr_clear(hdmi);
+	xlnx_hdmi_ddc_intr_clear(hdmi);
+
+	/* PIO: Set event rising edge masks */
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_IN_EVT_RE,
+			 HDMI_TX_PIO_IN_BRIDGE_UFLOW |
+			 HDMI_TX_PIO_IN_BRIDGE_OFLOW |
+			 HDMI_TX_PIO_IN_BRIDGE_LOCKED |
+			 HDMI_TX_PIO_IN_HPD_TOGGLE |
+			 HDMI_TX_PIO_IN_HPD_CONNECT |
+			 HDMI_TX_PIO_IN_VS |
+			 HDMI_TX_PIO_IN_LNK_RDY);
+	/* PIO: Set event falling edge masks */
+	xlnx_hdmi_writel(hdmi, HDMI_TX_PIO_IN_EVT_FE,
+			 HDMI_TX_PIO_IN_BRIDGE_LOCKED |
+			 HDMI_TX_PIO_IN_HPD_CONNECT |
+			 HDMI_TX_PIO_IN_LNK_RDY);
+
+	/* Set the Timegrid for HPD */
+	xlnx_hdmi_writel(hdmi, HDMI_TX_HPD_TIMEGRID, HDMI_TX_TIMEGRID_VAL);
+	xlnx_hdmi_writel(hdmi, HDMI_TX_HPD_TOGGLE_CONF,
+			 HDMI_TX_TOGGLE_CONF_VAL);
+	xlnx_hdmi_writel(hdmi, HDMI_TX_HPD_CONNECT_CONF,
+			 HDMI_TX_CONNECT_CONF_VAL);
+
+	xlnx_hdmi_set_hdmi_mode(hdmi);
+	xlnx_hdmi_aux_enable(hdmi);
+
+	/* ddc init */
+	clkrate = clk_get_rate(hdmitx_clks[S_AXI_CPU_ACLK].clk);
+	val = div_u64(clkrate, HDMI_TX_DDC_CLKDIV * 2);
+	val = (val << HDMI_TX_DDC_CTRL_CLK_DIV_SHIFT) &
+		HDMI_TX_DDC_CTRL_CLK_DIV;
+
+	/* Update DDC Control register */
+	xlnx_hdmi_writel(hdmi, HDMI_TX_DDC_CTRL, val);
+
+	xlnx_hdmi_frl_reset(hdmi);
+	xlnx_hdmi_set_hdmi_mode(hdmi);
+	xlnx_hdmi_aux_enable(hdmi);
+
+	xlnx_hdmi_reset(hdmi);
+
+	phy_cfg.hdmi.config_hdmi20 = 1;
+	ret = xlnx_hdmi_phy_configure(hdmi, &phy_cfg);
+	if (ret) {
+		dev_err(hdmi->dev, "phy_cfg: hdmi20 err %d\n", ret);
+		return ret;
+	}
+
+	/* Enable Interrupts */
+	xlnx_hdmi_piointr_ie_enable(hdmi);
+	xlnx_hdmi_piointr_run_enable(hdmi);
+
+	return 0;
+}
+
+static int xlnx_hdmi_parse_of(struct xlnx_hdmi *hdmi)
+{
+	struct xlnx_hdmi_config *config = &hdmi->config;
+	struct device_node *node = hdmi->dev->of_node;
+	int ret;
+	u32 ppc, bpc, vid, frl_rate;
+
+	ret = of_property_read_u32(node, "xlnx,input-pixels-per-clock", &ppc);
+	if (ret || (ppc != HDMI_TX_PPC_4 && ppc != HDMI_TX_PPC_8)) {
+		dev_err(hdmi->dev, "missing or invalid pixels per clock dt prop\n");
+		return -EINVAL;
+	}
+	config->ppc = ppc;
+
+	ret = of_property_read_u32(node, "xlnx,max-bits-per-component", &bpc);
+	if (ret || (bpc != HDMI_TX_BPC_8 && bpc != HDMI_TX_BPC_10 &&
+		    bpc != HDMI_TX_BPC_12 && bpc != HDMI_TX_BPC_16)) {
+		dev_err(hdmi->dev, "missing or invalid max bpc dt prop\n");
+		return -EINVAL;
+	}
+	config->bpc = bpc;
+
+	config->hdcp1x_enable = of_property_read_bool(node, "xlnx,include-hdcp-1-4");
+	config->hdcp2x_enable = of_property_read_bool(node, "xlnx,include-hdcp-2-2");
+
+	ret = of_property_read_u32(node, "xlnx,vid-interface", &vid);
+	if (ret || (vid != HDMI_TX_AXI_STREAM && vid != HDMI_TX_NATIVE &&
+		    vid != HDMI_TX_NATIVE_IDE)) {
+		dev_err(hdmi->dev, "missing or unsupported video interface\n");
+		return -EINVAL;
+	}
+	config->vid_interface = vid;
+
+	ret = of_property_read_u32(node, "xlnx,max-frl-rate", &frl_rate);
+	if (ret || frl_rate > HDMI_TX_MAX_FRL_RATE) {
+		dev_err(hdmi->dev, "missing or unsupported frl rate\n");
+		return -EINVAL;
+	}
+	config->max_frl_rate = frl_rate;
+
+	if (of_device_is_compatible(node, "xlnx,v-hdmi-txss1-1.1")) {
+		config->htiming_div_fact = config->ppc;
+	} else {
+		/* VTC core updated to support arbitrary resolutions */
+		config->htiming_div_fact = 1;
+		/* Remapper in subsystem will generate 4 ppc */
+		config->ppc = HDMI_TX_PPC_4;
+	}
+
+	return 0;
+}
+
+/**
+ * xlnx_hdmi_hdcp_exit - hdcp module de-initialization
+ * @hdmi: HDMI IP core structure
+ *
+ * Return: 0 on success, or the status from called functions
+ */
+static int xlnx_hdmi_hdcp_exit(struct xlnx_hdmi *hdmi)
+{
+	struct xlnx_hdcptx *xhdcp = &hdmi->txhdcp;
+	int ret;
+
+	if (xhdcp->hdcp2xenable) {
+		ret = xlnx_hdmi_hdcp_reset(hdmi);
+		if (ret < 0) {
+			dev_err(hdmi->dev, "failed to exit HDCP IP module");
+			return ret;
+		}
+	}
+	xlnx_hdcp_tx_timer_exit(xhdcp);
+	xlnx_hdcp_tx_exit(xhdcp);
+
+	return 0;
+}
+
+/**
+ * xlnx_hdmi_hdcp_cp_irq_func - Checks for HDCP information
+ * whenever CP Irq is detected
+ * @work: work structure
+ *
+ * This function checks for HDCP authentication information via rxstatus register
+ * as soon as cp irq interrupt triggers.
+ */
+static void xlnx_hdmi_hdcp_cp_irq_func(struct work_struct *work)
+{
+	struct xlnx_hdmi *hdmi;
+	struct xlnx_hdcptx *xhdcp;
+
+	hdmi = container_of(work, struct xlnx_hdmi, hdcp_cp_irq_work.work);
+	xhdcp = &hdmi->txhdcp;
+	xlnx_hdcp_tx_process_cp_irq(xhdcp);
+}
+
+/**
+ * xlnx_hdmi_hdcp_status_update - hdcp status notification
+ * @ref: callback reference pointer
+ * @notification: hdcp notification
+ */
+static void xlnx_hdmi_hdcp_status_update(void *ref, u32 notification)
+{
+	struct xlnx_hdmi *hdmi = (struct xlnx_hdmi *)ref;
+
+	switch (notification) {
+	case XHDCPTX_INCOMPATIBLE_RX:
+		dev_dbg(hdmi->dev, "HDCP Tx compatible receiver is not found\n");
+		break;
+	case XHDCPTX_AUTHENTICATION_BUSY:
+		dev_dbg(hdmi->dev, "HDCP Tx Authentication Busy\n");
+		break;
+	case XHDCPTX_AUTHENTICATED:
+		dev_dbg(hdmi->dev, "HDCP Tx Authenticated\n");
+		break;
+	case XHDCPTX_REAUTHENTICATE_REQUESTED:
+		dev_dbg(hdmi->dev, "HDCP Tx Re-authentication Request received\n");
+		break;
+	case XHDCPTX_DEVICE_IS_REVOKED:
+		dev_dbg(hdmi->dev, "HDCP Tx , a device in the hdcp chain is revoked\n");
+		break;
+	case XHDCPTX_NO_SRM_LOADED:
+		dev_dbg(hdmi->dev, "HDCP Tx , no valid srm is loaded\n");
+		break;
+	case XHDCPTX_UNAUTHENTICATED:
+		dev_dbg(hdmi->dev, "HDCP Tx Unauthenticated\n");
+		break;
+	default:
+		dev_dbg(hdmi->dev, "Error, HDCP is not initialized\n");
+		break;
+	}
+}
+
+/**
+ * xlnx_hdmi_hdcp_irq_handler - HDCP protocol message interrupt handler
+ * @irq: IRQ number of the interrupt being handled
+ * @data: Pointer to device structure
+ *
+ * Return: irq handler status
+ */
+static irqreturn_t xlnx_hdmi_hdcp_irq_handler(int irq, void *data)
+{
+	struct xlnx_hdmi *hdmi = (struct xlnx_hdmi *)data;
+	struct xlnx_hdcptx *hdmitxhdcp = &hdmi->txhdcp;
+
+	xlnx_hdcp1x_interrupt_handler(hdmitxhdcp);
+
+	return IRQ_HANDLED;
+}
+
+/**
+ * xlnx_hdmi_timer_irq_handler - hdcp timer interrupt handler
+ * @irq: IRQ number of the interrupt being handled
+ * @data: Pointer to device structure
+ *
+ * Return: irq handler status
+ */
+static irqreturn_t xlnx_hdmi_timer_irq_handler(int irq, void *data)
+{
+	struct xlnx_hdmi *hdmi = (struct xlnx_hdmi *)data;
+	struct xlnx_hdcptx *xhdcp = &hdmi->txhdcp;
+
+	xlnx_hdcp_tmrcntr_interrupt_handler(xhdcp->xhdcptmr);
+
+	return IRQ_HANDLED;
+}
+
+static int xlnx_hdmi_hdcp_ddc_callback_write(void *ref, u32 offset,
+					     void *buf, u32 buf_size)
+{
+	struct xlnx_hdmi *hdmi = (struct xlnx_hdmi *)ref;
+	int ret;
+	bool stop_flag;
+
+	stop_flag = (buf_size > 1) ? true : false;
+
+	ret = xlnx_hdmi_ddcwrite(hdmi, HDMI_HDCP_DDC_BASE_OFFSET, buf_size, (u8 *)buf, stop_flag);
+	if (ret < 0) {
+		dev_err(hdmi->dev, "DDC write failed");
+		return ret;
+	}
+	return buf_size;
+}
+
+static int xlnx_hdmi_hdcp_ddc_callback_read(void *ref, u32 offset,
+					    void *buf, u32 buf_size)
+{
+	struct xlnx_hdmi *hdmi = (struct xlnx_hdmi *)ref;
+	int ret;
+
+	if (!buf_size)
+		return buf_size;
+	ret = xlnx_hdmi_ddc_readreg(hdmi, HDMI_HDCP_DDC_BASE_OFFSET, buf_size, offset, buf);
+	if (ret < 0) {
+		dev_err(hdmi->dev, "DDC read failed");
+		return ret;
+	}
+	return buf_size;
+}
+
+/**
+ * xlnx_hdcp_init - hdcp module initialization
+ * @hdmi: HDMI IP core structure
+ * @pdev: platform structure
+ *
+ * Return: 0 on success, or return the error code from the called functions.
+ */
+static int xlnx_hdcp_init(struct xlnx_hdmi *hdmi,
+			  struct platform_device *pdev)
+{
+	struct xlnx_hdcptx *xhdcp = &hdmi->txhdcp;
+	int ret;
+
+	xhdcp->dev = hdmi->dev;
+	xhdcp->hdcp2xenable = hdmi->config.hdcp2x_enable;
+	xhdcp->hdcp1xenable = hdmi->config.hdcp1x_enable;
+	xhdcp->is_hdcp_initialized = false;
+
+	if (hdmi->config.hdcp2x_enable) {
+		xhdcp->xhdcp2x = xlnx_hdcp_tx_init(&pdev->dev, hdmi, xhdcp,
+						   hdmi->base + HDMI_HDCP2X_OFFSET,
+						   0, XHDCPTX_HDCP_2X,
+						   hdmi->stream.sink_max_lanes,
+						   XHDCP2X_TX_HDMI, hdmi->hdcp1x_keymgmt_base);
+
+		if (IS_ERR(xhdcp->xhdcp2x)) {
+			dev_err(hdmi->dev, "failed to initialize HDCP2X module\n");
+			return PTR_ERR(xhdcp->xhdcp2x);
+		}
+		hdmi->hdcp2x_timer_irq =
+				 platform_get_irq_byname(pdev, "hdcp22timer");
+		if (hdmi->hdcp2x_timer_irq < 0) {
+			dev_err(hdmi->dev, "failed to get HDCP2X timer irq");
+			return -EINVAL;
+		}
+		ret = devm_request_threaded_irq(hdmi->dev, hdmi->hdcp2x_timer_irq, NULL,
+						xlnx_hdmi_timer_irq_handler,
+						IRQF_TRIGGER_HIGH | IRQF_ONESHOT,
+						"hdcp22timer", hdmi);
+		if (ret < 0) {
+			dev_err(hdmi->dev, "failed to register HDCP timer irq");
+			return ret;
+		}
+		xhdcp->xhdcptmr =
+				xlnx_hdcp_timer_init(&pdev->dev,
+						     hdmi->base + HDMI_HDCP2X_OFFSET + 0x10000);
+		if (IS_ERR(xhdcp->xhdcptmr)) {
+			dev_err(hdmi->dev, "failed to initialize HDCP timer\n");
+			return PTR_ERR(xhdcp->xhdcptmr);
+		}
+	}
+	if (hdmi->config.hdcp1x_enable) {
+		xhdcp->xhdcp1x = xlnx_hdcp_tx_init(&pdev->dev, hdmi, xhdcp,
+						   hdmi->base + HDMI_HDCP1X_OFFSET,
+						   0, XHDCPTX_HDCP_1X,
+						   hdmi->stream.sink_max_lanes,
+						   XHDCP2X_TX_HDMI,
+						   hdmi->hdcp1x_keymgmt_base);
+
+		if (IS_ERR(xhdcp->xhdcp1x)) {
+			dev_err(hdmi->dev, "failed to initialize HDCP1X module\n");
+			return PTR_ERR(xhdcp->xhdcp1x);
+		}
+
+		xhdcp->xhdcptmr =
+			xlnx_hdcp_timer_init(&pdev->dev, hdmi->base + HDMI_HDCP_TIMER_OFFSET);
+		if (IS_ERR(xhdcp->xhdcptmr)) {
+			dev_err(hdmi->dev, "failed to initialize HDCP timer\n");
+			return PTR_ERR(xhdcp->xhdcptmr);
+		}
+
+		hdmi->hdcp1x_timer_irq =
+				 platform_get_irq_byname(pdev, "hdcp14timer");
+		if (hdmi->hdcp1x_timer_irq < 0) {
+			dev_err(hdmi->dev, "failed to get HDCP timer irq ");
+			return -EINVAL;
+		}
+
+		ret = devm_request_threaded_irq(hdmi->dev, hdmi->hdcp1x_timer_irq, NULL,
+						xlnx_hdmi_timer_irq_handler,
+						IRQF_TRIGGER_HIGH | IRQF_ONESHOT,
+						"hdcp14timer", hdmi);
+		if (ret < 0) {
+			dev_err(hdmi->dev, "failed to register HDCP timer irq");
+			return ret;
+		}
+
+		hdmi->hdcp_irq =
+				 platform_get_irq_byname(pdev, "hdcp14");
+		if (hdmi->hdcp_irq < 0) {
+			dev_err(hdmi->dev, "failed to get HDCP irq ");
+			return -EINVAL;
+		}
+
+		ret = devm_request_threaded_irq(hdmi->dev, hdmi->hdcp_irq, NULL,
+						xlnx_hdmi_hdcp_irq_handler,
+						IRQF_TRIGGER_HIGH | IRQF_ONESHOT,
+						"hdcp14", hdmi);
+		if (ret < 0) {
+			dev_err(hdmi->dev, "failed to register HDCP interrupt irq");
+			return ret;
+		}
+	}
+	xlnx_hdcp_tx_set_callback(xhdcp, HDMI_HDCP_DPCD_WRITE,
+				  xlnx_hdmi_hdcp_ddc_callback_write);
+
+	xlnx_hdcp_tx_set_callback(xhdcp, HDMI_HDCP_DPCD_READ,
+				  xlnx_hdmi_hdcp_ddc_callback_read);
+
+	xlnx_hdcp_tx_set_callback(xhdcp, HDMI_HDCP_STATUS,
+				  xlnx_hdmi_hdcp_status_update);
+
+	INIT_DELAYED_WORK(&hdmi->hdcp_cp_irq_work, xlnx_hdmi_hdcp_cp_irq_func);
+
+	xhdcp->is_hdcp_initialized = true;
+
+	return 0;
+}
+
+static int xlnx_hdmi_probe(struct platform_device *pdev)
+{
+	struct xlnx_hdmi *hdmi;
+	struct resource *res;
+	struct device_node *vpss_node;
+	unsigned int index;
+	int ret, num_clks = ARRAY_SIZE(hdmitx_clks);
+
+	hdmi = devm_kzalloc(&pdev->dev, sizeof(*hdmi), GFP_KERNEL);
+	if (!hdmi)
+		return -ENOMEM;
+
+	hdmi->dpms = DRM_MODE_DPMS_OFF;
+	hdmi->dev = &pdev->dev;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	hdmi->base = devm_ioremap_resource(hdmi->dev, res);
+	if (IS_ERR(hdmi->base))
+		return PTR_ERR(hdmi->base);
+
+	ret = xlnx_hdmi_parse_of(hdmi);
+	if (ret < 0)
+		return ret;
+
+	/* VPSS bridge support */
+	vpss_node = of_parse_phandle(hdmi->dev->of_node, "xlnx,vpss", 0);
+	if (vpss_node) {
+		hdmi->bridge = of_xlnx_bridge_get(vpss_node);
+		if (!hdmi->bridge) {
+			dev_info(hdmi->dev, "Didn't get bridge instance\n");
+			return -EPROBE_DEFER;
+		}
+	}
+
+	ret = clk_bulk_get(&pdev->dev, num_clks, hdmitx_clks);
+	if (ret)
+		return ret;
+
+	ret = clk_bulk_prepare_enable(num_clks, hdmitx_clks);
+	if (ret)
+		goto err_clk_put;
+
+	/* acquire hdmi phy lanes */
+	for (index = 0; index < HDMI_MAX_LANES; index++) {
+		char phy_name[16];
+
+		snprintf(phy_name, sizeof(phy_name), "hdmi-phy%d", index);
+		hdmi->phy[index] = devm_phy_get(hdmi->dev, phy_name);
+		if (IS_ERR(hdmi->phy[index])) {
+			dev_err(hdmi->dev, "failed to get hdmi phy\n");
+			ret = PTR_ERR(hdmi->phy[index]);
+			goto err_clk_put;
+		}
+		ret = phy_init(hdmi->phy[index]);
+		if (ret) {
+			dev_err(hdmi->dev, "failed to init hdmi phy\n");
+			goto error_phy;
+		}
+	}
+
+	dev_dbg(hdmi->dev, "axi_cpu_aclk = %lu Hz\n",
+		clk_get_rate(hdmitx_clks[S_AXI_CPU_ACLK].clk));
+	dev_dbg(hdmi->dev, "link clk = %lu Hz\n",
+		clk_get_rate(hdmitx_clks[LINK_CLK].clk));
+	dev_dbg(hdmi->dev, "video clk = %lu Hz\n",
+		clk_get_rate(hdmitx_clks[VIDEO_CLK].clk));
+	dev_dbg(hdmi->dev, "frl clk = %lu Hz\n",
+		clk_get_rate(hdmitx_clks[FRL_CLK].clk));
+	dev_dbg(hdmi->dev, "video aclk rate = %lu Hz\n",
+		clk_get_rate(hdmitx_clks[S_AXIS_VIDEO_ACLK].clk));
+
+	hdmi->irq = platform_get_irq(pdev, 0);
+	if (hdmi->irq < 0) {
+		dev_err(hdmi->dev, "platform_get_irq() failed\n");
+		ret = hdmi->irq;
+		goto error_phy;
+	}
+
+	/* Request the interrupt */
+	ret = devm_request_threaded_irq(hdmi->dev, hdmi->irq,
+					hdmitx_irq_handler, hdmitx_irq_thread,
+					IRQF_TRIGGER_HIGH,
+					"xilinx-hdmitxss", hdmi/* dev_id */);
+	if (ret) {
+		dev_err(hdmi->dev, "unable to request IRQ %d\n", hdmi->irq);
+		goto error_phy;
+	}
+
+	platform_set_drvdata(pdev, hdmi);
+
+	/* initialize hw */
+	ret = xlnx_hdmi_initialize(hdmi);
+	if (ret) {
+		dev_err(hdmi->dev, "hdmi initialization failed\n");
+		goto error_phy;
+	}
+	if (hdmi->config.hdcp2x_enable || hdmi->config.hdcp1x_enable) {
+		ret = sysfs_create_group(&hdmi->dev->kobj, &xlnx_hdcp_key_attr_group);
+		if (ret) {
+			dev_err(hdmi->dev, "\nunable to create sysfs group");
+			goto error_phy;
+		}
+	}
+
+	if (hdmi->config.hdcp1x_enable) {
+		hdmi->hdcp1x_keymgmt_base =
+			syscon_regmap_lookup_by_phandle(hdmi->dev->of_node,
+							"xlnx,hdcp1x-keymgmt");
+		if (IS_ERR(hdmi->hdcp1x_keymgmt_base)) {
+			dev_err(hdmi->dev, "couldn't map HDCP1X Keymgmt registers\n");
+			goto error_phy;
+		}
+	}
+
+	if (hdmi->config.hdcp1x_enable || hdmi->config.hdcp2x_enable) {
+		ret = xlnx_hdcp_init(hdmi, pdev);
+		if (ret < 0)
+			goto error_hdcp;
+	}
+
+	return component_add(hdmi->dev, &xlnx_hdmi_component_ops);
+
+error_hdcp:
+	xlnx_hdmi_hdcp_exit(hdmi);
+	sysfs_remove_group(&pdev->dev.kobj, &xlnx_hdcp_key_attr_group);
+error_phy:
+	dev_dbg(hdmi->dev, "probe failed:: error_phy:\n");
+	xlnx_hdmi_exit_phy(hdmi);
+	clk_bulk_disable_unprepare(num_clks, hdmitx_clks);
+err_clk_put:
+	clk_bulk_put(num_clks, hdmitx_clks);
+
+	return ret;
+}
+
+static void xlnx_hdmi_remove(struct platform_device *pdev)
+{
+	struct xlnx_hdmi *hdmi = platform_get_drvdata(pdev);
+	int num_clks = ARRAY_SIZE(hdmitx_clks);
+
+	if (hdmi->bridge)
+		xlnx_bridge_disable(hdmi->bridge);
+
+	xlnx_hdmi_exit_phy(hdmi);
+	sysfs_remove_group(&pdev->dev.kobj, &xlnx_hdcp_key_attr_group);
+	component_del(&pdev->dev, &xlnx_hdmi_component_ops);
+	clk_bulk_disable_unprepare(num_clks, hdmitx_clks);
+	clk_bulk_put(num_clks, hdmitx_clks);
+}
+
+static const struct of_device_id xlnx_hdmi_of_match[] = {
+	{ .compatible = "xlnx,v-hdmi-txss1-1.1" },
+	{ .compatible = "xlnx,v-hdmi-txss1-1.2" },
+	{ /* end of table */ },
+};
+
+MODULE_DEVICE_TABLE(of, xlnx_hdmi_of_match);
+
+static struct platform_driver xlnx_hdmi_driver = {
+	.probe			= xlnx_hdmi_probe,
+	.remove			= xlnx_hdmi_remove,
+	.driver			= {
+		.name		= "xlnx-hdmi",
+		.of_match_table	= xlnx_hdmi_of_match,
+	},
+};
+
+module_platform_driver(xlnx_hdmi_driver);
+
+MODULE_AUTHOR("Venkateshwar Rao G <vgannava@xilinx.com>");
+MODULE_DESCRIPTION("Xilinx DRM KMS HDMI Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/xlnx_mixer.c b/drivers/gpu/drm/xlnx/xlnx_mixer.c
new file mode 100644
index 000000000..acf978e41
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_mixer.c
@@ -0,0 +1,3257 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx logicore video mixer driver
+ *
+ * Copyright (C) 2017 - 2018 Xilinx, Inc.
+ *
+ * Author: Saurabh Sengar <saurabhs@xilinx.com>
+ *       : Jeffrey Mouroux <jmouroux@xilinx.com>
+ */
+
+#include <drm/drm_vblank.h>
+#include <drm/drm_atomic.h>
+#include <drm/drm_atomic_helper.h>
+#include <drm/drm_atomic_uapi.h>
+#include <drm/drm_crtc.h>
+#include <drm/drm_fb_dma_helper.h>
+#include <drm/drm_fourcc.h>
+#include <drm/drm_gem_dma_helper.h>
+#include <drm/drm_framebuffer.h>
+#include <drm/drm_modeset_helper_vtables.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/component.h>
+#include <linux/dma/xilinx_frmbuf.h>
+#include <linux/of_reserved_mem.h>
+#include <linux/gpio/consumer.h>
+#include <linux/of.h>
+#include <linux/of_dma.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/platform_device.h>
+#include <linux/dmaengine.h>
+#include <linux/dma-mapping.h>
+#include <video/videomode.h>
+#include <linux/media-bus-format.h>
+#include "xlnx_bridge.h"
+#include "xlnx_crtc.h"
+#include "xlnx_drv.h"
+
+/**************************** Register Data **********************************/
+#define XVMIX_AP_CTRL			0x00000
+#define XVMIX_GIE			0x00004
+#define XVMIX_IER			0x00008
+#define XVMIX_ISR			0x0000c
+#define XVMIX_WIDTH_DATA		0x00010
+#define XVMIX_HEIGHT_DATA		0x00018
+#define XVMIX_BACKGROUND_Y_R_DATA	0x00028
+#define XVMIX_BACKGROUND_U_G_DATA	0x00030
+#define XVMIX_BACKGROUND_V_B_DATA	0x00038
+#define XVMIX_LAYERENABLE_DATA		0x00040
+#define XVMIX_K00_1			0x00048
+#define XVMIX_K01_1			0x00050
+#define XVMIX_K02_1			0x00058
+#define XVMIX_K10_1			0x00060
+#define XVMIX_K11_1			0x00068
+#define XVMIX_K12_1			0x00070
+#define XVMIX_K20_1			0x00078
+#define XVMIX_K21_1			0x00080
+#define XVMIX_K22_1			0x00088
+#define XVMIX_Y_DATA			0x00090
+#define XVMIX_U_DATA			0x00098
+#define XVMIX_V_DATA			0x000A0
+#define XVMIX_LAYERALPHA_0_DATA		0x00100
+#define XVMIX_LAYERSTARTX_0_DATA	0x00108
+#define XVMIX_LAYERSTARTY_0_DATA	0x00110
+#define XVMIX_LAYERWIDTH_0_DATA		0x00118
+#define XVMIX_LAYERSTRIDE_0_DATA	0x00120
+#define XVMIX_LAYERHEIGHT_0_DATA	0x00128
+#define XVMIX_LAYERSCALE_0_DATA		0x00130
+#define XVMIX_LAYERVIDEOFORMAT_0_DATA	0x00138
+#define XVMIX_K00_2			0x00140
+#define XVMIX_K01_2			0x00148
+#define XVMIX_K02_2			0x00150
+#define XVMIX_K10_2			0x00158
+#define XVMIX_K11_2			0x00160
+#define XVMIX_K12_2			0x00168
+#define XVMIX_K20_2			0x00170
+#define XVMIX_K21_2			0x00178
+#define XVMIX_K22_2			0x00180
+#define XVMIX_R_DATA			0x00188
+#define XVMIX_G_DATA			0x00190
+#define XVMIX_B_DATA			0x00198
+#define XVMIX_LAYER1_BUF1_V_DATA	0x00240
+#define XVMIX_LAYER1_BUF2_V_DATA	0x0024c
+#define XVMIX_LAYER1_BUF3_V_DATA	0x00258
+#define XVMIX_LOGOSTARTX_DATA		0x01000
+#define XVMIX_LOGOSTARTY_DATA		0x01008
+#define XVMIX_LOGOWIDTH_DATA		0x01010
+#define XVMIX_LOGOHEIGHT_DATA		0x01018
+#define XVMIX_LOGOSCALEFACTOR_DATA	0x01020
+#define XVMIX_LOGOALPHA_DATA		0x01028
+#define XVMIX_LOGOCLRKEYMIN_R_DATA	0x01030
+#define XVMIX_LOGOCLRKEYMIN_G_DATA	0x01038
+#define XVMIX_LOGOCLRKEYMIN_B_DATA	0x01040
+#define XVMIX_LOGOCLRKEYMAX_R_DATA	0x01048
+#define XVMIX_LOGOCLRKEYMAX_G_DATA	0x01050
+#define XVMIX_LOGOCLRKEYMAX_B_DATA	0x01058
+#define XVMIX_LOGOR_V_BASE		0x10000
+#define XVMIX_LOGOR_V_HIGH		0x10fff
+#define XVMIX_LOGOG_V_BASE		0x20000
+#define XVMIX_LOGOG_V_HIGH		0x20fff
+#define XVMIX_LOGOB_V_BASE		0x30000
+#define XVMIX_LOGOB_V_HIGH		0x30fff
+#define XVMIX_LOGOA_V_BASE		0x40000
+#define XVMIX_LOGOA_V_HIGH		0x40fff
+
+/************************** Constant Definitions *****************************/
+#define XVMIX_LOGO_OFFSET		0x1000
+#define XVMIX_MASK_DISABLE_ALL_LAYERS   0x0
+#define XVMIX_REG_OFFSET                0x100
+#define XVMIX_MASTER_LAYER_IDX		0x0
+#define XVMIX_LOGO_LAYER_IDX		0x1
+#define XVMIX_DISP_MAX_WIDTH		8192
+#define XVMIX_DISP_MAX_HEIGHT		4320
+#define XVMIX_DISP_MIN_WIDTH		64
+#define XVMIX_DISP_MIN_HEIGHT		64
+#define XVMIX_MAX_OVERLAY_LAYERS	16
+#define XVMIX_MAX_BPC			16
+#define XVMIX_ALPHA_MIN			0
+#define XVMIX_ALPHA_MAX			256
+#define XVMIX_LAYER_WIDTH_MIN		64
+#define XVMIX_LAYER_HEIGHT_MIN		64
+#define XVMIX_LOGO_LAYER_WIDTH_MIN	32
+#define XVMIX_LOGO_LAYER_HEIGHT_MIN	32
+#define XVMIX_LOGO_LAYER_WIDTH_MAX	256
+#define XVMIX_LOGO_LAYER_HEIGHT_MAX	256
+#define XVMIX_IRQ_DONE_MASK		BIT(0)
+#define XVMIX_GIE_EN_MASK		BIT(0)
+#define XVMIX_AP_EN_MASK		BIT(0)
+#define XVMIX_AP_RST_MASK		BIT(7)
+#define XVMIX_MAX_NUM_SUB_PLANES	4
+#define XVMIX_SCALE_FACTOR_1X		0
+#define	XVMIX_SCALE_FACTOR_2X		1
+#define	XVMIX_SCALE_FACTOR_4X		2
+#define	XVMIX_SCALE_FACTOR_INVALID	3
+#define	XVMIX_BASE_ALIGN		8
+#define XVMIX_CSC_MAX_ROWS		(3)
+#define XVMIX_CSC_MAX_COLS		(3)
+#define XVMIX_CSC_MATRIX_SIZE	(XVMIX_CSC_MAX_ROWS * XVMIX_CSC_MAX_COLS)
+#define XVMIX_CSC_COEFF_SIZE		(12)
+#define XVMIX_CSC_SCALE_FACTOR		(4096)
+#define XVMIX_CSC_DIVISOR		(10000)
+#define XVMIX_MAX_PLANES		3
+
+/*************************** STATIC DATA  ************************************/
+static const s16
+xlnx_mix_yuv2rgb_coeffs[][DRM_COLOR_ENCODING_MAX][XVMIX_CSC_COEFF_SIZE] = {
+	[DRM_COLOR_YCBCR_BT601][DRM_COLOR_YCBCR_LIMITED_RANGE] = {
+		10000, 0, 13669,
+		10000, -3367, -6986,
+		10000, 17335, 0,
+		-175, 132, -222
+	},
+	[DRM_COLOR_YCBCR_BT601][DRM_COLOR_YCBCR_FULL_RANGE] = {
+		10479, 0, 13979,
+		10479, -3443, -7145,
+		10479, 17729, 0,
+		-179, 136, -227
+	},
+	[DRM_COLOR_YCBCR_BT709][DRM_COLOR_YCBCR_LIMITED_RANGE] = {
+		10000, 0, 15406,
+		10000, -1832, -4579,
+		10000, 18153, 0,
+		-197, 82, -232
+	},
+	[DRM_COLOR_YCBCR_BT709][DRM_COLOR_YCBCR_FULL_RANGE] = {
+		10233, 0, 15756,
+		10233, -1873, -4683,
+		10233, 18566, 0,
+		-202, 84, -238
+	},
+	[DRM_COLOR_YCBCR_BT2020][DRM_COLOR_YCBCR_LIMITED_RANGE] = {
+		10000, 0, 14426,
+		10000, -1609, -5589,
+		10000, 18406, 0,
+		-185, 92, -236
+	},
+	[DRM_COLOR_YCBCR_BT2020][DRM_COLOR_YCBCR_FULL_RANGE] = {
+		10233, 0, 14754,
+		10233, -1646, -5716,
+		10233, 18824, 0,
+		-189, 94, -241
+	}
+};
+
+static const s16
+xlnx_mix_rgb2yuv_coeffs[][DRM_COLOR_ENCODING_MAX][XVMIX_CSC_COEFF_SIZE] = {
+	[DRM_COLOR_YCBCR_BT601][DRM_COLOR_YCBCR_LIMITED_RANGE] = {
+		2990, 5870, 1440,
+		-1720, -3390, 5110,
+		5110, -4280, -830,
+		0, 128, 128
+	},
+	[DRM_COLOR_YCBCR_BT601][DRM_COLOR_YCBCR_FULL_RANGE] = {
+		2921, 5735, 1113,
+		-1686, -3310, 4393,
+		4393, -4184, -812,
+		0, 128, 128
+	},
+	[DRM_COLOR_YCBCR_BT709][DRM_COLOR_YCBCR_LIMITED_RANGE] = {
+		2120, 7150, 720,
+		-1170, -3940, 5110,
+		5110, -4640, -470,
+		0, 128, 128
+	},
+	[DRM_COLOR_YCBCR_BT709][DRM_COLOR_YCBCR_FULL_RANGE] = {
+		2077, 6988, 705,
+		-1144, -3582, 4997,
+		4997, -4538, -458,
+		0, 128, 128
+	},
+	[DRM_COLOR_YCBCR_BT2020][DRM_COLOR_YCBCR_LIMITED_RANGE] = {
+		2625, 6775, 592,
+		-1427, -3684, 5110,
+		5110, -4699, -410,
+		0, 128, 128
+	},
+	[DRM_COLOR_YCBCR_BT2020][DRM_COLOR_YCBCR_FULL_RANGE] = {
+		2566, 6625, 579,
+		-1396, -3602, 4997,
+		4997, -4595, -401,
+		0, 128, 128
+	}
+};
+
+static const u32 color_table[] = {
+	DRM_FORMAT_BGR888,
+	DRM_FORMAT_RGB888,
+	DRM_FORMAT_XBGR2101010,
+	DRM_FORMAT_XRGB8888,
+	DRM_FORMAT_RGBA8888,
+	DRM_FORMAT_ABGR8888,
+	DRM_FORMAT_ARGB8888,
+	DRM_FORMAT_XBGR8888,
+	DRM_FORMAT_YUYV,
+	DRM_FORMAT_UYVY,
+	DRM_FORMAT_AYUV,
+	DRM_FORMAT_NV12,
+	DRM_FORMAT_NV16,
+	DRM_FORMAT_Y8,
+	DRM_FORMAT_Y10,
+	DRM_FORMAT_XVUY2101010,
+	DRM_FORMAT_VUY888,
+	DRM_FORMAT_XVUY8888,
+	DRM_FORMAT_XV15,
+	DRM_FORMAT_XV20,
+	DRM_FORMAT_YUV444,
+	DRM_FORMAT_X403,
+	DRM_FORMAT_X423,
+};
+
+static bool xlnx_mixer_primary_enable = true;
+module_param_named(mixer_primary_enable, xlnx_mixer_primary_enable, bool, 0600);
+MODULE_PARM_DESC(mixer_primary_enable, "Enable mixer primary plane (default: 1)");
+
+/*********************** Inline Functions/Macros *****************************/
+#define to_mixer_hw(p) (&((p)->mixer->mixer_hw))
+#define to_xlnx_crtc(x)	container_of(x, struct xlnx_crtc, crtc)
+#define to_xlnx_plane(x)	container_of(x, struct xlnx_mix_plane, base)
+#define to_xlnx_mixer(x)	container_of(x, struct xlnx_mix, crtc)
+
+/**
+ * enum xlnx_mix_layer_id - Describes the layer by index to be acted upon
+ * @XVMIX_LAYER_MASTER: Master layer
+ * @XVMIX_LAYER_1: Layer 1
+ * @XVMIX_LAYER_2: Layer 2
+ * @XVMIX_LAYER_3: Layer 3
+ * @XVMIX_LAYER_4: Layer 4
+ * @XVMIX_LAYER_5: Layer 5
+ * @XVMIX_LAYER_6: Layer 6
+ * @XVMIX_LAYER_7: Layer 7
+ * @XVMIX_LAYER_8: Layer 8
+ * @XVMIX_LAYER_9: Layer 9
+ * @XVMIX_LAYER_10: Layer 10
+ * @XVMIX_LAYER_11: Layer 11
+ * @XVMIX_LAYER_12: Layer 12
+ * @XVMIX_LAYER_13: Layer 13
+ * @XVMIX_LAYER_14: Layer 14
+ * @XVMIX_LAYER_15: Layer 15
+ * @XVMIX_LAYER_16: Layer 16
+ */
+enum xlnx_mix_layer_id {
+	XVMIX_LAYER_MASTER = 0,
+	XVMIX_LAYER_1,
+	XVMIX_LAYER_2,
+	XVMIX_LAYER_3,
+	XVMIX_LAYER_4,
+	XVMIX_LAYER_5,
+	XVMIX_LAYER_6,
+	XVMIX_LAYER_7,
+	XVMIX_LAYER_8,
+	XVMIX_LAYER_9,
+	XVMIX_LAYER_10,
+	XVMIX_LAYER_11,
+	XVMIX_LAYER_12,
+	XVMIX_LAYER_13,
+	XVMIX_LAYER_14,
+	XVMIX_LAYER_15,
+	XVMIX_LAYER_16
+};
+
+/**
+ * struct xlnx_mix_layer_data - Describes the hardware configuration of a given
+ * mixer layer
+ * @hw_config: struct specifying the IP hardware constraints for this layer
+ * @hw_config.vid_fmt: DRM format for this layer
+ * @hw_config.can_alpha: Indicates that layer alpha is enabled for this layer
+ * @hw_config.can_scale: Indicates that layer scaling is enabled for this layer
+ * @hw_config.is_streaming: Indicates layer is not using mixer DMA but streaming from
+ *  external DMA
+ * @hw_config.max_width: Max possible pixel width
+ * @hw_config.max_height: Max possible pixel height
+ * @hw_config.min_width: Min possible pixel width
+ * @hw_config.min_height: Min possible pixel height
+ * @layer_regs: struct containing current cached register values
+ * @layer_regs.buff_addr1: Current physical address of image buffer plane1
+ * @layer_regs.buff_addr2: Current physical address of image buffer plane2
+ * @layer_regs.buff_addr3: Current physical address of image buffer plane3
+ * @layer_regs.x_pos: Current CRTC x offset
+ * @layer_regs.y_pos: Current CRTC y offset
+ * @layer_regs.width: Current width in pixels
+ * @layer_regs.height: Current hight in pixels
+ * @layer_regs.stride: Current stride (when Mixer is performing DMA)
+ * @layer_regs.alpha: Current alpha setting
+ * @layer_regs.is_active: Logical flag indicating layer in use.  If false, calls to
+ *  enable layer will be ignored.
+ * @layer_regs.scale_fact: Current scaling factor applied to layer
+ * @id: The logical layer id identifies which layer this struct describes
+ *  (e.g. 0 = master, 1-15 = overlay).
+ *
+ * All mixer layers are reprsented by an instance of this struct:
+ * output streaming, overlay, logo.
+ * Current layer-specific register state is stored in the layer_regs struct.
+ * The hardware configuration is stored in struct hw_config.
+ *
+ * Note:
+ * Some properties of the logo layer are unique and not described in this
+ * struct.  Those properites are part of the xlnx_mix struct as global
+ * properties.
+ */
+struct xlnx_mix_layer_data {
+	struct {
+		u32     vid_fmt;
+		bool    can_alpha;
+		bool    can_scale;
+		bool    is_streaming;
+		bool	plane_3;
+		u32     max_width;
+		u32     max_height;
+		u32     min_width;
+		u32     min_height;
+	} hw_config;
+
+	struct {
+		u64     buff_addr1;
+		u64     buff_addr2;
+		u64	buff_addr3;
+		u32     x_pos;
+		u32     y_pos;
+		u32     width;
+		u32     height;
+		u32     stride;
+		u32     alpha;
+		bool	is_active;
+		u32	scale_fact;
+	} layer_regs;
+
+	enum xlnx_mix_layer_id id;
+};
+
+/**
+ * struct xlnx_mix_hw - Describes a mixer IP block instance within the design
+ * @base: Base physical address of Mixer IP in memory map
+ * @logo_layer_en: Indicates logo layer is enabled in hardware
+ * @logo_pixel_alpha_enabled: Indicates that per-pixel alpha supported for logo
+ *  layer
+ * @csc_enabled: Indicates that colorimetry coefficients are programmable
+ * @max_layer_width: Max possible width for any layer on this Mixer
+ * @max_layer_height: Max possible height for any layer on this Mixer
+ * @max_logo_layer_width: Min possible width for any layer on this Mixer
+ * @max_logo_layer_height: Min possible height for any layer on this Mixer
+ * @num_layers: Max number of layers (excl: logo)
+ * @bg_layer_bpc: Bits per component for the background streaming layer
+ * @dma_addr_size: dma address size in bits
+ * @ppc: Pixels per component
+ * @irq: Interrupt request number assigned
+ * @bg_color: Current RGB color value for internal background color generator
+ * @three_planes_prop : three planes video formats enabled
+ * @layer_data: Array of layer data
+ * @layer_cnt: Layer data array count
+ * @max_layers: Maximum number of layers supported by hardware
+ * @logo_layer_id: Index of logo layer
+ * @logo_en_mask: Mask used to enable logo layer
+ * @enable_all_mask: Mask used to enable all layers
+ * @reset_gpio: GPIO line used to reset IP between modesetting operations
+ * @intrpt_handler_fn: Interrupt handler function called when frame is completed
+ * @intrpt_data: Data pointer passed to interrupt handler
+ *
+ * Used as the primary data structure for many L2 driver functions. Logo layer
+ * data, if enabled within the IP, is described in this structure.  All other
+ * layers are described by an instance of xlnx_mix_layer_data referenced by this
+ * struct.
+ *
+ */
+struct xlnx_mix_hw {
+	void __iomem        *base;
+	bool                logo_layer_en;
+	bool                logo_pixel_alpha_enabled;
+	bool                three_planes_prop;
+	u32		    csc_enabled;
+	u32                 max_layer_width;
+	u32                 max_layer_height;
+	u32                 max_logo_layer_width;
+	u32                 max_logo_layer_height;
+	u32                 num_layers;
+	u32                 bg_layer_bpc;
+	u32		    dma_addr_size;
+	u32                 ppc;
+	int		    irq;
+	u64		    bg_color;
+	struct xlnx_mix_layer_data *layer_data;
+	u32 layer_cnt;
+	u32 max_layers;
+	u32 logo_layer_id;
+	u32 logo_en_mask;
+	u32 enable_all_mask;
+	struct gpio_desc *reset_gpio;
+	void (*intrpt_handler_fn)(void *);
+	void *intrpt_data;
+};
+
+/**
+ * struct xlnx_mix - Container for interfacing DRM driver to mixer
+ * @mixer_hw: Object representing actual hardware state of mixer
+ * @master: Logical master device from xlnx drm
+ * @crtc: Xilinx DRM driver crtc object
+ * @drm_primary_layer: Hardware layer serving as logical DRM primary layer
+ * @hw_master_layer: Base video streaming layer
+ * @hw_logo_layer: Hardware logo layer
+ * @planes: Mixer overlay layers
+ * @num_planes : number of planes
+ * @max_width : maximum width of plane
+ * @max_height : maximum height of plane
+ * @max_cursor_width : maximum cursor width
+ * @max_cursor_height: maximum cursor height
+ * @alpha_prop: Global layer alpha property
+ * @scale_prop: Layer scale property (1x, 2x or 4x)
+ * @bg_color: Background color property for primary layer
+ * @drm: core drm object
+ * @pixel_clock: pixel clock for mixer
+ * @pixel_clock_enabled: pixel clock status
+ * @dpms: mixer drm state
+ * @event: vblank pending event
+ * @vtc_bridge: vtc_bridge structure
+ * @disp_bridge: disp_bridge structure
+ *
+ * Contains pointers to logical constructions such as the DRM plane manager as
+ * well as pointers to distinquish the mixer layer serving as the DRM "primary"
+ * plane from the actual mixer layer which serves as the background layer in
+ * hardware.
+ *
+ */
+struct xlnx_mix {
+	struct xlnx_mix_hw mixer_hw;
+	struct platform_device *master;
+	struct xlnx_crtc crtc;
+	struct xlnx_mix_plane *drm_primary_layer;
+	struct xlnx_mix_plane *hw_master_layer;
+	struct xlnx_mix_plane *hw_logo_layer;
+	struct xlnx_mix_plane *planes;
+	u32 num_planes;
+	u32 max_width;
+	u32 max_height;
+	u32 max_cursor_width;
+	u32 max_cursor_height;
+	struct drm_property *alpha_prop;
+	struct drm_property *scale_prop;
+	struct drm_property *bg_color;
+	struct drm_device *drm;
+	struct clk *pixel_clock;
+	bool pixel_clock_enabled;
+	int dpms;
+	struct drm_pending_vblank_event *event;
+	struct xlnx_bridge *vtc_bridge;
+	struct xlnx_bridge *disp_bridge;
+};
+
+/**
+ * struct xlnx_mix_plane_dma - Xilinx drm plane VDMA object
+ *
+ * @chan: dma channel
+ * @xt: dma interleaved configuration template
+ * @sgl: data chunk for dma_interleaved_template
+ * @is_active: flag if the DMA is active
+ */
+struct xlnx_mix_plane_dma {
+	struct dma_chan *chan;
+	struct dma_interleaved_template xt;
+	struct data_chunk sgl[1];
+	bool is_active;
+};
+
+/**
+ * struct xlnx_mix_plane - Xilinx drm plane object
+ *
+ * @base: base drm plane object
+ * @mixer_layer: video mixer hardware layer data instance
+ * @mixer: mixer DRM object
+ * @dma: dma object
+ * @id: plane id
+ * @dpms: current dpms level
+ * @format: pixel format
+ */
+struct xlnx_mix_plane {
+	struct drm_plane base;
+	struct xlnx_mix_layer_data *mixer_layer;
+	struct xlnx_mix *mixer;
+	struct xlnx_mix_plane_dma dma[XVMIX_MAX_NUM_SUB_PLANES];
+	int id;
+	int dpms;
+	u32 format;
+};
+
+static inline void reg_writel(void __iomem *base, int offset, u32 val)
+{
+	writel(val, base + offset);
+}
+
+static inline void reg_writeq(void __iomem *base, int offset, u64 val)
+{
+	writel(lower_32_bits(val), base + offset);
+	writel(upper_32_bits(val), base + offset + 4);
+}
+
+static inline u32 reg_readl(void __iomem *base, int offset)
+{
+	return readl(base + offset);
+}
+
+static u32 xlnx_mix_get_bus_fmt(struct xlnx_mix *mixer)
+{
+	struct xlnx_mix_layer_data *master;
+
+	master = &mixer->mixer_hw.layer_data[XVMIX_MASTER_LAYER_IDX];
+
+	switch (master->hw_config.vid_fmt) {
+	case DRM_FORMAT_BGR888:
+	case DRM_FORMAT_RGB888:
+	case DRM_FORMAT_XRGB8888:
+	case DRM_FORMAT_RGBA8888:
+	case DRM_FORMAT_ABGR8888:
+	case DRM_FORMAT_ARGB8888:
+	case DRM_FORMAT_XBGR8888:
+		return MEDIA_BUS_FMT_RBG888_1X24;
+	case DRM_FORMAT_XBGR2101010:
+		return MEDIA_BUS_FMT_RBG101010_1X30;
+	case DRM_FORMAT_YUYV:
+	case DRM_FORMAT_UYVY:
+	case DRM_FORMAT_NV16:
+		return MEDIA_BUS_FMT_UYVY8_1X16;
+	case DRM_FORMAT_AYUV:
+	case DRM_FORMAT_VUY888:
+	case DRM_FORMAT_XVUY8888:
+	case DRM_FORMAT_YUV444:
+		return MEDIA_BUS_FMT_VUY8_1X24;
+	case DRM_FORMAT_NV12:
+		return MEDIA_BUS_FMT_VYYUYY8_1X24;
+	case DRM_FORMAT_Y8:
+		return MEDIA_BUS_FMT_Y8_1X8;
+	case DRM_FORMAT_Y10:
+		return MEDIA_BUS_FMT_Y10_1X10;
+	case DRM_FORMAT_XVUY2101010:
+	case DRM_FORMAT_X403:
+		return MEDIA_BUS_FMT_VUY10_1X30;
+	case DRM_FORMAT_XV15:
+		return MEDIA_BUS_FMT_VYYUYY10_4X20;
+	case DRM_FORMAT_XV20:
+		return MEDIA_BUS_FMT_UYVY10_1X20;
+	case DRM_FORMAT_X423:
+		return MEDIA_BUS_FMT_YUV12_1X36;
+	default:
+		DRM_DEBUG_KMS("invalid layer format: %d\n",
+			      master->hw_config.vid_fmt);
+		return 0;
+	}
+}
+
+/**
+ * xlnx_mix_intrpt_enable_done - Enables interrupts
+ * @mixer: instance of mixer IP core
+ *
+ * Enables interrupts in the mixer core
+ */
+static void xlnx_mix_intrpt_enable_done(struct xlnx_mix_hw *mixer)
+{
+	u32 curr_val = reg_readl(mixer->base, XVMIX_IER);
+
+	/* Enable Interrupts */
+	reg_writel(mixer->base, XVMIX_IER, curr_val | XVMIX_IRQ_DONE_MASK);
+	reg_writel(mixer->base, XVMIX_GIE, XVMIX_GIE_EN_MASK);
+}
+
+/**
+ * xlnx_mix_intrpt_disable - Disable interrupts
+ * @mixer: instance of mixer IP core
+ *
+ * Disables interrupts in the mixer core
+ */
+static void xlnx_mix_intrpt_disable(struct xlnx_mix_hw *mixer)
+{
+	u32 curr_val =  reg_readl(mixer->base, XVMIX_IER);
+
+	reg_writel(mixer->base, XVMIX_IER, curr_val & (~XVMIX_IRQ_DONE_MASK));
+	reg_writel(mixer->base, XVMIX_GIE, 0);
+}
+
+/**
+ * xlnx_mix_start - Start the mixer core video generator
+ * @mixer: Mixer core instance for which to start video output
+ *
+ * Starts the core to generate a video frame.
+ */
+static void xlnx_mix_start(struct xlnx_mix_hw *mixer)
+{
+	u32 val;
+
+	val = XVMIX_AP_RST_MASK | XVMIX_AP_EN_MASK;
+	reg_writel(mixer->base, XVMIX_AP_CTRL, val);
+}
+
+/**
+ * xlnx_mix_stop - Stop the mixer core video generator
+ * @mixer: Mixer core instance for which to stop video output
+ *
+ * Starts the core to generate a video frame.
+ */
+static void xlnx_mix_stop(struct xlnx_mix_hw *mixer)
+{
+	reg_writel(mixer->base, XVMIX_AP_CTRL, 0);
+}
+
+static inline uint32_t xlnx_mix_get_intr_status(struct xlnx_mix_hw *mixer)
+{
+	return reg_readl(mixer->base, XVMIX_ISR) & XVMIX_IRQ_DONE_MASK;
+}
+
+static inline void xlnx_mix_clear_intr_status(struct xlnx_mix_hw *mixer,
+					      uint32_t intr)
+{
+	reg_writel(mixer->base, XVMIX_ISR, intr);
+}
+
+/**
+ * xlnx_mix_set_yuv2_rgb_coeff - Programs yuv to rgb coeffiecients
+ * @plane: Xilinx drm plane object
+ * @enc: Colorimetry encoding scheme
+ * @range: Colorimetry range
+ * Programs the colorimetry coefficients required for yuv to rgb
+ * conversion.
+ */
+static void xlnx_mix_set_yuv2_rgb_coeff(struct xlnx_mix_plane *plane,
+					enum drm_color_encoding enc,
+					enum drm_color_range range)
+{
+	struct xlnx_mix *mixer = plane->mixer;
+	u32 i;
+	u32 bpc_scale = 1 << (mixer->mixer_hw.bg_layer_bpc - 8);
+
+	for (i = 0; i < XVMIX_CSC_MATRIX_SIZE; i++)
+		reg_writel(mixer->mixer_hw.base, XVMIX_K00_1 + i * 8,
+			   xlnx_mix_yuv2rgb_coeffs[enc][range][i] *
+			   XVMIX_CSC_SCALE_FACTOR / XVMIX_CSC_DIVISOR);
+
+	for (i = XVMIX_CSC_MATRIX_SIZE; i < XVMIX_CSC_COEFF_SIZE; i++)
+		reg_writel(mixer->mixer_hw.base, XVMIX_K00_1 + i * 8,
+			   (xlnx_mix_yuv2rgb_coeffs[enc][range][i] *
+			    bpc_scale));
+}
+
+/**
+ * xlnx_mix_set_rgb2_yuv_coeff - Programs rgb to yuv coeffiecients
+ * @plane: Xilinx drm plane object
+ * @enc: Colorimetry encoding scheme
+ * @range: Colorimetry range
+ * Programs the colorimetry coefficients required for rgb to yuv
+ * conversion.
+ */
+static void xlnx_mix_set_rgb2_yuv_coeff(struct xlnx_mix_plane *plane,
+					enum drm_color_encoding enc,
+					enum drm_color_range range)
+{
+	struct xlnx_mix *mixer = plane->mixer;
+	u32 i;
+	u32 bpc_scale = 1 << (mixer->mixer_hw.bg_layer_bpc - 8);
+
+	for (i = 0; i < XVMIX_CSC_MATRIX_SIZE; i++)
+		reg_writel(mixer->mixer_hw.base, XVMIX_K00_2 + i * 8,
+			   xlnx_mix_rgb2yuv_coeffs[enc][range][i] *
+			   XVMIX_CSC_SCALE_FACTOR / XVMIX_CSC_DIVISOR);
+
+	for (i = XVMIX_CSC_MATRIX_SIZE; i < XVMIX_CSC_COEFF_SIZE; i++)
+		reg_writel(mixer->mixer_hw.base, XVMIX_K00_2 + i * 8,
+			   (xlnx_mix_rgb2yuv_coeffs[enc][range][i] *
+			    bpc_scale));
+}
+
+/**
+ * xlnx_mix_get_layer_data - Retrieve current hardware and register
+ * values for a logical video layer
+ * @mixer: Mixer instance to interrogate
+ * @id: Id of layer for which data is requested
+ *
+ * Return:
+ * Structure containing layer-specific data; NULL upon failure
+ */
+static struct xlnx_mix_layer_data *
+xlnx_mix_get_layer_data(struct xlnx_mix_hw *mixer, enum xlnx_mix_layer_id id)
+{
+	u32 i;
+	struct xlnx_mix_layer_data *layer_data;
+
+	for (i = 0; i <= (mixer->layer_cnt - 1); i++) {
+		layer_data = &mixer->layer_data[i];
+		if (layer_data->id == id)
+			return layer_data;
+	}
+	return NULL;
+}
+
+/**
+ * xlnx_mix_set_active_area - Sets the number of active horizontal and
+ * vertical scan lines for the mixer background layer.
+ * @mixer: Mixer instance for which to set a new viewable area
+ * @hactive: Width of new background image dimension
+ * @vactive: Height of new background image dimension
+ *
+ * Minimum values are 64x64 with maximum values determined by the IP hardware
+ * design.
+ *
+ * Return:
+ * Zero on success, -EINVAL on failure
+ */
+static int xlnx_mix_set_active_area(struct xlnx_mix_hw *mixer,
+				    u32 hactive, u32 vactive)
+{
+	struct xlnx_mix_layer_data *ld =
+		xlnx_mix_get_layer_data(mixer, XVMIX_LAYER_MASTER);
+
+	if (hactive > ld->hw_config.max_width ||
+	    vactive > ld->hw_config.max_height) {
+		DRM_ERROR("Invalid layer dimension\n");
+		return -EINVAL;
+	}
+	/* set resolution */
+	reg_writel(mixer->base, XVMIX_HEIGHT_DATA, vactive);
+	reg_writel(mixer->base, XVMIX_WIDTH_DATA, hactive);
+	ld->layer_regs.width  = hactive;
+	ld->layer_regs.height = vactive;
+
+	return 0;
+}
+
+/**
+ * is_window_valid - Validate requested plane dimensions
+ * @mixer: Mixer core instance for which to stop video output
+ * @x_pos: x position requested for start of plane
+ * @y_pos: y position requested for start of plane
+ * @width: width of plane
+ * @height: height of plane
+ * @scale: scale factor of plane
+ *
+ * Validates if the requested window is within the frame boundary
+ *
+ * Return:
+ * true on success, false on failure
+ */
+static bool is_window_valid(struct xlnx_mix_hw *mixer, u32 x_pos, u32 y_pos,
+			    u32 width, u32 height, u32 scale)
+{
+	struct xlnx_mix_layer_data *master_layer;
+	int scale_factor[3] = {1, 2, 4};
+
+	master_layer = xlnx_mix_get_layer_data(mixer, XVMIX_LAYER_MASTER);
+
+	/* Check if window scale factor is set */
+	if (scale < XVMIX_SCALE_FACTOR_INVALID) {
+		width  *= scale_factor[scale];
+		height *= scale_factor[scale];
+	}
+
+	/* verify overlay falls within currently active background area */
+	if (((x_pos + width)  <= master_layer->layer_regs.width) &&
+	    ((y_pos + height) <= master_layer->layer_regs.height))
+		return true;
+
+	DRM_ERROR("Requested plane dimensions can't be set\n");
+	return false;
+}
+
+/**
+ *  xlnx_mix_layer_enable - Enables the requested layers
+ * @mixer: Mixer instance in which to enable a video layer
+ * @id: Logical id (e.g. 16 = logo layer) to enable
+ *
+ * Enables (permit video output) for layers in mixer
+ * Enables the layer denoted by id in the IP core.
+ * Layer 0 will indicate the background layer and layer 8 the logo
+ * layer. Passing max layers value will enable all
+ */
+static void xlnx_mix_layer_enable(struct xlnx_mix_hw *mixer,
+				  enum xlnx_mix_layer_id id)
+{
+	struct xlnx_mix_layer_data *layer_data;
+	u32 curr_state;
+	struct xlnx_mix *mix;
+
+	mix = container_of(mixer, struct xlnx_mix, mixer_hw);
+	if (mix->drm_primary_layer->mixer_layer->id == id) {
+		if (!xlnx_mixer_primary_enable)
+			return;
+	}
+
+	/* Ensure layer is marked as 'active' by application before
+	 * turning on in hardware.  In some cases, layer register data
+	 * may be written to otherwise inactive layers in lieu of, eventually,
+	 * turning them on.
+	 */
+	layer_data = xlnx_mix_get_layer_data(mixer, id);
+	if (!layer_data) {
+		DRM_ERROR("Invalid layer id %d\n", id);
+		return;
+	}
+	if (!layer_data->layer_regs.is_active)
+		return; /* for inactive layers silently return */
+
+	/* Check if request is to enable all layers or single layer */
+	if (id == mixer->max_layers) {
+		reg_writel(mixer->base, XVMIX_LAYERENABLE_DATA,
+			   mixer->enable_all_mask);
+
+	} else if ((id < mixer->layer_cnt) || ((id == mixer->logo_layer_id) &&
+		   mixer->logo_layer_en)) {
+		curr_state = reg_readl(mixer->base, XVMIX_LAYERENABLE_DATA);
+		if (id == mixer->logo_layer_id)
+			curr_state |= mixer->logo_en_mask;
+		else
+			curr_state |= BIT(id);
+		reg_writel(mixer->base, XVMIX_LAYERENABLE_DATA, curr_state);
+	} else {
+		DRM_ERROR("Can't enable requested layer %d\n", id);
+	}
+}
+
+/**
+ * xlnx_mix_disp_layer_enable - Enables video output represented by the
+ * plane object
+ * @plane: Drm plane object describing video layer to enable
+ *
+ */
+static void xlnx_mix_disp_layer_enable(struct xlnx_mix_plane *plane)
+{
+	struct xlnx_mix_hw *mixer_hw;
+	struct xlnx_mix_layer_data *l_data;
+	u32 id;
+
+	if (!plane)
+		return;
+	mixer_hw = to_mixer_hw(plane);
+	l_data = plane->mixer_layer;
+	id = l_data->id;
+	if (id > mixer_hw->logo_layer_id) {
+		DRM_DEBUG_KMS("Attempt to activate invalid layer: %d\n", id);
+		return;
+	}
+	if (id == XVMIX_LAYER_MASTER && !l_data->hw_config.is_streaming)
+		return;
+
+	xlnx_mix_layer_enable(mixer_hw, id);
+}
+
+/**
+ * xlnx_mix_layer_disable - Disables the requested layer
+ * @mixer:  Mixer for which the layer will be disabled
+ * @id: Logical id of the layer to be disabled (0-16)
+ *
+ * Disables the layer denoted by layer_id in the IP core.
+ * Layer 0 will indicate the background layer and layer 16 the logo
+ * layer. Passing the value of max layers will disable all
+ * layers.
+ */
+static void xlnx_mix_layer_disable(struct xlnx_mix_hw *mixer,
+				   enum xlnx_mix_layer_id id)
+{
+	u32 num_layers, curr_state;
+
+	num_layers = mixer->layer_cnt;
+
+	if (id == mixer->max_layers) {
+		reg_writel(mixer->base, XVMIX_LAYERENABLE_DATA,
+			   XVMIX_MASK_DISABLE_ALL_LAYERS);
+	} else if ((id < num_layers) ||
+		   ((id == mixer->logo_layer_id) && (mixer->logo_layer_en))) {
+		curr_state = reg_readl(mixer->base, XVMIX_LAYERENABLE_DATA);
+		if (id == mixer->logo_layer_id)
+			curr_state &= ~(mixer->logo_en_mask);
+		else
+			curr_state &= ~(BIT(id));
+		reg_writel(mixer->base, XVMIX_LAYERENABLE_DATA, curr_state);
+	} else {
+		DRM_ERROR("Can't disable requested layer %d\n", id);
+	}
+}
+
+/**
+ * xlnx_mix_disp_layer_disable - Disables video output represented by the
+ * plane object
+ * @plane: Drm plane object describing video layer to disable
+ *
+ */
+static void xlnx_mix_disp_layer_disable(struct xlnx_mix_plane *plane)
+{
+	struct xlnx_mix_hw *mixer_hw;
+	u32 layer_id;
+
+	if (plane)
+		mixer_hw = to_mixer_hw(plane);
+	else
+		return;
+	layer_id = plane->mixer_layer->id;
+	if (layer_id > mixer_hw->logo_layer_id)
+		return;
+
+	xlnx_mix_layer_disable(mixer_hw, layer_id);
+}
+
+static int xlnx_mix_mark_layer_inactive(struct xlnx_mix_plane *plane)
+{
+	if (!plane || !plane->mixer_layer)
+		return -ENODEV;
+
+	plane->mixer_layer->layer_regs.is_active = false;
+
+	return 0;
+}
+
+/* apply mode to plane pipe */
+static void xlnx_mix_plane_commit(struct drm_plane *base_plane)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(base_plane);
+	struct dma_async_tx_descriptor *desc;
+	enum dma_ctrl_flags flags;
+	unsigned int i;
+
+	/* for xlnx video framebuffer dma, if used */
+	xilinx_xdma_drm_config(plane->dma[0].chan, plane->format);
+	for (i = 0; i < XVMIX_MAX_NUM_SUB_PLANES; i++) {
+		struct xlnx_mix_plane_dma *dma = &plane->dma[i];
+
+		if (dma->chan && dma->is_active) {
+			flags = DMA_CTRL_ACK | DMA_PREP_INTERRUPT;
+			desc = dmaengine_prep_interleaved_dma(dma->chan,
+							      &dma->xt,
+							      flags);
+			if (!desc) {
+				DRM_ERROR("failed to prepare DMA descriptor\n");
+				return;
+			}
+			dmaengine_submit(desc);
+			dma_async_issue_pending(dma->chan);
+		}
+	}
+}
+
+static int xlnx_mix_plane_get_max_width(struct drm_plane *base_plane)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(base_plane);
+
+	return plane->mixer->max_width;
+}
+
+static int xlnx_mix_plane_get_max_height(struct drm_plane *base_plane)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(base_plane);
+
+	return plane->mixer->max_height;
+}
+
+static int xlnx_mix_plane_get_max_cursor_width(struct drm_plane *base_plane)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(base_plane);
+
+	return plane->mixer->max_cursor_width;
+}
+
+static int xlnx_mix_plane_get_max_cursor_height(struct drm_plane *base_plane)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(base_plane);
+
+	return plane->mixer->max_cursor_height;
+}
+
+static int xlnx_mix_crtc_get_max_width(struct xlnx_crtc *crtc)
+{
+	return xlnx_mix_plane_get_max_width(crtc->crtc.primary);
+}
+
+static int xlnx_mix_crtc_get_max_height(struct xlnx_crtc *crtc)
+{
+	return xlnx_mix_plane_get_max_height(crtc->crtc.primary);
+}
+
+static unsigned int xlnx_mix_crtc_get_max_cursor_width(struct xlnx_crtc *crtc)
+{
+	return xlnx_mix_plane_get_max_cursor_width(crtc->crtc.primary);
+}
+
+static unsigned int xlnx_mix_crtc_get_max_cursor_height(struct xlnx_crtc *crtc)
+{
+	return xlnx_mix_plane_get_max_cursor_height(crtc->crtc.primary);
+}
+
+/**
+ * xlnx_mix_crtc_get_format - Get the current device format
+ * @crtc: xlnx crtc object
+ *
+ * Get the current format of pipeline
+ *
+ * Return: the corresponding DRM_FORMAT_XXX
+ */
+static uint32_t xlnx_mix_crtc_get_format(struct xlnx_crtc *crtc)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(crtc->crtc.primary);
+
+	return plane->format;
+}
+
+/**
+ * xlnx_mix_crtc_get_align - Get the alignment value for pitch
+ * @crtc: xlnx crtc object
+ *
+ * Get the alignment value for pitch from the plane
+ *
+ * Return: The alignment value if successful, or the error code.
+ */
+static unsigned int xlnx_mix_crtc_get_align(struct xlnx_crtc *crtc)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(crtc->crtc.primary);
+	struct xlnx_mix *m = plane->mixer;
+
+	return XVMIX_BASE_ALIGN * m->mixer_hw.ppc;
+}
+
+/**
+ * xlnx_mix_attach_plane_prop - Attach mixer-specific drm property to
+ * the given plane
+ * @plane: Xilinx drm plane object to inspect and attach appropriate
+ *  properties to
+ *
+ * The linked mixer layer will be inspected to see what capabilities it offers
+ * (e.g. global layer alpha; scaling) and drm property objects that indicate
+ * those capabilities will then be attached and initialized to default values.
+ */
+static void xlnx_mix_attach_plane_prop(struct xlnx_mix_plane *plane)
+{
+	struct drm_mode_object *base = &plane->base.base;
+	struct xlnx_mix *mixer = plane->mixer;
+
+	if (plane->mixer_layer->hw_config.can_scale)
+		drm_object_attach_property(base, mixer->scale_prop,
+					   XVMIX_SCALE_FACTOR_1X);
+	if (plane->mixer_layer->hw_config.can_alpha)
+		drm_object_attach_property(base, mixer->alpha_prop,
+					   XVMIX_ALPHA_MAX);
+	if (mixer->mixer_hw.csc_enabled) {
+		u32 supported_encodings = BIT(DRM_COLOR_YCBCR_BT601) |
+					  BIT(DRM_COLOR_YCBCR_BT709) |
+					  BIT(DRM_COLOR_YCBCR_BT2020);
+		u32 supported_ranges = BIT(DRM_COLOR_YCBCR_LIMITED_RANGE) |
+				       BIT(DRM_COLOR_YCBCR_FULL_RANGE);
+		enum drm_color_encoding encoding = DRM_COLOR_YCBCR_BT709;
+		enum drm_color_range range = DRM_COLOR_YCBCR_LIMITED_RANGE;
+
+		drm_plane_create_color_properties(&plane->base,
+						  supported_encodings,
+						  supported_ranges,
+						  encoding, range);
+	}
+}
+
+static int xlnx_mix_mark_layer_active(struct xlnx_mix_plane *plane)
+{
+	if (!plane->mixer_layer)
+		return -ENODEV;
+	plane->mixer_layer->layer_regs.is_active = true;
+
+	return 0;
+}
+
+static bool xlnx_mix_isfmt_support(u32 format)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(color_table); i++) {
+		if (format == color_table[i])
+			return true;
+	}
+	return false;
+}
+
+/*************** DISPLAY ************/
+
+/**
+ * xlnx_mix_get_layer_scaling - Get layer scaling factor
+ * @mixer: Mixer instance to program with new background color
+ * @id: Plane id
+ *
+ * Applicable only for overlay layers
+ *
+ * Return:
+ * scaling factor of the specified layer
+ */
+static int xlnx_mix_get_layer_scaling(struct xlnx_mix_hw *mixer,
+				      enum xlnx_mix_layer_id id)
+{
+	int scale_factor = 0;
+	u32 reg;
+	struct xlnx_mix_layer_data *l_data = xlnx_mix_get_layer_data(mixer, id);
+
+	if (id == mixer->logo_layer_id) {
+		if (mixer->logo_layer_en) {
+			if (mixer->max_layers > XVMIX_MAX_OVERLAY_LAYERS)
+				reg = XVMIX_LOGOSCALEFACTOR_DATA +
+					XVMIX_LOGO_OFFSET;
+			else
+				reg = XVMIX_LOGOSCALEFACTOR_DATA;
+			scale_factor = reg_readl(mixer->base, reg);
+			l_data->layer_regs.scale_fact = scale_factor;
+		}
+	} else {
+		/*Layer0-Layer15*/
+		if (id < mixer->logo_layer_id && l_data->hw_config.can_scale) {
+			reg = XVMIX_LAYERSCALE_0_DATA + (id * XVMIX_REG_OFFSET);
+			scale_factor = reg_readl(mixer->base, reg);
+			l_data->layer_regs.scale_fact = scale_factor;
+		}
+	}
+	return scale_factor;
+}
+
+/**
+ * xlnx_mix_set_layer_window - Sets the position of an overlay layer
+ * @mixer: Specific mixer object instance controlling the video
+ * @id: Logical layer id (1-15) to be positioned
+ * @x_pos: new: Column to start display of overlay layer
+ * @y_pos: new: Row to start display of overlay layer
+ * @width: Number of active columns to dislay for overlay layer
+ * @height: Number of active columns to display for overlay layer
+ * @stride: Width in bytes of overaly memory buffer (memory layer only)
+ *
+ * Sets the position of an overlay layer over the background layer (layer 0)
+ * Applicable only for layers 1-15 or the logo layer
+ *
+ * Return:
+ * Zero on success, -EINVAL if position is invalid or -ENODEV if layer
+ */
+static int xlnx_mix_set_layer_window(struct xlnx_mix_hw *mixer,
+				     enum xlnx_mix_layer_id id, u32 x_pos,
+				     u32 y_pos, u32 width, u32 height,
+				     u32 stride)
+{
+	struct xlnx_mix_layer_data *l_data;
+	u32 scale = 0;
+	int status = -EINVAL;
+	u32 x_reg, y_reg, w_reg, h_reg, s_reg;
+	u32 off;
+
+	l_data = xlnx_mix_get_layer_data(mixer, id);
+	if (!l_data)
+		return status;
+
+	scale = xlnx_mix_get_layer_scaling(mixer, id);
+	if (!is_window_valid(mixer, x_pos, y_pos, width, height, scale))
+		return status;
+
+	if (id == mixer->logo_layer_id) {
+		if (!(mixer->logo_layer_en &&
+		      width <= l_data->hw_config.max_width &&
+		      height <= l_data->hw_config.max_height &&
+		      height >= l_data->hw_config.min_height &&
+		      width >= l_data->hw_config.min_width))
+			return status;
+
+		if (mixer->max_layers > XVMIX_MAX_OVERLAY_LAYERS) {
+			x_reg = XVMIX_LOGOSTARTX_DATA + XVMIX_LOGO_OFFSET;
+			y_reg = XVMIX_LOGOSTARTY_DATA + XVMIX_LOGO_OFFSET;
+			w_reg = XVMIX_LOGOWIDTH_DATA + XVMIX_LOGO_OFFSET;
+			h_reg = XVMIX_LOGOHEIGHT_DATA + XVMIX_LOGO_OFFSET;
+		} else {
+			x_reg = XVMIX_LOGOSTARTX_DATA;
+			y_reg = XVMIX_LOGOSTARTY_DATA;
+			w_reg = XVMIX_LOGOWIDTH_DATA;
+			h_reg = XVMIX_LOGOHEIGHT_DATA;
+		}
+		reg_writel(mixer->base, x_reg, x_pos);
+		reg_writel(mixer->base, y_reg, y_pos);
+		reg_writel(mixer->base, w_reg, width);
+		reg_writel(mixer->base, h_reg, height);
+		l_data->layer_regs.x_pos = x_pos;
+		l_data->layer_regs.y_pos = y_pos;
+		l_data->layer_regs.width = width;
+		l_data->layer_regs.height = height;
+		status = 0;
+	} else {
+		 /*Layer1-Layer15*/
+
+		if (!(id < mixer->layer_cnt &&
+		      width <= l_data->hw_config.max_width &&
+		      width >= l_data->hw_config.min_width))
+			return status;
+		x_reg = XVMIX_LAYERSTARTX_0_DATA;
+		y_reg = XVMIX_LAYERSTARTY_0_DATA;
+		w_reg = XVMIX_LAYERWIDTH_0_DATA;
+		h_reg = XVMIX_LAYERHEIGHT_0_DATA;
+		s_reg = XVMIX_LAYERSTRIDE_0_DATA;
+
+		off = id * XVMIX_REG_OFFSET;
+		reg_writel(mixer->base, (x_reg + off), x_pos);
+		reg_writel(mixer->base, (y_reg + off), y_pos);
+		reg_writel(mixer->base, (w_reg + off), width);
+		reg_writel(mixer->base, (h_reg + off), height);
+		l_data->layer_regs.x_pos = x_pos;
+		l_data->layer_regs.y_pos = y_pos;
+		l_data->layer_regs.width = width;
+		l_data->layer_regs.height = height;
+
+		if (!l_data->hw_config.is_streaming)
+			reg_writel(mixer->base, (s_reg + off), stride);
+		status = 0;
+	}
+	return status;
+}
+
+/**
+ * xlnx_mix_set_layer_dimensions - Set layer dimensions
+ * @plane: Drm plane object desribing video layer to reposition
+ * @crtc_x: New horizontal anchor postion from which to begin rendering
+ * @crtc_y: New vertical anchor position from which to begin rendering
+ * @width: Width, in pixels, to render from stream or memory buffer
+ * @height: Height, in pixels, to render from stream or memory buffer
+ * @stride: Width, in bytes, of a memory buffer.  Used only for
+ *  memory layers.  Use 0 for streaming layers.
+ *
+ * Establishes new coordinates and dimensions for a video plane layer
+ * New size and coordinates of window must fit within the currently active
+ * area of the crtc (e.g. the background resolution)
+ *
+ * Return: 0 if successful; Either -EINVAL if coordindate data is invalid
+ * or -ENODEV if layer data not present
+ */
+static int xlnx_mix_set_layer_dimensions(struct xlnx_mix_plane *plane,
+					 u32 crtc_x, u32 crtc_y,
+					  u32 width, u32 height, u32 stride)
+{
+	struct xlnx_mix *mixer = plane->mixer;
+	struct xlnx_mix_hw *mixer_hw = to_mixer_hw(plane);
+	struct xlnx_mix_layer_data *layer_data;
+	enum xlnx_mix_layer_id layer_id;
+	int ret = 0;
+
+	layer_data = plane->mixer_layer;
+	layer_id = layer_data->id;
+	if (layer_data->layer_regs.height != height ||
+	    layer_data->layer_regs.width != width) {
+		if (mixer->drm_primary_layer == plane)
+			xlnx_mix_layer_disable(mixer_hw, XVMIX_LAYER_MASTER);
+
+		xlnx_mix_layer_disable(mixer_hw, layer_id);
+	}
+	if (mixer->drm_primary_layer == plane) {
+		crtc_x = 0;
+		crtc_y = 0;
+		ret = xlnx_mix_set_active_area(mixer_hw, width, height);
+		if (ret)
+			return ret;
+		xlnx_mix_layer_enable(mixer_hw, XVMIX_LAYER_MASTER);
+	}
+	if (layer_id != XVMIX_LAYER_MASTER && layer_id < mixer_hw->max_layers) {
+		ret = xlnx_mix_set_layer_window(mixer_hw, layer_id, crtc_x,
+						crtc_y, width, height, stride);
+		if (ret)
+			return ret;
+		xlnx_mix_disp_layer_enable(plane);
+	}
+	return ret;
+}
+
+/**
+ * xlnx_mix_set_layer_scaling - Sets scaling factor
+ * @mixer: Instance of mixer to be subject of scaling request
+ * @id: Logical id of video layer subject to new scale setting
+ * @scale: scale Factor (1x, 2x or 4x) for horiz. and vert. dimensions
+ *
+ * Sets the scaling factor for the specified video layer
+ * Not applicable to background stream layer (layer 0)
+ *
+ * Return:
+ * Zero on success, -EINVAL on failure to set scale for layer (likely
+ * returned if resulting size of layer exceeds dimensions of active
+ * display area
+ */
+static int xlnx_mix_set_layer_scaling(struct xlnx_mix_hw *mixer,
+				      enum xlnx_mix_layer_id id, u32 scale)
+{
+	void __iomem *reg = mixer->base;
+	struct xlnx_mix_layer_data *l_data;
+	int status = 0;
+	u32 x_pos, y_pos, width, height, offset;
+
+	l_data = xlnx_mix_get_layer_data(mixer, id);
+	x_pos = l_data->layer_regs.x_pos;
+	y_pos = l_data->layer_regs.y_pos;
+	width  = l_data->layer_regs.width;
+	height = l_data->layer_regs.height;
+
+	if (!is_window_valid(mixer, x_pos, y_pos, width, height, scale))
+		return -EINVAL;
+
+	if (id == mixer->logo_layer_id) {
+		if (mixer->logo_layer_en) {
+			if (mixer->max_layers > XVMIX_MAX_OVERLAY_LAYERS)
+				reg_writel(reg, XVMIX_LOGOSCALEFACTOR_DATA +
+					   XVMIX_LOGO_OFFSET, scale);
+			else
+				reg_writel(reg, XVMIX_LOGOSCALEFACTOR_DATA,
+					   scale);
+			l_data->layer_regs.scale_fact = scale;
+			status = 0;
+		}
+	} else {
+		 /* Layer0-Layer15 */
+		if (id < mixer->layer_cnt && l_data->hw_config.can_scale) {
+			offset = id * XVMIX_REG_OFFSET;
+
+			reg_writel(reg, (XVMIX_LAYERSCALE_0_DATA + offset),
+				   scale);
+			l_data->layer_regs.scale_fact = scale;
+			status = 0;
+		}
+	}
+	return status;
+}
+
+/**
+ * xlnx_mix_set_layer_scale - Change video scale factor for video plane
+ * @plane: Drm plane object describing layer to be modified
+ * @val: Index of scale factor to use:
+ *		0 = 1x
+ *		1 = 2x
+ *		2 = 4x
+ *
+ * Return:
+ * Zero on success, either -EINVAL if scale value is illegal or
+ * -ENODEV if layer does not exist (null)
+ */
+static int xlnx_mix_set_layer_scale(struct xlnx_mix_plane *plane,
+				    uint64_t val)
+{
+	struct xlnx_mix_hw *mixer_hw = to_mixer_hw(plane);
+	struct xlnx_mix_layer_data *layer = plane->mixer_layer;
+	int ret;
+
+	if (!layer || !layer->hw_config.can_scale)
+		return -ENODEV;
+	if (val > XVMIX_SCALE_FACTOR_4X) {
+		DRM_ERROR("Mixer layer scale value illegal.\n");
+		return -EINVAL;
+	}
+	xlnx_mix_disp_layer_disable(plane);
+	msleep(50);
+	ret = xlnx_mix_set_layer_scaling(mixer_hw, layer->id, val);
+	xlnx_mix_disp_layer_enable(plane);
+
+	return ret;
+}
+
+/**
+ * xlnx_mix_set_layer_alpha - Set the alpha value
+ * @mixer: Instance of mixer controlling layer to modify
+ * @layer_id: Logical id of video overlay to adjust alpha setting
+ * @alpha: Desired alpha setting (0-255) for layer specified
+ *            255 = completely opaque
+ *            0 = fully transparent
+ *
+ * Set the layer global transparency for a video overlay
+ * Not applicable to background streaming layer
+ *
+ * Return:
+ * Zero on success, -EINVAL on failure
+ */
+static int xlnx_mix_set_layer_alpha(struct xlnx_mix_hw *mixer,
+				    enum xlnx_mix_layer_id layer_id, u32 alpha)
+{
+	struct xlnx_mix_layer_data *layer_data;
+	u32 reg;
+	int status = -EINVAL;
+
+	layer_data = xlnx_mix_get_layer_data(mixer, layer_id);
+
+	if (layer_id == mixer->logo_layer_id) {
+		if (mixer->logo_layer_en) {
+			if (mixer->max_layers > XVMIX_MAX_OVERLAY_LAYERS)
+				reg = XVMIX_LOGOALPHA_DATA + XVMIX_LOGO_OFFSET;
+			else
+				reg = XVMIX_LOGOALPHA_DATA;
+			reg_writel(mixer->base, reg, alpha);
+			layer_data->layer_regs.alpha = alpha;
+			status = 0;
+		}
+	} else {
+		 /*Layer1-Layer15*/
+		if (layer_id < mixer->layer_cnt &&
+		    layer_data->hw_config.can_alpha) {
+			u32 offset =  layer_id * XVMIX_REG_OFFSET;
+
+			reg = XVMIX_LAYERALPHA_0_DATA;
+			reg_writel(mixer->base, (reg + offset), alpha);
+			layer_data->layer_regs.alpha = alpha;
+			status = 0;
+		}
+	}
+	return status;
+}
+
+/**
+ * xlnx_mix_disp_set_layer_alpha - Change the transparency of an entire plane
+ * @plane: Video layer affected by new alpha setting
+ * @val: Value of transparency setting (0-255) with 255 being opaque
+ *  0 being fully transparent
+ *
+ * Return:
+ * Zero on success, -EINVAL on failure
+ */
+static int xlnx_mix_disp_set_layer_alpha(struct xlnx_mix_plane *plane,
+					 uint64_t val)
+{
+	struct xlnx_mix_hw *mixer_hw = to_mixer_hw(plane);
+	struct xlnx_mix_layer_data *layer = plane->mixer_layer;
+
+	if (!layer || !layer->hw_config.can_alpha)
+		return -ENODEV;
+	if (val > XVMIX_ALPHA_MAX) {
+		DRM_ERROR("Mixer layer alpha dts value illegal.\n");
+		return -EINVAL;
+	}
+	return xlnx_mix_set_layer_alpha(mixer_hw, layer->id, val);
+}
+
+/**
+ * xlnx_mix_set_layer_buff_addr - Set buff addr for layer
+ * @mixer: Instance of mixer controlling layer to modify
+ * @id: Logical id of video overlay to adjust alpha setting
+ * @luma_addr: Start address of plane 1 of frame buffer for layer 1
+ * @chroma_addr: Start address of plane 2 of frame buffer for layer 1
+ * @chroma_addr2: Start address of plane 3 of frame buffer for layer 1
+ *
+ * Sets the buffer address of the specified layer
+ * Return:
+ * Zero on success, -EINVAL on failure
+ */
+static int xlnx_mix_set_layer_buff_addr(struct xlnx_mix_hw *mixer,
+					enum xlnx_mix_layer_id id,
+					dma_addr_t luma_addr,
+					dma_addr_t chroma_addr,
+					dma_addr_t chroma_addr2)
+{
+	struct xlnx_mix_layer_data *layer_data;
+	u32 align, offset;
+	u32 reg[XVMIX_MAX_PLANES];
+
+	memset(reg, 0, sizeof(reg));
+
+	if (id >= mixer->layer_cnt)
+		return -EINVAL;
+
+	/* Check if addr is aligned to aximm width (PPC * 64-bits) */
+	align = mixer->ppc * 8;
+	if ((luma_addr % align) || (chroma_addr % align) || (chroma_addr2 % align))
+		return -EINVAL;
+
+	layer_data = &mixer->layer_data[id];
+
+	offset = (id - 1) * XVMIX_REG_OFFSET;
+	reg[0] = XVMIX_LAYER1_BUF1_V_DATA + offset;
+	reg[1] = XVMIX_LAYER1_BUF2_V_DATA + offset;
+	/* set only in case of 3 plane YUV444 8, 10 and 12 video formats */
+	if (mixer->three_planes_prop && layer_data->hw_config.plane_3)
+		reg[2] = XVMIX_LAYER1_BUF3_V_DATA + offset;
+
+	if (mixer->dma_addr_size == 64 && sizeof(dma_addr_t) == 8) {
+		reg_writeq(mixer->base, reg[0], luma_addr);
+		reg_writeq(mixer->base, reg[1], chroma_addr);
+		if (mixer->three_planes_prop && layer_data->hw_config.plane_3)
+			reg_writeq(mixer->base, reg[2], chroma_addr2);
+		/* TODO: Test 64 bit address configuration */
+	} else {
+		reg_writel(mixer->base, reg[0], (u32)luma_addr);
+		reg_writel(mixer->base, reg[1], (u32)chroma_addr);
+		if (mixer->three_planes_prop && layer_data->hw_config.plane_3)
+			reg_writel(mixer->base, reg[2], (u32)chroma_addr2);
+	}
+	layer_data->layer_regs.buff_addr1 = luma_addr;
+	layer_data->layer_regs.buff_addr2 = chroma_addr;
+	if (mixer->three_planes_prop && layer_data->hw_config.plane_3)
+		layer_data->layer_regs.buff_addr3 = chroma_addr2;
+
+	return 0;
+}
+
+/**
+ * xlnx_mix_hw_plane_dpms - Implementation of display power management
+ * system call (dpms).
+ * @plane: Plane/mixer layer to enable/disable (based on dpms value)
+ * @dpms: Display power management state to act upon
+ *
+ * Designed to disable and turn off a plane and restore all attached drm
+ * properities to their initial values.  Alterntively, if dpms is "on", will
+ * enable a layer.
+ */
+
+static void
+xlnx_mix_hw_plane_dpms(struct xlnx_mix_plane *plane, int dpms)
+{
+	struct xlnx_mix *mixer;
+
+	if (!plane->mixer)
+		return;
+	mixer = plane->mixer;
+	plane->dpms = dpms;
+
+	switch (dpms) {
+	case DRM_MODE_DPMS_ON:
+		xlnx_mix_disp_layer_enable(plane);
+		break;
+	default:
+		xlnx_mix_mark_layer_inactive(plane);
+		xlnx_mix_disp_layer_disable(plane);
+		/* restore to default property values */
+		if (mixer->alpha_prop)
+			xlnx_mix_disp_set_layer_alpha(plane, XVMIX_ALPHA_MAX);
+		if (mixer->scale_prop)
+			xlnx_mix_set_layer_scale(plane, XVMIX_SCALE_FACTOR_1X);
+	}
+}
+
+static void xlnx_mix_plane_dpms(struct drm_plane *base_plane, int dpms)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(base_plane);
+	unsigned int i;
+
+	DRM_DEBUG_KMS("plane->id: %d\n", plane->id);
+	DRM_DEBUG_KMS("dpms: %d -> %d\n", plane->dpms, dpms);
+
+	if (plane->dpms == dpms)
+		return;
+	plane->dpms = dpms;
+	switch (dpms) {
+	case DRM_MODE_DPMS_ON:
+		/* start dma engine */
+		for (i = 0; i < XVMIX_MAX_NUM_SUB_PLANES; i++)
+			if (plane->dma[i].chan && plane->dma[i].is_active)
+				dma_async_issue_pending(plane->dma[i].chan);
+		xlnx_mix_hw_plane_dpms(plane, dpms);
+		break;
+	default:
+		xlnx_mix_hw_plane_dpms(plane, dpms);
+		/* stop dma engine and release descriptors */
+		for (i = 0; i < XVMIX_MAX_NUM_SUB_PLANES; i++) {
+			if (plane->dma[i].chan && plane->dma[i].is_active) {
+				dmaengine_terminate_sync(plane->dma[i].chan);
+				plane->dma[i].is_active = false;
+			}
+		}
+		break;
+	}
+}
+
+static int
+xlnx_mix_disp_plane_atomic_set_property(struct drm_plane *base_plane,
+					struct drm_plane_state *state,
+				      struct drm_property *property, u64 val)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(base_plane);
+	struct xlnx_mix *mixer = plane->mixer;
+
+	if (property == mixer->alpha_prop)
+		return xlnx_mix_disp_set_layer_alpha(plane, val);
+	else if (property == mixer->scale_prop)
+		return xlnx_mix_set_layer_scale(plane, val);
+	else
+		return -EINVAL;
+	return 0;
+}
+
+static int
+xlnx_mix_disp_plane_atomic_get_property(struct drm_plane *base_plane,
+					const struct drm_plane_state *state,
+				      struct drm_property *property,
+				      uint64_t *val)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(base_plane);
+	struct xlnx_mix *mixer = plane->mixer;
+	struct xlnx_mix_hw *mixer_hw = to_mixer_hw(plane);
+	u32 layer_id = plane->mixer_layer->id;
+
+	if (property == mixer->alpha_prop)
+		*val = mixer_hw->layer_data[layer_id].layer_regs.alpha;
+	else if (property == mixer->scale_prop)
+		*val = mixer_hw->layer_data[layer_id].layer_regs.scale_fact;
+	else
+		return -EINVAL;
+
+	return 0;
+}
+
+/**
+ * xlnx_mix_disp_plane_atomic_update_plane - plane update using atomic
+ * @plane: plane object to update
+ * @crtc: owning CRTC of owning plane
+ * @fb: framebuffer to flip onto plane
+ * @crtc_x: x offset of primary plane on crtc
+ * @crtc_y: y offset of primary plane on crtc
+ * @crtc_w: width of primary plane rectangle on crtc
+ * @crtc_h: height of primary plane rectangle on crtc
+ * @src_x: x offset of @fb for panning
+ * @src_y: y offset of @fb for panning
+ * @src_w: width of source rectangle in @fb
+ * @src_h: height of source rectangle in @fb
+ * @ctx: lock acquire context
+ *
+ * Provides a default plane update handler using the atomic driver interface.
+ *
+ * RETURNS:
+ * Zero on success, error code on failure
+ */
+static int
+xlnx_mix_disp_plane_atomic_update_plane(struct drm_plane *plane,
+					struct drm_crtc *crtc,
+					struct drm_framebuffer *fb,
+					int crtc_x, int crtc_y,
+					unsigned int crtc_w,
+					unsigned int crtc_h,
+					uint32_t src_x, uint32_t src_y,
+					uint32_t src_w, uint32_t src_h,
+					struct drm_modeset_acquire_ctx *ctx)
+{
+	struct drm_atomic_state *state;
+	struct drm_plane_state *plane_state;
+	int ret = 0;
+
+	state = drm_atomic_state_alloc(plane->dev);
+	if (!state)
+		return -ENOMEM;
+
+	state->acquire_ctx = ctx;
+	plane_state = drm_atomic_get_plane_state(state, plane);
+	if (IS_ERR(plane_state)) {
+		ret = PTR_ERR(plane_state);
+		goto fail;
+	}
+
+	ret = drm_atomic_set_crtc_for_plane(plane_state, crtc);
+	if (ret != 0)
+		goto fail;
+
+	drm_atomic_set_fb_for_plane(plane_state, fb);
+	plane_state->crtc_x = crtc_x;
+	plane_state->crtc_y = crtc_y;
+	plane_state->crtc_w = crtc_w;
+	plane_state->crtc_h = crtc_h;
+	plane_state->src_x = src_x;
+	plane_state->src_y = src_y;
+	plane_state->src_w = src_w;
+	plane_state->src_h = src_h;
+
+	if (plane == crtc->cursor)
+		state->legacy_cursor_update = true;
+
+	/* Do async-update if possible */
+	state->async_update = !drm_atomic_helper_async_check(plane->dev, state);
+
+	ret = drm_atomic_commit(state);
+
+fail:
+	drm_atomic_state_put(state);
+	return ret;
+}
+
+static struct drm_plane_funcs xlnx_mix_plane_funcs = {
+	.update_plane	= xlnx_mix_disp_plane_atomic_update_plane,
+	.disable_plane	= drm_atomic_helper_disable_plane,
+	.atomic_set_property	= xlnx_mix_disp_plane_atomic_set_property,
+	.atomic_get_property	= xlnx_mix_disp_plane_atomic_get_property,
+	.destroy		= drm_plane_cleanup,
+	.reset			= drm_atomic_helper_plane_reset,
+	.atomic_duplicate_state	= drm_atomic_helper_plane_duplicate_state,
+	.atomic_destroy_state	= drm_atomic_helper_plane_destroy_state,
+};
+
+/**
+ * xlnx_mix_logo_load - Loads mixer's internal bram
+ * @mixer: Mixer instance to act upon
+ * @logo_w: Width of logo in pixels
+ * @logo_h: Height of logo in pixels
+ * @r_buf: Pointer to byte buffer array of R data values
+ * @g_buf: Pointer to byte buffer array of G data values
+ * @b_buf: Pointer to byte buffer array of B data values
+ * @a_buf: Pointer to byte buffer array of A data values
+ *
+ * Loads mixer's internal bram with planar R, G, B and A data
+ *
+ * Return:
+ * Zero on success, -ENODEV if logo layer not enabled; -EINVAL otherwise
+ */
+static int xlnx_mix_logo_load(struct xlnx_mix_hw *mixer, u32 logo_w, u32 logo_h,
+			      u8 *r_buf, u8 *g_buf, u8 *b_buf, u8 *a_buf)
+{
+	void __iomem *reg = mixer->base;
+	struct xlnx_mix_layer_data *layer_data;
+
+	int x;
+	u32 shift;
+	u32 rword, gword, bword, aword;
+	u32 pixel_cnt = logo_w * logo_h;
+	u32 unaligned_pix_cnt = pixel_cnt % 4;
+	u32 curr_x_pos, curr_y_pos;
+	u32 rbase_addr, gbase_addr, bbase_addr, abase_addr;
+
+	layer_data = xlnx_mix_get_layer_data(mixer, mixer->logo_layer_id);
+	rword = 0;
+	gword = 0;
+	bword = 0;
+	aword = 0;
+
+	if (!layer_data)
+		return -ENODEV;
+
+	/* RGBA data should be 32-bit word aligned */
+	if (unaligned_pix_cnt && mixer->logo_pixel_alpha_enabled)
+		return -EINVAL;
+
+	if (!(mixer->logo_layer_en &&
+	      logo_w <= layer_data->hw_config.max_width &&
+	    logo_h <= layer_data->hw_config.max_height))
+		return -EINVAL;
+
+	rbase_addr = XVMIX_LOGOR_V_BASE;
+	gbase_addr = XVMIX_LOGOG_V_BASE;
+	bbase_addr = XVMIX_LOGOB_V_BASE;
+	abase_addr = XVMIX_LOGOA_V_BASE;
+
+	for (x = 0; x < pixel_cnt; x++) {
+		shift = (x % 4) * 8;
+		rword |= r_buf[x] << shift;
+		gword |= g_buf[x] << shift;
+		bword |= b_buf[x] << shift;
+		if (mixer->logo_pixel_alpha_enabled)
+			aword |= a_buf[x] << shift;
+
+		if (x % 4 == 3) {
+			reg_writel(reg, (rbase_addr + (x - 3)), rword);
+			reg_writel(reg, (gbase_addr + (x - 3)), gword);
+			reg_writel(reg, (bbase_addr + (x - 3)), bword);
+			if (mixer->logo_pixel_alpha_enabled)
+				reg_writel(reg, (abase_addr + (x - 3)), aword);
+		}
+	}
+
+	curr_x_pos = layer_data->layer_regs.x_pos;
+	curr_y_pos = layer_data->layer_regs.y_pos;
+	return xlnx_mix_set_layer_window(mixer, mixer->logo_layer_id,
+					 curr_x_pos, curr_y_pos,
+					 logo_w, logo_h, 0);
+}
+
+static int xlnx_mix_update_logo_img(struct xlnx_mix_plane *plane,
+				    struct drm_gem_dma_object *buffer,
+				     u32 src_w, u32 src_h)
+{
+	struct xlnx_mix_layer_data *logo_layer = plane->mixer_layer;
+	struct xlnx_mix_hw *mixer = to_mixer_hw(plane);
+	size_t pixel_cnt = src_h * src_w;
+	bool per_pixel_alpha = false;
+	u32 max_width = logo_layer->hw_config.max_width;
+	u32 max_height = logo_layer->hw_config.max_height;
+	u32 min_width = logo_layer->hw_config.min_width;
+	u32 min_height = logo_layer->hw_config.min_height;
+	u8 *r_data = NULL;
+	u8 *g_data = NULL;
+	u8 *b_data = NULL;
+	u8 *a_data = NULL;
+	size_t el_size = sizeof(u8);
+	u8 *pixel_mem_data;
+	int ret, i, j;
+
+	/* ensure valid conditions for update */
+	if (logo_layer->id != mixer->logo_layer_id)
+		return 0;
+
+	if (src_h > max_height || src_w > max_width ||
+	    src_h < min_height || src_w < min_width) {
+		DRM_ERROR("Mixer logo/cursor layer dimensions illegal.\n");
+		return -EINVAL;
+	}
+
+	if (!xlnx_mix_isfmt_support(plane->mixer_layer->hw_config.vid_fmt)) {
+		DRM_ERROR("DRM color format not supported for logo layer\n");
+		return -EINVAL;
+	}
+	per_pixel_alpha = (logo_layer->hw_config.vid_fmt ==
+			   DRM_FORMAT_RGBA8888) ? true : false;
+	r_data = kcalloc(pixel_cnt, el_size, GFP_KERNEL);
+	g_data = kcalloc(pixel_cnt, el_size, GFP_KERNEL);
+	b_data = kcalloc(pixel_cnt, el_size, GFP_KERNEL);
+	if (per_pixel_alpha)
+		a_data = kcalloc(pixel_cnt, el_size, GFP_KERNEL);
+
+	if (!r_data || !g_data || !b_data || (per_pixel_alpha && !a_data)) {
+		DRM_ERROR("Unable to allocate memory for logo layer data\n");
+		ret = -ENOMEM;
+		goto free;
+	}
+	/* ensure buffer attributes have changed to indicate new logo
+	 * has been created
+	 */
+	if ((phys_addr_t)buffer->vaddr == logo_layer->layer_regs.buff_addr1 &&
+	    src_w == logo_layer->layer_regs.width &&
+	    src_h == logo_layer->layer_regs.height)
+		return 0;
+
+	/* cache buffer address for future comparison */
+	logo_layer->layer_regs.buff_addr1 = (phys_addr_t)buffer->vaddr;
+	pixel_mem_data = (u8 *)(buffer->vaddr);
+	for (i = 0, j = 0; j < pixel_cnt; j++) {
+		if (per_pixel_alpha && a_data)
+			a_data[j] = pixel_mem_data[i++];
+
+		b_data[j] = pixel_mem_data[i++];
+		g_data[j] = pixel_mem_data[i++];
+		r_data[j] = pixel_mem_data[i++];
+	}
+	ret = xlnx_mix_logo_load(to_mixer_hw(plane), src_w, src_h, r_data,
+				 g_data, b_data,
+				 per_pixel_alpha ? a_data : NULL);
+free:
+	kfree(r_data);
+	kfree(g_data);
+	kfree(b_data);
+	kfree(a_data);
+
+	return ret;
+}
+
+/**
+ * xlnx_mix_set_plane - Implementation of DRM plane_update callback
+ * @plane: xlnx_mix_plane object containing references to
+ *  the base plane and mixer
+ * @fb: Framebuffer descriptor
+ * @crtc_x: X position of layer on crtc.  Note, if the plane represents either
+ *  the master hardware layer (video0) or the layer representing the DRM primary
+ *  layer, the crtc x/y coordinates are either ignored and/or set to 0/0
+ *  respectively.
+ * @crtc_y: Y position of layer.  See description of crtc_x handling
+ * for more inforation.
+ * @src_x: x-offset in memory buffer from which to start reading
+ * @src_y: y-offset in memory buffer from which to start reading
+ * @src_w: Number of horizontal pixels to read from memory per row
+ * @src_h: Number of rows of video data to read from memory
+ *
+ * Configures a mixer layer to comply with user space SET_PLANE icotl
+ * call.
+ *
+ * Return:
+ * Zero on success, non-zero linux error code otherwise.
+ */
+static int xlnx_mix_set_plane(struct xlnx_mix_plane *plane,
+			      struct drm_framebuffer *fb,
+			      int crtc_x, int crtc_y,
+			      u32 src_x, u32 src_y,
+			      u32 src_w, u32 src_h)
+{
+	struct xlnx_mix_hw *mixer_hw;
+	struct xlnx_mix *mixer;
+	struct drm_gem_dma_object *luma_buffer;
+	u32 luma_stride = fb->pitches[0];
+	dma_addr_t luma_addr, chroma_addr = 0, chroma_addr2 = 0;
+	u32 active_area_width;
+	u32 active_area_height;
+	enum xlnx_mix_layer_id layer_id;
+	int ret;
+	const struct drm_format_info *info = fb->format;
+
+	mixer = plane->mixer;
+	mixer_hw = &mixer->mixer_hw;
+	layer_id = plane->mixer_layer->id;
+	active_area_width =
+		mixer->drm_primary_layer->mixer_layer->layer_regs.width;
+	active_area_height =
+		mixer->drm_primary_layer->mixer_layer->layer_regs.height;
+	/* compute memory data */
+	luma_buffer = drm_fb_dma_get_gem_obj(fb, 0);
+	luma_addr = drm_fb_dma_get_gem_addr(fb, plane->base.state, 0);
+	if (!luma_addr) {
+		DRM_ERROR("%s failed to get luma paddr\n", __func__);
+		return -EINVAL;
+	}
+
+	if (info->num_planes > 1) {
+		chroma_addr = drm_fb_dma_get_gem_addr(fb, plane->base.state, 1);
+		if (!chroma_addr) {
+			DRM_ERROR("failed to get chroma paddr\n");
+			return -EINVAL;
+		}
+
+		/* Allocating the buffer for 3rd Plane use case */
+		if (mixer_hw->three_planes_prop && plane->mixer_layer->hw_config.plane_3) {
+			chroma_addr2 = drm_fb_dma_get_gem_addr(fb, plane->base.state, 2);
+			if (!chroma_addr2) {
+				DRM_ERROR("failed to get chroma paddr 2\n");
+				return -EINVAL;
+			}
+		}
+	}
+	ret = xlnx_mix_mark_layer_active(plane);
+	if (ret)
+		return ret;
+
+	switch (layer_id) {
+	case XVMIX_LAYER_MASTER:
+		if (!plane->mixer_layer->hw_config.is_streaming)
+			xlnx_mix_mark_layer_inactive(plane);
+		if (mixer->drm_primary_layer == mixer->hw_master_layer) {
+			xlnx_mix_layer_disable(mixer_hw, layer_id);
+			ret = xlnx_mix_set_active_area(mixer_hw, src_w, src_h);
+			if (ret)
+				return ret;
+			xlnx_mix_layer_enable(mixer_hw, layer_id);
+
+		} else if (src_w != active_area_width ||
+			   src_h != active_area_height) {
+			DRM_ERROR("Invalid dimensions for mixer layer 0.\n");
+			return -EINVAL;
+		}
+		break;
+
+	default:
+		ret = xlnx_mix_set_layer_dimensions(plane, crtc_x, crtc_y,
+						    src_w, src_h, luma_stride);
+		if (ret)
+			break;
+		if (layer_id == mixer_hw->logo_layer_id) {
+			ret = xlnx_mix_update_logo_img(plane, luma_buffer,
+						       src_w, src_h);
+		} else {
+			if (!plane->mixer_layer->hw_config.is_streaming)
+				ret = xlnx_mix_set_layer_buff_addr
+					(mixer_hw, plane->mixer_layer->id,
+					 luma_addr, chroma_addr, chroma_addr2);
+		}
+	}
+	return ret;
+}
+
+/* mode set a plane */
+static int xlnx_mix_plane_mode_set(struct drm_plane *base_plane,
+				   struct drm_framebuffer *fb,
+				   int crtc_x, int crtc_y,
+				   unsigned int crtc_w, unsigned int crtc_h,
+				   u32 src_x, uint32_t src_y,
+				   u32 src_w, uint32_t src_h)
+{
+	struct xlnx_mix_plane *plane = to_xlnx_plane(base_plane);
+	struct xlnx_mix_hw *mixer_hw = to_mixer_hw(plane);
+	const struct drm_format_info *info = fb->format;
+	size_t i = 0;
+	dma_addr_t luma_paddr;
+	int ret;
+	u32 stride;
+
+	/* JPM TODO begin start of code to extract into prep-interleaved*/
+	DRM_DEBUG_KMS("plane->id: %d\n", plane->id);
+	DRM_DEBUG_KMS("h: %d(%d), v: %d(%d)\n", src_w, crtc_x, src_h, crtc_y);
+
+	/* We have multiple dma channels.  Set each per video plane */
+	for (; i < info->num_planes; i++) {
+		unsigned int width = src_w / (i ? info->hsub : 1);
+		unsigned int height = src_h / (i ? info->vsub : 1);
+
+		luma_paddr = drm_fb_dma_get_gem_addr(fb, base_plane->state, i);
+		if (!luma_paddr) {
+			DRM_ERROR("%s failed to get luma paddr\n", __func__);
+			return -EINVAL;
+		}
+
+		plane->dma[i].xt.numf = height;
+		plane->dma[i].sgl[0].size =
+			drm_format_plane_width_bytes(info, 0, width);
+		plane->dma[i].sgl[0].icg = fb->pitches[0] -
+						plane->dma[i].sgl[0].size;
+		plane->dma[i].xt.src_start = luma_paddr;
+		plane->dma[i].xt.frame_size = info->num_planes;
+		plane->dma[i].xt.dir = DMA_MEM_TO_DEV;
+		plane->dma[i].xt.src_sgl = true;
+		plane->dma[i].xt.dst_sgl = false;
+		plane->dma[i].is_active = true;
+	}
+
+	for (; i < XVMIX_MAX_NUM_SUB_PLANES; i++)
+		plane->dma[i].is_active = false;
+	/* Do we have a video format aware dma channel?
+	 * If so, modify descriptor accordingly
+	 */
+	if (plane->dma[0].chan && !plane->dma[1].chan && info->num_planes > 1) {
+		stride = plane->dma[0].sgl[0].size + plane->dma[0].sgl[0].icg;
+		plane->dma[0].sgl[0].src_icg = plane->dma[1].xt.src_start -
+				plane->dma[0].xt.src_start -
+				(plane->dma[0].xt.numf * stride);
+	}
+
+	if (mixer_hw->csc_enabled) {
+		/**
+		 * magic numbers of coefficient table for colorimetry
+		 * and range are derived from the following references:
+		 * [1] Rec. ITU-R BT.601-6
+		 * [2] Rec. ITU-R BT.709-5
+		 * [3] Rec. ITU-R BT.2020
+		 * [4] http://en.wikipedia.org/wiki/YCbCr
+		 * coefficient table supports BT601 / BT709 / BT2020 encoding
+		 * schemes and 16-235(limited) / 16-240(full) range.
+		 */
+		xlnx_mix_set_yuv2_rgb_coeff(plane,
+					    base_plane->state->color_encoding,
+					    base_plane->state->color_range);
+		xlnx_mix_set_rgb2_yuv_coeff(plane,
+					    base_plane->state->color_encoding,
+					    base_plane->state->color_range);
+	}
+
+	ret = xlnx_mix_set_plane(plane, fb, crtc_x, crtc_y, src_x, src_y,
+				 src_w, src_h);
+	return ret;
+}
+
+static int xlnx_mix_plane_prepare_fb(struct drm_plane *plane,
+				     struct drm_plane_state *new_state)
+{
+	return 0;
+}
+
+static void xlnx_mix_plane_cleanup_fb(struct drm_plane *plane,
+				      struct drm_plane_state *old_state)
+{
+}
+
+static int xlnx_mix_plane_atomic_check(struct drm_plane *plane,
+				       struct drm_atomic_state *statea)
+{
+	int scale;
+	struct xlnx_mix_plane *mix_plane = to_xlnx_plane(plane);
+	struct xlnx_mix_hw *mixer_hw = to_mixer_hw(mix_plane);
+	struct xlnx_mix *mix;
+	int scale_factor[3] = {1, 2, 4};
+	struct drm_plane_state *state = drm_atomic_get_new_plane_state(statea,
+								       plane);
+
+	/* No check required for the drm_primary_plane */
+	mix = container_of(mixer_hw, struct xlnx_mix, mixer_hw);
+	if (mix->drm_primary_layer == mix_plane)
+		return 0;
+
+	scale = xlnx_mix_get_layer_scaling(mixer_hw,
+					   mix_plane->mixer_layer->id);
+
+	if (state->fb && (((state->src_w >> 16) * scale_factor[scale] != state->crtc_w) ||
+			  ((state->src_h >> 16) * scale_factor[scale] != state->crtc_h))) {
+		DRM_DEBUG_KMS("Not possible to scale to the desired dimensions\n");
+		return -EINVAL;
+	}
+
+	if (is_window_valid(mixer_hw, state->crtc_x, state->crtc_y,
+			    state->src_w >> 16, state->src_h >> 16, scale))
+		return 0;
+
+	return -EINVAL;
+}
+
+static void xlnx_mix_plane_atomic_update(struct drm_plane *plane,
+					 struct drm_atomic_state *state)
+{
+	int ret;
+	struct drm_plane_state *old_state = drm_atomic_get_old_plane_state(state, plane);
+
+	if (!plane->state->crtc || !plane->state->fb)
+		return;
+
+	if (old_state->fb &&
+	    old_state->fb->format->format != plane->state->fb->format->format)
+		xlnx_mix_plane_dpms(plane, DRM_MODE_DPMS_OFF);
+
+	ret = xlnx_mix_plane_mode_set(plane, plane->state->fb,
+				      plane->state->crtc_x,
+				      plane->state->crtc_y,
+				      plane->state->crtc_w,
+				      plane->state->crtc_h,
+				      plane->state->src_x >> 16,
+				      plane->state->src_y >> 16,
+				      plane->state->src_w >> 16,
+				      plane->state->src_h >> 16);
+	if (ret) {
+		DRM_ERROR("failed to mode-set a plane\n");
+		return;
+	}
+	/* apply the new fb addr */
+	xlnx_mix_plane_commit(plane);
+	/* make sure a plane is on */
+	xlnx_mix_plane_dpms(plane, DRM_MODE_DPMS_ON);
+}
+
+static void xlnx_mix_plane_atomic_disable(struct drm_plane *plane,
+					  struct drm_atomic_state *state)
+{
+	xlnx_mix_plane_dpms(plane, DRM_MODE_DPMS_OFF);
+}
+
+static int xlnx_mix_plane_atomic_async_check(struct drm_plane *plane,
+					     struct drm_atomic_state *state)
+{
+	return 0;
+}
+
+static void
+xlnx_mix_plane_atomic_async_update(struct drm_plane *plane,
+				   struct drm_atomic_state *state)
+{
+	struct drm_plane_state *new_state =
+		drm_atomic_get_new_plane_state(state, plane);
+
+	/* Update the current state with new configurations */
+	swap(plane->state->fb, new_state->fb);
+	plane->state->crtc = new_state->crtc;
+	plane->state->crtc_x = new_state->crtc_x;
+	plane->state->crtc_y = new_state->crtc_y;
+	plane->state->crtc_w = new_state->crtc_w;
+	plane->state->crtc_h = new_state->crtc_h;
+	plane->state->src_x = new_state->src_x;
+	plane->state->src_y = new_state->src_y;
+	plane->state->src_w = new_state->src_w;
+	plane->state->src_h = new_state->src_h;
+	plane->state->state = new_state->state;
+
+	xlnx_mix_plane_atomic_update(plane, state);
+}
+
+static const struct drm_plane_helper_funcs xlnx_mix_plane_helper_funcs = {
+	.prepare_fb	= xlnx_mix_plane_prepare_fb,
+	.cleanup_fb	= xlnx_mix_plane_cleanup_fb,
+	.atomic_check	= xlnx_mix_plane_atomic_check,
+	.atomic_update	= xlnx_mix_plane_atomic_update,
+	.atomic_disable	= xlnx_mix_plane_atomic_disable,
+	.atomic_async_check = xlnx_mix_plane_atomic_async_check,
+	.atomic_async_update = xlnx_mix_plane_atomic_async_update,
+};
+
+static int xlnx_mix_init_plane(struct xlnx_mix_plane *plane,
+			       unsigned int poss_crtcs,
+			       struct device_node *layer_node)
+{
+	struct xlnx_mix *mixer = plane->mixer;
+	char name[16];
+	enum drm_plane_type type;
+	int ret, i;
+
+	plane->dpms = DRM_MODE_DPMS_OFF;
+	type = DRM_PLANE_TYPE_OVERLAY;
+
+	for (i = 0; i < XVMIX_MAX_NUM_SUB_PLANES; i++) {
+		snprintf(name, sizeof(name), "dma%d", i);
+		plane->dma[i].chan = of_dma_request_slave_channel(layer_node,
+								  name);
+		if (PTR_ERR(plane->dma[i].chan) == -ENODEV) {
+			plane->dma[i].chan = NULL;
+			continue;
+		}
+		if (IS_ERR(plane->dma[i].chan)) {
+			DRM_ERROR("failed to request dma channel\n");
+			ret = PTR_ERR(plane->dma[i].chan);
+			plane->dma[i].chan = NULL;
+			goto err_dma;
+		}
+	}
+	if (!xlnx_mix_isfmt_support(plane->mixer_layer->hw_config.vid_fmt)) {
+		DRM_ERROR("DRM color format not supported by mixer\n");
+		ret = -ENODEV;
+		goto err_init;
+	}
+	plane->format = plane->mixer_layer->hw_config.vid_fmt;
+	if (plane == mixer->hw_logo_layer)
+		type = DRM_PLANE_TYPE_CURSOR;
+	if (plane == mixer->drm_primary_layer)
+		type = DRM_PLANE_TYPE_PRIMARY;
+
+	/* initialize drm plane */
+	ret = drm_universal_plane_init(mixer->drm, &plane->base,
+				       poss_crtcs, &xlnx_mix_plane_funcs,
+				       &plane->format,
+				       1, NULL, type, NULL);
+
+	if (ret) {
+		DRM_ERROR("failed to initialize plane\n");
+		goto err_init;
+	}
+	drm_plane_helper_add(&plane->base, &xlnx_mix_plane_helper_funcs);
+	of_node_put(layer_node);
+
+	return 0;
+
+err_init:
+	xlnx_mix_disp_layer_disable(plane);
+err_dma:
+	for (i = 0; i < XVMIX_MAX_NUM_SUB_PLANES; i++)
+		if (plane->dma[i].chan)
+			dma_release_channel(plane->dma[i].chan);
+
+	of_node_put(layer_node);
+	return ret;
+}
+
+static int xlnx_mix_parse_dt_bg_video_fmt(struct device_node *node,
+					  struct xlnx_mix_hw *mixer_hw)
+{
+	struct device_node *layer_node;
+	struct xlnx_mix_layer_data *layer;
+	const char *vformat;
+
+	layer_node = of_get_child_by_name(node, "layer_0");
+	layer = &mixer_hw->layer_data[XVMIX_MASTER_LAYER_IDX];
+
+	/* Set default values */
+	layer->hw_config.can_alpha = false;
+	layer->hw_config.can_scale = false;
+	layer->hw_config.min_width = XVMIX_LAYER_WIDTH_MIN;
+	layer->hw_config.min_height = XVMIX_LAYER_HEIGHT_MIN;
+
+	if (of_property_count_u8_elems(layer_node, "xlnx,vformat") != sizeof(u32) + 1) {
+		DRM_ERROR("xlnx,vformat property missing or invalid\n");
+		return -EINVAL;
+	}
+
+	if (of_property_read_string(layer_node, "xlnx,vformat", &vformat)) {
+		DRM_ERROR("No xlnx,vformat value for layer 0 in dts\n");
+		return -EINVAL;
+	}
+
+	layer->hw_config.vid_fmt = fourcc_code(vformat[0], vformat[1], vformat[2], vformat[3]);
+	if (!drm_format_info(layer->hw_config.vid_fmt))
+		return -EINVAL;
+
+	layer->hw_config.is_streaming =
+		of_property_read_bool(layer_node, "xlnx,layer-streaming");
+	if (of_property_read_u32(node, "xlnx,bpc", &mixer_hw->bg_layer_bpc)) {
+		DRM_ERROR("Failed to get bits per component (bpc) prop\n");
+		return -EINVAL;
+	}
+
+	/* set only when 3 Plane video formats are selected */
+	layer->hw_config.plane_3 = 0;
+
+	if (of_property_read_u32(layer_node, "xlnx,layer-max-width",
+				 &layer->hw_config.max_width)) {
+		DRM_ERROR("Failed to get screen width prop\n");
+		return -EINVAL;
+	} else if (layer->hw_config.max_width > XVMIX_DISP_MAX_WIDTH ||
+		   layer->hw_config.max_width < XVMIX_DISP_MIN_WIDTH) {
+		DRM_ERROR("Invalid width in dt");
+		return -EINVAL;
+	}
+
+	mixer_hw->max_layer_width = layer->hw_config.max_width;
+	if (of_property_read_u32(layer_node, "xlnx,layer-max-height",
+				 &layer->hw_config.max_height)) {
+		DRM_ERROR("Failed to get screen height prop\n");
+		return -EINVAL;
+	} else if (layer->hw_config.max_height > XVMIX_DISP_MAX_HEIGHT ||
+		   layer->hw_config.max_height < XVMIX_DISP_MIN_HEIGHT) {
+		DRM_ERROR("Invalid height in dt");
+		return -EINVAL;
+	}
+
+	mixer_hw->max_layer_height = layer->hw_config.max_height;
+	layer->id = XVMIX_LAYER_MASTER;
+
+	return 0;
+}
+
+static int xlnx_mix_parse_dt_logo_data(struct device_node *node,
+				       struct xlnx_mix_hw *mixer_hw)
+{
+	struct xlnx_mix_layer_data *layer_data;
+	struct device_node *logo_node;
+	u32 max_width, max_height;
+
+	logo_node = of_get_child_by_name(node, "logo");
+	if (!logo_node) {
+		DRM_ERROR("No logo node specified in device tree.\n");
+		return -EINVAL;
+	}
+
+	layer_data = &mixer_hw->layer_data[XVMIX_LOGO_LAYER_IDX];
+
+	/* set defaults for logo layer */
+	layer_data->hw_config.min_height = XVMIX_LOGO_LAYER_HEIGHT_MIN;
+	layer_data->hw_config.min_width = XVMIX_LOGO_LAYER_WIDTH_MIN;
+	layer_data->hw_config.is_streaming = false;
+	layer_data->hw_config.vid_fmt = DRM_FORMAT_RGB888;
+	layer_data->hw_config.can_alpha = true;
+	layer_data->hw_config.can_scale = true;
+	layer_data->layer_regs.buff_addr1 = 0;
+	layer_data->layer_regs.buff_addr2 = 0;
+	layer_data->layer_regs.buff_addr3 = 0;
+	layer_data->id = mixer_hw->logo_layer_id;
+
+	if (of_property_read_u32(logo_node, "xlnx,logo-width", &max_width)) {
+		DRM_ERROR("Failed to get logo width prop\n");
+		return -EINVAL;
+	}
+	if (max_width > XVMIX_LOGO_LAYER_WIDTH_MAX ||
+	    max_width < XVMIX_LOGO_LAYER_WIDTH_MIN) {
+		DRM_ERROR("Illegal mixer logo layer width.\n");
+		return -EINVAL;
+	}
+	layer_data->hw_config.max_width = max_width;
+	mixer_hw->max_logo_layer_width = layer_data->hw_config.max_width;
+
+	if (of_property_read_u32(logo_node, "xlnx,logo-height", &max_height)) {
+		DRM_ERROR("Failed to get logo height prop\n");
+		return -EINVAL;
+	}
+	if (max_height > XVMIX_LOGO_LAYER_HEIGHT_MAX ||
+	    max_height < XVMIX_LOGO_LAYER_HEIGHT_MIN) {
+		DRM_ERROR("Illegal mixer logo layer height.\n");
+		return -EINVAL;
+	}
+	layer_data->hw_config.max_height = max_height;
+	mixer_hw->max_logo_layer_height = layer_data->hw_config.max_height;
+	mixer_hw->logo_pixel_alpha_enabled =
+		of_property_read_bool(logo_node, "xlnx,logo-pixel-alpha");
+	if (mixer_hw->logo_pixel_alpha_enabled)
+		layer_data->hw_config.vid_fmt = DRM_FORMAT_RGBA8888;
+
+	return 0;
+}
+
+static int xlnx_mix_dt_dp_bridge(struct device *dev, struct xlnx_mix *mixer)
+{
+	struct device_node *node, *disp_node;
+
+	node = dev->of_node;
+	/* Disp Bridge support */
+	disp_node = of_parse_phandle(node, "xlnx,disp-bridge", 0);
+	if (disp_node) {
+		mixer->disp_bridge = of_xlnx_bridge_get(disp_node);
+		if (!mixer->disp_bridge) {
+			dev_info(dev, "Didn't get disp bridge instance\n");
+			return -1;
+		}
+	} else {
+		dev_info(dev, "disp bridge property not present\n");
+		return -1;
+	}
+	return 0;
+}
+
+static int xlnx_mix_dt_parse(struct device *dev, struct xlnx_mix *mixer)
+{
+	struct xlnx_mix_plane *planes;
+	struct xlnx_mix_hw *mixer_hw;
+	struct device_node *node, *vtc_node, *port;
+	struct xlnx_mix_layer_data *l_data;
+	struct resource	res;
+	int ret, l_cnt, i;
+
+	node = dev->of_node;
+	mixer_hw = &mixer->mixer_hw;
+	mixer->dpms = DRM_MODE_DPMS_OFF;
+
+	mixer_hw->reset_gpio = devm_gpiod_get(dev, "reset", GPIOD_OUT_LOW);
+	if (IS_ERR(mixer_hw->reset_gpio)) {
+		ret = PTR_ERR(mixer_hw->reset_gpio);
+		if (ret == -EPROBE_DEFER)
+			dev_dbg(dev, "No gpio probed for mixer. Deferring\n");
+		else
+			dev_err(dev, "No reset gpio info from dts for mixer\n");
+		return ret;
+	}
+	gpiod_set_raw_value(mixer_hw->reset_gpio, 0);
+	gpiod_set_raw_value(mixer_hw->reset_gpio, 1);
+
+	ret = of_address_to_resource(node, 0, &res);
+	if (ret) {
+		dev_err(dev, "Invalid memory address for mixer %d\n", ret);
+		return ret;
+	}
+	/* Read in mandatory global dts properties */
+	mixer_hw->base = devm_ioremap_resource(dev, &res);
+	if (IS_ERR(mixer_hw->base)) {
+		dev_err(dev, "Failed to map io mem space for mixer\n");
+		return PTR_ERR(mixer_hw->base);
+	}
+
+	if (of_device_is_compatible(dev->of_node, "xlnx,mixer-3.0") ||
+	    of_device_is_compatible(dev->of_node, "xlnx,mixer-4.0"))
+		dev_warn(dev, "xlnx,mixer-3.0/4.0 are deprecated.\n");
+
+	if (of_device_is_compatible(dev->of_node, "xlnx,v-mix-5.3"))
+		mixer_hw->three_planes_prop = true;
+
+	if (of_device_is_compatible(dev->of_node, "xlnx,mixer-4.0") ||
+	    of_device_is_compatible(dev->of_node, "xlnx,mixer-5.0") ||
+	    of_device_is_compatible(dev->of_node, "xlnx,v-mix-5.3")) {
+		mixer_hw->max_layers = 18;
+		mixer_hw->logo_en_mask = BIT(23);
+		mixer_hw->enable_all_mask = (GENMASK(16, 0) |
+						mixer_hw->logo_en_mask);
+	} else {
+		mixer_hw->max_layers = 10;
+		mixer_hw->logo_en_mask = BIT(15);
+		mixer_hw->enable_all_mask = (GENMASK(8, 0) |
+						mixer_hw->logo_en_mask);
+	}
+	if (of_device_is_compatible(dev->of_node, "xlnx,mixer-5.0")) {
+		const char *prop_name = "xlnx,enable-csc-coefficient-register";
+
+		mixer_hw->csc_enabled = of_property_read_bool(node, prop_name);
+	}
+
+	ret = of_property_read_u32(node, "xlnx,num-layers",
+				   &mixer_hw->num_layers);
+	if (ret) {
+		dev_err(dev, "No xlnx,num-layers dts prop for mixer node\n");
+		return ret;
+	}
+	mixer_hw->logo_layer_id = mixer_hw->max_layers - 1;
+	if (mixer_hw->num_layers > mixer_hw->max_layers) {
+		dev_err(dev, "Num layer nodes in device tree > mixer max\n");
+		return -EINVAL;
+	}
+	ret = of_property_read_u32(node, "xlnx,dma-addr-width",
+				   &mixer_hw->dma_addr_size);
+	if (ret) {
+		dev_err(dev, "missing addr-width dts prop\n");
+		return ret;
+	}
+	if (mixer_hw->dma_addr_size != 32 && mixer_hw->dma_addr_size != 64) {
+		dev_err(dev, "invalid addr-width dts prop\n");
+		return -EINVAL;
+	}
+
+	/* VTC Bridge support */
+	vtc_node = of_parse_phandle(node, "xlnx,bridge", 0);
+	if (vtc_node) {
+		mixer->vtc_bridge = of_xlnx_bridge_get(vtc_node);
+		if (!mixer->vtc_bridge) {
+			dev_info(dev, "Didn't get vtc bridge instance\n");
+			return -EPROBE_DEFER;
+		}
+	} else {
+		dev_info(dev, "vtc bridge property not present\n");
+	}
+
+	mixer_hw->logo_layer_en = of_property_read_bool(node,
+							"xlnx,logo-layer");
+	l_cnt = mixer_hw->num_layers + (mixer_hw->logo_layer_en ? 1 : 0);
+	mixer_hw->layer_cnt = l_cnt;
+
+	l_data = devm_kzalloc(dev, sizeof(*l_data) * l_cnt, GFP_KERNEL);
+	if (!l_data)
+		return -ENOMEM;
+	mixer_hw->layer_data = l_data;
+	/* init DRM planes */
+	planes = devm_kzalloc(dev, sizeof(*planes) * l_cnt, GFP_KERNEL);
+	if (!planes)
+		return -ENOMEM;
+	mixer->planes = planes;
+	mixer->num_planes = l_cnt;
+	for (i = 0; i < mixer->num_planes; i++)
+		mixer->planes[i].mixer = mixer;
+
+	/* establish background layer video properties from dts */
+	ret = xlnx_mix_parse_dt_bg_video_fmt(node, mixer_hw);
+	if (ret)
+		return ret;
+	if (mixer_hw->logo_layer_en) {
+		/* read logo data from dts */
+		ret = xlnx_mix_parse_dt_logo_data(node, mixer_hw);
+		return ret;
+	}
+
+	/* Fill out crtc port OF node */
+	for_each_child_of_node(node, port) {
+		if (!port->name || of_node_cmp(port->name, "port"))
+			continue;
+		mixer->crtc.crtc.port = port;
+		break;
+	}
+	return 0;
+}
+
+static int xlnx_mix_of_init_layer(struct device *dev, struct device_node *node,
+				  char *name, struct xlnx_mix_layer_data *layer,
+				  u32 max_width, struct xlnx_mix *mixer, int id)
+{
+	struct device_node *layer_node;
+	const struct drm_format_info *info;
+	const char *vformat;
+	int ret;
+
+	layer_node = of_get_child_by_name(node, name);
+	if (!layer_node)
+		return -EINVAL;
+
+	/* Set default values */
+	layer->hw_config.can_alpha = false;
+	layer->hw_config.can_scale = false;
+	layer->hw_config.is_streaming = false;
+	layer->hw_config.max_width = max_width;
+	layer->hw_config.min_width = XVMIX_LAYER_WIDTH_MIN;
+	layer->hw_config.min_height = XVMIX_LAYER_HEIGHT_MIN;
+	layer->hw_config.vid_fmt = 0;
+	layer->id = 0;
+	mixer->planes[id].mixer_layer = layer;
+
+	ret = of_property_read_u32(layer_node, "xlnx,layer-id", &layer->id);
+	if (ret) {
+		dev_err(dev, "xlnx,layer-id property not found\n");
+		return ret;
+	}
+	if (layer->id < 1 || layer->id >= mixer->mixer_hw.max_layers) {
+		dev_err(dev, "Mixer layer id %u in dts is out of legal range\n",
+			layer->id);
+		return -EINVAL;
+	}
+
+	if (of_property_count_u8_elems(layer_node, "xlnx,vformat") != sizeof(u32) + 1) {
+		DRM_ERROR("xlnx,vformat property missing or invalid\n");
+		return -EINVAL;
+	}
+
+	if (of_property_read_string(layer_node, "xlnx,vformat", &vformat)) {
+		DRM_ERROR("No xlnx,vformat value for layer 0 in dts\n");
+		return -EINVAL;
+	}
+
+	layer->hw_config.vid_fmt = fourcc_code(vformat[0], vformat[1], vformat[2], vformat[3]);
+	info = drm_format_info(layer->hw_config.vid_fmt);
+	if (!info) {
+		DRM_ERROR("No DRM info, Invalid fourcc code\n");
+		return -EINVAL;
+	}
+
+	/* Set flag only for 3 planar video formats */
+	if (info->num_planes == 3)
+		layer->hw_config.plane_3 = true;
+
+	layer->hw_config.can_scale =
+		    of_property_read_bool(layer_node, "xlnx,layer-scale");
+	if (layer->hw_config.can_scale) {
+		ret = of_property_read_u32(layer_node, "xlnx,layer-max-width",
+					   &layer->hw_config.max_width);
+		if (ret) {
+			dev_err(dev, "Mixer layer %d dts missing width prop.\n",
+				layer->id);
+			return ret;
+		}
+
+		if (layer->hw_config.max_width > max_width) {
+			dev_err(dev, "Illlegal Mixer layer %d width %d\n",
+				layer->id, layer->hw_config.max_width);
+			return -EINVAL;
+		}
+	}
+	layer->hw_config.can_alpha =
+		    of_property_read_bool(layer_node, "xlnx,layer-alpha");
+	layer->hw_config.is_streaming =
+		    of_property_read_bool(layer_node, "xlnx,layer-streaming");
+	if (of_property_read_bool(layer_node, "xlnx,layer-primary")) {
+		if (mixer->drm_primary_layer) {
+			dev_err(dev,
+				"More than one primary layer in mixer dts\n");
+			return -EINVAL;
+		}
+		mixer->drm_primary_layer = &mixer->planes[id];
+	}
+	ret = xlnx_mix_init_plane(&mixer->planes[id], 1, layer_node);
+	if (ret)
+		dev_err(dev, "Unable to init drm mixer plane id = %u", id);
+
+	return ret;
+}
+
+static irqreturn_t xlnx_mix_intr_handler(int irq, void *data)
+{
+	struct xlnx_mix_hw *mixer = data;
+	u32 intr = xlnx_mix_get_intr_status(mixer);
+
+	if (!intr)
+		return IRQ_NONE;
+	if (mixer->intrpt_handler_fn)
+		mixer->intrpt_handler_fn(mixer->intrpt_data);
+	xlnx_mix_clear_intr_status(mixer, intr);
+
+	return IRQ_HANDLED;
+}
+
+static void xlnx_mix_create_plane_properties(struct xlnx_mix *mixer)
+{
+	mixer->scale_prop = drm_property_create_range(mixer->drm, 0, "scale",
+						      XVMIX_SCALE_FACTOR_1X,
+						      XVMIX_SCALE_FACTOR_4X);
+	mixer->alpha_prop = drm_property_create_range(mixer->drm, 0, "alpha",
+						      XVMIX_ALPHA_MIN,
+						      XVMIX_ALPHA_MAX);
+}
+
+static int xlnx_mix_plane_create(struct device *dev, struct xlnx_mix *mixer)
+{
+	struct xlnx_mix_hw		*mixer_hw;
+	struct device_node		*node, *layer_node;
+	char				name[20];
+	struct xlnx_mix_layer_data	*layer_data;
+	int				ret, i;
+	int				layer_idx;
+
+	node = dev->of_node;
+	mixer_hw = &mixer->mixer_hw;
+	xlnx_mix_create_plane_properties(mixer);
+
+	mixer->planes[XVMIX_MASTER_LAYER_IDX].mixer_layer =
+				&mixer_hw->layer_data[XVMIX_MASTER_LAYER_IDX];
+	mixer->planes[XVMIX_MASTER_LAYER_IDX].id = XVMIX_MASTER_LAYER_IDX;
+	mixer->hw_master_layer = &mixer->planes[XVMIX_MASTER_LAYER_IDX];
+
+	if (mixer_hw->logo_layer_en) {
+		mixer->planes[XVMIX_LOGO_LAYER_IDX].mixer_layer =
+				&mixer_hw->layer_data[XVMIX_LOGO_LAYER_IDX];
+		mixer->planes[XVMIX_LOGO_LAYER_IDX].id = XVMIX_LOGO_LAYER_IDX;
+		mixer->hw_logo_layer = &mixer->planes[XVMIX_LOGO_LAYER_IDX];
+		layer_node = of_get_child_by_name(node, "logo");
+		ret = xlnx_mix_init_plane(&mixer->planes[XVMIX_LOGO_LAYER_IDX],
+					  1, layer_node);
+		if (ret)
+			return ret;
+	}
+	layer_idx = mixer_hw->logo_layer_en ? 2 : 1;
+	for (i = 1; i < mixer_hw->num_layers; i++, layer_idx++) {
+		snprintf(name, sizeof(name), "layer_%d", i);
+		ret = xlnx_mix_of_init_layer(dev, node, name,
+					     &mixer_hw->layer_data[layer_idx],
+					     mixer_hw->max_layer_width,
+					     mixer, layer_idx);
+		if (ret)
+			return ret;
+	}
+	/* If none of the overlay layers were designated as the drm
+	 * primary layer, default to the mixer's video0 layer as drm primary
+	 */
+	if (!mixer->drm_primary_layer)
+		mixer->drm_primary_layer = mixer->hw_master_layer;
+	layer_node = of_get_child_by_name(node, "layer_0");
+	ret = xlnx_mix_init_plane(&mixer->planes[XVMIX_MASTER_LAYER_IDX], 1,
+				  layer_node);
+	/* request irq and obtain pixels-per-clock (ppc) property */
+	mixer_hw->irq = irq_of_parse_and_map(node, 0);
+	if (mixer_hw->irq > 0) {
+		ret = devm_request_irq(dev, mixer_hw->irq,
+				       xlnx_mix_intr_handler,
+				       IRQF_SHARED, "xlnx-mixer", mixer_hw);
+		if (ret) {
+			dev_err(dev, "Failed to request irq\n");
+			return ret;
+		}
+	}
+	ret = of_property_read_u32(node, "xlnx,ppc", &mixer_hw->ppc);
+	if (ret) {
+		dev_err(dev, "No xlnx,ppc property for mixer dts\n");
+		return ret;
+	}
+
+	mixer->max_width = mixer_hw->max_layer_width;
+	mixer->max_height = mixer_hw->max_layer_height;
+
+	if (mixer->hw_logo_layer) {
+		layer_data = &mixer_hw->layer_data[XVMIX_LOGO_LAYER_IDX];
+		mixer->max_cursor_width = layer_data->hw_config.max_width;
+		mixer->max_cursor_height = layer_data->hw_config.max_height;
+	}
+	return 0;
+}
+
+/**
+ * xlnx_mix_plane_restore - Restore the plane states
+ * @mixer: mixer device core structure
+ *
+ * Restore the plane states to the default ones. Any state that needs to be
+ * restored should be here. This improves consistency as applications see
+ * the same default values, and removes mismatch between software and hardware
+ * values as software values are updated as hardware values are reset.
+ */
+static void xlnx_mix_plane_restore(struct xlnx_mix *mixer)
+{
+	struct xlnx_mix_plane *plane;
+	unsigned int i;
+
+	if (!mixer)
+		return;
+	/*
+	 * Reinitialize property default values as they get reset by DPMS OFF
+	 * operation. User will read the correct default values later, and
+	 * planes will be initialized with default values.
+	 */
+	for (i = 0; i < mixer->num_planes; i++) {
+		plane = &mixer->planes[i];
+		if (!plane)
+			continue;
+		xlnx_mix_hw_plane_dpms(plane, DRM_MODE_DPMS_OFF);
+	}
+}
+
+/**
+ * xlnx_mix_set_bkg_col - Set background color
+ * @mixer: Mixer instance to program with new background color
+ * @rgb_value: RGB encoded as 32-bit integer in little-endian format
+ *
+ * Set the color to be output as background color when background stream layer
+ */
+static void xlnx_mix_set_bkg_col(struct xlnx_mix_hw *mixer, u64 rgb_value)
+{
+	u32 bg_bpc = mixer->bg_layer_bpc;
+	u32 bpc_mask_shift = XVMIX_MAX_BPC - bg_bpc;
+	u32 val_mask = (GENMASK(15, 0) >> bpc_mask_shift);
+	u16 b_val = (rgb_value >> (bg_bpc * 2)) & val_mask;
+	u16 g_val = (rgb_value >> bg_bpc) & val_mask;
+	u16 r_val = (rgb_value >> 0) &  val_mask;
+
+	/* Set Background Color */
+	reg_writel(mixer->base, XVMIX_BACKGROUND_Y_R_DATA, r_val);
+	reg_writel(mixer->base, XVMIX_BACKGROUND_U_G_DATA, g_val);
+	reg_writel(mixer->base, XVMIX_BACKGROUND_V_B_DATA, b_val);
+	mixer->bg_color = rgb_value;
+}
+
+/**
+ * xlnx_mix_reset - Reset the mixer core video generator
+ * @mixer: Mixer core instance for which to start video output
+ *
+ * Toggle the reset gpio and restores the bg color, plane and interrupt mask.
+ */
+static void xlnx_mix_reset(struct xlnx_mix *mixer)
+{
+	struct xlnx_mix_hw *mixer_hw = &mixer->mixer_hw;
+
+	gpiod_set_raw_value(mixer_hw->reset_gpio, 0);
+	gpiod_set_raw_value(mixer_hw->reset_gpio, 1);
+	/* restore layer properties and bg color after reset */
+	xlnx_mix_set_bkg_col(mixer_hw, mixer_hw->bg_color);
+	xlnx_mix_plane_restore(mixer);
+	xlnx_mix_intrpt_enable_done(&mixer->mixer_hw);
+}
+
+static void xlnx_mix_dpms(struct xlnx_mix *mixer, int dpms)
+{
+	switch (dpms) {
+	case DRM_MODE_DPMS_ON:
+		xlnx_mix_start(&mixer->mixer_hw);
+		break;
+	default:
+		xlnx_mix_stop(&mixer->mixer_hw);
+		mdelay(50); /* let IP shut down */
+		xlnx_mix_reset(mixer);
+	}
+}
+
+/* set crtc dpms */
+static void xlnx_mix_crtc_dpms(struct drm_crtc *base_crtc, int dpms)
+{
+	struct xlnx_crtc *crtc = to_xlnx_crtc(base_crtc);
+	struct xlnx_mix *mixer = to_xlnx_mixer(crtc);
+	int ret;
+	struct videomode vm;
+	struct drm_display_mode *mode = &base_crtc->mode;
+	struct drm_display_mode *adjusted_mode =
+					&base_crtc->state->adjusted_mode;
+
+	DRM_DEBUG_KMS("dpms: %d\n", dpms);
+	if (mixer->dpms == dpms)
+		return;
+	mixer->dpms = dpms;
+
+	switch (dpms) {
+	case DRM_MODE_DPMS_ON:
+		if (!mixer->pixel_clock_enabled) {
+			ret = clk_prepare_enable(mixer->pixel_clock);
+			if (ret) {
+				DRM_ERROR("failed to enable a pixel clock\n");
+				mixer->pixel_clock_enabled = false;
+			}
+		}
+		mixer->pixel_clock_enabled = true;
+
+		if (mixer->vtc_bridge) {
+			drm_display_mode_to_videomode(mode, &vm);
+			xlnx_bridge_set_timing(mixer->vtc_bridge, &vm);
+			xlnx_bridge_enable(mixer->vtc_bridge);
+		}
+
+		if (mixer->disp_bridge) {
+			drm_display_mode_to_videomode(adjusted_mode, &vm);
+			xlnx_bridge_set_input(mixer->disp_bridge,
+					      adjusted_mode->hdisplay,
+					      adjusted_mode->vdisplay,
+					      xlnx_mix_get_bus_fmt(mixer));
+			xlnx_bridge_set_timing(mixer->disp_bridge, &vm);
+			xlnx_bridge_enable(mixer->disp_bridge);
+		}
+
+		xlnx_mix_dpms(mixer, dpms);
+		xlnx_mix_plane_dpms(base_crtc->primary, dpms);
+		break;
+	default:
+		xlnx_mix_plane_dpms(base_crtc->primary, dpms);
+		xlnx_mix_dpms(mixer, dpms);
+		xlnx_bridge_disable(mixer->vtc_bridge);
+		if (mixer->pixel_clock_enabled) {
+			clk_disable_unprepare(mixer->pixel_clock);
+			mixer->pixel_clock_enabled = false;
+		}
+		break;
+	}
+}
+
+static void xlnx_mix_set_intr_handler(struct xlnx_mix *mixer,
+				      void (*intr_handler_fn)(void *),
+				       void *data)
+{
+	mixer->mixer_hw.intrpt_handler_fn = intr_handler_fn;
+	mixer->mixer_hw.intrpt_data = data;
+}
+
+static void xlnx_mix_crtc_vblank_handler(void *data)
+{
+	struct drm_crtc *base_crtc = data;
+	struct xlnx_crtc *crtc = to_xlnx_crtc(base_crtc);
+	struct xlnx_mix *mixer = to_xlnx_mixer(crtc);
+	struct drm_device *drm = base_crtc->dev;
+	struct drm_pending_vblank_event *event;
+	unsigned long flags;
+
+	drm_crtc_handle_vblank(base_crtc);
+	/* Finish page flip */
+	spin_lock_irqsave(&drm->event_lock, flags);
+	event = mixer->event;
+	mixer->event = NULL;
+	if (event) {
+		drm_crtc_send_vblank_event(base_crtc, event);
+		drm_crtc_vblank_put(base_crtc);
+	}
+	spin_unlock_irqrestore(&drm->event_lock, flags);
+}
+
+static int xlnx_mix_crtc_enable_vblank(struct drm_crtc *base_crtc)
+{
+	struct xlnx_crtc *crtc = to_xlnx_crtc(base_crtc);
+	struct xlnx_mix *mixer = to_xlnx_mixer(crtc);
+
+	xlnx_mix_set_intr_handler(mixer, xlnx_mix_crtc_vblank_handler,
+				  base_crtc);
+	return 0;
+}
+
+static void xlnx_mix_crtc_disable_vblank(struct drm_crtc *base_crtc)
+{
+	struct xlnx_crtc *crtc = to_xlnx_crtc(base_crtc);
+	struct xlnx_mix *mixer = to_xlnx_mixer(crtc);
+
+	mixer->mixer_hw.intrpt_handler_fn = NULL;
+	mixer->mixer_hw.intrpt_data = NULL;
+}
+
+static void xlnx_mix_crtc_destroy(struct drm_crtc *base_crtc)
+{
+	struct xlnx_crtc *crtc = to_xlnx_crtc(base_crtc);
+	struct xlnx_mix *mixer = to_xlnx_mixer(crtc);
+
+	/* make sure crtc is off */
+	mixer->alpha_prop = NULL;
+	mixer->scale_prop = NULL;
+	mixer->bg_color = NULL;
+	xlnx_mix_crtc_dpms(base_crtc, DRM_MODE_DPMS_OFF);
+
+	if (mixer->pixel_clock_enabled) {
+		clk_disable_unprepare(mixer->pixel_clock);
+		mixer->pixel_clock_enabled = false;
+	}
+	drm_crtc_cleanup(base_crtc);
+}
+
+static int
+xlnx_mix_disp_crtc_atomic_set_property(struct drm_crtc *crtc,
+				       struct drm_crtc_state *state,
+				     struct drm_property *property,
+				     uint64_t val)
+{
+	return 0;
+}
+
+static int
+xlnx_mix_disp_crtc_atomic_get_property(struct drm_crtc *crtc,
+				       const struct drm_crtc_state *state,
+				     struct drm_property *property,
+				     uint64_t *val)
+{
+	return 0;
+}
+
+static struct drm_crtc_funcs xlnx_mix_crtc_funcs = {
+	.destroy		= xlnx_mix_crtc_destroy,
+	.set_config		= drm_atomic_helper_set_config,
+	.page_flip		= drm_atomic_helper_page_flip,
+	.atomic_set_property	= xlnx_mix_disp_crtc_atomic_set_property,
+	.atomic_get_property	= xlnx_mix_disp_crtc_atomic_get_property,
+	.reset			= drm_atomic_helper_crtc_reset,
+	.atomic_duplicate_state	= drm_atomic_helper_crtc_duplicate_state,
+	.atomic_destroy_state	= drm_atomic_helper_crtc_destroy_state,
+	.enable_vblank		= xlnx_mix_crtc_enable_vblank,
+	.disable_vblank		= xlnx_mix_crtc_disable_vblank,
+};
+
+static void
+xlnx_mix_crtc_atomic_enable(struct drm_crtc *crtc,
+			    struct drm_atomic_state *state)
+{
+	struct drm_display_mode *adjusted_mode = &crtc->state->adjusted_mode;
+	int vrefresh;
+
+	xlnx_mix_crtc_dpms(crtc, DRM_MODE_DPMS_ON);
+
+	/* Delay of 3 vblank interval for timing gen to be stable */
+	vrefresh = ((adjusted_mode->clock * 1000) /
+		    (adjusted_mode->vtotal * adjusted_mode->htotal));
+	msleep(3 * 1000 / vrefresh);
+}
+
+/**
+ * xlnx_mix_clear_event - Clear any event if pending
+ * @crtc: DRM crtc object
+ *
+ */
+static void xlnx_mix_clear_event(struct drm_crtc *crtc)
+{
+	if (crtc->state->event) {
+		complete_all(crtc->state->event->base.completion);
+		crtc->state->event = NULL;
+	}
+}
+
+static void
+xlnx_mix_crtc_atomic_disable(struct drm_crtc *crtc,
+			     struct drm_atomic_state *state)
+{
+	xlnx_mix_crtc_dpms(crtc, DRM_MODE_DPMS_OFF);
+	xlnx_mix_clear_event(crtc);
+	drm_crtc_vblank_off(crtc);
+}
+
+static void xlnx_mix_crtc_mode_set_nofb(struct drm_crtc *crtc)
+{
+}
+
+static int xlnx_mix_crtc_atomic_check(struct drm_crtc *crtc,
+				      struct drm_atomic_state *state)
+{
+	return drm_atomic_add_affected_planes(state, crtc);
+}
+
+static void
+xlnx_mix_crtc_atomic_begin(struct drm_crtc *crtc,
+			   struct drm_atomic_state *state)
+{
+	drm_crtc_vblank_on(crtc);
+	/* Don't rely on vblank when disabling crtc */
+	if (crtc->state->event) {
+		struct xlnx_crtc *xcrtc = to_xlnx_crtc(crtc);
+		struct xlnx_mix *mixer = to_xlnx_mixer(xcrtc);
+
+		/* Consume the flip_done event from atomic helper */
+		crtc->state->event->pipe = drm_crtc_index(crtc);
+		WARN_ON(drm_crtc_vblank_get(crtc) != 0);
+		mixer->event = crtc->state->event;
+		crtc->state->event = NULL;
+	}
+}
+
+static struct drm_crtc_helper_funcs xlnx_mix_crtc_helper_funcs = {
+	.atomic_enable	= xlnx_mix_crtc_atomic_enable,
+	.atomic_disable	= xlnx_mix_crtc_atomic_disable,
+	.mode_set_nofb	= xlnx_mix_crtc_mode_set_nofb,
+	.atomic_check	= xlnx_mix_crtc_atomic_check,
+	.atomic_begin	= xlnx_mix_crtc_atomic_begin,
+};
+
+/**
+ * xlnx_mix_crtc_create - create crtc for mixer
+ * @mixer: xilinx video mixer object
+ *
+ * Return:
+ * Zero on success, error on failure
+ *
+ */
+static int xlnx_mix_crtc_create(struct xlnx_mix *mixer)
+{
+	struct xlnx_crtc *crtc;
+	int ret, i;
+
+	crtc = &mixer->crtc;
+
+	for (i = 0; i < mixer->num_planes; i++)
+		xlnx_mix_attach_plane_prop(&mixer->planes[i]);
+	mixer->pixel_clock = devm_clk_get(mixer->drm->dev, NULL);
+	if (IS_ERR(mixer->pixel_clock)) {
+		DRM_DEBUG_KMS("failed to get pixel clock\n");
+		mixer->pixel_clock = NULL;
+	}
+	ret = clk_prepare_enable(mixer->pixel_clock);
+	if (ret) {
+		DRM_ERROR("failed to enable a pixel clock\n");
+		mixer->pixel_clock_enabled = false;
+		goto err_plane;
+	}
+	mixer->pixel_clock_enabled = true;
+	/* initialize drm crtc */
+	ret = drm_crtc_init_with_planes(mixer->drm, &crtc->crtc,
+					&mixer->drm_primary_layer->base,
+					&mixer->hw_logo_layer->base,
+					&xlnx_mix_crtc_funcs, NULL);
+	if (ret) {
+		DRM_ERROR("failed to initialize mixer crtc\n");
+		goto err_pixel_clk;
+	}
+	drm_crtc_helper_add(&crtc->crtc, &xlnx_mix_crtc_helper_funcs);
+	crtc->get_max_width = &xlnx_mix_crtc_get_max_width;
+	crtc->get_max_height = &xlnx_mix_crtc_get_max_height;
+	crtc->get_align = &xlnx_mix_crtc_get_align;
+	crtc->get_format = &xlnx_mix_crtc_get_format;
+	crtc->get_cursor_height = &xlnx_mix_crtc_get_max_cursor_height;
+	crtc->get_cursor_width = &xlnx_mix_crtc_get_max_cursor_width;
+	xlnx_crtc_register(mixer->drm, crtc);
+	dev_info(mixer->drm->dev,
+		 "Registered mixer CRTC with id: %d\n", crtc->crtc.base.id);
+
+	return 0;
+
+err_pixel_clk:
+	if (mixer->pixel_clock_enabled) {
+		clk_disable_unprepare(mixer->pixel_clock);
+		mixer->pixel_clock_enabled = false;
+	}
+err_plane:
+	return ret;
+}
+
+/**
+ * xlnx_mix_init - Establishes a default power-on state for the mixer IP
+ * core
+ * @mixer: instance of IP core to initialize to a default state
+ *
+ * Background layer initialized to maximum height and width settings based on
+ * device tree properties and all overlay layers set to minimum height and width
+ * sizes and positioned to 0,0 in the crtc.   All layers are inactive (resulting
+ * in video output being generated by the background color generator).
+ * Interrupts are disabled and the IP is started (with auto-restart enabled).
+ */
+static void xlnx_mix_init(struct xlnx_mix_hw *mixer)
+{
+	u32 i;
+	u32 bg_bpc = mixer->bg_layer_bpc;
+	u64 rgb_bg_clr = (0xFFFF >> (XVMIX_MAX_BPC - bg_bpc)) << (bg_bpc * 2);
+	enum xlnx_mix_layer_id layer_id;
+	struct xlnx_mix_layer_data *layer_data;
+
+	layer_data = xlnx_mix_get_layer_data(mixer, XVMIX_LAYER_MASTER);
+	xlnx_mix_layer_disable(mixer, mixer->max_layers);
+	xlnx_mix_set_active_area(mixer, layer_data->hw_config.max_width,
+				 layer_data->hw_config.max_height);
+	/* default to blue */
+	xlnx_mix_set_bkg_col(mixer, rgb_bg_clr);
+
+	for (i = 0; i < mixer->layer_cnt; i++) {
+		layer_id = mixer->layer_data[i].id;
+		layer_data = &mixer->layer_data[i];
+		if (layer_id == XVMIX_LAYER_MASTER)
+			continue;
+		xlnx_mix_set_layer_window(mixer, layer_id, 0, 0,
+					  XVMIX_LAYER_WIDTH_MIN,
+					  XVMIX_LAYER_HEIGHT_MIN, 0);
+		if (layer_data->hw_config.can_scale)
+			xlnx_mix_set_layer_scaling(mixer, layer_id, 0);
+		if (layer_data->hw_config.can_alpha)
+			xlnx_mix_set_layer_alpha(mixer, layer_id,
+						 XVMIX_ALPHA_MAX);
+	}
+	xlnx_mix_intrpt_enable_done(mixer);
+}
+
+static int xlnx_mix_bind(struct device *dev, struct device *master,
+			 void *data)
+{
+	struct xlnx_mix *mixer = dev_get_drvdata(dev);
+	struct drm_device *drm = data;
+	u32 ret;
+
+	xlnx_mix_dt_dp_bridge(dev, mixer);
+
+	mixer->drm = drm;
+	ret = xlnx_mix_plane_create(dev, mixer);
+	if (ret)
+		return ret;
+	ret = xlnx_mix_crtc_create(mixer);
+	if (ret)
+		return ret;
+	xlnx_mix_init(&mixer->mixer_hw);
+
+	return ret;
+}
+
+static void xlnx_mix_unbind(struct device *dev, struct device *master,
+			    void *data)
+{
+	struct xlnx_mix *mixer = dev_get_drvdata(dev);
+	int i, j;
+
+	for (i = 0; i < mixer->num_planes; i++) {
+		for (j = 0; j < XVMIX_MAX_NUM_SUB_PLANES; j++) {
+			if (mixer->planes[i].dma[j].chan)
+				dma_release_channel(mixer->planes[i].dma[j].chan);
+		}
+	}
+
+	dev_set_drvdata(dev, NULL);
+	xlnx_mix_intrpt_disable(&mixer->mixer_hw);
+	xlnx_crtc_unregister(mixer->drm, &mixer->crtc);
+}
+
+static const struct component_ops xlnx_mix_component_ops = {
+	.bind	= xlnx_mix_bind,
+	.unbind	= xlnx_mix_unbind,
+};
+
+static int xlnx_mix_probe(struct platform_device *pdev)
+{
+	struct xlnx_mix *mixer;
+	int ret;
+
+	mixer = devm_kzalloc(&pdev->dev, sizeof(*mixer), GFP_KERNEL);
+	if (!mixer)
+		return -ENOMEM;
+
+	ret = of_reserved_mem_device_init(&pdev->dev);
+	if (ret)
+		dev_dbg(&pdev->dev, "of_reserved_mem_device_init: %d\n", ret);
+
+	ret = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));
+	if (ret) {
+		dev_err(&pdev->dev, "dma_set_coherent_mask: %d\n", ret);
+		return ret;
+	}
+
+	/* Sub-driver will access mixer from drvdata */
+	platform_set_drvdata(pdev, mixer);
+	ret = xlnx_mix_dt_parse(&pdev->dev, mixer);
+	if (ret) {
+		if (ret != -EPROBE_DEFER)
+			dev_err(&pdev->dev, "Failed to probe mixer\n");
+		return ret;
+	}
+
+	ret = component_add(&pdev->dev, &xlnx_mix_component_ops);
+	if (ret)
+		goto err;
+
+	mixer->master = xlnx_drm_pipeline_init(pdev);
+	if (IS_ERR(mixer->master)) {
+		dev_err(&pdev->dev, "Failed to initialize the drm pipeline\n");
+		goto err_component;
+	}
+
+	dev_info(&pdev->dev, "Xilinx Mixer driver probed success\n");
+	return ret;
+
+err_component:
+	component_del(&pdev->dev, &xlnx_mix_component_ops);
+err:
+	return ret;
+}
+
+static void xlnx_mix_remove(struct platform_device *pdev)
+{
+	struct xlnx_mix *mixer = platform_get_drvdata(pdev);
+
+	if (mixer->vtc_bridge)
+		of_xlnx_bridge_put(mixer->vtc_bridge);
+	if (mixer->disp_bridge) {
+		of_xlnx_bridge_put(mixer->disp_bridge);
+		xlnx_mix_crtc_atomic_disable(&mixer->crtc.crtc, NULL);
+	}
+	xlnx_drm_pipeline_exit(mixer->master);
+	component_del(&pdev->dev, &xlnx_mix_component_ops);
+}
+
+/*
+ * TODO:
+ * In Mixer IP core version 4.0, layer enable bits and logo layer offsets
+ * have been changed. To provide backward compatibility number of max layers
+ * field has been taken to differentiate IP versions.
+ * This logic will have to be changed properly using the IP core version.
+ */
+
+static const struct of_device_id xlnx_mix_of_match[] = {
+	{ .compatible = "xlnx,mixer-3.0", },
+	{ .compatible = "xlnx,mixer-4.0", },
+	{ .compatible = "xlnx,mixer-5.0", },
+	{ .compatible = "xlnx,v-mix-5.3", },
+	{ /* end of table */ },
+};
+MODULE_DEVICE_TABLE(of, xlnx_mix_of_match);
+
+static struct platform_driver xlnx_mix_driver = {
+	.probe			= xlnx_mix_probe,
+	.remove			= xlnx_mix_remove,
+	.driver			= {
+		.name		= "xlnx-mixer",
+		.of_match_table	= xlnx_mix_of_match,
+	},
+};
+
+module_platform_driver(xlnx_mix_driver);
+
+MODULE_AUTHOR("Saurabh Sengar");
+MODULE_DESCRIPTION("Xilinx Mixer Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/xlnx_pl_disp.c b/drivers/gpu/drm/xlnx/xlnx_pl_disp.c
new file mode 100644
index 000000000..9c6c27ba6
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_pl_disp.c
@@ -0,0 +1,708 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx DRM CRTC DMA engine driver
+ *
+ * Copyright (C) 2017 - 2018 Xilinx, Inc.
+ *
+ * Author : Saurabh Sengar <saurabhs@xilinx.com>
+ *        : Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ */
+
+#include <drm/drm_atomic.h>
+#include <drm/drm_atomic_helper.h>
+#include <drm/drm_crtc.h>
+#include <drm/drm_crtc_helper.h>
+#include <drm/drm_fb_dma_helper.h>
+#include <drm/drm_fourcc.h>
+#include <drm/drm_framebuffer.h>
+#include <drm/drm_gem_dma_helper.h>
+#include <drm/drm_vblank.h>
+#include <linux/component.h>
+#include <linux/delay.h>
+#include <linux/device.h>
+#include <linux/dmaengine.h>
+#include <linux/dma-mapping.h>
+#include <linux/dma/xilinx_frmbuf.h>
+#include <linux/of.h>
+#include <linux/of_dma.h>
+#include <linux/of_reserved_mem.h>
+#include <linux/platform_device.h>
+#include <video/videomode.h>
+#include "xlnx_bridge.h"
+#include "xlnx_crtc.h"
+#include "xlnx_drv.h"
+
+#define XLNX_PL_DISP_MAX_NUM_PLANES	3
+#define XLNX_PL_DISP_VFMT_SIZE		5
+/*
+ * Overview
+ * --------
+ *
+ * This driver intends to support the display pipeline with DMA engine
+ * driver by initializing DRM crtc and plane objects. The driver makes
+ * an assumption that it's single plane pipeline, as multi-plane pipeline
+ * would require programing beyond the DMA engine interface.
+ */
+
+/**
+ * struct xlnx_dma_chan - struct for DMA engine
+ * @dma_chan: DMA channel
+ * @xt: Interleaved desc config container
+ * @sgl: Data chunk for dma_interleaved_template
+ */
+struct xlnx_dma_chan {
+	struct dma_chan *dma_chan;
+	struct dma_interleaved_template xt;
+	struct data_chunk sgl[1];
+};
+
+/**
+ * struct xlnx_pl_disp - struct for display subsystem
+ * @dev: device structure
+ * @master: logical master device from xlnx drm
+ * @xlnx_crtc: Xilinx DRM driver crtc object
+ * @plane: base drm plane object
+ * @chan: struct for DMA engine
+ * @event: vblank pending event
+ * @callback: callback for registering DMA callback function
+ * @callback_param: parameter for passing  to DMA callback function
+ * @drm: core drm object
+ * @fmt: drm color format
+ * @vtc_bridge: vtc_bridge structure
+ * @fid: field id
+ * @fid_err_prop: field id error property
+ * @fid_err_val: field id error value
+ * @fid_out_prop: field id out property
+ * @fid_out_val: field out value
+ */
+struct xlnx_pl_disp {
+	struct device *dev;
+	struct platform_device *master;
+	struct xlnx_crtc xlnx_crtc;
+	struct drm_plane plane;
+	struct xlnx_dma_chan *chan;
+	struct drm_pending_vblank_event *event;
+	dma_async_tx_callback callback;
+	void *callback_param;
+	struct drm_device *drm;
+	u32 fmt;
+	struct xlnx_bridge *vtc_bridge;
+	u32 fid;
+	struct drm_property *fid_err_prop;
+	u32 fid_err_val;
+	struct drm_property *fid_out_prop;
+	u32 fid_out_val;
+};
+
+/*
+ * Xlnx crtc functions
+ */
+static inline struct xlnx_pl_disp *crtc_to_dma(struct xlnx_crtc *xlnx_crtc)
+{
+	return container_of(xlnx_crtc, struct xlnx_pl_disp, xlnx_crtc);
+}
+
+/**
+ * xlnx_pl_disp_complete - vblank handler
+ * @param: parameter to vblank handler
+ *
+ * This function handles the vblank interrupt, and sends an event to
+ * CRTC object.
+ */
+static void xlnx_pl_disp_complete(void *param)
+{
+	struct xlnx_pl_disp *xlnx_pl_disp = param;
+	struct drm_device *drm = xlnx_pl_disp->drm;
+	struct xlnx_dma_chan *xlnx_dma_chan = xlnx_pl_disp->chan;
+	int ret;
+
+	/* Get fid err flag and fid out val */
+	ret = xilinx_xdma_get_fid_err_flag(xlnx_dma_chan->dma_chan,
+					   &xlnx_pl_disp->fid_err_val);
+	if (ret)
+		dev_dbg(xlnx_pl_disp->dev, "failed to get fid_err info\n");
+
+	ret = xilinx_xdma_get_fid_out(xlnx_dma_chan->dma_chan,
+				      &xlnx_pl_disp->fid_out_val);
+	if (ret)
+		dev_dbg(xlnx_pl_disp->dev, "failed to get fid_out info\n");
+
+	drm_handle_vblank(drm, 0);
+}
+
+/**
+ * xlnx_pl_disp_get_format - Get the current display pipeline format
+ * @xlnx_crtc: xlnx crtc object
+ *
+ * Get the current format of pipeline
+ *
+ * Return: the corresponding DRM_FORMAT_XXX
+ */
+static uint32_t xlnx_pl_disp_get_format(struct xlnx_crtc *xlnx_crtc)
+{
+	struct xlnx_pl_disp *xlnx_pl_disp = crtc_to_dma(xlnx_crtc);
+
+	return xlnx_pl_disp->fmt;
+}
+
+/**
+ * xlnx_pl_disp_get_align - Get the alignment value for pitch
+ * @xlnx_crtc: xlnx crtc object
+ *
+ * Get the alignment value for pitch from the plane
+ *
+ * Return: The alignment value if successful, or the error code.
+ */
+static unsigned int xlnx_pl_disp_get_align(struct xlnx_crtc *xlnx_crtc)
+{
+	struct xlnx_pl_disp *xlnx_pl_disp = crtc_to_dma(xlnx_crtc);
+
+	return 1 << xlnx_pl_disp->chan->dma_chan->device->copy_align;
+}
+
+/*
+ * DRM plane functions
+ */
+static inline struct xlnx_pl_disp *plane_to_dma(struct drm_plane *plane)
+{
+	return container_of(plane, struct xlnx_pl_disp, plane);
+}
+
+/**
+ * xlnx_pl_disp_plane_disable - Disables DRM plane
+ * @plane: DRM plane object
+ *
+ * Disable the DRM plane, by stopping the corrosponding DMA
+ */
+static void xlnx_pl_disp_plane_disable(struct drm_plane *plane)
+{
+	struct xlnx_pl_disp *xlnx_pl_disp = plane_to_dma(plane);
+	struct xlnx_dma_chan *xlnx_dma_chan = xlnx_pl_disp->chan;
+
+	dmaengine_terminate_sync(xlnx_dma_chan->dma_chan);
+}
+
+/**
+ * xlnx_pl_disp_plane_enable - Enables DRM plane
+ * @plane: DRM plane object
+ *
+ * Enable the DRM plane, by enabling the corresponding DMA
+ */
+static void xlnx_pl_disp_plane_enable(struct drm_plane *plane)
+{
+	struct xlnx_pl_disp *xlnx_pl_disp = plane_to_dma(plane);
+	struct dma_async_tx_descriptor *desc;
+	unsigned long flags;
+	struct xlnx_dma_chan *xlnx_dma_chan = xlnx_pl_disp->chan;
+	struct dma_chan *dma_chan = xlnx_dma_chan->dma_chan;
+	struct dma_interleaved_template *xt = &xlnx_dma_chan->xt;
+
+	flags = DMA_CTRL_ACK | DMA_PREP_INTERRUPT;
+	desc = dmaengine_prep_interleaved_dma(dma_chan, xt, flags);
+	if (!desc) {
+		dev_err(xlnx_pl_disp->dev,
+			"failed to prepare DMA descriptor\n");
+		return;
+	}
+	desc->callback = xlnx_pl_disp->callback;
+	desc->callback_param = xlnx_pl_disp->callback_param;
+	xilinx_xdma_set_earlycb(xlnx_dma_chan->dma_chan, desc, EARLY_CALLBACK);
+
+	if (plane->state->crtc->state->adjusted_mode.flags &
+			DRM_MODE_FLAG_INTERLACE) {
+		/*
+		 * Framebuffer DMA Reader sends the first field twice, which
+		 * causes the following fields out of order. The fid is
+		 * reverted to restore the order
+		 */
+		if (plane->state->fb->flags == DRM_MODE_FB_ALTERNATE_TOP) {
+			xlnx_pl_disp->fid = 0;
+		} else if (plane->state->fb->flags ==
+				DRM_MODE_FB_ALTERNATE_BOTTOM) {
+			xlnx_pl_disp->fid = 1;
+		} else {
+			/*
+			 * FIXME: for interlace mode, application may send
+			 * dummy packets before the video field, need to set
+			 * the fid correctly to avoid display distortion
+			 */
+			xlnx_pl_disp->fid = 0;
+		}
+
+		xilinx_xdma_set_fid(xlnx_dma_chan->dma_chan, desc,
+				    xlnx_pl_disp->fid);
+	}
+
+	dmaengine_submit(desc);
+	dma_async_issue_pending(xlnx_dma_chan->dma_chan);
+}
+
+static void xlnx_pl_disp_plane_atomic_disable(struct drm_plane *plane,
+					      struct drm_atomic_state *state)
+{
+	xlnx_pl_disp_plane_disable(plane);
+}
+
+static int xlnx_pl_disp_plane_mode_set(struct drm_plane *plane,
+				       struct drm_framebuffer *fb,
+				       int crtc_x, int crtc_y,
+				       unsigned int crtc_w, unsigned int crtc_h,
+				       u32 src_x, uint32_t src_y,
+				       u32 src_w, uint32_t src_h)
+{
+	struct xlnx_pl_disp *xlnx_pl_disp = plane_to_dma(plane);
+	const struct drm_format_info *info = fb->format;
+	dma_addr_t luma_paddr, chroma_paddr;
+	size_t stride;
+	struct xlnx_dma_chan *xlnx_dma_chan = xlnx_pl_disp->chan;
+
+	if (info->num_planes > XLNX_PL_DISP_MAX_NUM_PLANES) {
+		dev_err(xlnx_pl_disp->dev, "Color format not supported\n");
+		return -EINVAL;
+	}
+	luma_paddr = drm_fb_dma_get_gem_addr(fb, plane->state, 0);
+	if (!luma_paddr) {
+		dev_err(xlnx_pl_disp->dev, "failed to get luma paddr\n");
+		return -EINVAL;
+	}
+
+	dev_dbg(xlnx_pl_disp->dev, "num planes = %d\n", info->num_planes);
+	xlnx_dma_chan->xt.numf = src_h;
+	xlnx_dma_chan->sgl[0].size = drm_format_plane_width_bytes(info,
+								  0, src_w);
+	xlnx_dma_chan->sgl[0].icg = fb->pitches[0] - xlnx_dma_chan->sgl[0].size;
+	xlnx_dma_chan->xt.src_start = luma_paddr;
+	xlnx_dma_chan->xt.frame_size = info->num_planes;
+	xlnx_dma_chan->xt.dir = DMA_MEM_TO_DEV;
+	xlnx_dma_chan->xt.src_sgl = true;
+	xlnx_dma_chan->xt.dst_sgl = false;
+
+	/* Do we have a video format aware dma channel?
+	 * so, modify descriptor accordingly. Hueristic test:
+	 * we have a multi-plane format but only one dma channel
+	 */
+	if (info->num_planes > 1) {
+		chroma_paddr = drm_fb_dma_get_gem_addr(fb, plane->state, 1);
+		if (!chroma_paddr) {
+			dev_err(xlnx_pl_disp->dev,
+				"failed to get chroma paddr\n");
+			return -EINVAL;
+		}
+		stride = xlnx_dma_chan->sgl[0].size +
+			xlnx_dma_chan->sgl[0].icg;
+		xlnx_dma_chan->sgl[0].src_icg = chroma_paddr -
+			xlnx_dma_chan->xt.src_start -
+			(xlnx_dma_chan->xt.numf * stride);
+	}
+
+	return 0;
+}
+
+static void xlnx_pl_disp_plane_atomic_update(struct drm_plane *plane,
+					     struct drm_atomic_state *state)
+{
+	int ret;
+	struct xlnx_pl_disp *xlnx_pl_disp = plane_to_dma(plane);
+
+	ret = xlnx_pl_disp_plane_mode_set(plane,
+					  plane->state->fb,
+					  plane->state->crtc_x,
+					  plane->state->crtc_y,
+					  plane->state->crtc_w,
+					  plane->state->crtc_h,
+					  plane->state->src_x >> 16,
+					  plane->state->src_y >> 16,
+					  plane->state->src_w >> 16,
+					  plane->state->src_h >> 16);
+	if (ret) {
+		dev_err(xlnx_pl_disp->dev, "failed to mode set a plane\n");
+		return;
+	}
+	/* in case frame buffer is used set the color format */
+	xilinx_xdma_drm_config(xlnx_pl_disp->chan->dma_chan,
+			       xlnx_pl_disp->plane.state->fb->format->format);
+	/* apply the new fb addr and enable */
+	xlnx_pl_disp_plane_enable(plane);
+}
+
+static int
+xlnx_pl_disp_plane_atomic_check(struct drm_plane *plane,
+				struct drm_atomic_state *state)
+{
+	struct drm_plane_state *new_plane_state = drm_atomic_get_new_plane_state(state, plane);
+	const struct drm_plane_state *old_plane_state =
+		drm_atomic_get_old_plane_state(state, plane);
+	struct drm_crtc *crtc = new_plane_state->crtc ?: old_plane_state->crtc;
+	struct drm_crtc_state *new_crtc_state;
+
+	if (!crtc)
+		return 0;
+
+	new_crtc_state = drm_atomic_get_new_crtc_state(state, crtc);
+
+	/* plane must be enabled when state is active */
+	if (new_crtc_state->active && !new_plane_state->crtc)
+		return -EINVAL;
+
+	/*
+	 * This check is required to call modeset if there is a change in color
+	 * format
+	 */
+	if (new_plane_state->fb && old_plane_state->fb &&
+	    new_plane_state->fb->format->format !=
+	    old_plane_state->fb->format->format)
+		new_crtc_state->mode_changed = true;
+
+	return 0;
+}
+
+static int
+xlnx_pl_disp_plane_atomic_get_property(struct drm_plane *plane,
+				       const struct drm_plane_state *state,
+				       struct drm_property *property,
+				       uint64_t *val)
+{
+	struct xlnx_pl_disp *xlnx_pl_disp = plane_to_dma(plane);
+
+	if (property == xlnx_pl_disp->fid_err_prop)
+		*val = xlnx_pl_disp->fid_err_val;
+	else if (property == xlnx_pl_disp->fid_out_prop)
+		*val = xlnx_pl_disp->fid_out_val;
+	else
+		return -EINVAL;
+
+	return 0;
+}
+
+static const struct drm_plane_helper_funcs xlnx_pl_disp_plane_helper_funcs = {
+	.atomic_update = xlnx_pl_disp_plane_atomic_update,
+	.atomic_disable = xlnx_pl_disp_plane_atomic_disable,
+	.atomic_check = xlnx_pl_disp_plane_atomic_check,
+};
+
+static struct drm_plane_funcs xlnx_pl_disp_plane_funcs = {
+	.update_plane = drm_atomic_helper_update_plane,
+	.disable_plane = drm_atomic_helper_disable_plane,
+	.destroy = drm_plane_cleanup,
+	.reset = drm_atomic_helper_plane_reset,
+	.atomic_duplicate_state	= drm_atomic_helper_plane_duplicate_state,
+	.atomic_destroy_state = drm_atomic_helper_plane_destroy_state,
+	.atomic_get_property = xlnx_pl_disp_plane_atomic_get_property,
+};
+
+static inline struct xlnx_pl_disp *drm_crtc_to_dma(struct drm_crtc *crtc)
+{
+	struct xlnx_crtc *xlnx_crtc = to_xlnx_crtc(crtc);
+
+	return crtc_to_dma(xlnx_crtc);
+}
+
+static void xlnx_pl_disp_crtc_atomic_begin(struct drm_crtc *crtc,
+					   struct drm_atomic_state *state)
+{
+	drm_crtc_vblank_on(crtc);
+	spin_lock_irq(&crtc->dev->event_lock);
+	if (crtc->state->event) {
+		/* Consume the flip_done event from atomic helper */
+		crtc->state->event->pipe = drm_crtc_index(crtc);
+		WARN_ON(drm_crtc_vblank_get(crtc) != 0);
+		drm_crtc_arm_vblank_event(crtc, crtc->state->event);
+		crtc->state->event = NULL;
+	}
+	spin_unlock_irq(&crtc->dev->event_lock);
+}
+
+static void xlnx_pl_disp_clear_event(struct drm_crtc *crtc)
+{
+	if (crtc->state->event) {
+		complete_all(crtc->state->event->base.completion);
+		crtc->state->event = NULL;
+	}
+}
+
+static void xlnx_pl_disp_crtc_atomic_enable(struct drm_crtc *crtc,
+					    struct drm_atomic_state *state)
+{
+	struct drm_display_mode *adjusted_mode = &crtc->state->adjusted_mode;
+	int vrefresh;
+	struct xlnx_crtc *xlnx_crtc = to_xlnx_crtc(crtc);
+	struct xlnx_pl_disp *xlnx_pl_disp = crtc_to_dma(xlnx_crtc);
+	struct videomode vm;
+
+	if (xlnx_pl_disp->vtc_bridge) {
+		/* set video timing */
+		drm_display_mode_to_videomode(adjusted_mode, &vm);
+		xlnx_bridge_set_timing(xlnx_pl_disp->vtc_bridge, &vm);
+		xlnx_bridge_enable(xlnx_pl_disp->vtc_bridge);
+	}
+
+	xlnx_pl_disp_plane_enable(crtc->primary);
+
+	/* Delay of 1 vblank interval for timing gen to be stable */
+	vrefresh = (adjusted_mode->clock * 1000) /
+		   (adjusted_mode->vtotal * adjusted_mode->htotal);
+	msleep(1 * 1000 / vrefresh);
+}
+
+static void xlnx_pl_disp_crtc_atomic_disable(struct drm_crtc *crtc,
+					     struct drm_atomic_state *state)
+{
+	struct xlnx_crtc *xlnx_crtc = to_xlnx_crtc(crtc);
+	struct xlnx_pl_disp *xlnx_pl_disp = crtc_to_dma(xlnx_crtc);
+
+	xlnx_pl_disp_plane_disable(crtc->primary);
+	xlnx_pl_disp_clear_event(crtc);
+	drm_crtc_vblank_off(crtc);
+	if (xlnx_pl_disp->vtc_bridge)
+		xlnx_bridge_disable(xlnx_pl_disp->vtc_bridge);
+}
+
+static int xlnx_pl_disp_crtc_atomic_check(struct drm_crtc *crtc,
+					  struct drm_atomic_state *state)
+{
+	return drm_atomic_add_affected_planes(state, crtc);
+}
+
+static struct drm_crtc_helper_funcs xlnx_pl_disp_crtc_helper_funcs = {
+	.atomic_enable = xlnx_pl_disp_crtc_atomic_enable,
+	.atomic_disable = xlnx_pl_disp_crtc_atomic_disable,
+	.atomic_check = xlnx_pl_disp_crtc_atomic_check,
+	.atomic_begin = xlnx_pl_disp_crtc_atomic_begin,
+};
+
+static void xlnx_pl_disp_crtc_destroy(struct drm_crtc *crtc)
+{
+	xlnx_pl_disp_plane_disable(crtc->primary);
+	drm_crtc_cleanup(crtc);
+}
+
+static int xlnx_pl_disp_crtc_enable_vblank(struct drm_crtc *crtc)
+{
+	struct xlnx_crtc *xlnx_crtc = to_xlnx_crtc(crtc);
+	struct xlnx_pl_disp *xlnx_pl_disp = crtc_to_dma(xlnx_crtc);
+
+	/*
+	 * Use the complete callback for vblank event assuming the dma engine
+	 * starts on the next descriptor upon this event. This may not be safe
+	 * assumption for some dma engines.
+	 */
+	xlnx_pl_disp->callback = xlnx_pl_disp_complete;
+	xlnx_pl_disp->callback_param = xlnx_pl_disp;
+
+	return 0;
+}
+
+static void xlnx_pl_disp_crtc_disable_vblank(struct drm_crtc *crtc)
+{
+	struct xlnx_crtc *xlnx_crtc = to_xlnx_crtc(crtc);
+	struct xlnx_pl_disp *xlnx_pl_disp = crtc_to_dma(xlnx_crtc);
+
+	xlnx_pl_disp->callback = NULL;
+	xlnx_pl_disp->callback_param = NULL;
+}
+
+static struct drm_crtc_funcs xlnx_pl_disp_crtc_funcs = {
+	.destroy = xlnx_pl_disp_crtc_destroy,
+	.set_config = drm_atomic_helper_set_config,
+	.page_flip = drm_atomic_helper_page_flip,
+	.reset = drm_atomic_helper_crtc_reset,
+	.atomic_duplicate_state = drm_atomic_helper_crtc_duplicate_state,
+	.atomic_destroy_state = drm_atomic_helper_crtc_destroy_state,
+	.enable_vblank = xlnx_pl_disp_crtc_enable_vblank,
+	.disable_vblank = xlnx_pl_disp_crtc_disable_vblank,
+};
+
+static int xlnx_pl_disp_bind(struct device *dev, struct device *master,
+			     void *data)
+{
+	struct drm_device *drm = data;
+	struct xlnx_pl_disp *xlnx_pl_disp = dev_get_drvdata(dev);
+	struct drm_mode_object *obj = &xlnx_pl_disp->plane.base;
+	int ret;
+	u32 *fmts = NULL;
+	unsigned int num_fmts = 0;
+
+	/* in case of fb IP query the supported formats and there count */
+	xilinx_xdma_get_drm_vid_fmts(xlnx_pl_disp->chan->dma_chan,
+				     &num_fmts, &fmts);
+	ret = drm_universal_plane_init(drm, &xlnx_pl_disp->plane, 0,
+				       &xlnx_pl_disp_plane_funcs,
+				       fmts ? fmts : &xlnx_pl_disp->fmt,
+				       num_fmts ? num_fmts : 1,
+				       NULL, DRM_PLANE_TYPE_PRIMARY, NULL);
+	if (ret)
+		return ret;
+
+	drm_plane_helper_add(&xlnx_pl_disp->plane,
+			     &xlnx_pl_disp_plane_helper_funcs);
+
+	ret = drm_crtc_init_with_planes(drm, &xlnx_pl_disp->xlnx_crtc.crtc,
+					&xlnx_pl_disp->plane, NULL,
+					&xlnx_pl_disp_crtc_funcs, NULL);
+	if (ret) {
+		drm_plane_cleanup(&xlnx_pl_disp->plane);
+		return ret;
+	}
+
+	drm_crtc_helper_add(&xlnx_pl_disp->xlnx_crtc.crtc,
+			    &xlnx_pl_disp_crtc_helper_funcs);
+	xlnx_pl_disp->xlnx_crtc.get_format = &xlnx_pl_disp_get_format;
+	xlnx_pl_disp->xlnx_crtc.get_align = &xlnx_pl_disp_get_align;
+	xlnx_pl_disp->drm = drm;
+
+	xlnx_pl_disp->fid_err_prop = drm_property_create_bool(xlnx_pl_disp->drm,
+							      0, "fid_err");
+	xlnx_pl_disp->fid_out_prop = drm_property_create_bool(xlnx_pl_disp->drm,
+							      0, "fid_out");
+	drm_object_attach_property(obj, xlnx_pl_disp->fid_err_prop, 0);
+	drm_object_attach_property(obj, xlnx_pl_disp->fid_out_prop, 0);
+
+	xlnx_crtc_register(xlnx_pl_disp->drm, &xlnx_pl_disp->xlnx_crtc);
+
+	return 0;
+}
+
+static void xlnx_pl_disp_unbind(struct device *dev, struct device *master,
+				void *data)
+{
+	struct xlnx_pl_disp *xlnx_pl_disp = dev_get_drvdata(dev);
+
+	drm_property_destroy(xlnx_pl_disp->drm, xlnx_pl_disp->fid_out_prop);
+	drm_property_destroy(xlnx_pl_disp->drm, xlnx_pl_disp->fid_err_prop);
+	xlnx_crtc_unregister(xlnx_pl_disp->drm, &xlnx_pl_disp->xlnx_crtc);
+	drm_plane_cleanup(&xlnx_pl_disp->plane);
+	drm_crtc_cleanup(&xlnx_pl_disp->xlnx_crtc.crtc);
+}
+
+static const struct component_ops xlnx_pl_disp_component_ops = {
+	.bind	= xlnx_pl_disp_bind,
+	.unbind	= xlnx_pl_disp_unbind,
+};
+
+static int xlnx_pl_disp_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct device_node *vtc_node;
+	struct xlnx_pl_disp *xlnx_pl_disp;
+	int ret;
+	const char *vformat;
+	struct dma_chan *dma_chan;
+	struct xlnx_dma_chan *xlnx_dma_chan;
+	const struct drm_format_info *info;
+
+	xlnx_pl_disp = devm_kzalloc(dev, sizeof(*xlnx_pl_disp), GFP_KERNEL);
+	if (!xlnx_pl_disp)
+		return -ENOMEM;
+
+	dma_chan = of_dma_request_slave_channel(dev->of_node, "dma0");
+	if (IS_ERR_OR_NULL(dma_chan)) {
+		dev_err(dev, "failed to request dma channel\n");
+		return PTR_ERR(dma_chan);
+	}
+
+	xlnx_dma_chan = devm_kzalloc(dev, sizeof(*xlnx_dma_chan), GFP_KERNEL);
+	if (!xlnx_dma_chan)
+		return -ENOMEM;
+
+	xlnx_dma_chan->dma_chan = dma_chan;
+	xlnx_pl_disp->chan = xlnx_dma_chan;
+	ret = of_property_read_string(dev->of_node, "xlnx,vformat", &vformat);
+	if (ret) {
+		dev_err(dev, "No xlnx,vformat value in dts\n");
+		goto err_dma;
+	}
+
+	strscpy((char *)&xlnx_pl_disp->fmt, vformat, XLNX_PL_DISP_VFMT_SIZE);
+	info = drm_format_info(xlnx_pl_disp->fmt);
+	if (!info) {
+		dev_err(dev, "Invalid video format in dts\n");
+		ret = -EINVAL;
+		goto err_dma;
+	}
+
+	/* VTC Bridge support */
+	vtc_node = of_parse_phandle(dev->of_node, "xlnx,bridge", 0);
+	if (vtc_node) {
+		xlnx_pl_disp->vtc_bridge = of_xlnx_bridge_get(vtc_node);
+		if (!xlnx_pl_disp->vtc_bridge) {
+			dev_info(dev, "Didn't get vtc bridge instance\n");
+			ret = -EPROBE_DEFER;
+			goto err_dma;
+		}
+	} else {
+		dev_info(dev, "vtc bridge property not present\n");
+	}
+
+	ret = of_reserved_mem_device_init(&pdev->dev);
+	if (ret)
+		dev_dbg(&pdev->dev, "of_reserved_mem_device_init: %d\n", ret);
+
+	ret = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));
+	if (ret) {
+		dev_err(&pdev->dev, "dma_set_mask_and_coherent: %d\n", ret);
+		goto err_dma;
+	}
+
+	xlnx_pl_disp->dev = dev;
+	platform_set_drvdata(pdev, xlnx_pl_disp);
+
+	ret = component_add(dev, &xlnx_pl_disp_component_ops);
+	if (ret)
+		goto err_dma;
+
+	xlnx_pl_disp->master = xlnx_drm_pipeline_init(pdev);
+	if (IS_ERR(xlnx_pl_disp->master)) {
+		ret = PTR_ERR(xlnx_pl_disp->master);
+		dev_err(dev, "failed to initialize the drm pipeline\n");
+		goto err_component;
+	}
+
+	dev_info(&pdev->dev, "Xlnx PL display driver probed\n");
+
+	return 0;
+
+err_component:
+	component_del(dev, &xlnx_pl_disp_component_ops);
+err_dma:
+	of_reserved_mem_device_release(&pdev->dev);
+	dma_release_channel(xlnx_pl_disp->chan->dma_chan);
+
+	return ret;
+}
+
+static void xlnx_pl_disp_remove(struct platform_device *pdev)
+{
+	struct xlnx_pl_disp *xlnx_pl_disp = platform_get_drvdata(pdev);
+	struct xlnx_dma_chan *xlnx_dma_chan = xlnx_pl_disp->chan;
+
+	if (xlnx_pl_disp->vtc_bridge)
+		of_xlnx_bridge_put(xlnx_pl_disp->vtc_bridge);
+	xlnx_drm_pipeline_exit(xlnx_pl_disp->master);
+	component_del(&pdev->dev, &xlnx_pl_disp_component_ops);
+
+	/* Make sure the channel is terminated before release */
+	dmaengine_terminate_sync(xlnx_dma_chan->dma_chan);
+	dma_release_channel(xlnx_dma_chan->dma_chan);
+	of_reserved_mem_device_release(&pdev->dev);
+}
+
+static const struct of_device_id xlnx_pl_disp_of_match[] = {
+	{ .compatible = "xlnx,pl-disp"},
+	{ }
+};
+MODULE_DEVICE_TABLE(of, xlnx_pl_disp_of_match);
+
+static struct platform_driver xlnx_pl_disp_driver = {
+	.probe = xlnx_pl_disp_probe,
+	.remove = xlnx_pl_disp_remove,
+	.driver = {
+		.name = "xlnx-pl-disp",
+		.of_match_table = xlnx_pl_disp_of_match,
+	},
+};
+
+module_platform_driver(xlnx_pl_disp_driver);
+
+MODULE_AUTHOR("Saurabh Sengar");
+MODULE_DESCRIPTION("Xilinx DRM Display Driver for PL IPs");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/xlnx_scaler.c b/drivers/gpu/drm/xlnx/xlnx_scaler.c
new file mode 100644
index 000000000..a9daedafb
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_scaler.c
@@ -0,0 +1,1977 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * VPSS SCALER DRM bridge driver
+ *
+ * Copyright (C) 2017-2018 Xilinx, Inc.
+ *
+ * Author: Venkateshwar rao G <vgannava@xilinx.com>
+ *	   Rohit Athavale <rathavale@xilinx.com>
+ */
+
+/*
+ * Overview:
+ * This experimentatl driver works as a bridge driver and
+ * reused the code from V4L2.
+ * TODO:
+ * Need to implement in a modular approach to share driver code between
+ * V4L2 and DRM frameworks.
+ * Should be integrated with plane.
+ */
+
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/err.h>
+#include <linux/gpio/consumer.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <uapi/linux/media-bus-format.h>
+
+#include "xlnx_bridge.h"
+
+#define XSCALER_MAX_WIDTH		(3840)
+#define XSCALER_MAX_HEIGHT		(2160)
+#define XSCALER_MAX_PHASES		(64)
+#define XSCALER_MIN_WIDTH		(64)
+#define XSCALER_MIN_HEIGHT		(64)
+
+/* Video subsytems block offset */
+#define S_AXIS_RESET_OFF		(0x00010000)
+#define V_HSCALER_OFF			(0x00000000)
+#define V_VSCALER_OFF			(0x00020000)
+
+/* HW Reset Network GPIO Channel */
+#define XGPIO_CH_RESET_SEL		(1)
+#define XGPIO_RESET_MASK_VIDEO_IN	BIT(0)
+#define XGPIO_RESET_MASK_IP_AXIS	BIT(1)
+#define XGPIO_RESET_MASK_ALL_BLOCKS	(XGPIO_RESET_MASK_VIDEO_IN | \
+						XGPIO_RESET_MASK_IP_AXIS)
+#define XGPIO_DATA_OFFSET		(0x0)
+#define XGPIO_DATA2_OFFSET		(0x8)
+#define XGPIO_TRI2_OFFSET		(0xc)
+
+#define XGPIO_ISR_OFFSET		(0x120)
+#define XGPIO_IER_OFFSET		(0x128)
+#define XGPIO_CHAN_OFFSET		(8)
+#define STEP_PRECISION			(65536)
+
+/* SCALER POWER MACROS */
+#define XSCALER_RESET_ASSERT            (0x1)
+#define XSCALER_RESET_DEASSERT          (0x0)
+
+/* Video IP PPC */
+#define XSCALER_PPC_1			(1)
+#define XSCALER_PPC_2			(2)
+
+#define XV_HSCALER_MAX_H_TAPS		(12)
+#define XV_HSCALER_MAX_H_PHASES		(64)
+#define XV_HSCALER_MAX_LINE_WIDTH	(3840)
+#define XV_VSCALER_MAX_V_TAPS		(12)
+#define XV_VSCALER_MAX_V_PHASES		(64)
+
+#define XV_HSCALER_TAPS_2		(2)
+#define XV_HSCALER_TAPS_4		(4)
+#define XV_HSCALER_TAPS_6		(6)
+#define XV_HSCALER_TAPS_8		(8)
+#define XV_HSCALER_TAPS_10		(10)
+#define XV_HSCALER_TAPS_12		(12)
+#define XV_VSCALER_TAPS_2		(2)
+#define XV_VSCALER_TAPS_4		(4)
+#define XV_VSCALER_TAPS_6		(6)
+#define XV_VSCALER_TAPS_8		(8)
+#define XV_VSCALER_TAPS_10		(10)
+#define XV_VSCALER_TAPS_12		(12)
+
+/* Mask definitions for Low and high 16 bits in a 32 bit number */
+#define XHSC_MASK_LOW_16BITS		GENMASK(15, 0)
+#define XHSC_MASK_HIGH_16BITS		GENMASK(31, 16)
+#define XHSC_MASK_LOW_32BITS		GENMASK(31, 0)
+#define XHSC_STEP_PRECISION_SHIFT	(16)
+#define XHSC_HPHASE_SHIFT_BY_6		(6)
+#define XHSC_HPHASE_MULTIPLIER		(9)
+#define XSCALER_BITSHIFT_16		(16)
+
+/* Mask definitions for Low and high 16 bits in a 32 bit number */
+#define XVSC_MASK_LOW_16BITS		GENMASK(15, 0)
+#define XVSC_MASK_HIGH_16BITS		GENMASK(31, 16)
+
+/* Scaler AP Control Registers */
+#define XSCALER_START			BIT(0)
+#define XSCALER_AUTO_RESTART		BIT(7)
+#define XSCALER_STREAM_ON		(XSCALER_START | XSCALER_AUTO_RESTART)
+
+/* H-scaler registers */
+#define XV_HSCALER_CTRL_ADDR_AP_CTRL			(0x0000)
+#define XV_HSCALER_CTRL_ADDR_GIE			(0x0004)
+#define XV_HSCALER_CTRL_ADDR_IER			(0x0008)
+#define XV_HSCALER_CTRL_ADDR_ISR			(0x000c)
+#define XV_HSCALER_CTRL_ADDR_HWREG_HEIGHT_DATA		(0x0010)
+#define XV_HSCALER_CTRL_ADDR_HWREG_WIDTHIN_DATA		(0x0018)
+#define XV_HSCALER_CTRL_ADDR_HWREG_WIDTHOUT_DATA	(0x0020)
+#define XV_HSCALER_CTRL_ADDR_HWREG_COLORMODE_DATA	(0x0028)
+#define XV_HSCALER_CTRL_ADDR_HWREG_PIXELRATE_DATA	(0x0030)
+#define XV_HSCALER_CTRL_ADDR_HWREG_COLORMODEOUT_DATA	(0X0038)
+#define XV_HSCALER_CTRL_ADDR_HWREG_HFLTCOEFF_BASE	(0x0800)
+#define XV_HSCALER_CTRL_ADDR_HWREG_HFLTCOEFF_HIGH	(0x0bff)
+
+#define XV_HSCALER_CTRL_WIDTH_HWREG_HFLTCOEFF		(16)
+#define XV_HSCALER_CTRL_DEPTH_HWREG_HFLTCOEFF		(384)
+#define XV_HSCALER_CTRL_ADDR_HWREG_PHASESH_V_BASE	(0x2000)
+#define XV_HSCALER_CTRL_ADDR_HWREG_PHASESH_V_HIGH	(0x3fff)
+#define XV_HSCALER_CTRL_WIDTH_HWREG_PHASESH_V		(18)
+#define XV_HSCALER_CTRL_DEPTH_HWREG_PHASESH_V		(1920)
+#define XV_HSCALER_CTRL_ADDR_HWREG_PHASEH_FIX		(0x4000)
+
+/* H-scaler masks */
+#define XV_HSCALER_PHASESH_V_OUTPUT_WR_EN		BIT(8)
+
+/* V-scaler registers */
+#define XV_VSCALER_CTRL_ADDR_AP_CTRL			(0x000)
+#define XV_VSCALER_CTRL_ADDR_GIE			(0x004)
+#define XV_VSCALER_CTRL_ADDR_IER			(0x008)
+#define XV_VSCALER_CTRL_ADDR_ISR			(0x00c)
+#define XV_VSCALER_CTRL_ADDR_HWREG_HEIGHTIN_DATA	(0x010)
+#define XV_VSCALER_CTRL_ADDR_HWREG_WIDTH_DATA		(0x018)
+#define XV_VSCALER_CTRL_ADDR_HWREG_HEIGHTOUT_DATA	(0x020)
+#define XV_VSCALER_CTRL_ADDR_HWREG_LINERATE_DATA	(0x028)
+#define XV_VSCALER_CTRL_ADDR_HWREG_COLORMODE_DATA	(0x030)
+#define XV_VSCALER_CTRL_ADDR_HWREG_VFLTCOEFF_BASE	(0x800)
+#define XV_VSCALER_CTRL_ADDR_HWREG_VFLTCOEFF_HIGH	(0xbff)
+
+/* Coefficients for 6, 8, 10 and 12 tap filters */
+
+static const s16
+XV_lanczos2_taps6[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_6] = {
+	{   0,    0, 4096,    0,    0,   0, },
+	{   0,  -40, 4099,   42,    0,  -5, },
+	{  -1,  -77, 4097,   87,   -1,  -9, },
+	{  -2, -111, 4092,  134,   -2, -15, },
+	{  -4, -143, 4082,  184,   -4, -19, },
+	{  -6, -173, 4068,  237,   -7, -23, },
+	{  -8, -201, 4051,  292,  -10, -28, },
+	{ -11, -226, 4029,  350,  -13, -33, },
+	{ -14, -248, 4003,  411,  -18, -38, },
+	{ -17, -269, 3974,  474,  -23, -43, },
+	{ -21, -287, 3940,  539,  -28, -47, },
+	{ -24, -303, 3903,  608,  -34, -54, },
+	{ -28, -317, 3862,  678,  -41, -58, },
+	{ -32, -329, 3817,  751,  -49, -62, },
+	{ -37, -339, 3768,  826,  -57, -65, },
+	{ -41, -347, 3716,  903,  -65, -70, },
+	{ -45, -353, 3661,  982,  -75, -74, },
+	{ -50, -358, 3602, 1063,  -84, -77, },
+	{ -54, -361, 3539, 1146,  -95, -79, },
+	{ -58, -362, 3474, 1230, -106, -82, },
+	{ -62, -361, 3406, 1317, -117, -87, },
+	{ -66, -359, 3335, 1404, -128, -90, },
+	{ -70, -356, 3261, 1493, -140, -92, },
+	{ -74, -351, 3185, 1583, -153, -94, },
+	{ -77, -346, 3106, 1673, -165, -95, },
+	{ -81, -339, 3025, 1765, -178, -96, },
+	{ -84, -331, 2942, 1857, -191, -97, },
+	{ -87, -322, 2858, 1950, -204, -99, },
+	{ -89, -313, 2771, 2043, -217, -99, },
+	{ -92, -302, 2683, 2136, -230, -99, },
+	{ -94, -292, 2594, 2228, -243, -97, },
+	{ -95, -280, 2504, 2321, -256, -98, },
+	{ -97, -268, 2413, 2413, -268, -97, },
+	{ -97, -256, 2321, 2504, -280, -96, },
+	{ -98, -243, 2228, 2594, -292, -93, },
+	{ -98, -230, 2136, 2683, -302, -93, },
+	{ -98, -217, 2043, 2771, -313, -90, },
+	{ -98, -204, 1950, 2858, -322, -88, },
+	{ -97, -191, 1857, 2942, -331, -84, },
+	{ -96, -178, 1765, 3025, -339, -81, },
+	{ -95, -165, 1673, 3106, -346, -77, },
+	{ -93, -153, 1583, 3185, -351, -75, },
+	{ -91, -140, 1493, 3261, -356, -71, },
+	{ -89, -128, 1404, 3335, -359, -67, },
+	{ -86, -117, 1317, 3406, -361, -63, },
+	{ -83, -106, 1230, 3474, -362, -57, },
+	{ -80,  -95, 1146, 3539, -361, -53, },
+	{ -77,  -84, 1063, 3602, -358, -50, },
+	{ -73,  -75,  982, 3661, -353, -46, },
+	{ -69,  -65,  903, 3716, -347, -42, },
+	{ -65,  -57,  826, 3768, -339, -37, },
+	{ -61,  -49,  751, 3817, -329, -33, },
+	{ -57,  -41,  678, 3862, -317, -29, },
+	{ -52,  -34,  608, 3903, -303, -26, },
+	{ -47,  -28,  539, 3940, -287, -21, },
+	{ -43,  -23,  474, 3974, -269, -17, },
+	{ -38,  -18,  411, 4003, -248, -14, },
+	{ -33,  -13,  350, 4029, -226, -11, },
+	{ -28,  -10,  292, 4051, -201,  -8, },
+	{ -24,   -7,  237, 4068, -173,  -5, },
+	{ -19,   -4,  184, 4082, -143,  -4, },
+	{ -14,   -2,  134, 4092, -111,  -3, },
+	{  -9,   -1,   87, 4097,  -77,  -1, },
+	{  -5,    0,   42, 4099,  -40,   0, }
+};
+
+/* ScalingRatio = 1.25 */
+static const s16
+XV_fixedcoeff_taps6_SR1p2[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_6] = {
+	{ -102,  512, 3208,  512, -102,  68, },
+	{  -97,  471, 3209,  555, -107,  65, },
+	{  -92,  431, 3208,  599, -113,  63, },
+	{  -87,  392, 3205,  645, -118,  59, },
+	{  -82,  354, 3199,  691, -124,  58, },
+	{  -77,  318, 3191,  739, -130,  55, },
+	{  -72,  282, 3181,  788, -136,  53, },
+	{  -68,  248, 3169,  838, -141,  50, },
+	{  -64,  216, 3155,  889, -147,  47, },
+	{  -59,  184, 3139,  941, -153,  44, },
+	{  -55,  154, 3120,  993, -158,  42, },
+	{  -52,  125, 3100, 1047, -164,  40, },
+	{  -48,   98, 3077, 1101, -169,  37, },
+	{  -44,   71, 3052, 1157, -174,  34, },
+	{  -41,   46, 3025, 1212, -180,  34, },
+	{  -38,   23, 2996, 1269, -184,  30, },
+	{  -35,    0, 2965, 1326, -189,  29, },
+	{  -32,  -21, 2933, 1383, -193,  26, },
+	{  -29,  -41, 2898, 1441, -198,  25, },
+	{  -26,  -60, 2862, 1500, -201,  21, },
+	{  -24,  -78, 2823, 1558, -205,  22, },
+	{  -21,  -94, 2784, 1617, -208,  18, },
+	{  -19, -109, 2742, 1676, -210,  16, },
+	{  -17, -123, 2699, 1734, -212,  15, },
+	{  -14, -136, 2654, 1793, -214,  13, },
+	{  -12, -148, 2608, 1852, -214,  10, },
+	{  -10, -159, 2560, 1910, -215,  10, },
+	{   -9, -168, 2512, 1968, -215,   8, },
+	{   -7, -177, 2461, 2026, -214,   7, },
+	{   -5, -185, 2410, 2083, -212,   5, },
+	{   -3, -192, 2358, 2139, -209,   3, },
+	{   -2, -197, 2304, 2195, -206,   2, },
+	{    0, -202, 2250, 2250, -202,   0, },
+	{    2, -206, 2195, 2304, -197,  -2, },
+	{    3, -209, 2139, 2358, -192,  -3, },
+	{    5, -212, 2083, 2410, -185,  -5, },
+	{    6, -214, 2026, 2461, -177,  -6, },
+	{    8, -215, 1968, 2512, -168,  -9, },
+	{   10, -215, 1910, 2560, -159, -10, },
+	{   11, -214, 1852, 2608, -148, -13, },
+	{   13, -214, 1793, 2654, -136, -14, },
+	{   15, -212, 1734, 2699, -123, -17, },
+	{   17, -210, 1676, 2742, -109, -20, },
+	{   18, -208, 1617, 2784,  -94, -21, },
+	{   20, -205, 1558, 2823,  -78, -22, },
+	{   22, -201, 1500, 2862,  -60, -27, },
+	{   24, -198, 1441, 2898,  -41, -28, },
+	{   26, -193, 1383, 2933,  -21, -32, },
+	{   28, -189, 1326, 2965,    0, -34, },
+	{   30, -184, 1269, 2996,   23, -38, },
+	{   33, -180, 1212, 3025,   46, -40, },
+	{   35, -174, 1157, 3052,   71, -45, },
+	{   37, -169, 1101, 3077,   98, -48, },
+	{   40, -164, 1047, 3100,  125, -52, },
+	{   42, -158,  993, 3120,  154, -55, },
+	{   44, -153,  941, 3139,  184, -59, },
+	{   47, -147,  889, 3155,  216, -64, },
+	{   50, -141,  838, 3169,  248, -68, },
+	{   52, -136,  788, 3181,  282, -71, },
+	{   55, -130,  739, 3191,  318, -77, },
+	{   57, -124,  691, 3199,  354, -81, },
+	{   60, -118,  645, 3205,  392, -88, },
+	{   63, -113,  599, 3208,  431, -92, },
+	{   65, -107,  555, 3209,  471, -97, }
+};
+
+/* ScalingRatio = 2.0 */
+static const s16
+XV_fixedcoeff_taps6_SR2[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_6] = {
+	{   0, 970, 2235,  970,   0, -79, },
+	{  -3, 943, 2233,  997,   3, -77, },
+	{  -5, 915, 2231, 1025,   6, -76, },
+	{  -8, 888, 2227, 1052,  10, -73, },
+	{ -10, 861, 2223, 1079,  14, -71, },
+	{ -12, 834, 2218, 1107,  18, -69, },
+	{ -14, 808, 2213, 1134,  22, -67, },
+	{ -15, 782, 2206, 1162,  27, -66, },
+	{ -17, 756, 2199, 1189,  32, -63, },
+	{ -18, 731, 2191, 1217,  37, -62, },
+	{ -20, 706, 2182, 1245,  42, -59, },
+	{ -21, 681, 2172, 1272,  48, -56, },
+	{ -22, 657, 2162, 1300,  55, -56, },
+	{ -22, 633, 2151, 1327,  61, -54, },
+	{ -23, 609, 2139, 1355,  68, -52, },
+	{ -24, 586, 2126, 1382,  76, -50, },
+	{ -25, 564, 2113, 1410,  83, -49, },
+	{ -25, 541, 2099, 1437,  91, -47, },
+	{ -26, 520, 2084, 1464, 100, -46, },
+	{ -26, 498, 2069, 1491, 109, -45, },
+	{ -27, 477, 2053, 1517, 118, -42, },
+	{ -27, 457, 2036, 1544, 128, -42, },
+	{ -27, 437, 2019, 1570, 138, -41, },
+	{ -28, 418, 2001, 1596, 148, -39, },
+	{ -28, 399, 1983, 1622, 160, -40, },
+	{ -29, 380, 1964, 1647, 171, -37, },
+	{ -29, 362, 1944, 1672, 183, -36, },
+	{ -29, 345, 1924, 1697, 195, -36, },
+	{ -30, 328, 1903, 1722, 208, -35, },
+	{ -30, 311, 1882, 1746, 221, -34, },
+	{ -31, 295, 1860, 1770, 235, -33, },
+	{ -31, 279, 1838, 1793, 249, -32, },
+	{ -32, 264, 1816, 1816, 264, -32, },
+	{ -32, 249, 1793, 1838, 279, -31, },
+	{ -33, 235, 1770, 1860, 295, -31, },
+	{ -34, 221, 1746, 1882, 311, -30, },
+	{ -35, 208, 1722, 1903, 328, -30, },
+	{ -35, 195, 1697, 1924, 345, -30, },
+	{ -36, 183, 1672, 1944, 362, -29, },
+	{ -37, 171, 1647, 1964, 380, -29, },
+	{ -38, 160, 1622, 1983, 399, -30, },
+	{ -39, 148, 1596, 2001, 418, -28, },
+	{ -40, 138, 1570, 2019, 437, -28, },
+	{ -42, 128, 1544, 2036, 457, -27, },
+	{ -43, 118, 1517, 2053, 477, -26, },
+	{ -44, 109, 1491, 2069, 498, -27, },
+	{ -46, 100, 1464, 2084, 520, -26, },
+	{ -47,  91, 1437, 2099, 541, -25, },
+	{ -49,  83, 1410, 2113, 564, -25, },
+	{ -50,  76, 1382, 2126, 586, -24, },
+	{ -52,  68, 1355, 2139, 609, -23, },
+	{ -54,  61, 1327, 2151, 633, -22, },
+	{ -55,  55, 1300, 2162, 657, -23, },
+	{ -57,  48, 1272, 2172, 681, -20, },
+	{ -59,  42, 1245, 2182, 706, -20, },
+	{ -61,  37, 1217, 2191, 731, -19, },
+	{ -63,  32, 1189, 2199, 756, -17, },
+	{ -65,  27, 1162, 2206, 782, -16, },
+	{ -67,  22, 1134, 2213, 808, -14, },
+	{ -69,  18, 1107, 2218, 834, -12, },
+	{ -71,  14, 1079, 2223, 861, -10, },
+	{ -73,  10, 1052, 2227, 888,  -8, },
+	{ -75,   6, 1025, 2231, 915,  -6, },
+	{ -77,   3,  997, 2233, 943,  -3, }
+};
+
+/* ScalingRatio = 3.0 */
+static const s16
+XV_fixedcoeff_taps6_SR3[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_6] = {
+	{ 126, 1019, 1806, 1019,  126,   0, },
+	{ 120, 1000, 1805, 1038,  132,   1, },
+	{ 114,  980, 1804, 1057,  138,   3, },
+	{ 108,  961, 1802, 1075,  145,   5, },
+	{ 103,  942, 1800, 1094,  152,   5, },
+	{  98,  922, 1797, 1113,  159,   7, },
+	{  93,  903, 1794, 1131,  167,   8, },
+	{  88,  884, 1790, 1150,  174,  10, },
+	{  84,  865, 1786, 1168,  182,  11, },
+	{  80,  846, 1782, 1187,  191,  10, },
+	{  76,  827, 1777, 1205,  199,  12, },
+	{  72,  809, 1771, 1223,  208,  13, },
+	{  68,  790, 1766, 1241,  217,  14, },
+	{  65,  772, 1759, 1259,  226,  15, },
+	{  61,  753, 1753, 1277,  236,  16, },
+	{  58,  735, 1746, 1295,  246,  16, },
+	{  56,  717, 1738, 1313,  256,  16, },
+	{  53,  699, 1730, 1330,  266,  18, },
+	{  50,  682, 1722, 1347,  277,  18, },
+	{  48,  664, 1713, 1364,  288,  19, },
+	{  46,  647, 1704, 1381,  299,  19, },
+	{  43,  630, 1694, 1398,  311,  20, },
+	{  41,  613, 1684, 1414,  323,  21, },
+	{  40,  596, 1674, 1430,  335,  21, },
+	{  38,  580, 1663, 1446,  347,  22, },
+	{  36,  563, 1652, 1462,  360,  23, },
+	{  35,  547, 1641, 1478,  373,  22, },
+	{  33,  531, 1629, 1493,  386,  24, },
+	{  32,  516, 1617, 1508,  399,  24, },
+	{  31,  500, 1604, 1523,  413,  25, },
+	{  30,  485, 1592, 1537,  427,  25, },
+	{  29,  470, 1578, 1551,  441,  27, },
+	{  28,  455, 1565, 1565,  455,  28, },
+	{  27,  441, 1551, 1578,  470,  29, },
+	{  26,  427, 1537, 1592,  485,  29, },
+	{  25,  413, 1523, 1604,  500,  31, },
+	{  24,  399, 1508, 1617,  516,  32, },
+	{  24,  386, 1493, 1629,  531,  33, },
+	{  23,  373, 1478, 1641,  547,  34, },
+	{  22,  360, 1462, 1652,  563,  37, },
+	{  22,  347, 1446, 1663,  580,  38, },
+	{  21,  335, 1430, 1674,  596,  40, },
+	{  20,  323, 1414, 1684,  613,  42, },
+	{  20,  311, 1398, 1694,  630,  43, },
+	{  19,  299, 1381, 1704,  647,  46, },
+	{  19,  288, 1364, 1713,  664,  48, },
+	{  18,  277, 1347, 1722,  682,  50, },
+	{  17,  266, 1330, 1730,  699,  54, },
+	{  17,  256, 1313, 1738,  717,  55, },
+	{  16,  246, 1295, 1746,  735,  58, },
+	{  15,  236, 1277, 1753,  753,  62, },
+	{  15,  226, 1259, 1759,  772,  65, },
+	{  14,  217, 1241, 1766,  790,  68, },
+	{  13,  208, 1223, 1771,  809,  72, },
+	{  12,  199, 1205, 1777,  827,  76, },
+	{  11,  191, 1187, 1782,  846,  79, },
+	{  10,  182, 1168, 1786,  865,  85, },
+	{   9,  174, 1150, 1790,  884,  89, },
+	{   8,  167, 1131, 1794,  903,  93, },
+	{   7,  159, 1113, 1797,  922,  98, },
+	{   6,  152, 1094, 1800,  942, 102, },
+	{   5,  145, 1075, 1802,  961, 108, },
+	{   3,  138, 1057, 1804,  980, 114, },
+	{   2,  132, 1038, 1805, 1000, 119, }
+};
+
+/* ScalingRatio = 4 */
+static const s16
+XV_fixedcoeff_taps6_SR4[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_6] = {
+	{ 176, 1009, 1643, 1009, 176,  83, },
+	{ 169,  993, 1644, 1026, 183,  81, },
+	{ 162,  978, 1644, 1042, 190,  80, },
+	{ 156,  962, 1643, 1058, 198,  79, },
+	{ 150,  946, 1642, 1074, 205,  79, },
+	{ 144,  930, 1641, 1091, 213,  77, },
+	{ 138,  914, 1640, 1107, 222,  75, },
+	{ 133,  898, 1638, 1123, 230,  74, },
+	{ 128,  882, 1635, 1139, 239,  73, },
+	{ 123,  866, 1633, 1154, 248,  72, },
+	{ 118,  850, 1629, 1170, 257,  72, },
+	{ 114,  834, 1626, 1186, 267,  69, },
+	{ 109,  818, 1622, 1201, 276,  70, },
+	{ 105,  802, 1618, 1217, 286,  68, },
+	{ 101,  786, 1613, 1232, 297,  67, },
+	{  97,  771, 1608, 1247, 307,  66, },
+	{  94,  755, 1603, 1262, 318,  64, },
+	{  91,  739, 1597, 1276, 328,  65, },
+	{  87,  724, 1591, 1291, 339,  64, },
+	{  85,  708, 1585, 1305, 351,  62, },
+	{  82,  693, 1578, 1319, 362,  62, },
+	{  79,  677, 1571, 1333, 374,  62, },
+	{  77,  662, 1563, 1347, 386,  61, },
+	{  75,  647, 1556, 1360, 398,  60, },
+	{  73,  632, 1547, 1373, 410,  61, },
+	{  71,  617, 1539, 1386, 423,  60, },
+	{  69,  602, 1530, 1399, 436,  60, },
+	{  68,  587, 1521, 1412, 449,  59, },
+	{  66,  573, 1511, 1424, 462,  60, },
+	{  65,  558, 1501, 1436, 475,  61, },
+	{  64,  544, 1491, 1447, 488,  62, },
+	{  63,  530, 1481, 1459, 502,  61, },
+	{  62,  516, 1470, 1470, 516,  62, },
+	{  62,  502, 1459, 1481, 530,  62, },
+	{  61,  488, 1447, 1491, 544,  65, },
+	{  61,  475, 1436, 1501, 558,  65, },
+	{  60,  462, 1424, 1511, 573,  66, },
+	{  60,  449, 1412, 1521, 587,  67, },
+	{  60,  436, 1399, 1530, 602,  69, },
+	{  60,  423, 1386, 1539, 617,  71, },
+	{  61,  410, 1373, 1547, 632,  73, },
+	{  61,  398, 1360, 1556, 647,  74, },
+	{  61,  386, 1347, 1563, 662,  77, },
+	{  62,  374, 1333, 1571, 677,  79, },
+	{  62,  362, 1319, 1578, 693,  82, },
+	{  63,  351, 1305, 1585, 708,  84, },
+	{  64,  339, 1291, 1591, 724,  87, },
+	{  64,  328, 1276, 1597, 739,  92, },
+	{  65,  318, 1262, 1603, 755,  93, },
+	{  66,  307, 1247, 1608, 771,  97, },
+	{  67,  297, 1232, 1613, 786, 101, },
+	{  68,  286, 1217, 1618, 802, 105, },
+	{  69,  276, 1201, 1622, 818, 110, },
+	{  70,  267, 1186, 1626, 834, 113, },
+	{  71,  257, 1170, 1629, 850, 119, },
+	{  72,  248, 1154, 1633, 866, 123, },
+	{  73,  239, 1139, 1635, 882, 128, },
+	{  75,  230, 1123, 1638, 898, 132, },
+	{  76,  222, 1107, 1640, 914, 137, },
+	{  77,  213, 1091, 1641, 930, 144, },
+	{  78,  205, 1074, 1642, 946, 151, },
+	{  79,  198, 1058, 1643, 962, 156, },
+	{  80,  190, 1042, 1644, 978, 162, },
+	{  82,  183, 1026, 1644, 993, 168, }
+};
+
+/* ScalingRatio = 2.0 */
+static const s16
+XV_fixedcoeff_taps8_SR2[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_8] = {
+	{ -55,   0, 1078, 2049, 1078,    0, -55,   1, },
+	{ -53,  -7, 1055, 2049, 1102,    7, -56,  -1, },
+	{ -52, -13, 1032, 2048, 1126,   15, -58,  -2, },
+	{ -50, -20, 1009, 2047, 1149,   22, -59,  -2, },
+	{ -49, -26,  986, 2046, 1173,   31, -61,  -4, },
+	{ -47, -31,  963, 2043, 1197,   39, -62,  -6, },
+	{ -46, -37,  940, 2040, 1220,   48, -64,  -5, },
+	{ -45, -42,  917, 2037, 1244,   57, -65,  -7, },
+	{ -43, -47,  894, 2033, 1267,   66, -67,  -7, },
+	{ -42, -51,  871, 2028, 1290,   76, -69,  -7, },
+	{ -41, -55,  848, 2023, 1313,   86, -70,  -8, },
+	{ -40, -59,  826, 2017, 1336,   97, -72,  -9, },
+	{ -38, -63,  803, 2010, 1359,  108, -73, -10, },
+	{ -37, -67,  781, 2003, 1382,  119, -75, -10, },
+	{ -36, -70,  759, 1996, 1405,  130, -76, -12, },
+	{ -35, -73,  737, 1987, 1427,  142, -78, -11, },
+	{ -34, -76,  715, 1979, 1449,  154, -79, -12, },
+	{ -33, -78,  693, 1969, 1471,  167, -81, -12, },
+	{ -32, -81,  672, 1959, 1493,  180, -82, -13, },
+	{ -31, -83,  650, 1949, 1514,  193, -83, -13, },
+	{ -30, -85,  629, 1938, 1536,  207, -85, -14, },
+	{ -29, -86,  609, 1926, 1557,  221, -86, -16, },
+	{ -28, -88,  588, 1914, 1577,  235, -87, -15, },
+	{ -28, -89,  568, 1902, 1598,  250, -88, -17, },
+	{ -27, -90,  548, 1889, 1618,  265, -89, -18, },
+	{ -26, -91,  528, 1875, 1638,  280, -90, -18, },
+	{ -25, -92,  508, 1861, 1657,  296, -91, -18, },
+	{ -24, -93,  489, 1846, 1676,  312, -92, -18, },
+	{ -24, -93,  470, 1831, 1695,  328, -92, -19, },
+	{ -23, -94,  451, 1816, 1714,  345, -93, -20, },
+	{ -22, -94,  432, 1800, 1732,  361, -93, -20, },
+	{ -22, -94,  414, 1783, 1749,  379, -94, -19, },
+	{ -21, -94,  396, 1767, 1767,  396, -94, -21, },
+	{ -21, -94,  379, 1749, 1783,  414, -94, -20, },
+	{ -20, -93,  361, 1732, 1800,  432, -94, -22, },
+	{ -19, -93,  345, 1714, 1816,  451, -94, -24, },
+	{ -19, -92,  328, 1695, 1831,  470, -93, -24, },
+	{ -18, -92,  312, 1676, 1846,  489, -93, -24, },
+	{ -18, -91,  296, 1657, 1861,  508, -92, -25, },
+	{ -17, -90,  280, 1638, 1875,  528, -91, -27, },
+	{ -17, -89,  265, 1618, 1889,  548, -90, -28, },
+	{ -16, -88,  250, 1598, 1902,  568, -89, -29, },
+	{ -16, -87,  235, 1577, 1914,  588, -88, -27, },
+	{ -15, -86,  221, 1557, 1926,  609, -86, -30, },
+	{ -14, -85,  207, 1536, 1938,  629, -85, -30, },
+	{ -14, -83,  193, 1514, 1949,  650, -83, -30, },
+	{ -13, -82,  180, 1493, 1959,  672, -81, -32, },
+	{ -13, -81,  167, 1471, 1969,  693, -78, -32, },
+	{ -12, -79,  154, 1449, 1979,  715, -76, -34, },
+	{ -12, -78,  142, 1427, 1987,  737, -73, -34, },
+	{ -11, -76,  130, 1405, 1996,  759, -70, -37, },
+	{ -10, -75,  119, 1382, 2003,  781, -67, -37, },
+	{ -10, -73,  108, 1359, 2010,  803, -63, -38, },
+	{  -9, -72,   97, 1336, 2017,  826, -59, -40, },
+	{  -8, -70,   86, 1313, 2023,  848, -55, -41, },
+	{  -8, -69,   76, 1290, 2028,  871, -51, -41, },
+	{  -7, -67,   66, 1267, 2033,  894, -47, -43, },
+	{  -6, -65,   57, 1244, 2037,  917, -42, -46, },
+	{  -5, -64,   48, 1220, 2040,  940, -37, -46, },
+	{  -5, -62,   39, 1197, 2043,  963, -31, -48, },
+	{  -4, -61,   31, 1173, 2046,  986, -26, -49, },
+	{  -3, -59,   22, 1149, 2047, 1009, -20, -49, },
+	{  -2, -58,   15, 1126, 2048, 1032, -13, -52, },
+	{  -1, -56,    7, 1102, 2049, 1055,  -7, -53, }
+};
+
+/* ScalingRatio = 3.0 */
+static const s16
+XV_fixedcoeff_taps8_SR3[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_8] = {
+	{   0, 275, 1036, 1514, 1036,  275,   0, -40, },
+	{  -1, 266, 1023, 1514, 1048,  283,   1, -38, },
+	{  -2, 257, 1010, 1513, 1060,  292,   2, -36, },
+	{  -3, 249,  997, 1512, 1073,  301,   3, -36, },
+	{  -3, 241,  983, 1510, 1085,  310,   5, -35, },
+	{  -4, 233,  970, 1509, 1097,  319,   6, -34, },
+	{  -5, 225,  957, 1507, 1109,  329,   7, -33, },
+	{  -6, 217,  944, 1505, 1121,  338,   9, -32, },
+	{  -6, 210,  931, 1503, 1133,  348,  10, -33, },
+	{  -7, 202,  917, 1500, 1144,  358,  12, -30, },
+	{  -7, 195,  904, 1497, 1156,  368,  13, -30, },
+	{  -8, 188,  891, 1494, 1167,  378,  15, -29, },
+	{  -9, 181,  877, 1491, 1179,  388,  17, -28, },
+	{  -9, 174,  864, 1487, 1190,  398,  19, -27, },
+	{  -9, 168,  851, 1483, 1201,  409,  21, -28, },
+	{ -10, 161,  837, 1479, 1212,  419,  23, -25, },
+	{ -10, 155,  824, 1475, 1223,  430,  25, -26, },
+	{ -11, 149,  811, 1470, 1233,  441,  27, -24, },
+	{ -11, 142,  798, 1465, 1244,  452,  29, -23, },
+	{ -12, 137,  784, 1460, 1254,  463,  32, -22, },
+	{ -12, 131,  771, 1455, 1264,  474,  34, -21, },
+	{ -12, 125,  758, 1449, 1275,  486,  37, -22, },
+	{ -13, 120,  745, 1444, 1284,  497,  40, -21, },
+	{ -13, 115,  732, 1438, 1294,  509,  42, -21, },
+	{ -13, 109,  719, 1432, 1304,  520,  45, -20, },
+	{ -14, 104,  706, 1425, 1313,  532,  48, -18, },
+	{ -14, 100,  693, 1418, 1322,  544,  52, -19, },
+	{ -14,  95,  680, 1412, 1332,  556,  55, -20, },
+	{ -15,  90,  667, 1404, 1340,  568,  58, -16, },
+	{ -15,  86,  655, 1397, 1349,  580,  62, -18, },
+	{ -16,  82,  642, 1390, 1358,  592,  66, -18, },
+	{ -16,  77,  630, 1382, 1366,  605,  69, -17, },
+	{ -16,  73,  617, 1374, 1374,  617,  73, -16, },
+	{ -17,  69,  605, 1366, 1382,  630,  77, -16, },
+	{ -17,  66,  592, 1358, 1390,  642,  82, -17, },
+	{ -18,  62,  580, 1349, 1397,  655,  86, -15, },
+	{ -18,  58,  568, 1340, 1404,  667,  90, -13, },
+	{ -18,  55,  556, 1332, 1412,  680,  95, -16, },
+	{ -19,  52,  544, 1322, 1418,  693, 100, -14, },
+	{ -19,  48,  532, 1313, 1425,  706, 104, -13, },
+	{ -20,  45,  520, 1304, 1432,  719, 109, -13, },
+	{ -20,  42,  509, 1294, 1438,  732, 115, -14, },
+	{ -21,  40,  497, 1284, 1444,  745, 120, -13, },
+	{ -22,  37,  486, 1275, 1449,  758, 125, -12, },
+	{ -22,  34,  474, 1264, 1455,  771, 131, -11, },
+	{ -23,  32,  463, 1254, 1460,  784, 137, -11, },
+	{ -23,  29,  452, 1244, 1465,  798, 142, -11, },
+	{ -24,  27,  441, 1233, 1470,  811, 149, -11, },
+	{ -25,  25,  430, 1223, 1475,  824, 155, -11, },
+	{ -26,  23,  419, 1212, 1479,  837, 161,  -9, },
+	{ -26,  21,  409, 1201, 1483,  851, 168, -11, },
+	{ -27,  19,  398, 1190, 1487,  864, 174,  -9, },
+	{ -28,  17,  388, 1179, 1491,  877, 181,  -9, },
+	{ -29,  15,  378, 1167, 1494,  891, 188,  -8, },
+	{ -29,  13,  368, 1156, 1497,  904, 195,  -8, },
+	{ -30,  12,  358, 1144, 1500,  917, 202,  -7, },
+	{ -31,  10,  348, 1133, 1503,  931, 210,  -8, },
+	{ -32,   9,  338, 1121, 1505,  944, 217,  -6, },
+	{ -33,   7,  329, 1109, 1507,  957, 225,  -5, },
+	{ -34,   6,  319, 1097, 1509,  970, 233,  -4, },
+	{ -35,   5,  310, 1085, 1510,  983, 241,  -3, },
+	{ -36,   3,  301, 1073, 1512,  997, 249,  -3, },
+	{ -37,   2,  292, 1060, 1513, 1010, 257,  -1, },
+	{ -38,   1,  283, 1048, 1514, 1023, 266,  -1, }
+};
+
+/* ScalingRatio = 4 */
+static const s16
+XV_fixedcoeff_taps8_SR4[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_8] = {
+	{ 49, 366, 977, 1312,  977, 366,  49,  0, },
+	{ 48, 357, 967, 1312,  986, 374,  51,  1, },
+	{ 46, 349, 958, 1311,  995, 382,  54,  1, },
+	{ 44, 342, 948, 1311, 1004, 390,  56,  1, },
+	{ 42, 334, 939, 1310, 1013, 399,  58,  1, },
+	{ 40, 326, 929, 1309, 1021, 407,  60,  4, },
+	{ 39, 318, 919, 1308, 1030, 415,  63,  4, },
+	{ 37, 311, 910, 1307, 1039, 424,  65,  3, },
+	{ 36, 303, 900, 1305, 1047, 433,  68,  4, },
+	{ 34, 296, 890, 1303, 1055, 442,  70,  6, },
+	{ 33, 289, 880, 1301, 1064, 450,  73,  6, },
+	{ 32, 282, 870, 1299, 1072, 459,  76,  6, },
+	{ 31, 275, 861, 1297, 1080, 468,  79,  5, },
+	{ 29, 268, 851, 1295, 1088, 477,  82,  6, },
+	{ 28, 261, 841, 1292, 1096, 486,  85,  7, },
+	{ 27, 254, 831, 1289, 1104, 496,  88,  7, },
+	{ 26, 248, 821, 1287, 1112, 505,  91,  6, },
+	{ 25, 241, 811, 1284, 1119, 514,  94,  8, },
+	{ 24, 235, 800, 1280, 1127, 523,  98,  9, },
+	{ 23, 228, 790, 1277, 1134, 533, 101, 10, },
+	{ 22, 222, 780, 1273, 1141, 542, 105, 11, },
+	{ 22, 216, 770, 1270, 1148, 552, 109,  9, },
+	{ 21, 210, 760, 1266, 1155, 561, 112, 11, },
+	{ 20, 204, 750, 1262, 1162, 571, 116, 11, },
+	{ 19, 198, 740, 1257, 1169, 581, 120, 12, },
+	{ 19, 193, 730, 1253, 1175, 590, 124, 12, },
+	{ 18, 187, 720, 1248, 1182, 600, 129, 12, },
+	{ 17, 182, 710, 1244, 1188, 610, 133, 12, },
+	{ 17, 176, 700, 1239, 1194, 620, 137, 13, },
+	{ 16, 171, 690, 1234, 1201, 630, 142, 12, },
+	{ 16, 166, 680, 1229, 1206, 640, 146, 13, },
+	{ 15, 161, 670, 1223, 1212, 650, 151, 14, },
+	{ 15, 156, 660, 1218, 1218, 660, 156, 13, },
+	{ 14, 151, 650, 1212, 1223, 670, 161, 15, },
+	{ 14, 146, 640, 1206, 1229, 680, 166, 15, },
+	{ 13, 142, 630, 1201, 1234, 690, 171, 15, },
+	{ 13, 137, 620, 1194, 1239, 700, 176, 17, },
+	{ 12, 133, 610, 1188, 1244, 710, 182, 17, },
+	{ 12, 129, 600, 1182, 1248, 720, 187, 18, },
+	{ 11, 124, 590, 1175, 1253, 730, 193, 20, },
+	{ 11, 120, 581, 1169, 1257, 740, 198, 20, },
+	{ 11, 116, 571, 1162, 1262, 750, 204, 20, },
+	{ 10, 112, 561, 1155, 1266, 760, 210, 22, },
+	{ 10, 109, 552, 1148, 1270, 770, 216, 21, },
+	{ 10, 105, 542, 1141, 1273, 780, 222, 23, },
+	{  9, 101, 533, 1134, 1277, 790, 228, 24, },
+	{  9,  98, 523, 1127, 1280, 800, 235, 24, },
+	{  8,  94, 514, 1119, 1284, 811, 241, 25, },
+	{  8,  91, 505, 1112, 1287, 821, 248, 24, },
+	{  8,  88, 496, 1104, 1289, 831, 254, 26, },
+	{  7,  85, 486, 1096, 1292, 841, 261, 28, },
+	{  7,  82, 477, 1088, 1295, 851, 268, 28, },
+	{  6,  79, 468, 1080, 1297, 861, 275, 30, },
+	{  6,  76, 459, 1072, 1299, 870, 282, 32, },
+	{  5,  73, 450, 1064, 1301, 880, 289, 34, },
+	{  5,  70, 442, 1055, 1303, 890, 296, 35, },
+	{  4,  68, 433, 1047, 1305, 900, 303, 36, },
+	{  4,  65, 424, 1039, 1307, 910, 311, 36, },
+	{  3,  63, 415, 1030, 1308, 919, 318, 40, },
+	{  3,  60, 407, 1021, 1309, 929, 326, 41, },
+	{  2,  58, 399, 1013, 1310, 939, 334, 41, },
+	{  2,  56, 390, 1004, 1311, 948, 342, 43, },
+	{  1,  54, 382,  995, 1311, 958, 349, 46, },
+	{  1,  51, 374,  986, 1312, 967, 357, 48, }
+};
+
+/* ScalingRatio = 3.0 */
+static const s16
+XV_fixedcoeff_taps10_SR3[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_10] = {
+	{ -31,   0, 359, 1033, 1399, 1033,  359,   0, -31, -25, },
+	{ -31,  -2, 350, 1022, 1398, 1043,  368,   3, -31, -24, },
+	{ -30,  -4, 341, 1012, 1398, 1053,  378,   5, -32, -25, },
+	{ -30,  -6, 333, 1002, 1398, 1062,  387,   8, -32, -26, },
+	{ -30,  -8, 324,  992, 1397, 1072,  396,  10, -32, -25, },
+	{ -30, -10, 315,  981, 1396, 1082,  406,  13, -33, -24, },
+	{ -29, -12, 307,  971, 1395, 1091,  415,  16, -33, -25, },
+	{ -29, -13, 298,  960, 1393, 1101,  425,  18, -33, -24, },
+	{ -29, -15, 290,  949, 1392, 1110,  434,  21, -34, -22, },
+	{ -28, -17, 282,  939, 1390, 1120,  444,  25, -34, -25, },
+	{ -28, -18, 274,  928, 1388, 1129,  454,  28, -34, -25, },
+	{ -28, -20, 266,  917, 1386, 1138,  464,  31, -34, -24, },
+	{ -27, -21, 258,  906, 1384, 1147,  474,  34, -35, -24, },
+	{ -27, -22, 250,  895, 1381, 1156,  484,  38, -35, -24, },
+	{ -27, -23, 242,  885, 1379, 1164,  494,  41, -35, -24, },
+	{ -27, -25, 235,  874, 1376, 1173,  504,  45, -35, -24, },
+	{ -26, -26, 227,  863, 1373, 1181,  515,  49, -36, -24, },
+	{ -26, -27, 220,  852, 1369, 1190,  525,  53, -36, -24, },
+	{ -26, -28, 213,  841, 1366, 1198,  535,  56, -36, -23, },
+	{ -26, -29, 206,  830, 1362, 1206,  546,  61, -36, -24, },
+	{ -25, -29, 199,  819, 1358, 1214,  556,  65, -36, -25, },
+	{ -25, -30, 192,  808, 1354, 1222,  567,  69, -36, -25, },
+	{ -25, -31, 185,  797, 1350, 1229,  577,  73, -36, -23, },
+	{ -25, -32, 178,  785, 1346, 1237,  588,  78, -36, -23, },
+	{ -25, -32, 172,  774, 1341, 1244,  599,  83, -36, -24, },
+	{ -25, -33, 165,  763, 1336, 1252,  610,  87, -36, -23, },
+	{ -24, -33, 159,  752, 1331, 1259,  620,  92, -36, -24, },
+	{ -24, -34, 153,  741, 1326, 1266,  631,  97, -36, -24, },
+	{ -24, -34, 147,  730, 1321, 1272,  642, 102, -36, -24, },
+	{ -24, -35, 141,  719, 1315, 1279,  653, 107, -36, -23, },
+	{ -24, -35, 135,  708, 1310, 1285,  664, 113, -36, -24, },
+	{ -24, -35, 129,  697, 1304, 1292,  675, 118, -36, -24, },
+	{ -24, -36, 124,  686, 1298, 1298,  686, 124, -36, -24, },
+	{ -24, -36, 118,  675, 1292, 1304,  697, 129, -35, -24, },
+	{ -24, -36, 113,  664, 1285, 1310,  708, 135, -35, -24, },
+	{ -24, -36, 107,  653, 1279, 1315,  719, 141, -35, -23, },
+	{ -24, -36, 102,  642, 1272, 1321,  730, 147, -34, -24, },
+	{ -23, -36,  97,  631, 1266, 1326,  741, 153, -34, -25, },
+	{ -23, -36,  92,  620, 1259, 1331,  752, 159, -33, -25, },
+	{ -23, -36,  87,  610, 1252, 1336,  763, 165, -33, -25, },
+	{ -23, -36,  83,  599, 1244, 1341,  774, 172, -32, -26, },
+	{ -23, -36,  78,  588, 1237, 1346,  785, 178, -32, -25, },
+	{ -23, -36,  73,  577, 1229, 1350,  797, 185, -31, -25, },
+	{ -23, -36,  69,  567, 1222, 1354,  808, 192, -30, -27, },
+	{ -23, -36,  65,  556, 1214, 1358,  819, 199, -29, -27, },
+	{ -24, -36,  61,  546, 1206, 1362,  830, 206, -29, -26, },
+	{ -24, -36,  56,  535, 1198, 1366,  841, 213, -28, -25, },
+	{ -24, -36,  53,  525, 1190, 1369,  852, 220, -27, -26, },
+	{ -24, -36,  49,  515, 1181, 1373,  863, 227, -26, -26, },
+	{ -24, -35,  45,  504, 1173, 1376,  874, 235, -25, -27, },
+	{ -24, -35,  41,  494, 1164, 1379,  885, 242, -23, -27, },
+	{ -24, -35,  38,  484, 1156, 1381,  895, 250, -22, -27, },
+	{ -24, -35,  34,  474, 1147, 1384,  906, 258, -21, -27, },
+	{ -24, -34,  31,  464, 1138, 1386,  917, 266, -20, -28, },
+	{ -24, -34,  28,  454, 1129, 1388,  928, 274, -18, -29, },
+	{ -24, -34,  25,  444, 1120, 1390,  939, 282, -17, -29, },
+	{ -24, -34,  21,  434, 1110, 1392,  949, 290, -15, -27, },
+	{ -24, -33,  18,  425, 1101, 1393,  960, 298, -13, -29, },
+	{ -24, -33,  16,  415, 1091, 1395,  971, 307, -12, -30, },
+	{ -25, -33,  13,  406, 1082, 1396,  981, 315, -10, -29, },
+	{ -25, -32,  10,  396, 1072, 1397,  992, 324,  -8, -30, },
+	{ -25, -32,   8,  387, 1062, 1398, 1002, 333,  -6, -31, },
+	{ -25, -32,   5,  378, 1053, 1398, 1012, 341,  -4, -30, },
+	{ -25, -31,   3,  368, 1043, 1398, 1022, 350,  -2, -30, }
+};
+
+/* ScalingRatio = 4 */
+static const s16
+XV_fixedcoeff_taps10_SR4[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_10] = {
+	{   0, 107, 454, 924, 1150,  924, 454, 107,   0, -24, },
+	{   0, 104, 446, 917, 1149,  930, 461, 110,   0, -21, },
+	{  -1, 100, 439, 910, 1149,  936, 468, 114,   1, -20, },
+	{  -1,  97, 432, 904, 1149,  942, 475, 117,   2, -21, },
+	{  -2,  94, 425, 897, 1148,  948, 482, 121,   2, -19, },
+	{  -2,  91, 418, 890, 1147,  954, 490, 125,   3, -20, },
+	{  -3,  88, 411, 883, 1147,  960, 497, 128,   3, -18, },
+	{  -3,  85, 404, 876, 1146,  966, 504, 132,   4, -18, },
+	{  -3,  82, 397, 869, 1145,  972, 512, 136,   5, -19, },
+	{  -4,  79, 390, 862, 1144,  978, 519, 140,   5, -17, },
+	{  -4,  76, 384, 855, 1142,  983, 526, 144,   6, -16, },
+	{  -4,  74, 377, 848, 1141,  989, 534, 148,   7, -18, },
+	{  -5,  71, 370, 841, 1139,  995, 541, 152,   7, -15, },
+	{  -5,  68, 364, 834, 1138, 1000, 549, 156,   8, -16, },
+	{  -5,  66, 357, 827, 1136, 1005, 556, 160,   9, -15, },
+	{  -6,  63, 350, 820, 1134, 1011, 564, 165,  10, -15, },
+	{  -6,  61, 344, 812, 1132, 1016, 571, 169,  11, -14, },
+	{  -6,  59, 338, 805, 1130, 1021, 579, 174,  12, -16, },
+	{  -6,  56, 331, 798, 1128, 1026, 586, 178,  13, -14, },
+	{  -7,  54, 325, 790, 1126, 1031, 594, 183,  14, -14, },
+	{  -7,  52, 319, 783, 1124, 1036, 601, 187,  15, -14, },
+	{  -7,  50, 312, 776, 1121, 1041, 609, 192,  16, -14, },
+	{  -7,  48, 306, 768, 1119, 1045, 617, 197,  17, -14, },
+	{  -8,  46, 300, 761, 1116, 1050, 624, 202,  18, -13, },
+	{  -8,  44, 294, 753, 1113, 1054, 632, 207,  19, -12, },
+	{  -8,  42, 288, 746, 1110, 1059, 639, 212,  20, -12, },
+	{  -8,  40, 282, 738, 1107, 1063, 647, 217,  22, -12, },
+	{  -9,  38, 277, 731, 1104, 1067, 655, 222,  23, -12, },
+	{  -9,  36, 271, 723, 1101, 1071, 662, 227,  24, -10, },
+	{  -9,  35, 265, 715, 1097, 1075, 670, 232,  26, -10, },
+	{  -9,  33, 259, 708, 1094, 1079, 677, 238,  27, -10, },
+	{ -10,  32, 254, 700, 1091, 1083, 685, 243,  28, -10, },
+	{ -10,  30, 248, 693, 1087, 1087, 693, 248,  30, -10, },
+	{ -10,  28, 243, 685, 1083, 1091, 700, 254,  32, -10, },
+	{ -10,  27, 238, 677, 1079, 1094, 708, 259,  33,  -9, },
+	{ -11,  26, 232, 670, 1075, 1097, 715, 265,  35,  -8, },
+	{ -11,  24, 227, 662, 1071, 1101, 723, 271,  36,  -8, },
+	{ -11,  23, 222, 655, 1067, 1104, 731, 277,  38, -10, },
+	{ -12,  22, 217, 647, 1063, 1107, 738, 282,  40,  -8, },
+	{ -12,  20, 212, 639, 1059, 1110, 746, 288,  42,  -8, },
+	{ -12,  19, 207, 632, 1054, 1113, 753, 294,  44,  -8, },
+	{ -12,  18, 202, 624, 1050, 1116, 761, 300,  46,  -9, },
+	{ -13,  17, 197, 617, 1045, 1119, 768, 306,  48,  -8, },
+	{ -13,  16, 192, 609, 1041, 1121, 776, 312,  50,  -8, },
+	{ -13,  15, 187, 601, 1036, 1124, 783, 319,  52,  -8, },
+	{ -14,  14, 183, 594, 1031, 1126, 790, 325,  54,  -7, },
+	{ -14,  13, 178, 586, 1026, 1128, 798, 331,  56,  -6, },
+	{ -14,  12, 174, 579, 1021, 1130, 805, 338,  59,  -8, },
+	{ -15,  11, 169, 571, 1016, 1132, 812, 344,  61,  -5, },
+	{ -15,  10, 165, 564, 1011, 1134, 820, 350,  63,  -6, },
+	{ -16,   9, 160, 556, 1005, 1136, 827, 357,  66,  -4, },
+	{ -16,   8, 156, 549, 1000, 1138, 834, 364,  68,  -5, },
+	{ -16,   7, 152, 541,  995, 1139, 841, 370,  71,  -4, },
+	{ -17,   7, 148, 534,  989, 1141, 848, 377,  74,  -5, },
+	{ -17,   6, 144, 526,  983, 1142, 855, 384,  76,  -3, },
+	{ -18,   5, 140, 519,  978, 1144, 862, 390,  79,  -3, },
+	{ -18,   5, 136, 512,  972, 1145, 869, 397,  82,  -4, },
+	{ -19,   4, 132, 504,  966, 1146, 876, 404,  85,  -2, },
+	{ -19,   3, 128, 497,  960, 1147, 883, 411,  88,  -2, },
+	{ -20,   3, 125, 490,  954, 1147, 890, 418,  91,  -2, },
+	{ -20,   2, 121, 482,  948, 1148, 897, 425,  94,  -1, },
+	{ -21,   2, 117, 475,  942, 1149, 904, 432,  97,  -1, },
+	{ -21,   1, 114, 468,  936, 1149, 910, 439, 100,   0, },
+	{ -22,   0, 110, 461,  930, 1149, 917, 446, 104,   1, }
+};
+
+/* ScalingRatio = 4 */
+static const s16
+XV_fixedcoeff_taps12_SR4[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_TAPS_12] = {
+	{ -19,   0, 152, 498, 893, 1070,  893, 498, 152,   0, -19, -22, },
+	{ -19,  -1, 147, 487, 879, 1059,  889, 499, 155,   1, -19,  19, },
+	{ -19,  -2, 143, 480, 874, 1059,  894, 506, 159,   2, -19,  19, },
+	{ -19,  -3, 139, 474, 869, 1059,  899, 512, 163,   3, -19,  19, },
+	{ -19,  -4, 136, 468, 863, 1059,  904, 519, 167,   4, -19,  18, },
+	{ -19,  -5, 132, 461, 858, 1058,  909, 525, 171,   5, -19,  20, },
+	{ -19,  -5, 128, 455, 853, 1058,  913, 531, 175,   7, -19,  19, },
+	{ -18,  -6, 125, 449, 847, 1057,  918, 538, 180,   8, -19,  17, },
+	{ -18,  -7, 121, 443, 842, 1056,  923, 544, 184,   9, -19,  18, },
+	{ -18,  -8, 118, 436, 836, 1056,  927, 551, 188,  10, -19,  19, },
+	{ -18,  -8, 114, 430, 831, 1055,  932, 557, 193,  12, -19,  17, },
+	{ -18,  -9, 111, 424, 825, 1054,  936, 564, 197,  13, -19,  18, },
+	{ -18, -10, 107, 418, 819, 1053,  941, 570, 202,  14, -19,  19, },
+	{ -18, -10, 104, 412, 814, 1052,  945, 577, 206,  16, -19,  17, },
+	{ -18, -11, 101, 406, 808, 1050,  949, 583, 211,  17, -19,  19, },
+	{ -18, -11,  98, 400, 802, 1049,  954, 590, 216,  19, -19,  16, },
+	{ -18, -12,  95, 394, 796, 1048,  958, 596, 220,  20, -19,  18, },
+	{ -18, -12,  92, 388, 791, 1046,  962, 603, 225,  22, -19,  16, },
+	{ -18, -13,  89, 382, 785, 1045,  966, 609, 230,  24, -19,  16, },
+	{ -18, -13,  86, 376, 779, 1043,  970, 616, 235,  25, -19,  16, },
+	{ -18, -14,  83, 370, 773, 1041,  973, 622, 240,  27, -19,  18, },
+	{ -18, -14,  80, 364, 767, 1039,  977, 629, 244,  29, -19,  18, },
+	{ -18, -15,  77, 358, 761, 1037,  981, 635, 249,  31, -19,  19, },
+	{ -18, -15,  74, 352, 755, 1035,  984, 642, 255,  33, -19,  18, },
+	{ -18, -15,  71, 347, 749, 1033,  988, 648, 260,  35, -19,  17, },
+	{ -18, -16,  69, 341, 743, 1031,  991, 654, 265,  36, -19,  19, },
+	{ -18, -16,  66, 335, 736, 1029,  995, 661, 270,  38, -19,  19, },
+	{ -18, -16,  64, 330, 730, 1026,  998, 667, 275,  41, -18,  17, },
+	{ -18, -17,  61, 324, 724, 1024, 1001, 674, 280,  43, -18,  18, },
+	{ -18, -17,  59, 318, 718, 1021, 1004, 680, 286,  45, -18,  18, },
+	{ -18, -17,  56, 313, 712, 1019, 1007, 686, 291,  47, -18,  18, },
+	{ -18, -17,  54, 307, 705, 1016, 1010, 693, 296,  49, -18,  19, },
+	{ -18, -18,  51, 302, 699, 1013, 1013, 699, 302,  51, -18,  20, },
+	{ -18, -18,  49, 296, 693, 1010, 1016, 705, 307,  54, -17,  19, },
+	{ -18, -18,  47, 291, 686, 1007, 1019, 712, 313,  56, -17,  18, },
+	{ -18, -18,  45, 286, 680, 1004, 1021, 718, 318,  59, -17,  18, },
+	{ -18, -18,  43, 280, 674, 1001, 1024, 724, 324,  61, -17,  18, },
+	{ -18, -18,  41, 275, 667,  998, 1026, 730, 330,  64, -16,  17, },
+	{ -18, -19,  38, 270, 661,  995, 1029, 736, 335,  66, -16,  19, },
+	{ -19, -19,  36, 265, 654,  991, 1031, 743, 341,  69, -16,  20, },
+	{ -19, -19,  35, 260, 648,  988, 1033, 749, 347,  71, -15,  18, },
+	{ -19, -19,  33, 255, 642,  984, 1035, 755, 352,  74, -15,  19, },
+	{ -19, -19,  31, 249, 635,  981, 1037, 761, 358,  77, -15,  20, },
+	{ -19, -19,  29, 244, 629,  977, 1039, 767, 364,  80, -14,  19, },
+	{ -19, -19,  27, 240, 622,  973, 1041, 773, 370,  83, -14,  19, },
+	{ -19, -19,  25, 235, 616,  970, 1043, 779, 376,  86, -13,  17, },
+	{ -19, -19,  24, 230, 609,  966, 1045, 785, 382,  89, -13,  17, },
+	{ -19, -19,  22, 225, 603,  962, 1046, 791, 388,  92, -12,  17, },
+	{ -19, -19,  20, 220, 596,  958, 1048, 796, 394,  95, -12,  19, },
+	{ -20, -19,  19, 216, 590,  954, 1049, 802, 400,  98, -11,  18, },
+	{ -20, -19,  17, 211, 583,  949, 1050, 808, 406, 101, -11,  21, },
+	{ -20, -19,  16, 206, 577,  945, 1052, 814, 412, 104, -10,  19, },
+	{ -20, -19,  14, 202, 570,  941, 1053, 819, 418, 107, -10,  21, },
+	{ -20, -19,  13, 197, 564,  936, 1054, 825, 424, 111,  -9,  20, },
+	{ -20, -19,  12, 193, 557,  932, 1055, 831, 430, 114,  -8,  19, },
+	{ -21, -19,  10, 188, 551,  927, 1056, 836, 436, 118,  -8,  22, },
+	{ -21, -19,   9, 184, 544,  923, 1056, 842, 443, 121,  -7,  21, },
+	{ -21, -19,   8, 180, 538,  918, 1057, 847, 449, 125,  -6,  20, },
+	{ -21, -19,   7, 175, 531,  913, 1058, 853, 455, 128,  -5,  21, },
+	{ -21, -19,   5, 171, 525,  909, 1058, 858, 461, 132,  -5,  22, },
+	{ -21, -19,   4, 167, 519,  904, 1059, 863, 468, 136,  -4,  20, },
+	{ -22, -19,   3, 163, 512,  899, 1059, 869, 474, 139,  -3,  22, },
+	{ -22, -19,   2, 159, 506,  894, 1059, 874, 480, 143,  -2,  22, },
+	{ -22, -19,   1, 155, 499,  889, 1059, 879, 487, 147,  -1,  22, }
+};
+
+enum xilinx_scaler_vid_reg_fmts {
+	XVIDC_CSF_RGB = 0,
+	XVIDC_CSF_YCRCB_444,
+	XVIDC_CSF_YCRCB_422,
+	XVIDC_CSF_YCRCB_420,
+};
+
+static const u32 xilinx_scaler_video_fmts[] = {
+	MEDIA_BUS_FMT_RGB888_1X24,
+	MEDIA_BUS_FMT_VUY8_1X24,
+	MEDIA_BUS_FMT_UYVY8_1X16,
+	MEDIA_BUS_FMT_VYYUYY8_1X24,
+};
+
+/* This bit is for xscaler feature flag */
+#define XSCALER_HPHASE_FIX	BIT(0)
+
+/**
+ * struct xscaler_feature - dt or IP property structure
+ * @flags: Bitmask of properties enabled in IP or dt
+ */
+struct xscaler_feature {
+	u32 flags;
+};
+
+/**
+ * struct xilinx_scaler - Core configuration of scaler device structure
+ * @base: pointer to register base address
+ * @dev: device structure
+ * @bridge: xilinx bridge
+ * @width_in: input width
+ * @height_in: input height
+ * @width_out: output width
+ * @height_out: output height
+ * @fmt_in: input format
+ * @fmt_out: output format
+ * @num_hori_taps: number of horizontal taps
+ * @num_vert_taps: number of vertical taps
+ * @max_num_phases: maximum number of phases
+ * @pix_per_clk: Pixels per Clock cycle the IP operates upon
+ * @max_pixels: The maximum number of pixels that the H-scaler examines
+ * @max_lines: The maximum number of lines that the V-scaler examines
+ * @H_phases: The phases needed to program the H-scaler for different taps
+ * @hscaler_coeff: The complete array of H-scaler coefficients
+ * @vscaler_coeff: The complete array of V-scaler coefficients
+ * @is_polyphase: Track if scaling algorithm is polyphase or not
+ * @rst_gpio: GPIO reset line to bring VPSS Scaler out of reset
+ * @ctrl_clk: AXI Lite clock
+ * @axis_clk: Video Clock
+ * @cfg: Pointer to scaler config structure
+ */
+struct xilinx_scaler {
+	void __iomem *base;
+	struct device *dev;
+	struct xlnx_bridge bridge;
+	u32 width_in;
+	u32 height_in;
+	u32 width_out;
+	u32 height_out;
+	u32 fmt_in;
+	u32 fmt_out;
+	u32 num_hori_taps;
+	u32 num_vert_taps;
+	u32 max_num_phases;
+	u32 pix_per_clk;
+	u32 max_pixels;
+	u32 max_lines;
+	u32 H_phases[XV_HSCALER_MAX_LINE_WIDTH];
+	short hscaler_coeff[XV_HSCALER_MAX_H_PHASES][XV_HSCALER_MAX_H_TAPS];
+	short vscaler_coeff[XV_VSCALER_MAX_V_PHASES][XV_VSCALER_MAX_V_TAPS];
+	bool is_polyphase;
+	struct gpio_desc *rst_gpio;
+	struct clk *ctrl_clk;
+	struct clk *axis_clk;
+	const struct xscaler_feature *cfg;
+};
+
+static inline void xilinx_scaler_write(void __iomem *base, u32 offset, u32 val)
+{
+	writel(val, base + offset);
+}
+
+static inline u32 xilinx_scaler_read(void __iomem *base, u32 offset)
+{
+	return readl(base + offset);
+}
+
+static inline void xilinx_scaler_clr(void __iomem *base, u32 offset, u32 clr)
+{
+	xilinx_scaler_write(base, offset,
+			    xilinx_scaler_read(base, offset) & ~clr);
+}
+
+static inline void xilinx_scaler_set(void __iomem *base, u32 offset, u32 set)
+{
+	xilinx_scaler_write(base, offset,
+			    xilinx_scaler_read(base, offset) | set);
+}
+
+static inline void
+xilinx_scaler_disable_block(struct xilinx_scaler *scaler, u32 channel,
+			    u32 ip_block)
+{
+	xilinx_scaler_clr(scaler->base, ((channel - 1) * XGPIO_CHAN_OFFSET) +
+			  XGPIO_DATA_OFFSET + S_AXIS_RESET_OFF, ip_block);
+}
+
+static inline void
+xilinx_scaler_enable_block(struct xilinx_scaler *scaler, u32 channel,
+			   u32 ip_block)
+{
+	xilinx_scaler_set(scaler->base, ((channel - 1) * XGPIO_CHAN_OFFSET) +
+			  XGPIO_DATA_OFFSET + S_AXIS_RESET_OFF, ip_block);
+}
+
+/**
+ * bridge_to_layer - Gets the parent structure
+ * @bridge: pointer to the member.
+ *
+ * Return: parent structure pointer
+ */
+static inline struct xilinx_scaler *bridge_to_layer(struct xlnx_bridge *bridge)
+{
+	return container_of(bridge, struct xilinx_scaler, bridge);
+}
+
+/**
+ * xilinx_scaler_reset - Resets scaler block
+ * @scaler: Pointer to scaler device structure
+ *
+ * This function resets scaler block
+ */
+static void xilinx_scaler_reset(struct xilinx_scaler *scaler)
+{
+	xilinx_scaler_disable_block(scaler, XGPIO_CH_RESET_SEL,
+				    XGPIO_RESET_MASK_ALL_BLOCKS);
+	xilinx_scaler_enable_block(scaler, XGPIO_CH_RESET_SEL,
+				   XGPIO_RESET_MASK_IP_AXIS);
+}
+
+/**
+ * xv_hscaler_calculate_phases - Calculates h-scaler phases
+ * @scaler: Pointer to scaler registers base
+ * @width_in: input width
+ * @width_out: output width
+ * @pixel_rate: pixel rate
+ */
+static void
+xv_hscaler_calculate_phases(struct xilinx_scaler *scaler,
+			    u32 width_in, u32 width_out, u32 pixel_rate)
+{
+	unsigned int loop_width;
+	unsigned int x, s;
+	int offset = 0;
+	int xwrite_pos = 0;
+	bool output_write_en;
+	bool get_new_pix;
+	u64 phaseH;
+	u32 array_idx = 0;
+	int nr_rds = 0;
+	int nr_rds_clck;
+	unsigned int nphases = scaler->max_num_phases;
+	unsigned int nppc = scaler->pix_per_clk;
+	unsigned int shift = XHSC_STEP_PRECISION_SHIFT - ilog2(nphases);
+
+	loop_width = max_t(u32, width_in, width_out);
+	loop_width = ALIGN(loop_width + nppc - 1, nppc);
+
+	for (x = 0; x < loop_width; x++) {
+		nr_rds_clck = 0;
+		for (s = 0; s < nppc; s++) {
+			phaseH = (offset >> shift) & (nphases - 1);
+			get_new_pix = false;
+			output_write_en = false;
+			if ((offset >> XHSC_STEP_PRECISION_SHIFT) != 0) {
+				get_new_pix = true;
+				offset -= (1 << XHSC_STEP_PRECISION_SHIFT);
+				array_idx++;
+			}
+
+			if (((offset >> XHSC_STEP_PRECISION_SHIFT) == 0) &&
+			    xwrite_pos < width_out) {
+				offset += pixel_rate;
+				output_write_en = true;
+				xwrite_pos++;
+			}
+
+			scaler->H_phases[x] |= (phaseH <<
+						(s * XHSC_HPHASE_MULTIPLIER));
+			scaler->H_phases[x] |= (array_idx <<
+						(XHSC_HPHASE_SHIFT_BY_6 +
+						(s * XHSC_HPHASE_MULTIPLIER)));
+			if (output_write_en) {
+				scaler->H_phases[x] |=
+				(XV_HSCALER_PHASESH_V_OUTPUT_WR_EN <<
+				(s * XHSC_HPHASE_MULTIPLIER));
+			}
+
+			if (get_new_pix)
+				nr_rds_clck++;
+		}
+		if (array_idx >= nppc)
+			array_idx &= (nppc - 1);
+
+		nr_rds += nr_rds_clck;
+		if (nr_rds >= nppc)
+			nr_rds -= nppc;
+	}
+}
+
+/**
+ * xv_hscaler_load_ext_coeff - Loads external coefficients of h-scaler
+ * @scaler: Pointer to scaler registers base
+ * @coeff: Pointer to coeff array
+ * @ntaps: number of taps
+ *
+ * This function loads h-scaler coefficients.
+ */
+static void
+xv_hscaler_load_ext_coeff(struct xilinx_scaler *scaler,
+			  const short *coeff, u32 ntaps)
+{
+	unsigned int i, j, pad, offset;
+	u32 nphases = scaler->max_num_phases;
+
+	/* Determine if coefficient needs padding (effective vs. max taps) */
+	pad = XV_HSCALER_MAX_H_TAPS - ntaps;
+	offset = pad >> 1;
+	/* Load coefficients into scaler coefficient table */
+	for (i = 0; i < nphases; i++) {
+		for (j = 0; j < ntaps; ++j)
+			scaler->hscaler_coeff[i][j + offset] =
+						coeff[i * ntaps + j];
+	}
+
+	if (pad) {
+		for (i = 0; i < nphases; i++) {
+			for (j = 0; j < offset; j++)
+				scaler->hscaler_coeff[i][j] = 0;
+			j = ntaps + offset;
+			for (; j < XV_HSCALER_MAX_H_TAPS; j++)
+				scaler->hscaler_coeff[i][j] = 0;
+		}
+	}
+}
+
+static const short *xv_select_coeff(struct xilinx_scaler *scaler,
+				    u32 in, u32 out, u32 *ntaps)
+{
+	const short *coeff = NULL;
+
+	/*
+	 * Scale Down Mode will use dynamic filter selection logic
+	 * Scale Up Mode (including 1:1) will always use 6 tap filter
+	 */
+	if (out < in) {
+		u16 scale_ratio = (in * 10) / out;
+
+		/* Since XV_HSCALER_TAPS_* is same as XV_VSCALER_TAPS_* */
+		switch (*ntaps) {
+		case XV_HSCALER_TAPS_6:
+			*ntaps = XV_HSCALER_TAPS_6;
+			if (scale_ratio > 35)
+				coeff = &XV_fixedcoeff_taps6_SR4[0][0];
+			else if (scale_ratio > 25)
+				coeff = &XV_fixedcoeff_taps6_SR3[0][0];
+			else if (scale_ratio > 15)
+				coeff = &XV_fixedcoeff_taps6_SR2[0][0];
+			else
+				coeff = &XV_fixedcoeff_taps6_SR1p2[0][0];
+			break;
+		case XV_HSCALER_TAPS_8:
+			if (scale_ratio > 35) {
+				coeff = &XV_fixedcoeff_taps8_SR4[0][0];
+				*ntaps = XV_HSCALER_TAPS_8;
+			} else if (scale_ratio > 25) {
+				coeff = &XV_fixedcoeff_taps8_SR3[0][0];
+				*ntaps = XV_HSCALER_TAPS_8;
+			} else if (scale_ratio > 15) {
+				coeff = &XV_fixedcoeff_taps8_SR2[0][0];
+				*ntaps = XV_HSCALER_TAPS_8;
+			} else {
+				coeff = &XV_fixedcoeff_taps6_SR1p2[0][0];
+				*ntaps = XV_HSCALER_TAPS_6;
+			}
+			break;
+		case XV_HSCALER_TAPS_10:
+			if (scale_ratio > 35) {
+				coeff = &XV_fixedcoeff_taps10_SR4[0][0];
+				*ntaps = XV_HSCALER_TAPS_10;
+			} else if (scale_ratio > 25) {
+				coeff = &XV_fixedcoeff_taps10_SR3[0][0];
+				*ntaps = XV_HSCALER_TAPS_10;
+			} else if (scale_ratio > 15) {
+				coeff = &XV_fixedcoeff_taps8_SR2[0][0];
+				*ntaps = XV_HSCALER_TAPS_8;
+			} else {
+				coeff = &XV_fixedcoeff_taps6_SR1p2[0][0];
+				*ntaps = XV_HSCALER_TAPS_6;
+			}
+			break;
+		case XV_HSCALER_TAPS_12:
+			if (scale_ratio > 35) {
+				coeff = &XV_fixedcoeff_taps12_SR4[0][0];
+				*ntaps = XV_HSCALER_TAPS_12;
+			} else if (scale_ratio > 25) {
+				coeff = &XV_fixedcoeff_taps10_SR3[0][0];
+				*ntaps = XV_HSCALER_TAPS_10;
+			} else if (scale_ratio > 15) {
+				coeff = &XV_fixedcoeff_taps8_SR2[0][0];
+				*ntaps = XV_HSCALER_TAPS_8;
+			} else {
+				coeff = &XV_fixedcoeff_taps6_SR1p2[0][0];
+				*ntaps = XV_HSCALER_TAPS_6;
+			}
+			break;
+		default:
+			dev_err(scaler->dev,
+				"Unsupported number of taps = %d",
+				*ntaps);
+		}
+	} else {
+		dev_dbg(scaler->dev, "scaler : scale up 6 tap");
+		coeff = &XV_lanczos2_taps6[0][0];
+		*ntaps = XV_HSCALER_TAPS_6;
+	}
+
+	return coeff;
+}
+
+/**
+ * xv_hscaler_select_coeff - Selection of H-Scaler coefficients of operation
+ * @scaler: Pointer to Scaler device structure
+ * @width_in: Width of input video
+ * @width_out: Width of desired output video
+ *
+ * There are instances when a N-tap filter might operate in an M-tap
+ * configuration where N > M.
+ *
+ * For example :
+ * Depending on the ratio of scaling (while downscaling), a 12-tap
+ * filter may operate with 10 tap coefficients and zero-pads the remaining
+ * coefficients.
+ *
+ * While upscaling the driver will program 6-tap filter coefficients
+ * in any N-tap configurations (for N >= 6).
+ *
+ * This selection is adopted by the as it gives optimal
+ * video output determined by repeated testing of the IP
+ *
+ * Return: Will return 0 if successful. Returns -EINVAL on an unsupported
+ * H-scaler number of taps.
+ */
+static int
+xv_hscaler_select_coeff(struct xilinx_scaler *scaler,
+			u32 width_in, u32 width_out)
+{
+	const short *coeff;
+	u32 ntaps = scaler->num_hori_taps;
+
+	coeff = xv_select_coeff(scaler, width_in, width_out, &ntaps);
+	if (!coeff)
+		return -EINVAL;
+
+	xv_hscaler_load_ext_coeff(scaler, coeff, ntaps);
+	return 0;
+}
+
+/**
+ * xv_hscaler_set_coeff - Sets h-scaler coefficients
+ * @scaler: Pointer to scaler device structure
+ *
+ * This function sets coefficients of h-scaler.
+ */
+static void xv_hscaler_set_coeff(struct xilinx_scaler *scaler)
+{
+	int val, i, j, offset, rd_indx;
+	u32 ntaps = scaler->num_hori_taps;
+	u32 nphases = scaler->max_num_phases;
+	u32 base_addr;
+
+	offset = (XV_HSCALER_MAX_H_TAPS - ntaps) / 2;
+	base_addr = V_HSCALER_OFF + XV_HSCALER_CTRL_ADDR_HWREG_HFLTCOEFF_BASE;
+	for (i = 0; i < nphases; i++) {
+		for (j = 0; j < ntaps / 2; j++) {
+			rd_indx = j * 2 + offset;
+			val = (scaler->hscaler_coeff[i][rd_indx + 1] <<
+			       XSCALER_BITSHIFT_16) |
+			       (scaler->hscaler_coeff[i][rd_indx] &
+			       XHSC_MASK_LOW_16BITS);
+			xilinx_scaler_write(scaler->base, base_addr +
+				((i * ntaps / 2 + j) * 4), val);
+		}
+	}
+}
+
+/**
+ * xv_vscaler_load_ext_coeff - Loads external coefficients of v-scaler
+ * @scaler: Pointer to scaler device structure
+ * @coeff: Pointer to coeff array
+ * @ntaps: number of taps
+ *
+ * This function loads v-scaler coefficients.
+ */
+static void
+xv_vscaler_load_ext_coeff(struct xilinx_scaler *scaler,
+			  const short *coeff, u32 ntaps)
+{
+	int i, j, pad, offset;
+	u32 nphases = scaler->max_num_phases;
+
+	/* Determine if coefficient needs padding (effective vs. max taps) */
+	pad = XV_VSCALER_MAX_V_TAPS - ntaps;
+	offset = pad ? (pad >> 1) : 0;
+	/* Load User defined coefficients into scaler coefficient table */
+	for (i = 0; i < nphases; i++) {
+		for (j = 0; j < ntaps; ++j)
+			scaler->vscaler_coeff[i][j + offset] =
+						coeff[i * ntaps + j];
+	}
+	if (pad) {
+		/* effective taps < max_taps */
+		for (i = 0; i < nphases; i++) {
+			/* pad left */
+			for (j = 0; j < offset; j++)
+				scaler->vscaler_coeff[i][j] = 0;
+			/* pad right */
+			j = ntaps + offset;
+			for (; j < XV_VSCALER_MAX_V_TAPS; j++)
+				scaler->vscaler_coeff[i][j] = 0;
+		}
+	}
+}
+
+/**
+ * xv_vscaler_set_coeff - Sets v-scaler coefficients
+ * @scaler: Pointer to scaler device structure
+ *
+ * This function sets coefficients of v-scaler.
+ */
+static void xv_vscaler_set_coeff(struct xilinx_scaler *scaler)
+{
+	u32 nphases = scaler->max_num_phases;
+	u32 ntaps = scaler->num_vert_taps;
+	int val, i, j, offset, rd_indx;
+	u32 base_addr;
+
+	offset = (XV_VSCALER_MAX_V_TAPS - ntaps) / 2;
+	base_addr = V_VSCALER_OFF + XV_VSCALER_CTRL_ADDR_HWREG_VFLTCOEFF_BASE;
+
+	for (i = 0; i < nphases; i++) {
+		for (j = 0; j < ntaps / 2; j++) {
+			rd_indx = j * 2 + offset;
+			val = (scaler->vscaler_coeff[i][rd_indx + 1] <<
+			       XSCALER_BITSHIFT_16) |
+			       (scaler->vscaler_coeff[i][rd_indx] &
+			       XVSC_MASK_LOW_16BITS);
+			xilinx_scaler_write(scaler->base, base_addr +
+				((i * ntaps / 2 + j) * 4), val);
+		}
+	}
+}
+
+/**
+ * xv_vscaler_select_coeff - Selection of V-Scaler coefficients of operation
+ * @scaler: Pointer to Scaler device structure
+ * @height_in: Height of input video
+ * @height_out: Height of desired output video
+ *
+ * There are instances when a N-tap filter might operate in an M-tap
+ * configuration where N > M.
+ *
+ * For example :
+ * Depending on the ratio of scaling (while downscaling), a 10-tap
+ * filter may operate with 6 tap coefficients and zero-pads the remaining
+ * coefficients.
+ *
+ * While upscaling the driver will program 6-tap filter coefficients
+ * in any N-tap configurations (for N >= 6).
+ *
+ * This selection is adopted by the as it gives optimal
+ * video output determined by repeated testing of the IP
+ *
+ * Return: Will return 0 if successful. Returns -EINVAL on an unsupported
+ * V-scaler number of taps.
+ */
+static int
+xv_vscaler_select_coeff(struct xilinx_scaler *scaler,
+			u32 height_in, u32 height_out)
+{
+	const short *coeff;
+	u32 ntaps = scaler->num_vert_taps;
+
+	coeff = xv_select_coeff(scaler, height_in, height_out, &ntaps);
+	if (!coeff)
+		return -EINVAL;
+
+	xv_vscaler_load_ext_coeff(scaler, coeff, ntaps);
+	return 0;
+}
+
+/**
+ * xv_hscaler_set_phases - Sets phases of h-scaler
+ * @scaler: Pointer to scaler device structure
+ *
+ * This function sets phases of h-scaler.
+ */
+static void
+xv_hscaler_set_phases(struct xilinx_scaler *scaler)
+{
+	u32 loop_width;
+	u32 index, val;
+	u32 offset, i, lsb, msb;
+
+	loop_width = scaler->max_pixels / scaler->pix_per_clk;
+	if (scaler->cfg->flags & XSCALER_HPHASE_FIX) {
+		offset = V_HSCALER_OFF +
+			XV_HSCALER_CTRL_ADDR_HWREG_PHASEH_FIX;
+	} else {
+		offset = V_HSCALER_OFF +
+			XV_HSCALER_CTRL_ADDR_HWREG_PHASESH_V_BASE;
+	}
+
+	switch (scaler->pix_per_clk) {
+	case XSCALER_PPC_1:
+		index = 0;
+		for (i = 0; i < loop_width; i += 2) {
+			lsb = scaler->H_phases[i] & XHSC_MASK_LOW_16BITS;
+			msb = scaler->H_phases[i + 1] & XHSC_MASK_LOW_16BITS;
+			val = (msb << 16 | lsb);
+			xilinx_scaler_write(scaler->base, offset +
+				(index * 4), val);
+			++index;
+		}
+		return;
+	case XSCALER_PPC_2:
+		for (i = 0; i < loop_width; i++) {
+			val = (scaler->H_phases[i] & XHSC_MASK_LOW_32BITS);
+			xilinx_scaler_write(scaler->base, offset +
+				(i * 4), val);
+		}
+		return;
+	}
+}
+
+/**
+ * xv_vscaler_setup_video_fmt - Sets video format of v-scaler
+ * @scaler: Pointer to scaler device structure
+ * @code_in: format to be set
+ *
+ * This function set the given format of v-scaler
+ *
+ * Return: format value on success. -EINVAL for invalid format.
+ *
+ */
+static int
+xv_vscaler_setup_video_fmt(struct xilinx_scaler *scaler, u32 code_in)
+{
+	u32 video_in;
+
+	switch (code_in) {
+	case MEDIA_BUS_FMT_UYVY8_1X16:
+		video_in = XVIDC_CSF_YCRCB_422;
+		break;
+	case MEDIA_BUS_FMT_VUY8_1X24:
+		video_in = XVIDC_CSF_YCRCB_444;
+		break;
+	case MEDIA_BUS_FMT_RGB888_1X24:
+		video_in = XVIDC_CSF_RGB;
+		break;
+	case MEDIA_BUS_FMT_VYYUYY8_1X24:
+		video_in = XVIDC_CSF_YCRCB_420;
+		break;
+	default:
+		dev_info(scaler->dev, "Vscaler Unsupported media fmt\n");
+		return -EINVAL;
+	}
+	xilinx_scaler_write(scaler->base, V_VSCALER_OFF +
+			    XV_VSCALER_CTRL_ADDR_HWREG_COLORMODE_DATA,
+			    video_in);
+	return video_in;
+}
+
+/**
+ * xv_hscaler_setup_video_fmt - Sets video format of h-scaler
+ * @scaler: Pointer to scaler device structure
+ * @code_out: bus format to be set
+ * @vsc_out: return value of vscaler
+ *
+ * This function set the given video format of h-scaler
+ *
+ * Return: format value on success. -EINVAL for invalid format.
+ *
+ */
+static int xv_hscaler_setup_video_fmt(struct xilinx_scaler *scaler,
+				      u32 code_out, u32 vsc_out)
+{
+	u32 video_out;
+
+	switch (vsc_out) {
+	case XVIDC_CSF_YCRCB_422:
+		break;
+	case XVIDC_CSF_YCRCB_444:
+		break;
+	case XVIDC_CSF_RGB:
+		break;
+	case XVIDC_CSF_YCRCB_420:
+		break;
+	default:
+		dev_info(scaler->dev, "unsupported format from Vscaler");
+		return -EINVAL;
+	}
+
+	xilinx_scaler_write(scaler->base, V_HSCALER_OFF +
+		XV_HSCALER_CTRL_ADDR_HWREG_COLORMODE_DATA,
+		vsc_out);
+
+	switch (code_out) {
+	case MEDIA_BUS_FMT_UYVY8_1X16:
+		video_out = XVIDC_CSF_YCRCB_422;
+		break;
+	case MEDIA_BUS_FMT_VUY8_1X24:
+		video_out = XVIDC_CSF_YCRCB_444;
+		break;
+	case MEDIA_BUS_FMT_RGB888_1X24:
+		video_out = XVIDC_CSF_RGB;
+		break;
+	case MEDIA_BUS_FMT_VYYUYY8_1X24:
+		video_out = XVIDC_CSF_YCRCB_420;
+		break;
+	default:
+		dev_info(scaler->dev, "Hscaler Unsupported Out media fmt\n");
+		return -EINVAL;
+	}
+	xilinx_scaler_write(scaler->base, V_HSCALER_OFF +
+			    XV_HSCALER_CTRL_ADDR_HWREG_COLORMODEOUT_DATA,
+			    video_out);
+	return 0;
+}
+
+/**
+ * xilinx_scaler_parse_of - Parse device tree information
+ * @scaler: Pointer to scaler device structure
+ *
+ * This function reads the device tree contents
+ *
+ * Return: 0 on success. -EINVAL for invalid value.
+ *
+ */
+static int xilinx_scaler_parse_of(struct xilinx_scaler *scaler)
+{
+	int ret;
+	u32 dt_ppc;
+	struct device_node *node = scaler->dev->of_node;
+
+	scaler->ctrl_clk = devm_clk_get(scaler->dev, "aclk_ctrl");
+	if (IS_ERR(scaler->ctrl_clk)) {
+		ret = PTR_ERR(scaler->ctrl_clk);
+		dev_err(scaler->dev, "failed to get axi lite clk %d\n", ret);
+		return ret;
+	}
+
+	scaler->axis_clk = devm_clk_get(scaler->dev, "aclk_axis");
+	if (IS_ERR(scaler->axis_clk)) {
+		ret = PTR_ERR(scaler->axis_clk);
+		dev_err(scaler->dev, "failed to get video clk %d\n", ret);
+		return ret;
+	}
+
+	ret = of_property_read_u32(node, "xlnx,h-scaler-taps",
+				   &scaler->num_hori_taps);
+	if (ret < 0) {
+		dev_info(scaler->dev, "h-scaler-taps not present in DT\n");
+		return ret;
+	}
+	switch (scaler->num_hori_taps) {
+	case XV_HSCALER_TAPS_2:
+	case XV_HSCALER_TAPS_4:
+		scaler->is_polyphase = false;
+		break;
+	case XV_HSCALER_TAPS_6:
+	case XV_HSCALER_TAPS_8:
+	case XV_HSCALER_TAPS_10:
+	case XV_HSCALER_TAPS_12:
+		scaler->is_polyphase = true;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	ret = of_property_read_u32(node, "xlnx,v-scaler-taps",
+				   &scaler->num_vert_taps);
+	if (ret < 0) {
+		dev_info(scaler->dev, "v-scaler-taps not present in DT\n");
+		return ret;
+	}
+
+	switch (scaler->num_vert_taps) {
+	case XV_HSCALER_TAPS_2:
+	case XV_VSCALER_TAPS_4:
+		if (scaler->num_vert_taps != scaler->num_hori_taps)
+			return -EINVAL;
+		break;
+	case XV_VSCALER_TAPS_6:
+	case XV_VSCALER_TAPS_8:
+	case XV_VSCALER_TAPS_10:
+	case XV_VSCALER_TAPS_12:
+		scaler->is_polyphase = true;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	ret = of_property_read_u32(node, "xlnx,samples-per-clk", &dt_ppc);
+	if (ret < 0) {
+		dev_info(scaler->dev, "PPC is missing in DT\n");
+		return ret;
+	}
+	if (dt_ppc != XSCALER_PPC_1 && dt_ppc != XSCALER_PPC_2) {
+		dev_info(scaler->dev, "Unsupported ppc: %d", dt_ppc);
+		return -EINVAL;
+	}
+	scaler->pix_per_clk = dt_ppc;
+
+	/* Reset GPIO */
+	scaler->rst_gpio = devm_gpiod_get(scaler->dev, "reset", GPIOD_OUT_HIGH);
+	if (IS_ERR(scaler->rst_gpio)) {
+		if (PTR_ERR(scaler->rst_gpio) != -EPROBE_DEFER)
+			dev_err(scaler->dev, "Reset GPIO not setup in DT");
+		return PTR_ERR(scaler->rst_gpio);
+	}
+
+	ret = of_property_read_u32(node, "xlnx,max-height",
+				   &scaler->max_lines);
+	if (ret < 0) {
+		dev_err(scaler->dev, "xlnx,max-height is missing!");
+		return -EINVAL;
+	} else if (scaler->max_lines > XSCALER_MAX_HEIGHT ||
+		   scaler->max_lines < XSCALER_MIN_HEIGHT) {
+		dev_err(scaler->dev, "Invalid height in dt");
+		return -EINVAL;
+	}
+
+	ret = of_property_read_u32(node, "xlnx,max-width",
+				   &scaler->max_pixels);
+	if (ret < 0) {
+		dev_err(scaler->dev, "xlnx,max-width is missing!");
+		return -EINVAL;
+	} else if (scaler->max_pixels > XSCALER_MAX_WIDTH ||
+		   scaler->max_pixels < XSCALER_MIN_WIDTH) {
+		dev_err(scaler->dev, "Invalid width in dt");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+/**
+ * xilinx_scaler_stream - Set up v-scaler and h-scaler for streaming
+ * @scaler: Pointer to scaler device structure
+ *
+ * This function sets up the required configuration of v-scaler and h-scaler
+ *
+ * Return: 0 on success. Returns -EINVAL on failure conditions.
+ */
+static int xilinx_scaler_stream(struct xilinx_scaler *scaler)
+{
+	u32 pixel_rate;
+	u32 line_rate;
+	int ret;
+
+	line_rate = (scaler->height_in * STEP_PRECISION) / scaler->height_out;
+
+	if (scaler->is_polyphase) {
+		ret = xv_vscaler_select_coeff(scaler, scaler->height_in,
+					      scaler->height_out);
+		if (ret < 0) {
+			dev_info(scaler->dev, "Failed: vscaler select coeff\n");
+			return ret;
+		}
+		xv_vscaler_set_coeff(scaler);
+	}
+	xilinx_scaler_write(scaler->base, V_VSCALER_OFF +
+			    XV_VSCALER_CTRL_ADDR_HWREG_LINERATE_DATA,
+			    line_rate);
+	ret = xv_vscaler_setup_video_fmt(scaler, scaler->fmt_in);
+	if (ret < 0) {
+		dev_info(scaler->dev, "Failed: vscaler setup video format\n");
+		return ret;
+	}
+	pixel_rate = (scaler->width_in * STEP_PRECISION) / scaler->width_out;
+	xilinx_scaler_write(scaler->base, V_HSCALER_OFF +
+			    XV_HSCALER_CTRL_ADDR_HWREG_PIXELRATE_DATA,
+			    pixel_rate);
+	ret = xv_hscaler_setup_video_fmt(scaler, scaler->fmt_out, ret);
+	if (ret < 0) {
+		dev_info(scaler->dev, "Failed: vscaler setup video format\n");
+		return ret;
+	}
+	if (scaler->is_polyphase) {
+		ret = xv_hscaler_select_coeff(scaler, scaler->width_in,
+					      scaler->width_out);
+		if (ret < 0) {
+			dev_info(scaler->dev, "Failed: hscaler select coeff\n");
+			return ret;
+		}
+		xv_hscaler_set_coeff(scaler);
+	}
+	xv_hscaler_calculate_phases(scaler, scaler->width_in,
+				    scaler->width_out, pixel_rate);
+	xv_hscaler_set_phases(scaler);
+	return 0;
+}
+
+/**
+ * xilinx_scaler_bridge_enable - enabes scaler sub-cores
+ * @bridge: bridge instance
+ *
+ * This function enables the scaler sub-cores
+ *
+ * Return: 0 on success. Return -EINVAL on failure conditions.
+ *
+ */
+static int xilinx_scaler_bridge_enable(struct xlnx_bridge *bridge)
+{
+	int ret;
+	struct xilinx_scaler *scaler = bridge_to_layer(bridge);
+
+	ret = xilinx_scaler_stream(scaler);
+	if (ret)
+		return ret;
+
+	xilinx_scaler_write(scaler->base, V_HSCALER_OFF +
+			    XV_HSCALER_CTRL_ADDR_AP_CTRL, XSCALER_STREAM_ON);
+	xilinx_scaler_write(scaler->base, V_VSCALER_OFF +
+			    XV_VSCALER_CTRL_ADDR_AP_CTRL, XSCALER_STREAM_ON);
+	xilinx_scaler_enable_block(scaler, XGPIO_CH_RESET_SEL,
+				   XGPIO_RESET_MASK_IP_AXIS);
+	return ret;
+}
+
+/**
+ * xilinx_scaler_bridge_disable - disables scaler sub-cores
+ * @bridge: bridge instance
+ *
+ * This function disables the scaler sub-cores
+ */
+static void xilinx_scaler_bridge_disable(struct xlnx_bridge *bridge)
+{
+	struct xilinx_scaler *scaler = bridge_to_layer(bridge);
+
+	xilinx_scaler_disable_block(scaler, XGPIO_CH_RESET_SEL,
+				    XGPIO_RESET_MASK_ALL_BLOCKS);
+}
+
+/**
+ * xilinx_scaler_bridge_set_input - Sets the input parameters of scaler
+ * @bridge: bridge instance
+ * @width: width of video
+ * @height: height of video
+ * @bus_fmt: video bus format
+ *
+ * This function sets the input parameters of scaler
+ * Return: 0 on success. -EINVAL for invalid parameters.
+ */
+static int xilinx_scaler_bridge_set_input(struct xlnx_bridge *bridge,
+					  u32 width, u32 height, u32 bus_fmt)
+{
+	struct xilinx_scaler *scaler = bridge_to_layer(bridge);
+
+	if (width > scaler->max_pixels || height > scaler->max_lines)
+		return -EINVAL;
+
+	scaler->height_in = height;
+	scaler->width_in = width;
+	scaler->fmt_in = bus_fmt;
+
+	/* IP Reset through GPIO */
+	gpiod_set_value_cansleep(scaler->rst_gpio, XSCALER_RESET_ASSERT);
+	gpiod_set_value_cansleep(scaler->rst_gpio, XSCALER_RESET_DEASSERT);
+	xilinx_scaler_reset(scaler);
+	memset(scaler->H_phases, 0, sizeof(scaler->H_phases));
+
+	xilinx_scaler_write(scaler->base, V_VSCALER_OFF +
+			    XV_VSCALER_CTRL_ADDR_HWREG_HEIGHTIN_DATA, height);
+	xilinx_scaler_write(scaler->base, V_VSCALER_OFF +
+			    XV_VSCALER_CTRL_ADDR_HWREG_WIDTH_DATA, width);
+	xilinx_scaler_write(scaler->base, V_HSCALER_OFF +
+			    XV_HSCALER_CTRL_ADDR_HWREG_WIDTHIN_DATA, width);
+
+	return 0;
+}
+
+/**
+ * xilinx_scaler_bridge_get_input_fmts - input formats supported by scaler
+ * @bridge: bridge instance
+ * @fmts: Pointer to be updated with formats information
+ * @count: count of video bus formats
+ *
+ * This function provides the input video formats information scaler
+ * Return: 0 on success.
+ */
+static int xilinx_scaler_bridge_get_input_fmts(struct xlnx_bridge *bridge,
+					       const u32 **fmts, u32 *count)
+{
+	*fmts = xilinx_scaler_video_fmts;
+	*count = ARRAY_SIZE(xilinx_scaler_video_fmts);
+	return 0;
+}
+
+/**
+ * xilinx_scaler_bridge_set_output - Sets the output parameters of scaler
+ * @bridge: bridge instance
+ * @width: width of video
+ * @height: height of video
+ * @bus_fmt: video bus format
+ *
+ * This function sets the output parameters of scaler
+ * Return: 0 on success. -EINVAL for invalid parameters.
+ */
+static int xilinx_scaler_bridge_set_output(struct xlnx_bridge *bridge,
+					   u32 width, u32 height, u32 bus_fmt)
+{
+	struct xilinx_scaler *scaler = bridge_to_layer(bridge);
+
+	if (width > scaler->max_pixels || height > scaler->max_lines)
+		return -EINVAL;
+
+	scaler->height_out = height;
+	scaler->width_out = width;
+	scaler->fmt_out = bus_fmt;
+
+	xilinx_scaler_write(scaler->base, V_VSCALER_OFF +
+			    XV_VSCALER_CTRL_ADDR_HWREG_HEIGHTOUT_DATA, height);
+	xilinx_scaler_write(scaler->base, V_HSCALER_OFF +
+			    XV_HSCALER_CTRL_ADDR_HWREG_HEIGHT_DATA, height);
+	xilinx_scaler_write(scaler->base, V_HSCALER_OFF +
+			    XV_HSCALER_CTRL_ADDR_HWREG_WIDTHOUT_DATA, width);
+	return 0;
+}
+
+/**
+ * xilinx_scaler_bridge_get_output_fmts - output formats supported by scaler
+ * @bridge: bridge instance
+ * @fmts: Pointer to be updated with formats information
+ * @count: count of video bus formats
+ *
+ * This function provides the output video formats information scaler
+ * Return: 0 on success.
+ */
+static int xilinx_scaler_bridge_get_output_fmts(struct xlnx_bridge *bridge,
+						const u32 **fmts, u32 *count)
+{
+	*fmts = xilinx_scaler_video_fmts;
+	*count = ARRAY_SIZE(xilinx_scaler_video_fmts);
+	return 0;
+}
+
+static const struct xscaler_feature xlnx_scaler_v2_2 = {
+	.flags = XSCALER_HPHASE_FIX,
+};
+
+static const struct xscaler_feature xlnx_scaler = {
+	.flags = 0,
+};
+
+static const struct of_device_id xilinx_scaler_of_match[] = {
+	{ .compatible = "xlnx,vpss-scaler",
+		.data = &xlnx_scaler},
+	{ .compatible = "xlnx,vpss-scaler-2.2",
+		.data = &xlnx_scaler_v2_2},
+	{ }
+};
+
+MODULE_DEVICE_TABLE(of, xilinx_scaler_of_match);
+
+static int xilinx_scaler_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct xilinx_scaler *scaler;
+	const struct of_device_id *match;
+	struct device_node *node = pdev->dev.of_node;
+	int ret;
+
+	scaler = devm_kzalloc(dev, sizeof(*scaler), GFP_KERNEL);
+	if (!scaler)
+		return -ENOMEM;
+	scaler->dev = dev;
+
+	match = of_match_node(xilinx_scaler_of_match, node);
+	if (!match)
+		return -ENODEV;
+
+	scaler->cfg = match->data;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	scaler->base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(scaler->base)) {
+		dev_err(dev, "failed to remap io region\n");
+		return -ENOMEM;
+	}
+	platform_set_drvdata(pdev, scaler);
+
+	ret = xilinx_scaler_parse_of(scaler);
+	if (ret < 0) {
+		dev_info(scaler->dev, "parse_of failed\n");
+		return ret;
+	}
+
+	ret = clk_prepare_enable(scaler->ctrl_clk);
+	if (ret) {
+		dev_err(scaler->dev, "unable to enable axi lite clk %d\n", ret);
+		return ret;
+	}
+
+	ret = clk_prepare_enable(scaler->axis_clk);
+	if (ret) {
+		dev_err(scaler->dev, "unable to enable video clk %d\n", ret);
+		goto err_ctrl_clk;
+	}
+
+	scaler->max_num_phases = XSCALER_MAX_PHASES;
+
+	/* Reset the Global IP Reset through a GPIO */
+	gpiod_set_value_cansleep(scaler->rst_gpio, XSCALER_RESET_DEASSERT);
+	xilinx_scaler_reset(scaler);
+
+	scaler->bridge.enable = &xilinx_scaler_bridge_enable;
+	scaler->bridge.disable = &xilinx_scaler_bridge_disable;
+	scaler->bridge.set_input = &xilinx_scaler_bridge_set_input;
+	scaler->bridge.get_input_fmts = &xilinx_scaler_bridge_get_input_fmts;
+	scaler->bridge.set_output = &xilinx_scaler_bridge_set_output;
+	scaler->bridge.get_output_fmts = &xilinx_scaler_bridge_get_output_fmts;
+	scaler->bridge.of_node = dev->of_node;
+
+	ret = xlnx_bridge_register(&scaler->bridge);
+	if (ret) {
+		dev_info(scaler->dev, "Bridge registration failed\n");
+		goto err_axis_clk;
+	}
+	dev_info(scaler->dev, "xlnx drm scaler experimental driver probed\n");
+
+	return 0;
+
+err_axis_clk:
+	clk_disable_unprepare(scaler->axis_clk);
+err_ctrl_clk:
+	clk_disable_unprepare(scaler->ctrl_clk);
+	return ret;
+}
+
+static void xilinx_scaler_remove(struct platform_device *pdev)
+{
+	struct xilinx_scaler *scaler = platform_get_drvdata(pdev);
+
+	xlnx_bridge_unregister(&scaler->bridge);
+	clk_disable_unprepare(scaler->axis_clk);
+	clk_disable_unprepare(scaler->ctrl_clk);
+}
+
+static struct platform_driver scaler_bridge_driver = {
+	.probe = xilinx_scaler_probe,
+	.remove = xilinx_scaler_remove,
+	.driver = {
+		.name = "xlnx,scaler-bridge",
+		.of_match_table = xilinx_scaler_of_match,
+	},
+};
+
+module_platform_driver(scaler_bridge_driver);
+
+MODULE_AUTHOR("Venkateshwar Rao <vgannava@xilinx.com>");
+MODULE_DESCRIPTION("Xilinx FPGA SCALER Bridge Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/xlnx_sdi.c b/drivers/gpu/drm/xlnx/xlnx_sdi.c
new file mode 100644
index 000000000..172bbf448
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_sdi.c
@@ -0,0 +1,1449 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx FPGA SDI Tx Subsystem driver.
+ *
+ * Copyright (c) 2017 Xilinx Pvt., Ltd
+ *
+ * Contacts: Saurabh Sengar <saurabhs@xilinx.com>
+ */
+
+#include <drm/drm_atomic_helper.h>
+#include <drm/drm_crtc_helper.h>
+#include <drm/drm_probe_helper.h>
+#include <drm/display/drm_dp_helper.h>
+#include <drm/display/drm_hdmi_helper.h>
+#include <linux/bitfield.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/component.h>
+#include <linux/device.h>
+#include <linux/gpio/consumer.h>
+#include <linux/of_device.h>
+#include <linux/of_graph.h>
+#include <linux/phy/phy.h>
+#include <linux/platform_device.h>
+#include <media/hdr-ctrls.h>
+#include <video/videomode.h>
+#include "xlnx_sdi_modes.h"
+#include "xlnx_sdi_timing.h"
+
+#include "xlnx_bridge.h"
+
+/* SDI register offsets */
+#define XSDI_TX_RST_CTRL		0x00
+#define XSDI_TX_MDL_CTRL		0x04
+#define XSDI_TX_GLBL_IER		0x0C
+#define XSDI_TX_ISR_STAT		0x10
+#define XSDI_TX_IER_STAT		0x14
+#define XSDI_TX_ST352_LINE		0x18
+#define XSDI_TX_ST352_DATA_CH0		0x1C
+#define XSDI_TX_VER			0x3C
+#define XSDI_TX_SYS_CFG			0x40
+#define XSDI_TX_STS_SB_TDATA		0x60
+#define XSDI_TX_AXI4S_STS1		0x68
+#define XSDI_TX_AXI4S_STS2		0x6C
+#define XSDI_TX_ST352_DATA_DS2		0x70
+
+/* MODULE_CTRL register masks */
+#define XSDI_TX_CTRL_HFR		BIT(3)
+#define XSDI_TX_CTRL_M			BIT(7)
+#define XSDI_TX_CTRL_INS_CRC		BIT(12)
+#define XSDI_TX_CTRL_INS_ST352		BIT(13)
+#define XSDI_TX_CTRL_OVR_ST352		BIT(14)
+#define XSDI_TX_CTRL_INS_SYNC_BIT	BIT(16)
+#define XSDI_TX_CTRL_USE_ANC_IN		BIT(18)
+#define XSDI_TX_CTRL_INS_LN		BIT(19)
+#define XSDI_TX_CTRL_INS_EDH		BIT(20)
+#define XSDI_TX_CTRL_MODE		0x7
+#define XSDI_TX_CTRL_MUX		0x7
+#define XSDI_TX_CTRL_MODE_SHIFT		4
+#define XSDI_TX_CTRL_M_SHIFT		7
+#define XSDI_TX_CTRL_MUX_SHIFT		8
+#define XSDI_TX_CTRL_ST352_F2_EN_SHIFT	15
+#define XSDI_TX_CTRL_420_BIT		BIT(21)
+#define XSDI_TX_CTRL_444_BIT		BIT(22)
+#define XSDI_TX_CTRL_INS_ST352_CHROMA	BIT(23)
+#define XSDI_TX_CTRL_USE_DS2_3GA	BIT(24)
+
+/* TX_ST352_LINE register masks */
+#define XSDI_TX_ST352_LINE_MASK		GENMASK(10, 0)
+#define XSDI_TX_ST352_LINE_F2_SHIFT	16
+
+/* ISR STAT register masks */
+#define XSDI_GTTX_RSTDONE_INTR		BIT(0)
+#define XSDI_TX_CE_ALIGN_ERR_INTR	BIT(1)
+#define XSDI_TX_VSYNC_INTR		BIT(2)
+#define XSDI_AXI4S_VID_LOCK_INTR	BIT(8)
+#define XSDI_OVERFLOW_INTR		BIT(9)
+#define XSDI_UNDERFLOW_INTR		BIT(10)
+#define XSDI_IER_EN_MASK		(XSDI_GTTX_RSTDONE_INTR | \
+					 XSDI_TX_CE_ALIGN_ERR_INTR | \
+					 XSDI_TX_VSYNC_INTR | \
+					 XSDI_OVERFLOW_INTR | \
+					 XSDI_UNDERFLOW_INTR)
+
+/* RST_CTRL_OFFSET masks */
+#define XSDI_TX_CTRL_EN			BIT(0)
+#define XSDI_TX_BRIDGE_CTRL_EN		BIT(8)
+#define XSDI_TX_AXI4S_CTRL_EN		BIT(9)
+/* STS_SB_TX_TDATA masks */
+#define XSDI_TX_TDATA_GT_RESETDONE	BIT(2)
+
+#define XSDI_TX_MUX_SD_HD_3GA		0
+#define	XSDI_TX_MUX_3GB			1
+#define	XSDI_TX_MUX_8STREAM_6G_12G	2
+#define	XSDI_TX_MUX_4STREAM_6G		3
+#define	XSDI_TX_MUX_16STREAM_12G	4
+
+#define SDI_MAX_DATASTREAM		8
+#define PIXELS_PER_CLK			2
+#define XSDI_CH_SHIFT			29
+#define XST352_PROG_PIC			BIT(6)
+#define XST352_PROG_TRANS		BIT(7)
+#define XST352_2048_SHIFT		BIT(6)
+#define XST352_YUV444_MASK		0x01
+#define XST352_YUV420_MASK		0x03
+#define ST352_BYTE3			0x00
+
+/* Electro Optical Transfer Function */
+#define XST352_BYTE2_EOTF_MASK		GENMASK(13, 12)
+#define XST352_BYTE2_EOTF_SDRTV		0x0
+#define XST352_BYTE2_EOTF_HLG		0x1
+#define XST352_BYTE2_EOTF_SMPTE2084	0x2
+#define XST352_BYTE2_EOTF_UNKNOWN	0x3
+#define XST352_BYTE3_COLORIMETRY_HD	BIT(23)
+#define XST352_BYTE3_COLORIMETRY	BIT(21)
+
+#define ST352_BYTE4			0x01
+#define GT_TIMEOUT			50
+/* SDI modes */
+#define XSDI_MODE_HD			0
+#define	XSDI_MODE_SD			1
+#define	XSDI_MODE_3GA			2
+#define	XSDI_MODE_3GB			3
+#define	XSDI_MODE_6G			4
+#define	XSDI_MODE_12G			5
+
+#define SDI_TIMING_PARAMS_SIZE		48
+#define CLK_RATE			148500000UL
+
+#define XSDI_HFR_MIN_FPS		90
+
+/**
+ * enum payload_line_1 - Payload Ids Line 1 number
+ * @PAYLD_LN1_HD_3_6_12G:	line 1 HD,3G,6G or 12G mode value
+ * @PAYLD_LN1_SDPAL:		line 1 SD PAL mode value
+ * @PAYLD_LN1_SDNTSC:		line 1 SD NTSC mode value
+ */
+enum payload_line_1 {
+	PAYLD_LN1_HD_3_6_12G = 10,
+	PAYLD_LN1_SDPAL = 9,
+	PAYLD_LN1_SDNTSC = 13
+};
+
+/**
+ * enum payload_line_2 - Payload Ids Line 2 number
+ * @PAYLD_LN2_HD_3_6_12G:	line 2 HD,3G,6G or 12G mode value
+ * @PAYLD_LN2_SDPAL:		line 2 SD PAL mode value
+ * @PAYLD_LN2_SDNTSC:		line 2 SD NTSC mode value
+ */
+enum payload_line_2 {
+	PAYLD_LN2_HD_3_6_12G = 572,
+	PAYLD_LN2_SDPAL = 322,
+	PAYLD_LN2_SDNTSC = 276
+};
+
+/**
+ * struct xlnx_sdi - Core configuration SDI Tx subsystem device structure
+ * @encoder: DRM encoder structure
+ * @connector: DRM connector structure
+ * @dev: device structure
+ * @gt_rst_gpio: GPIO handle to reset GT phy
+ * @base: Base address of SDI subsystem
+ * @mode_flags: SDI operation mode related flags
+ * @wait_event: wait event
+ * @event_received: wait event status
+ * @enable_st352_chroma: Able to send ST352 packets in Chroma stream.
+ * @enable_anc_data: Enable/Disable Ancillary Data insertion for Audio
+ * @sdi_mode: configurable SDI mode parameter, supported values are:
+ *		0 - HD
+ *		1 - SD
+ *		2 - 3GA
+ *		3 - 3GB
+ *		4 - 6G
+ *		5 - 12G
+ * @sdi_mod_prop_val: configurable SDI mode parameter value
+ * @sdi_data_strm: configurable SDI data stream parameter
+ * @sdi_data_strm_prop_val: configurable number of SDI data streams
+ *			    value currently supported are 2, 4 and 8
+ * @sdi_420_in: Specifying input bus color format parameter to SDI
+ * @sdi_420_in_val: 1 for yuv420 and 0 for yuv422
+ * @sdi_420_out: configurable SDI out color format parameter
+ * @sdi_420_out_val: 1 for yuv420 and 0 for yuv422
+ * @sdi_444_out: configurable SDI out color format parameter
+ * @sdi_444_out_val: 1 for yuv444 and 0 for yuv422
+ * @is_frac_prop: configurable SDI fractional fps parameter
+ * @is_frac_prop_val: configurable SDI fractional fps parameter value
+ * @bridge: bridge structure
+ * @height_out: configurable bridge output height parameter
+ * @height_out_prop_val: configurable bridge output height parameter value
+ * @width_out: configurable bridge output width parameter
+ * @width_out_prop_val: configurable bridge output width parameter value
+ * @in_fmt: configurable bridge input media format
+ * @in_fmt_prop_val: configurable media bus format value
+ * @out_fmt: configurable bridge output media format
+ * @out_fmt_prop_val: configurable media bus format value
+ * @en_st352_c_prop: configurable ST352 payload on Chroma stream parameter
+ * @en_st352_c_val: configurable ST352 payload on Chroma parameter value
+ * @use_ds2_3ga_prop: Use DS2 instead of DS3 in 3GA mode parameter
+ * @use_ds2_3ga_val: Use DS2 instead of DS3 in 3GA mode parameter value
+ * @c_encoding: configurable color encoding
+ * @c_encoding_prop_val: 1 for UHDTV and 0 for Rec709
+ * @video_mode: current display mode
+ * @axi_clk: AXI Lite interface clock
+ * @sditx_clk: SDI Tx Clock
+ * @vidin_clk: Video Clock
+ * @qpll1_enabled: indicates qpll1 presence
+ * @picxo_enabled: indicates picxo core presence
+ * @prev_eotf: previous end of transfer function
+ * @is_hfr: Indicates HFR video streaming
+ */
+struct xlnx_sdi {
+	struct drm_encoder encoder;
+	struct drm_connector connector;
+	struct device *dev;
+	struct gpio_desc *gt_rst_gpio;
+	void __iomem *base;
+	u32 mode_flags;
+	wait_queue_head_t wait_event;
+	bool event_received;
+	bool enable_st352_chroma;
+	bool enable_anc_data;
+	struct drm_property *sdi_mode;
+	u32 sdi_mod_prop_val;
+	struct drm_property *sdi_data_strm;
+	u32 sdi_data_strm_prop_val;
+	struct drm_property *sdi_420_in;
+	bool sdi_420_in_val;
+	struct drm_property *sdi_420_out;
+	bool sdi_420_out_val;
+	struct drm_property *sdi_444_out;
+	bool sdi_444_out_val;
+	struct drm_property *is_frac_prop;
+	bool is_frac_prop_val;
+	struct xlnx_bridge *bridge;
+	struct drm_property *height_out;
+	u32 height_out_prop_val;
+	struct drm_property *width_out;
+	u32 width_out_prop_val;
+	struct drm_property *in_fmt;
+	u32 in_fmt_prop_val;
+	struct drm_property *out_fmt;
+	u32 out_fmt_prop_val;
+	struct drm_property *en_st352_c_prop;
+	bool en_st352_c_val;
+	struct drm_property *use_ds2_3ga_prop;
+	bool use_ds2_3ga_val;
+	struct drm_property *c_encoding;
+	u32 c_encoding_prop_val;
+	struct drm_display_mode video_mode;
+	struct clk *axi_clk;
+	struct clk *sditx_clk;
+	struct clk *vidin_clk;
+	bool qpll1_enabled;
+	bool picxo_enabled;
+	u8 prev_eotf;
+	u8 is_hfr;
+};
+
+#define connector_to_sdi(c) container_of(c, struct xlnx_sdi, connector)
+#define encoder_to_sdi(e) container_of(e, struct xlnx_sdi, encoder)
+
+static inline void xlnx_sdi_writel(void __iomem *base, int offset, u32 val)
+{
+	writel(val, base + offset);
+}
+
+static inline u32 xlnx_sdi_readl(void __iomem *base, int offset)
+{
+	return readl(base + offset);
+}
+
+/**
+ * xlnx_sdi_en_axi4s - Enable SDI Tx AXI4S-to-Video core
+ * @sdi:	Pointer to SDI Tx structure
+ *
+ * This function enables the SDI Tx AXI4S-to-Video core.
+ */
+static void xlnx_sdi_en_axi4s(struct xlnx_sdi *sdi)
+{
+	u32 data;
+
+	data = xlnx_sdi_readl(sdi->base, XSDI_TX_RST_CTRL);
+	data |= XSDI_TX_AXI4S_CTRL_EN;
+	xlnx_sdi_writel(sdi->base, XSDI_TX_RST_CTRL, data);
+}
+
+/**
+ * xlnx_sdi_en_bridge - Enable SDI Tx bridge
+ * @sdi:	Pointer to SDI Tx structure
+ *
+ * This function enables the SDI Tx bridge.
+ */
+static void xlnx_sdi_en_bridge(struct xlnx_sdi *sdi)
+{
+	u32 data;
+
+	data = xlnx_sdi_readl(sdi->base, XSDI_TX_RST_CTRL);
+	data |= XSDI_TX_BRIDGE_CTRL_EN;
+	xlnx_sdi_writel(sdi->base, XSDI_TX_RST_CTRL, data);
+}
+
+/**
+ * xlnx_sdi_gt_reset - Reset cores through gpio
+ * @sdi: Pointer to SDI Tx structure
+ *
+ * This function resets the GT phy core.
+ */
+static void xlnx_sdi_gt_reset(struct xlnx_sdi *sdi)
+{
+	gpiod_set_value(sdi->gt_rst_gpio, 1);
+	gpiod_set_value(sdi->gt_rst_gpio, 0);
+	/* delay added to get vtc_en signal */
+	mdelay(5);
+}
+
+/**
+ * xlnx_sdi_set_eotf - Set eotf field in payload
+ * @sdi: Pointer to SDI Tx structure
+ *
+ * This function parse the hdr metadata and sets
+ * eotf and colorimetry fields of payload.
+ */
+static void xlnx_sdi_set_eotf(struct xlnx_sdi *sdi)
+{
+	struct hdmi_drm_infoframe frame;
+	struct drm_connector_state *state = sdi->connector.state;
+	u32 payload, i;
+	int ret;
+	u8 eotf, colori;
+
+	ret = drm_hdmi_infoframe_set_gen_hdr_metadata(&frame, state);
+	if (ret)
+		return;
+
+	eotf = (__u8)frame.eotf;
+
+	if (sdi->prev_eotf == eotf || eotf > XST352_BYTE2_EOTF_UNKNOWN)
+		return;
+
+	switch (eotf) {
+	case V4L2_EOTF_BT_2100_HLG:
+		eotf = XST352_BYTE2_EOTF_HLG;
+		break;
+	case V4L2_EOTF_TRADITIONAL_GAMMA_SDR:
+		eotf = XST352_BYTE2_EOTF_SDRTV;
+		break;
+	case V4L2_EOTF_SMPTE_ST2084:
+		eotf = XST352_BYTE2_EOTF_SMPTE2084;
+		break;
+	}
+
+	colori = sdi->c_encoding_prop_val;
+	payload = xlnx_sdi_readl(sdi->base, XSDI_TX_ST352_DATA_CH0);
+
+	/*
+	 * For HD mode, bit 23 and 20 of payload represents
+	 * colorimetry as per SMPTE 292-1:2018 Sec 9.5.
+	 * For other modes, its bit 21 and 20.
+	 * For BT709 & BT2020 - bit 20 is always zero
+	 */
+	if (sdi->sdi_mod_prop_val == XSDI_MODE_HD) {
+		payload &= ~(XST352_BYTE2_EOTF_MASK |
+			     XST352_BYTE3_COLORIMETRY_HD);
+		payload |= FIELD_PREP(XST352_BYTE2_EOTF_MASK, eotf) |
+			FIELD_PREP(XST352_BYTE3_COLORIMETRY_HD, colori);
+	} else {
+		payload &= ~(XST352_BYTE2_EOTF_MASK |
+			     XST352_BYTE3_COLORIMETRY);
+		payload |= FIELD_PREP(XST352_BYTE2_EOTF_MASK, eotf) |
+			FIELD_PREP(XST352_BYTE3_COLORIMETRY, colori);
+	}
+
+	dev_dbg(sdi->dev, "payload = 0x%x, eotf = %d\n", payload, eotf);
+	for (i = 0; i < sdi->sdi_data_strm_prop_val / 2; i++)
+		xlnx_sdi_writel(sdi->base,
+				(XSDI_TX_ST352_DATA_CH0 + (i * 4)), payload);
+	sdi->prev_eotf = eotf;
+}
+
+/**
+ * xlnx_sdi_irq_handler - SDI Tx interrupt
+ * @irq:	irq number
+ * @data:	irq data
+ *
+ * Return: IRQ_HANDLED for all cases.
+ *
+ * This is the compact GT ready interrupt.
+ */
+static irqreturn_t xlnx_sdi_irq_handler(int irq, void *data)
+{
+	struct xlnx_sdi *sdi = (struct xlnx_sdi *)data;
+	u32 reg;
+
+	reg = xlnx_sdi_readl(sdi->base, XSDI_TX_ISR_STAT);
+
+	if (reg & XSDI_TX_VSYNC_INTR)
+		xlnx_sdi_set_eotf(sdi);
+	if (reg & XSDI_GTTX_RSTDONE_INTR)
+		dev_dbg(sdi->dev, "GT reset interrupt received\n");
+	if (reg & XSDI_TX_CE_ALIGN_ERR_INTR)
+		dev_err_ratelimited(sdi->dev, "SDI SD CE align error\n");
+	if (reg & XSDI_OVERFLOW_INTR)
+		dev_err_ratelimited(sdi->dev, "AXI-4 Stream Overflow error\n");
+	if (reg & XSDI_UNDERFLOW_INTR)
+		dev_err_ratelimited(sdi->dev, "AXI-4 Stream Underflow error\n");
+	xlnx_sdi_writel(sdi->base, XSDI_TX_ISR_STAT,
+			reg & ~(XSDI_AXI4S_VID_LOCK_INTR));
+
+	reg = xlnx_sdi_readl(sdi->base, XSDI_TX_STS_SB_TDATA);
+	if (reg & XSDI_TX_TDATA_GT_RESETDONE ||
+	    !sdi->gt_rst_gpio) {
+		sdi->event_received = true;
+		wake_up_interruptible(&sdi->wait_event);
+	}
+	return IRQ_HANDLED;
+}
+
+/**
+ * xlnx_sdi_set_payload_line - set ST352 packet line number
+ * @sdi:	Pointer to SDI Tx structure
+ * @line_1:	line number used to insert st352 packet for field 1.
+ * @line_2:	line number used to insert st352 packet for field 2.
+ *
+ * This function set 352 packet line number.
+ */
+static void xlnx_sdi_set_payload_line(struct xlnx_sdi *sdi,
+				      u32 line_1, u32 line_2)
+{
+	u32 data;
+
+	data = ((line_1 & XSDI_TX_ST352_LINE_MASK) |
+		((line_2 & XSDI_TX_ST352_LINE_MASK) <<
+		XSDI_TX_ST352_LINE_F2_SHIFT));
+
+	xlnx_sdi_writel(sdi->base, XSDI_TX_ST352_LINE, data);
+
+	data = xlnx_sdi_readl(sdi->base, XSDI_TX_MDL_CTRL);
+	data |= (1 << XSDI_TX_CTRL_ST352_F2_EN_SHIFT);
+
+	xlnx_sdi_writel(sdi->base, XSDI_TX_MDL_CTRL, data);
+}
+
+/**
+ * xlnx_sdi_set_payload_data - set ST352 packet payload
+ * @sdi:		Pointer to SDI Tx structure
+ * @data_strm:		data stream number
+ * @payload:		st352 packet payload
+ *
+ * This function set ST352 payload data to corresponding stream.
+ */
+static void xlnx_sdi_set_payload_data(struct xlnx_sdi *sdi,
+				      u32 data_strm, u32 payload)
+{
+	xlnx_sdi_writel(sdi->base,
+			(XSDI_TX_ST352_DATA_CH0 + (data_strm * 4)), payload);
+
+	dev_dbg(sdi->dev, "enable_st352_chroma = %d and en_st352_c_val = %d\n",
+		sdi->enable_st352_chroma, sdi->en_st352_c_val);
+	if (sdi->enable_st352_chroma && sdi->en_st352_c_val) {
+		xlnx_sdi_writel(sdi->base,
+				(XSDI_TX_ST352_DATA_DS2 + (data_strm * 4)),
+				payload);
+	}
+}
+
+/**
+ * xlnx_sdi_set_display_disable - Disable the SDI Tx IP core enable
+ * register bit
+ * @sdi: SDI structure having the updated user parameters
+ *
+ * This function takes the SDI strucure and disables the core enable bit
+ * of core configuration register.
+ */
+static void xlnx_sdi_set_display_disable(struct xlnx_sdi *sdi)
+{
+	u32 i;
+
+	for (i = 0; i < SDI_MAX_DATASTREAM; i++)
+		xlnx_sdi_set_payload_data(sdi, i, 0);
+
+	xlnx_sdi_writel(sdi->base, XSDI_TX_GLBL_IER, 0);
+	xlnx_sdi_writel(sdi->base, XSDI_TX_RST_CTRL, 0);
+}
+
+/**
+ * xlnx_sdi_payload_config -  config the SDI payload parameters
+ * @sdi:	pointer Xilinx SDI Tx structure
+ * @mode:	display mode
+ *
+ * This function config the SDI st352 payload parameter.
+ */
+static void xlnx_sdi_payload_config(struct xlnx_sdi *sdi, u32 mode)
+{
+	u32 payload_1, payload_2;
+
+	switch (mode) {
+	case XSDI_MODE_SD:
+		payload_1 = PAYLD_LN1_SDPAL;
+		payload_2 = PAYLD_LN2_SDPAL;
+		break;
+	case XSDI_MODE_HD:
+	case XSDI_MODE_3GA:
+	case XSDI_MODE_3GB:
+	case XSDI_MODE_6G:
+	case XSDI_MODE_12G:
+		payload_1 = PAYLD_LN1_HD_3_6_12G;
+		payload_2 = PAYLD_LN2_HD_3_6_12G;
+		break;
+	default:
+		payload_1 = 0;
+		payload_2 = 0;
+		break;
+	}
+
+	xlnx_sdi_set_payload_line(sdi, payload_1, payload_2);
+}
+
+/**
+ * xlnx_sdi_set_mode -  Set mode parameters in SDI Tx
+ * @sdi:	pointer Xilinx SDI Tx structure
+ * @mode:	SDI Tx display mode
+ * @is_frac:	0 - integer 1 - fractional
+ * @mux_ptrn:	specify the data stream interleaving pattern to be used
+ * This function config the SDI st352 payload parameter.
+ */
+static void xlnx_sdi_set_mode(struct xlnx_sdi *sdi, u32 mode,
+			      bool is_frac, u32 mux_ptrn)
+{
+	u32 data;
+
+	xlnx_sdi_payload_config(sdi, mode);
+
+	data = xlnx_sdi_readl(sdi->base, XSDI_TX_MDL_CTRL);
+	data &= ~(XSDI_TX_CTRL_MODE << XSDI_TX_CTRL_MODE_SHIFT);
+	data &= ~(XSDI_TX_CTRL_M);
+	data &= ~(XSDI_TX_CTRL_MUX << XSDI_TX_CTRL_MUX_SHIFT);
+	data &= ~XSDI_TX_CTRL_420_BIT;
+
+	data |= (((mode & XSDI_TX_CTRL_MODE) << XSDI_TX_CTRL_MODE_SHIFT) |
+		(is_frac << XSDI_TX_CTRL_M_SHIFT) |
+		((mux_ptrn & XSDI_TX_CTRL_MUX) << XSDI_TX_CTRL_MUX_SHIFT));
+
+	dev_dbg(sdi->dev, "sdi_420_out_val = %d\n sdi_444_out_val = %d\n\r",
+		sdi->sdi_420_out_val, sdi->sdi_444_out_val);
+	if (sdi->sdi_420_out_val)
+		data |= XSDI_TX_CTRL_420_BIT;
+	else if (sdi->sdi_444_out_val)
+		data |= XSDI_TX_CTRL_444_BIT;
+
+	if (sdi->is_hfr) {
+		data |= XSDI_TX_CTRL_HFR;
+		dev_dbg(sdi->dev, "HFR enabled\n\r");
+	}
+
+	xlnx_sdi_writel(sdi->base, XSDI_TX_MDL_CTRL, data);
+}
+
+/**
+ * xlnx_sdi_set_config_parameters - Configure SDI Tx registers with parameters
+ * given from user application.
+ * @sdi: SDI structure having the updated user parameters
+ *
+ * This function takes the SDI structure having drm_property parameters
+ * configured from  user application and writes them into SDI IP registers.
+ */
+static void xlnx_sdi_set_config_parameters(struct xlnx_sdi *sdi)
+{
+	int mux_ptrn = -EINVAL;
+
+	switch (sdi->sdi_mod_prop_val) {
+	case XSDI_MODE_3GA:
+		mux_ptrn = XSDI_TX_MUX_SD_HD_3GA;
+		break;
+	case XSDI_MODE_3GB:
+		mux_ptrn = XSDI_TX_MUX_3GB;
+		break;
+	case XSDI_MODE_6G:
+		if (sdi->sdi_data_strm_prop_val == 4)
+			mux_ptrn = XSDI_TX_MUX_4STREAM_6G;
+		else if (sdi->sdi_data_strm_prop_val == 8)
+			mux_ptrn = XSDI_TX_MUX_8STREAM_6G_12G;
+		break;
+	case XSDI_MODE_12G:
+		if (sdi->sdi_data_strm_prop_val == 8)
+			mux_ptrn = XSDI_TX_MUX_8STREAM_6G_12G;
+		break;
+	default:
+		mux_ptrn = 0;
+		break;
+	}
+	if (mux_ptrn == -EINVAL) {
+		dev_err(sdi->dev, "%d data stream not supported for %d mode",
+			sdi->sdi_data_strm_prop_val, sdi->sdi_mod_prop_val);
+		return;
+	}
+	xlnx_sdi_set_mode(sdi, sdi->sdi_mod_prop_val, sdi->is_frac_prop_val,
+			  mux_ptrn);
+}
+
+/**
+ * xlnx_sdi_atomic_set_property - implementation of drm_connector_funcs
+ * set_property invoked by IOCTL call to DRM_IOCTL_MODE_OBJ_SETPROPERTY
+ *
+ * @connector: pointer Xilinx SDI connector
+ * @state: DRM connector state
+ * @property: pointer to the drm_property structure
+ * @val: SDI parameter value that is configured from user application
+ *
+ * This function takes a drm_property name and value given from user application
+ * and update the SDI structure property varabiles with the values.
+ * These values are later used to configure the SDI Rx IP.
+ *
+ * Return: 0 on success OR -EINVAL if setting property fails
+ */
+static int
+xlnx_sdi_atomic_set_property(struct drm_connector *connector,
+			     struct drm_connector_state *state,
+			     struct drm_property *property, uint64_t val)
+{
+	struct xlnx_sdi *sdi = connector_to_sdi(connector);
+
+	if (property == sdi->sdi_mode)
+		sdi->sdi_mod_prop_val = (unsigned int)val;
+	else if (property == sdi->sdi_data_strm)
+		sdi->sdi_data_strm_prop_val = (unsigned int)val;
+	else if (property == sdi->sdi_420_in)
+		sdi->sdi_420_in_val = val;
+	else if (property == sdi->sdi_420_out)
+		sdi->sdi_420_out_val = val;
+	else if (property == sdi->sdi_444_out)
+		sdi->sdi_444_out_val = val;
+	else if (property == sdi->is_frac_prop)
+		sdi->is_frac_prop_val = !!val;
+	else if (property == sdi->height_out)
+		sdi->height_out_prop_val = (unsigned int)val;
+	else if (property == sdi->width_out)
+		sdi->width_out_prop_val = (unsigned int)val;
+	else if (property == sdi->in_fmt)
+		sdi->in_fmt_prop_val = (unsigned int)val;
+	else if (property == sdi->out_fmt)
+		sdi->out_fmt_prop_val = (unsigned int)val;
+	else if (property == sdi->en_st352_c_prop)
+		sdi->en_st352_c_val = !!val;
+	else if (property == sdi->use_ds2_3ga_prop)
+		sdi->use_ds2_3ga_val = !!val;
+	else if (property == sdi->c_encoding)
+		sdi->c_encoding_prop_val = val;
+	else
+		return -EINVAL;
+	return 0;
+}
+
+static int
+xlnx_sdi_atomic_get_property(struct drm_connector *connector,
+			     const struct drm_connector_state *state,
+			     struct drm_property *property, uint64_t *val)
+{
+	struct xlnx_sdi *sdi = connector_to_sdi(connector);
+
+	if (property == sdi->sdi_mode)
+		*val = sdi->sdi_mod_prop_val;
+	else if (property == sdi->sdi_data_strm)
+		*val =  sdi->sdi_data_strm_prop_val;
+	else if (property == sdi->sdi_420_in)
+		*val = sdi->sdi_420_in_val;
+	else if (property == sdi->sdi_420_out)
+		*val = sdi->sdi_420_out_val;
+	else if (property == sdi->sdi_444_out)
+		*val = sdi->sdi_444_out_val;
+	else if (property == sdi->is_frac_prop)
+		*val =  sdi->is_frac_prop_val;
+	else if (property == sdi->height_out)
+		*val = sdi->height_out_prop_val;
+	else if (property == sdi->width_out)
+		*val = sdi->width_out_prop_val;
+	else if (property == sdi->in_fmt)
+		*val = sdi->in_fmt_prop_val;
+	else if (property == sdi->out_fmt)
+		*val = sdi->out_fmt_prop_val;
+	else if (property == sdi->en_st352_c_prop)
+		*val =  sdi->en_st352_c_val;
+	else if (property == sdi->use_ds2_3ga_prop)
+		*val =  sdi->use_ds2_3ga_val;
+	else if (property == sdi->c_encoding)
+		*val = sdi->c_encoding_prop_val;
+	else
+		return -EINVAL;
+
+	return 0;
+}
+
+/**
+ * xlnx_sdi_get_mode_id - Search for a video mode in the supported modes table
+ *
+ * @mode: mode being searched
+ *
+ * Return: mode id if mode is found OR -EINVAL otherwise
+ */
+static int xlnx_sdi_get_mode_id(struct drm_display_mode *mode)
+{
+	unsigned int i;
+
+	for (i = 0; i < ARRAY_SIZE(xlnx_sdi_modes); i++)
+		if (xlnx_sdi_modes[i].mode.htotal == mode->htotal &&
+		    xlnx_sdi_modes[i].mode.vtotal == mode->vtotal &&
+		    xlnx_sdi_modes[i].mode.clock == mode->clock &&
+		    xlnx_sdi_modes[i].mode.flags == mode->flags)
+			return i;
+	return -EINVAL;
+}
+
+/**
+ * xlnx_sdi_drm_add_modes - Adds SDI supported modes
+ * @connector: pointer Xilinx SDI connector
+ *
+ * Return:	Count of modes added
+ *
+ * This function adds the SDI modes supported and returns its count
+ */
+static int xlnx_sdi_drm_add_modes(struct drm_connector *connector)
+{
+	int num_modes = 0;
+	u32 i;
+	struct drm_display_mode *mode;
+	struct drm_device *dev = connector->dev;
+
+	for (i = 0; i < ARRAY_SIZE(xlnx_sdi_modes); i++) {
+		const struct drm_display_mode *ptr = &xlnx_sdi_modes[i].mode;
+
+		mode = drm_mode_duplicate(dev, ptr);
+		if (mode) {
+			drm_mode_probed_add(connector, mode);
+			num_modes++;
+		}
+	}
+	return num_modes;
+}
+
+static enum drm_connector_status
+xlnx_sdi_detect(struct drm_connector *connector, bool force)
+{
+	return connector_status_connected;
+}
+
+static void xlnx_sdi_connector_destroy(struct drm_connector *connector)
+{
+	drm_connector_unregister(connector);
+	drm_connector_cleanup(connector);
+	connector->dev = NULL;
+}
+
+static const struct drm_connector_funcs xlnx_sdi_connector_funcs = {
+	.detect = xlnx_sdi_detect,
+	.fill_modes = drm_helper_probe_single_connector_modes,
+	.destroy = xlnx_sdi_connector_destroy,
+	.atomic_duplicate_state	= drm_atomic_helper_connector_duplicate_state,
+	.atomic_destroy_state = drm_atomic_helper_connector_destroy_state,
+	.reset = drm_atomic_helper_connector_reset,
+	.atomic_set_property = xlnx_sdi_atomic_set_property,
+	.atomic_get_property = xlnx_sdi_atomic_get_property,
+};
+
+static struct drm_encoder *
+xlnx_sdi_best_encoder(struct drm_connector *connector)
+{
+	return &(connector_to_sdi(connector)->encoder);
+}
+
+static int xlnx_sdi_get_modes(struct drm_connector *connector)
+{
+	return xlnx_sdi_drm_add_modes(connector);
+}
+
+static int xlnx_sdi_mode_valid(struct drm_connector *connector,
+			       struct drm_display_mode *mode)
+{
+	if (mode->flags & DRM_MODE_FLAG_INTERLACE)
+		mode->vdisplay /= 2;
+
+	return MODE_OK;
+}
+
+static struct drm_connector_helper_funcs xlnx_sdi_connector_helper_funcs = {
+	.get_modes = xlnx_sdi_get_modes,
+	.best_encoder = xlnx_sdi_best_encoder,
+	.mode_valid = xlnx_sdi_mode_valid,
+};
+
+/**
+ * xlnx_sdi_drm_connector_create_property -  create SDI connector properties
+ *
+ * @base_connector: pointer to Xilinx SDI connector
+ *
+ * This function takes the xilinx SDI connector component and defines
+ * the drm_property variables with their default values.
+ */
+static void
+xlnx_sdi_drm_connector_create_property(struct drm_connector *base_connector)
+{
+	struct drm_device *dev = base_connector->dev;
+	struct xlnx_sdi *sdi  = connector_to_sdi(base_connector);
+
+	sdi->is_frac_prop = drm_property_create_bool(dev, 0, "is_frac");
+	sdi->sdi_mode = drm_property_create_range(dev, 0,
+						  "sdi_mode", 0, 5);
+	sdi->sdi_data_strm = drm_property_create_range(dev, 0,
+						       "sdi_data_stream", 2, 8);
+	sdi->sdi_420_in = drm_property_create_bool(dev, 0, "sdi_420_in");
+	sdi->sdi_420_out = drm_property_create_bool(dev, 0, "sdi_420_out");
+	sdi->sdi_444_out = drm_property_create_bool(dev, 0, "sdi_444_out");
+	sdi->height_out = drm_property_create_range(dev, 0,
+						    "height_out", 2, 4096);
+	sdi->width_out = drm_property_create_range(dev, 0,
+						   "width_out", 2, 4096);
+	sdi->in_fmt = drm_property_create_range(dev, 0,
+						"in_fmt", 0, 16384);
+	sdi->out_fmt = drm_property_create_range(dev, 0,
+						 "out_fmt", 0, 16384);
+	if (sdi->enable_st352_chroma) {
+		sdi->en_st352_c_prop = drm_property_create_bool(dev, 0,
+								"en_st352_c");
+		sdi->use_ds2_3ga_prop = drm_property_create_bool(dev, 0,
+								 "use_ds2_3ga");
+	}
+	sdi->c_encoding = drm_property_create_bool(dev, 0, "c_encoding");
+}
+
+/**
+ * xlnx_sdi_drm_connector_attach_property -  attach SDI connector
+ * properties
+ *
+ * @base_connector: pointer to Xilinx SDI connector
+ */
+static void
+xlnx_sdi_drm_connector_attach_property(struct drm_connector *base_connector)
+{
+	struct xlnx_sdi *sdi = connector_to_sdi(base_connector);
+	struct drm_mode_object *obj = &base_connector->base;
+
+	if (sdi->sdi_mode)
+		drm_object_attach_property(obj, sdi->sdi_mode, 0);
+
+	if (sdi->sdi_data_strm)
+		drm_object_attach_property(obj, sdi->sdi_data_strm, 0);
+
+	if (sdi->sdi_420_in)
+		drm_object_attach_property(obj, sdi->sdi_420_in, 0);
+
+	if (sdi->sdi_420_out)
+		drm_object_attach_property(obj, sdi->sdi_420_out, 0);
+
+	if (sdi->sdi_444_out)
+		drm_object_attach_property(obj, sdi->sdi_444_out, 0);
+
+	if (sdi->is_frac_prop)
+		drm_object_attach_property(obj, sdi->is_frac_prop, 0);
+
+	if (sdi->height_out)
+		drm_object_attach_property(obj, sdi->height_out, 0);
+
+	if (sdi->width_out)
+		drm_object_attach_property(obj, sdi->width_out, 0);
+
+	if (sdi->in_fmt)
+		drm_object_attach_property(obj, sdi->in_fmt, 0);
+
+	if (sdi->out_fmt)
+		drm_object_attach_property(obj, sdi->out_fmt, 0);
+
+	if (sdi->en_st352_c_prop)
+		drm_object_attach_property(obj, sdi->en_st352_c_prop, 0);
+
+	if (sdi->use_ds2_3ga_prop)
+		drm_object_attach_property(obj, sdi->use_ds2_3ga_prop, 0);
+
+	if (sdi->c_encoding)
+		drm_object_attach_property(obj, sdi->c_encoding, 0);
+
+	drm_object_attach_property(obj,
+				   base_connector->dev->mode_config.gen_hdr_output_metadata_property, 0);
+}
+
+static int xlnx_sdi_create_connector(struct drm_encoder *encoder)
+{
+	struct xlnx_sdi *sdi = encoder_to_sdi(encoder);
+	struct drm_connector *connector = &sdi->connector;
+	int ret;
+
+	connector->interlace_allowed = true;
+	connector->doublescan_allowed = true;
+
+	ret = drm_connector_init(encoder->dev, connector,
+				 &xlnx_sdi_connector_funcs,
+				 DRM_MODE_CONNECTOR_Unknown);
+	if (ret) {
+		dev_err(sdi->dev, "Failed to initialize connector with drm\n");
+		return ret;
+	}
+
+	drm_connector_helper_add(connector, &xlnx_sdi_connector_helper_funcs);
+	drm_connector_register(connector);
+	drm_connector_attach_encoder(connector, encoder);
+	xlnx_sdi_drm_connector_create_property(connector);
+	xlnx_sdi_drm_connector_attach_property(connector);
+
+	/* Fill out the supported EOTFs */
+	connector->hdr_sink_metadata.hdmi_type1.eotf |=
+		BIT(V4L2_EOTF_BT_2100_HLG) |
+		BIT(V4L2_EOTF_TRADITIONAL_GAMMA_SDR) |
+		BIT(V4L2_EOTF_SMPTE_ST2084);
+
+	return 0;
+}
+
+/**
+ * xlnx_sdi_set_display_enable - Enables the SDI Tx IP core enable
+ * register bit
+ * @sdi: SDI structure having the updated user parameters
+ *
+ * This function takes the SDI strucure and enables the core enable bit
+ * of core configuration register.
+ */
+static void xlnx_sdi_set_display_enable(struct xlnx_sdi *sdi)
+{
+	u32 data;
+
+	data = xlnx_sdi_readl(sdi->base, XSDI_TX_RST_CTRL);
+	data |= XSDI_TX_CTRL_EN;
+	xlnx_sdi_writel(sdi->base, XSDI_TX_RST_CTRL, data);
+}
+
+/**
+ * xlnx_sdi_calc_st352_payld -  calculate the st352 payload
+ *
+ * @sdi: pointer to SDI Tx structure
+ * @mode: DRM display mode
+ *
+ * This function calculates the st352 payload to be configured.
+ * Please refer to SMPTE ST352 documents for it.
+ * Return:	return st352 payload
+ */
+static u32 xlnx_sdi_calc_st352_payld(struct xlnx_sdi *sdi,
+				     struct drm_display_mode *mode)
+{
+	u8 byt1, byt2;
+	u16 is_p;
+	int id;
+	u32 sdi_mode = sdi->sdi_mod_prop_val;
+	bool is_frac = sdi->is_frac_prop_val;
+	u32 byt3 = ST352_BYTE3;
+
+	id = xlnx_sdi_get_mode_id(mode);
+	dev_dbg(sdi->dev, "mode id: %d\n", id);
+	if (mode->hdisplay == 2048 || mode->hdisplay == 4096)
+		byt3 |= XST352_2048_SHIFT;
+	if (sdi->sdi_420_in_val)
+		byt3 |= XST352_YUV420_MASK;
+	else if (sdi->sdi_444_out_val)
+		byt3 |= XST352_YUV444_MASK;
+
+	/* byte 2 calculation */
+	is_p = !(mode->flags & DRM_MODE_FLAG_INTERLACE);
+	byt2 = xlnx_sdi_modes[id].st352_byt2[is_frac];
+	if (sdi_mode == XSDI_MODE_3GB ||
+	    (mode->flags & DRM_MODE_FLAG_DBLSCAN) || is_p)
+		byt2 |= XST352_PROG_PIC;
+	if (is_p && mode->vtotal >= 1125)
+		byt2 |= XST352_PROG_TRANS;
+
+	/* byte 1 calculation */
+	byt1 = xlnx_sdi_modes[id].st352_byt1[sdi_mode];
+
+	return (ST352_BYTE4 << 24 | byt3 << 16 | byt2 << 8 | byt1);
+}
+
+static void xlnx_sdi_setup(struct xlnx_sdi *sdi)
+{
+	u32 reg;
+
+	dev_dbg(sdi->dev, "%s\n", __func__);
+
+	reg = xlnx_sdi_readl(sdi->base, XSDI_TX_MDL_CTRL);
+	reg |= XSDI_TX_CTRL_INS_CRC | XSDI_TX_CTRL_INS_ST352 |
+		XSDI_TX_CTRL_OVR_ST352 | XSDI_TX_CTRL_INS_SYNC_BIT |
+		XSDI_TX_CTRL_INS_EDH;
+
+	if (sdi->enable_anc_data)
+		reg |= XSDI_TX_CTRL_USE_ANC_IN;
+
+	if (sdi->enable_st352_chroma) {
+		if (sdi->en_st352_c_val) {
+			reg |= XSDI_TX_CTRL_INS_ST352_CHROMA;
+			if (sdi->use_ds2_3ga_val)
+				reg |= XSDI_TX_CTRL_USE_DS2_3GA;
+			else
+				reg &= ~XSDI_TX_CTRL_USE_DS2_3GA;
+		} else {
+			reg &= ~XSDI_TX_CTRL_INS_ST352_CHROMA;
+			reg &= ~XSDI_TX_CTRL_USE_DS2_3GA;
+		}
+	}
+
+	xlnx_sdi_writel(sdi->base, XSDI_TX_MDL_CTRL, reg);
+	xlnx_sdi_writel(sdi->base, XSDI_TX_IER_STAT, XSDI_IER_EN_MASK);
+	xlnx_sdi_writel(sdi->base, XSDI_TX_GLBL_IER, 1);
+	xlnx_stc_reset(sdi->base);
+}
+
+/**
+ * xlnx_sdi_encoder_atomic_mode_set -  drive the SDI timing parameters
+ *
+ * @encoder: pointer to Xilinx DRM encoder
+ * @crtc_state: DRM crtc state
+ * @connector_state: DRM connector state
+ *
+ * This function derives the SDI IP timing parameters from the timing
+ * values given to timing module.
+ */
+static void xlnx_sdi_encoder_atomic_mode_set(struct drm_encoder *encoder,
+					     struct drm_crtc_state *crtc_state,
+				  struct drm_connector_state *connector_state)
+{
+	struct xlnx_sdi *sdi = encoder_to_sdi(encoder);
+	struct drm_display_mode *adjusted_mode = &crtc_state->adjusted_mode;
+	struct videomode vm;
+	u32 payload, i;
+	u32 sditx_blank, vtc_blank;
+	unsigned long clkrate;
+	int ret;
+
+	/*
+	 * For the transceiver TX, for integer and fractional frame rate, the
+	 * PLL ref clock must be a different frequency. Other than SD mode
+	 * its 148.5MHz for an integer & 148.5/1.001 for fractional framerate.
+	 * Program clocks followed by reset, if picxo is not enabled.
+	 */
+	if (!sdi->picxo_enabled) {
+		if (sdi->is_frac_prop_val &&
+		    sdi->sdi_mod_prop_val != XSDI_MODE_SD)
+			clkrate = (CLK_RATE * 1000) / 1001;
+		else
+			clkrate = CLK_RATE;
+		ret = clk_set_rate(sdi->sditx_clk, clkrate);
+		if (ret)
+			dev_err(sdi->dev, "failed to set clk rate = %lu\n",
+				clkrate);
+		clkrate = clk_get_rate(sdi->sditx_clk);
+		dev_info(sdi->dev, "clkrate = %lu is_frac = %d\n", clkrate,
+			 sdi->is_frac_prop_val);
+		/*
+		 * Delay required to get QPLL1 lock as per the si5328
+		 * datasheet
+		 */
+		mdelay(50);
+		if (sdi->gt_rst_gpio)
+			xlnx_sdi_gt_reset(sdi);
+	}
+
+	/* Set timing parameters as per bridge output parameters */
+	xlnx_bridge_set_input(sdi->bridge, adjusted_mode->hdisplay,
+			      adjusted_mode->vdisplay, sdi->in_fmt_prop_val);
+	xlnx_bridge_set_output(sdi->bridge, sdi->width_out_prop_val,
+			       sdi->height_out_prop_val, sdi->out_fmt_prop_val);
+	xlnx_bridge_enable(sdi->bridge);
+
+	if (sdi->bridge) {
+		for (i = 0; i < ARRAY_SIZE(xlnx_sdi_modes); i++) {
+			if (xlnx_sdi_modes[i].mode.hdisplay ==
+			    sdi->width_out_prop_val &&
+			    xlnx_sdi_modes[i].mode.vdisplay ==
+			    sdi->height_out_prop_val &&
+			    adjusted_mode->flags == xlnx_sdi_modes[i].mode.flags &&
+			    drm_mode_vrefresh(&xlnx_sdi_modes[i].mode) ==
+			    drm_mode_vrefresh(adjusted_mode)) {
+				memcpy((char *)adjusted_mode +
+				       offsetof(struct drm_display_mode,
+						clock),
+				       &xlnx_sdi_modes[i].mode.clock,
+				       SDI_TIMING_PARAMS_SIZE);
+				break;
+			}
+		}
+	}
+
+	/* If HFR video is streaming */
+	if (drm_mode_vrefresh(adjusted_mode) >= XSDI_HFR_MIN_FPS)
+		sdi->is_hfr = 1;
+
+	xlnx_sdi_setup(sdi);
+	xlnx_sdi_set_config_parameters(sdi);
+
+	/* set st352 payloads */
+	payload = xlnx_sdi_calc_st352_payld(sdi, adjusted_mode);
+	dev_dbg(sdi->dev, "payload : %0x\n", payload);
+
+	for (i = 0; i < sdi->sdi_data_strm_prop_val / 2; i++) {
+		if (sdi->sdi_mod_prop_val == XSDI_MODE_3GB)
+			payload |= (i << 1) << XSDI_CH_SHIFT;
+		xlnx_sdi_set_payload_data(sdi, i, payload);
+	}
+
+	/* UHDSDI is fixed 2 pixels per clock, horizontal timings div by 2 */
+	vm.hactive = adjusted_mode->hdisplay / PIXELS_PER_CLK;
+	vm.hfront_porch = (adjusted_mode->hsync_start -
+			  adjusted_mode->hdisplay) / PIXELS_PER_CLK;
+	vm.hback_porch = (adjusted_mode->htotal -
+			 adjusted_mode->hsync_end) / PIXELS_PER_CLK;
+	vm.hsync_len = (adjusted_mode->hsync_end -
+		       adjusted_mode->hsync_start) / PIXELS_PER_CLK;
+
+	vm.vactive = adjusted_mode->vdisplay;
+	if (adjusted_mode->flags & DRM_MODE_FLAG_INTERLACE) {
+		vm.vfront_porch = adjusted_mode->vsync_start / 2 -
+				  adjusted_mode->vdisplay;
+		vm.vback_porch = (adjusted_mode->vtotal -
+				  adjusted_mode->vsync_end) / 2;
+		vm.vsync_len = (adjusted_mode->vsync_end -
+				adjusted_mode->vsync_start) / 2;
+	} else {
+		vm.vfront_porch = adjusted_mode->vsync_start -
+				  adjusted_mode->vdisplay;
+		vm.vback_porch = adjusted_mode->vtotal -
+				 adjusted_mode->vsync_end;
+		vm.vsync_len = adjusted_mode->vsync_end -
+			       adjusted_mode->vsync_start;
+	}
+
+	vm.flags = 0;
+	if (adjusted_mode->flags & DRM_MODE_FLAG_INTERLACE)
+		vm.flags |= DISPLAY_FLAGS_INTERLACED;
+	if (adjusted_mode->flags & DRM_MODE_FLAG_PHSYNC)
+		vm.flags |= DISPLAY_FLAGS_HSYNC_LOW;
+	if (adjusted_mode->flags & DRM_MODE_FLAG_PVSYNC)
+		vm.flags |= DISPLAY_FLAGS_VSYNC_LOW;
+
+	do {
+		sditx_blank = (adjusted_mode->hsync_start -
+			       adjusted_mode->hdisplay) +
+			      (adjusted_mode->hsync_end -
+			       adjusted_mode->hsync_start) +
+			      (adjusted_mode->htotal -
+			       adjusted_mode->hsync_end);
+
+		vtc_blank = (vm.hfront_porch + vm.hback_porch +
+			     vm.hsync_len) * PIXELS_PER_CLK;
+
+		if (vtc_blank != sditx_blank)
+			vm.hfront_porch++;
+	} while (vtc_blank < sditx_blank);
+
+	vm.pixelclock = adjusted_mode->clock * 1000;
+
+	/* parameters for sdi audio */
+	sdi->video_mode.vdisplay = adjusted_mode->vdisplay;
+	sdi->video_mode.hdisplay = adjusted_mode->hdisplay;
+	sdi->video_mode.flags = adjusted_mode->flags;
+	sdi->video_mode.htotal = adjusted_mode->htotal;
+	sdi->video_mode.vtotal = adjusted_mode->vtotal;
+	sdi->video_mode.clock = adjusted_mode->clock;
+
+	xlnx_stc_sig(sdi->base, &vm);
+}
+
+static void xlnx_sdi_commit(struct drm_encoder *encoder)
+{
+	struct xlnx_sdi *sdi = encoder_to_sdi(encoder);
+	long ret;
+
+	dev_dbg(sdi->dev, "%s\n", __func__);
+	xlnx_sdi_set_display_enable(sdi);
+	ret = wait_event_interruptible_timeout(sdi->wait_event,
+					       sdi->event_received,
+					       usecs_to_jiffies(GT_TIMEOUT));
+	if (!ret) {
+		dev_err(sdi->dev, "Timeout: GT interrupt not received\n");
+		return;
+	}
+	sdi->event_received = false;
+	/* enable sdi bridge, timing controller and Axi4s_vid_out_ctrl */
+	xlnx_sdi_en_bridge(sdi);
+	xlnx_stc_enable(sdi->base);
+	xlnx_sdi_en_axi4s(sdi);
+}
+
+static void xlnx_sdi_disable(struct drm_encoder *encoder)
+{
+	struct xlnx_sdi *sdi = encoder_to_sdi(encoder);
+
+	if (sdi->bridge)
+		xlnx_bridge_disable(sdi->bridge);
+
+	xlnx_sdi_set_display_disable(sdi);
+	xlnx_stc_disable(sdi->base);
+}
+
+static const struct drm_encoder_helper_funcs xlnx_sdi_encoder_helper_funcs = {
+	.atomic_mode_set	= xlnx_sdi_encoder_atomic_mode_set,
+	.enable			= xlnx_sdi_commit,
+	.disable		= xlnx_sdi_disable,
+};
+
+static const struct drm_encoder_funcs xlnx_sdi_encoder_funcs = {
+	.destroy = drm_encoder_cleanup,
+};
+
+static int xlnx_sdi_bind(struct device *dev, struct device *master,
+			 void *data)
+{
+	struct xlnx_sdi *sdi = dev_get_drvdata(dev);
+	struct drm_encoder *encoder = &sdi->encoder;
+	struct drm_device *drm_dev = data;
+	int ret;
+
+	/*
+	 * TODO: The possible CRTCs are 1 now as per current implementation of
+	 * SDI tx drivers. DRM framework can support more than one CRTCs and
+	 * SDI driver can be enhanced for that.
+	 */
+	encoder->possible_crtcs = 1;
+
+	drm_encoder_init(drm_dev, encoder, &xlnx_sdi_encoder_funcs,
+			 DRM_MODE_ENCODER_TMDS, NULL);
+
+	drm_encoder_helper_add(encoder, &xlnx_sdi_encoder_helper_funcs);
+
+	ret = xlnx_sdi_create_connector(encoder);
+	if (ret) {
+		dev_err(sdi->dev, "fail creating connector, ret = %d\n", ret);
+		drm_encoder_cleanup(encoder);
+	}
+	return ret;
+}
+
+static void xlnx_sdi_unbind(struct device *dev, struct device *master,
+			    void *data)
+{
+	struct xlnx_sdi *sdi = dev_get_drvdata(dev);
+
+	xlnx_sdi_set_display_disable(sdi);
+	xlnx_stc_disable(sdi->base);
+	drm_encoder_cleanup(&sdi->encoder);
+	drm_connector_cleanup(&sdi->connector);
+	xlnx_bridge_disable(sdi->bridge);
+}
+
+static const struct component_ops xlnx_sdi_component_ops = {
+	.bind	= xlnx_sdi_bind,
+	.unbind	= xlnx_sdi_unbind,
+};
+
+static int xlnx_sdi_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct xlnx_sdi *sdi;
+	struct device_node *vpss_node;
+	int ret, irq;
+	struct device_node *ports, *port;
+	u32 nports = 0, portmask = 0;
+	unsigned long clkrate = 0;
+	enum gpiod_flags flags;
+
+	sdi = devm_kzalloc(dev, sizeof(*sdi), GFP_KERNEL);
+	if (!sdi)
+		return -ENOMEM;
+
+	sdi->dev = dev;
+	sdi->base = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(sdi->base)) {
+		dev_err(dev, "failed to remap io region\n");
+		return PTR_ERR(sdi->base);
+	}
+	platform_set_drvdata(pdev, sdi);
+
+	sdi->axi_clk = devm_clk_get_enabled(dev, "s_axi_aclk");
+	if (IS_ERR(sdi->axi_clk)) {
+		ret = PTR_ERR(sdi->axi_clk);
+		dev_err(dev, "failed to get s_axi_aclk %d\n", ret);
+		return ret;
+	}
+
+	sdi->sditx_clk = devm_clk_get_enabled(dev, "sdi_tx_clk");
+	if (IS_ERR(sdi->sditx_clk)) {
+		ret = PTR_ERR(sdi->sditx_clk);
+		dev_err(dev, "failed to get sdi_tx_clk %d\n", ret);
+		return ret;
+	}
+
+	sdi->vidin_clk = devm_clk_get_enabled(dev, "video_in_clk");
+	if (IS_ERR(sdi->vidin_clk)) {
+		ret = PTR_ERR(sdi->vidin_clk);
+		dev_err(dev, "failed to get video_in_clk %d\n", ret);
+		return ret;
+	}
+
+	sdi->qpll1_enabled = of_property_read_bool(sdi->dev->of_node, "xlnx,qpll1-enabled");
+	if (!sdi->qpll1_enabled) {
+		sdi->qpll1_enabled = of_property_read_bool(sdi->dev->of_node, "xlnx,qpll1_enabled");
+		if (sdi->qpll1_enabled)
+			dev_warn(dev, "xlnx,qpll1_enabled is deprecated. Use xlnx,qpll1-enabled instead.\n");
+	}
+
+	sdi->picxo_enabled = of_property_read_bool(sdi->dev->of_node, "xlnx,picxo-enabled");
+	if (!sdi->picxo_enabled) {
+		sdi->picxo_enabled = of_property_read_bool(sdi->dev->of_node, "xlnx,picxo_enabled");
+		if (sdi->picxo_enabled)
+			dev_warn(dev, "xlnx,picxo_enabled is deprecated. Use xlnx,picxo-enabled instead.\n");
+	}
+
+	dev_dbg(dev, "Values - qpll1-enabled: %d, picxo-enabled: %d\n",
+		sdi->qpll1_enabled, sdi->picxo_enabled);
+
+	if (sdi->qpll1_enabled)
+		flags = GPIOD_OUT_LOW;
+	else
+		flags = GPIOD_OUT_HIGH;
+
+	sdi->gt_rst_gpio = devm_gpiod_get_optional(&pdev->dev, "phy-reset",
+						   flags);
+
+	if (IS_ERR(sdi->gt_rst_gpio))
+		return dev_err_probe(&pdev->dev, PTR_ERR(sdi->gt_rst_gpio),
+				     "Unable to get phy gpio\n");
+
+	ret = clk_set_rate(sdi->sditx_clk, CLK_RATE);
+	if (ret)
+		dev_err(sdi->dev, "failed to set clk rate = %lu\n", CLK_RATE);
+
+	clkrate = clk_get_rate(sdi->sditx_clk);
+	dev_dbg(sdi->dev, "clkrate = %lu\n", clkrate);
+
+	/* in case all "port" nodes are grouped under a "ports" node */
+	ports = of_get_child_by_name(sdi->dev->of_node, "ports");
+	if (!ports) {
+		dev_dbg(dev, "Searching for port nodes in device node.\n");
+		ports = sdi->dev->of_node;
+	}
+
+	for_each_child_of_node(ports, port) {
+		struct device_node *endpoint;
+		u32 index;
+
+		if (!port->name || of_node_cmp(port->name, "port")) {
+			dev_dbg(dev, "port name is null or node name is not port!\n");
+			continue;
+		}
+
+		endpoint = of_get_next_child(port, NULL);
+		if (!endpoint) {
+			dev_err(dev, "No remote port at %s\n", port->name);
+			of_node_put(endpoint);
+			return -EINVAL;
+		}
+
+		of_node_put(endpoint);
+
+		ret = of_property_read_u32(port, "reg", &index);
+		if (ret) {
+			dev_err(dev, "reg property not present - %d\n", ret);
+			return ret;
+		}
+
+		portmask |= (1 << index);
+
+		nports++;
+	}
+
+	if (nports == 2 && portmask & 0x3) {
+		dev_dbg(dev, "enable ancillary port\n");
+		sdi->enable_anc_data = true;
+	} else if (nports == 1 && portmask & 0x1) {
+		dev_dbg(dev, "no ancillary port\n");
+		sdi->enable_anc_data = false;
+	} else {
+		dev_err(dev, "Incorrect dt node!\n");
+		return -EINVAL;
+	}
+
+	sdi->enable_st352_chroma = of_property_read_bool(sdi->dev->of_node,
+							 "xlnx,tx-insert-c-str-st352");
+
+	/* disable interrupt */
+	xlnx_sdi_writel(sdi->base, XSDI_TX_GLBL_IER, 0);
+	irq = platform_get_irq_byname(pdev, "sdi_tx_irq");
+	if (irq < 0) {
+		/*
+		 * If there is no IRQ with this name, try to get the first
+		 * IRQ defined in the device tree.
+		 */
+		irq = platform_get_irq(pdev, 0);
+		if (irq < 0)
+			return irq;
+	}
+
+	ret = devm_request_threaded_irq(sdi->dev, irq, NULL,
+					xlnx_sdi_irq_handler, IRQF_ONESHOT,
+					dev_name(sdi->dev), sdi);
+	if (ret < 0)
+		return ret;
+
+	/* initialize the wait queue for GT reset event */
+	init_waitqueue_head(&sdi->wait_event);
+
+	/* Bridge support */
+	vpss_node = of_parse_phandle(sdi->dev->of_node, "xlnx,vpss", 0);
+	if (vpss_node) {
+		sdi->bridge = of_xlnx_bridge_get(vpss_node);
+		if (!sdi->bridge) {
+			dev_info(sdi->dev, "Didn't get bridge instance\n");
+			return -EPROBE_DEFER;
+		}
+	}
+
+	/* video mode properties needed by audio driver are shared to audio
+	 * driver through a pointer in platform data. This will be used in
+	 * audio driver. The solution may be needed to modify/extend to avoid
+	 * probable error scenarios
+	 */
+	pdev->dev.platform_data = &sdi->video_mode;
+	/* Initialize to IP default value */
+	sdi->prev_eotf = XST352_BYTE2_EOTF_SDRTV;
+
+	return component_add(dev, &xlnx_sdi_component_ops);
+}
+
+static void xlnx_sdi_remove(struct platform_device *pdev)
+{
+	component_del(&pdev->dev, &xlnx_sdi_component_ops);
+}
+
+static const struct of_device_id xlnx_sdi_of_match[] = {
+	{ .compatible = "xlnx,sdi-tx"},
+	{ }
+};
+MODULE_DEVICE_TABLE(of, xlnx_sdi_of_match);
+
+static struct platform_driver sdi_tx_driver = {
+	.probe = xlnx_sdi_probe,
+	.remove = xlnx_sdi_remove,
+	.driver = {
+		.name = "xlnx-sdi-tx",
+		.of_match_table = xlnx_sdi_of_match,
+	},
+};
+
+module_platform_driver(sdi_tx_driver);
+
+MODULE_AUTHOR("Saurabh Sengar <saurabhs@xilinx.com>");
+MODULE_DESCRIPTION("Xilinx FPGA SDI Tx Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/xlnx_sdi_modes.h b/drivers/gpu/drm/xlnx/xlnx_sdi_modes.h
new file mode 100644
index 000000000..21a0187ad
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_sdi_modes.h
@@ -0,0 +1,447 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx FPGA SDI modes timing values for various
+ * resolutions
+ *
+ * Copyright (c) 2017 Xilinx Pvt., Ltd
+ *
+ * Contacts: Saurabh Sengar <saurabhs@xilinx.com>
+ */
+
+#ifndef _XLNX_SDI_MODES_H_
+#define _XLNX_SDI_MODES_H_
+
+/**
+ * struct xlnx_sdi_display_config - SDI supported modes structure
+ * @mode: drm display mode
+ * @st352_byt2: st352 byte 2 value
+ *		index 0 : value for integral fps
+ *		index 1 : value for fractional fps
+ * @st352_byt1: st352 byte 1 value
+ *		index 0 : value for HD mode
+ *		index 1 : value for SD mode
+ *		index 2 : value for 3GA
+ *		index 3 : value for 3GB
+ *		index 4 : value for 6G
+ *		index 5 : value for 12G
+ */
+struct xlnx_sdi_display_config {
+	struct drm_display_mode mode;
+	u8 st352_byt2[2];
+	u8 st352_byt1[6];
+};
+
+/*
+ * xlnx_sdi_modes - SDI DRM modes
+ */
+static const struct xlnx_sdi_display_config xlnx_sdi_modes[] = {
+	/* 0 - dummy, VICs start at 1 */
+	{ },
+	/* SD: 720x486i@59.94Hz */
+	{{ DRM_MODE("720x486i", DRM_MODE_TYPE_DRIVER, 13500, 720, 739,
+		   801, 858, 0, 486, 494, 500, 525, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
+		   }, {0x7, 0x6},
+		   {0x81, 0x81, 0x81, 0x81, 0x81, 0x81} },
+	/* SD: 720x576i@50Hz */
+	{{ DRM_MODE("720x576i", DRM_MODE_TYPE_DRIVER, 13500, 720, 732,
+		   795, 864, 0, 576, 580, 586, 625, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLCLK),
+		   }, {0x9, 0x9},
+		   {0x81, 0x81, 0x81, 0x81, 0x81, 0x81} },
+	/* HD: 1280x720@25Hz */
+	{{ DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 74250, 1280, 2250,
+		   2990, 3960, 0, 720, 725, 730, 750, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x5, 0x5},
+		   {0x84, 0x84, 0x88, 0x84, 0x84, 0x84} },
+	/* HD: 1280x720@24Hz */
+	{{ DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 74250, 1280, 2250,
+		   3155, 4125, 0, 720, 725, 730, 750, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x3, 0x2},
+		   {0x84, 0x84, 0x88, 0x84, 0x84, 0x84} },
+	/* HD: 1280x720@30Hz */
+	 {{ DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 74250, 1280, 2250,
+		   2330, 3300, 0, 720, 725, 730, 750, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x7, 0x6},
+		   {0x84, 0x84, 0x88, 0x84, 0x84, 0x84} },
+	/* HD: 1280x720@50Hz */
+	{{ DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 74250, 1280, 1720,
+		   1760, 1980, 0, 720, 725, 730, 750, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x9, 0x9},
+		   {0x84, 0x84, 0x88, 0x84, 0x84, 0x84} },
+	/* HD: 1280x720@60Hz */
+	{{ DRM_MODE("1280x720", DRM_MODE_TYPE_DRIVER, 74250, 1280, 1390,
+		   1430, 1650, 0, 720, 725, 730, 750, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xB, 0xA},
+		   {0x84, 0x84, 0x88, 0x84, 0x84, 0x84} },
+	/* HD: 1920x1080@24Hz */
+	{{ DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2558,
+		   2602, 2750, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x3, 0x2},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 1920x1080@25Hz */
+	{{ DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2448,
+		   2492, 2640, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x5, 0x5},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 1920x1080@30Hz */
+	{{ DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2008,
+		   2052, 2200, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x7, 0x6},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 1920x1080i@48Hz */
+	{{ DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2291,
+		   2379, 2750, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x3, 0x2},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 1920x1080i@50Hz */
+	{{ DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2448,
+		   2492, 2640, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x5, 0x5},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 1920x1080i@60Hz */
+	{{ DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2008,
+		   2052, 2200, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x7, 0x6},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 1920x1080i@59.94Hz */
+	{{ DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 74175, 1920, 2008,
+		   2052, 2200, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x7, 0x6},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 1920x1080sf@24Hz */
+	{{ DRM_MODE("1920x1080sf", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2291,
+		   2379, 2750, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLSCAN),
+		   }, {0x3, 0x2},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 1920x1080sf@25Hz */
+	{{ DRM_MODE("1920x1080sf", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2448,
+		   2492, 2640, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLSCAN),
+		   }, {0x5, 0x5},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 1920x1080sf@30Hz */
+	{{ DRM_MODE("1920x1080sf", DRM_MODE_TYPE_DRIVER, 74250, 1920, 2008,
+		   2052, 2200, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLSCAN),
+		   }, {0x7, 0x6},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 2048x1080i@48Hz */
+	{{ DRM_MODE("2048x1080i", DRM_MODE_TYPE_DRIVER, 74250, 2048, 2377,
+		   2421, 2750, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x3, 0x2},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 2048x1080i@50Hz */
+	{{ DRM_MODE("2048x1080i", DRM_MODE_TYPE_DRIVER, 74250, 2048, 2322,
+		   2366, 2640, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x5, 0x5},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 2048x1080i@60Hz */
+	{{ DRM_MODE("2048x1080i", DRM_MODE_TYPE_DRIVER, 74250, 2048, 2114,
+		   2134, 2200, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x7, 0x6},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 2048x1080sf@24Hz */
+	{{ DRM_MODE("2048x1080sf", DRM_MODE_TYPE_DRIVER, 74250, 2048, 2377,
+		   2421, 2750, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLSCAN),
+		   }, {0x3, 0x2},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 2048x1080sf@25Hz */
+	{{ DRM_MODE("2048x1080sf", DRM_MODE_TYPE_DRIVER, 74250, 2048, 2322,
+		   2366, 2640, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLSCAN),
+		   }, {0x5, 0x5},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 2048x1080sf@30Hz */
+	{{ DRM_MODE("2048x1080sf", DRM_MODE_TYPE_DRIVER, 74250, 2048, 2114,
+		   2134, 2200, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE | DRM_MODE_FLAG_DBLSCAN),
+		   }, {0x7, 0x6},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 2048x1080@30Hz */
+	{{ DRM_MODE("2048x1080", DRM_MODE_TYPE_DRIVER, 74250, 2048, 2114,
+		   2134, 2200, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x7, 0x6},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 2048x1080@25Hz */
+	{{ DRM_MODE("2048x1080", DRM_MODE_TYPE_DRIVER, 74250, 2048, 2448,
+		   2492, 2640, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x5, 0x5},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* HD: 2048x1080@24Hz */
+	{{ DRM_MODE("2048x1080", DRM_MODE_TYPE_DRIVER, 74250, 2048, 2558,
+		   2602, 2750, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x3, 0x2},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G: 1920x1080@48Hz */
+	{{ DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 148500, 1920, 2558,
+		   2602, 2750, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x8, 0x4},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G: 1920x1080@50Hz */
+	{{ DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 148500, 1920, 2448,
+		   2492, 2640, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x9, 0x9},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G: 1920x1080@60Hz */
+	{{ DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 148500, 1920, 2008,
+		   2052, 2200, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xB, 0xA},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G: 1920x1080@59.94Hz */
+	{{ DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 148350, 1920, 2008,
+		   2052, 2200, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xB, 0xA},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G: 2048x1080@60Hz */
+	{{ DRM_MODE("2048x1080", DRM_MODE_TYPE_DRIVER, 148500, 2048, 2136,
+		   2180, 2200, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xB, 0xA},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G: 2048x1080@50Hz */
+	{{ DRM_MODE("2048x1080", DRM_MODE_TYPE_DRIVER, 148500, 2048, 2448,
+		   2492, 2640, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x9, 0x9},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G: 2048x1080@48Hz */
+	{{ DRM_MODE("2048x1080", DRM_MODE_TYPE_DRIVER, 148500, 2048, 2558,
+		   2602, 2750, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x8, 0x4},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G-B: 1920x1080i@96Hz */
+	{{ DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 148500, 1920, 2291,
+		   2379, 2750, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x8, 0x4},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G-B: 1920x1080i@100Hz */
+	{{ DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 148500, 1920, 2448,
+		   2492, 2640, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x9, 0x9},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G-B: 1920x1080i@120Hz */
+	{{ DRM_MODE("1920x1080i", DRM_MODE_TYPE_DRIVER, 148500, 1920, 2008,
+		   2052, 2200, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0xB, 0xA},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G-B: 2048x1080i@96Hz */
+	{{ DRM_MODE("2048x1080i", DRM_MODE_TYPE_DRIVER, 148500, 2048, 2377,
+		   2421, 2750, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x8, 0x4},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G-B: 2048x1080i@100Hz */
+	{{ DRM_MODE("2048x1080i", DRM_MODE_TYPE_DRIVER, 148500, 2048, 2322,
+		   2366, 2640, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0x9, 0x9},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 3G-B: 2048x1080i@120Hz */
+	{{ DRM_MODE("2048x1080i", DRM_MODE_TYPE_DRIVER, 148500, 2048, 2114,
+		   2134, 2200, 0, 1080, 1084, 1094, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC |
+		   DRM_MODE_FLAG_INTERLACE),
+		   }, {0xB, 0xA},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xC1} },
+	/* 6G: 3840x2160@29.97Hz */
+	{{ DRM_MODE("3840x2160", DRM_MODE_TYPE_DRIVER, 296704, 3840, 4016,
+		   4104, 4400, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x7, 0x6},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 6G: 3840x2160@30Hz */
+	{{ DRM_MODE("3840x2160", DRM_MODE_TYPE_DRIVER, 297000, 3840, 4016,
+		   4104, 4400, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x7, 0x6},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 6G: 3840x2160@25Hz */
+	{{ DRM_MODE("3840x2160", DRM_MODE_TYPE_DRIVER, 297000, 3840, 4896,
+		   4984, 5280, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x5, 0x5},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 6G: 3840x2160@23.98Hz */
+	{{ DRM_MODE("3840x2160", DRM_MODE_TYPE_DRIVER, 296704, 3840, 5116,
+		   5204, 5500, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x3, 0x2},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 6G: 3840x2160@24Hz */
+	{{ DRM_MODE("3840x2160", DRM_MODE_TYPE_DRIVER, 297000, 3840, 5116,
+		   5204, 5500, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x3, 0x2},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 6G: 4096x2160@23.98 */
+	{{ DRM_MODE("4096x2160", DRM_MODE_TYPE_DRIVER, 296704, 4096, 5116,
+		   5204, 5500, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x3, 0x2},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 6G: 4096x2160@24Hz */
+	{{ DRM_MODE("4096x2160", DRM_MODE_TYPE_DRIVER, 297000, 4096, 5116,
+		   5204, 5500, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x3, 0x2},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 6G: 4096x2160@25Hz */
+	{{ DRM_MODE("4096x2160", DRM_MODE_TYPE_DRIVER, 297000, 4096, 5064,
+		   5152, 5280, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x5, 0x5},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 6G: 4096x2160@29.97Hz */
+	{{ DRM_MODE("4096x2160", DRM_MODE_TYPE_DRIVER, 296704, 4096, 4184,
+		   4272, 4400, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x7, 0x6},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 6G: 4096x2160@30Hz */
+	{{ DRM_MODE("4096x2160", DRM_MODE_TYPE_DRIVER, 297000, 4096, 4184,
+		   4272, 4400, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x7, 0x6},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 12G: 3840x2160@48Hz */
+	{{ DRM_MODE("3840x2160", DRM_MODE_TYPE_DRIVER, 594000, 3840, 5116,
+		   5204, 5500, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x8, 0x4},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 12G: 3840x2160@50Hz */
+	{{ DRM_MODE("3840x2160", DRM_MODE_TYPE_DRIVER, 594000, 3840, 4896,
+		   4984, 5280, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x9, 0x9},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 12G: 3840x2160@59.94Hz */
+	{{ DRM_MODE("3840x2160", DRM_MODE_TYPE_DRIVER, 593406, 3840, 4016,
+		   4104, 4400, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xB, 0xA},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 12G: 3840x2160@60Hz */
+	{{ DRM_MODE("3840x2160", DRM_MODE_TYPE_DRIVER, 594000, 3840, 4016,
+		   4104, 4400, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xB, 0xA},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 12G: 4096x2160@47.95Hz */
+	{{ DRM_MODE("4096x2160", DRM_MODE_TYPE_DRIVER, 593406, 4096, 5116,
+		   5204, 5500, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x8, 0x4},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 12G: 4096x2160@48Hz */
+	{{ DRM_MODE("4096x2160", DRM_MODE_TYPE_DRIVER, 594000, 4096, 5116,
+		   5204, 5500, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x8, 0x4},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 12G: 4096x2160@50Hz */
+	{{ DRM_MODE("4096x2160", DRM_MODE_TYPE_DRIVER, 594000, 4096, 5064,
+		   5152, 5280, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0x9, 0x9},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 12G: 4096x2160@59.94Hz */
+	{{ DRM_MODE("4096x2160", DRM_MODE_TYPE_DRIVER, 593408, 4096, 4184,
+		   4272, 4400, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xB, 0xA},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* 12G: 4096x2160@60Hz */
+	{{ DRM_MODE("4096x2160", DRM_MODE_TYPE_DRIVER, 594000, 4096, 4184,
+		   4272, 4400, 0, 2160, 2168, 2178, 2250, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xB, 0xA},
+		   {0x98, 0x98, 0x97, 0x98, 0xC0, 0xCE} },
+	/* HFR: 1920x1080@100Hz */
+	{{ DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 297000, 1920, 2448,
+		   2492, 2640, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xD, 0xD},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xCF} },
+	/* HFR: 1920x1080@119.88Hz */
+	{{ DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 296703, 1920, 2008,
+		   2052, 2200, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xF, 0xE},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xCF} },
+	/* HFR: 1920x1080@120Hz */
+	{{ DRM_MODE("1920x1080", DRM_MODE_TYPE_DRIVER, 297000, 1920, 2008,
+		   2052, 2200, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xF, 0xE},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xCF} },
+	/* HFR: 2048x1080@100Hz */
+	{{ DRM_MODE("2048x1080", DRM_MODE_TYPE_DRIVER, 297000, 2048, 2448,
+		   2492, 2640, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xD, 0xD},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xCF} },
+	/* HFR: 2048x1080@119.88Hz */
+	{{ DRM_MODE("2048x1080", DRM_MODE_TYPE_DRIVER, 296703, 2048, 2136,
+		   2180, 2200, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xF, 0xE},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xCF} },
+	/* HFR: 2048x1080@120Hz */
+	{{ DRM_MODE("2048x1080", DRM_MODE_TYPE_DRIVER, 297000, 2048, 2136,
+		   2180, 2200, 0, 1080, 1084, 1089, 1125, 0,
+		   DRM_MODE_FLAG_PHSYNC | DRM_MODE_FLAG_PVSYNC),
+		   }, {0xF, 0xE},
+		   {0x85, 0x85, 0x89, 0x8A, 0xC1, 0xCF} },
+};
+
+#endif /* _XLNX_SDI_MODES_H_ */
diff --git a/drivers/gpu/drm/xlnx/xlnx_sdi_timing.c b/drivers/gpu/drm/xlnx/xlnx_sdi_timing.c
new file mode 100644
index 000000000..f0b00abc0
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_sdi_timing.c
@@ -0,0 +1,426 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Xilinx FPGA SDI Tx timing controller driver
+ *
+ * Copyright (c) 2017 Xilinx Pvt., Ltd
+ *
+ * Contacts: Saurabh Sengar <saurabhs@xilinx.com>
+ */
+
+#include <drm/drm_print.h>
+#include <linux/device.h>
+#include <video/videomode.h>
+#include <asm/io.h>
+#include "xlnx_sdi_timing.h"
+
+/* timing controller register offsets */
+#define XSTC_CTL	0x00
+#define XSTC_STATS	0x04
+#define XSTC_ERROR	0x08
+#define XSTC_GASIZE	0x60
+#define XSTC_GENC	0x68
+#define XSTC_GPOL	0x6c
+#define XSTC_GHSIZE	0x70
+#define XSTC_GVSIZE	0x74
+#define XSTC_GHSYNC	0x78
+#define XSTC_GVBH_F0	0x7c
+#define XSTC_GVSYNC_F0	0x80
+#define XSTC_GVSH_F0	0x84
+#define XSTC_GVBH_F1	0x88
+#define XSTC_GVSYNC_F1	0x8C
+#define XSTC_GVSH_F1	0x90
+#define XSTC_GASIZE_F1	0x94
+#define XSTC_OFFSET	0x10000
+
+/* timing controller register bit */
+#define XSTC_CTL_FIP	BIT(6)	/* field id polarity */
+#define XSTC_CTL_ACP	BIT(5)	/* active chroma polarity */
+#define XSTC_CTL_AVP	BIT(4)	/* active video polarity */
+#define XSTC_CTL_HSP	BIT(3)	/* hori sync polarity */
+#define XSTC_CTL_VSP	BIT(2)	/* vert sync polarity */
+#define XSTC_CTL_HBP	BIT(1)	/* hori blank polarity */
+#define XSTC_CTL_VBP	BIT(0)	/* vert blank polarity */
+#define XSTC_CTL_FIPSS	BIT(26)	/* field id polarity source */
+#define XSTC_CTL_ACPSS	BIT(25)	/* active chroma polarity src */
+#define XSTC_CTL_AVPSS	BIT(24)	/* active video polarity src */
+#define XSTC_CTL_HSPSS	BIT(23)	/* hori sync polarity src */
+#define XSTC_CTL_VSPSS	BIT(22)	/* vert sync polarity src */
+#define XSTC_CTL_HBPSS	BIT(21)	/* hori blank polarity src */
+#define XSTC_CTL_VBPSS	BIT(20)	/* vert blank polarity src */
+#define XSTC_CTL_VCSS	BIT(18)	/* chroma src */
+#define XSTC_CTL_VASS	BIT(17)	/* vertical offset src */
+#define XSTC_CTL_VBSS	BIT(16)	/* vertical sync end src */
+#define XSTC_CTL_VSSS	BIT(15)	/* vertical sync start src */
+#define XSTC_CTL_VFSS	BIT(14)	/* vertical active size src */
+#define XSTC_CTL_VTSS	BIT(13)	/* vertical frame size src */
+#define XSTC_CTL_HBSS	BIT(11)	/* horiz sync end src */
+#define XSTC_CTL_HSSS	BIT(10)	/* horiz sync start src */
+#define XSTC_CTL_HFSS	BIT(9)	/* horiz active size src */
+#define XSTC_CTL_HTSS	BIT(8)	/* horiz frame size src */
+#define XSTC_CTL_GE	BIT(2)	/* timing generator enable */
+#define XSTC_CTL_RU	BIT(1)	/* timing register update */
+
+/* timing generator horizontal 1 */
+#define XSTC_GH1_BPSTART_MASK	GENMASK(28, 16)
+#define XSTC_GH1_BPSTART_SHIFT	16
+#define XSTC_GH1_SYNCSTART_MASK	GENMASK(12, 0)
+/* timing generator vertical 1 (filed 0) */
+#define XSTC_GV1_BPSTART_MASK	GENMASK(28, 16)
+#define XSTC_GV1_BPSTART_SHIFT	16
+#define XSTC_GV1_SYNCSTART_MASK	GENMASK(12, 0)
+/* timing generator/detector vblank/vsync horizontal offset registers */
+#define XSTC_XVXHOX_HEND_MASK	GENMASK(28, 16)
+#define XSTC_XVXHOX_HEND_SHIFT	16
+#define XSTC_XVXHOX_HSTART_MASK	GENMASK(12, 0)
+
+#define XSTC_GHFRAME_HSIZE	GENMASK(12, 0)
+#define XSTC_GVFRAME_HSIZE_F1	GENMASK(12, 0)
+#define XSTC_GA_ACTSIZE_MASK	GENMASK(12, 0)
+/* reset register bit definition */
+#define XSTC_RST		BIT(31)
+/* Interlaced bit in XSTC_GENC */
+#define XSTC_GENC_INTERL	BIT(6)
+
+/**
+ * struct xlnx_stc_polarity - timing signal polarity
+ *
+ * @field_id: field ID polarity
+ * @vblank: vblank polarity
+ * @vsync: vsync polarity
+ * @hblank: hblank polarity
+ * @hsync: hsync polarity
+ */
+struct xlnx_stc_polarity {
+	u8 field_id;
+	u8 vblank;
+	u8 vsync;
+	u8 hblank;
+	u8 hsync;
+};
+
+/**
+ * struct xlnx_stc_hori_off - timing signal horizontal offset
+ *
+ * @v0blank_hori_start: vblank horizontal start (field 0)
+ * @v0blank_hori_end: vblank horizontal end (field 0)
+ * @v0sync_hori_start: vsync horizontal start (field 0)
+ * @v0sync_hori_end: vsync horizontal end (field 0)
+ * @v1blank_hori_start: vblank horizontal start (field 1)
+ * @v1blank_hori_end: vblank horizontal end (field 1)
+ * @v1sync_hori_start: vsync horizontal start (field 1)
+ * @v1sync_hori_end: vsync horizontal end (field 1)
+ */
+struct xlnx_stc_hori_off {
+	u16 v0blank_hori_start;
+	u16 v0blank_hori_end;
+	u16 v0sync_hori_start;
+	u16 v0sync_hori_end;
+	u16 v1blank_hori_start;
+	u16 v1blank_hori_end;
+	u16 v1sync_hori_start;
+	u16 v1sync_hori_end;
+};
+
+/**
+ * xlnx_stc_writel - Memory mapped SDI Tx timing controller write
+ * @base:	Pointer to SDI Tx registers base
+ * @offset:	Register offset
+ * @val:	value to be written
+ *
+ * This function writes the value to SDI TX timing controller registers
+ */
+static inline void xlnx_stc_writel(void __iomem *base, int offset, u32 val)
+{
+	writel(val, base + XSTC_OFFSET + offset);
+}
+
+/**
+ * xlnx_stc_readl - Memory mapped timing controllerregister read
+ * @base:	Pointer to SDI Tx registers base
+ * @offset:	Register offset
+ *
+ * Return: The contents of the SDI Tx timing controller register
+ *
+ * This function returns the contents of the corresponding SDI Tx register.
+ */
+static inline u32 xlnx_stc_readl(void __iomem *base, int offset)
+{
+	return readl(base + XSTC_OFFSET + offset);
+}
+
+/**
+ * xlnx_stc_enable - Enable timing controller
+ * @base:	Base address of SDI Tx subsystem
+ *
+ * This function enables the SDI Tx subsystem's timing controller
+ */
+void xlnx_stc_enable(void __iomem *base)
+{
+	u32 reg;
+
+	reg = xlnx_stc_readl(base, XSTC_CTL);
+	xlnx_stc_writel(base, XSTC_CTL, reg | XSTC_CTL_GE);
+}
+
+/**
+ * xlnx_stc_disable - Disable timing controller
+ * @base:	Base address of SDI Tx subsystem
+ *
+ * This function disables the SDI Tx subsystem's timing controller
+ */
+void xlnx_stc_disable(void __iomem *base)
+{
+	u32 reg;
+
+	reg = xlnx_stc_readl(base, XSTC_CTL);
+	xlnx_stc_writel(base, XSTC_CTL, reg & ~XSTC_CTL_GE);
+}
+
+/**
+ * xlnx_stc_reset - Reset timing controller
+ * @base:	Base address of SDI Tx subsystem
+ *
+ * This function resets the SDI Tx subsystem's timing controller
+ */
+void xlnx_stc_reset(void __iomem *base)
+{
+	u32 reg;
+
+	xlnx_stc_writel(base, XSTC_CTL, XSTC_RST);
+
+	/* enable register update */
+	reg = xlnx_stc_readl(base, XSTC_CTL);
+	xlnx_stc_writel(base, XSTC_CTL, reg | XSTC_CTL_RU);
+}
+
+/**
+ * xlnx_stc_polarity - Configure timing signal polarity
+ * @base:	Base address of SDI Tx subsystem
+ * @polarity:	timing signal polarity data
+ *
+ * This function configure timing signal polarity
+ */
+static void xlnx_stc_polarity(void __iomem *base,
+			      struct xlnx_stc_polarity *polarity)
+{
+	u32 reg = 0;
+
+	reg = XSTC_CTL_ACP;
+	reg |= XSTC_CTL_AVP;
+	if (polarity->field_id)
+		reg |= XSTC_CTL_FIP;
+	if (polarity->vblank)
+		reg |= XSTC_CTL_VBP;
+	if (polarity->vsync)
+		reg |= XSTC_CTL_VSP;
+	if (polarity->hblank)
+		reg |= XSTC_CTL_HBP;
+	if (polarity->hsync)
+		reg |= XSTC_CTL_HSP;
+
+	xlnx_stc_writel(base, XSTC_GPOL, reg);
+}
+
+/**
+ * xlnx_stc_hori_off - Configure horzontal timing offset
+ * @base:	Base address of SDI Tx subsystem
+ * @hori_off:	horizontal offset configuration data
+ * @flags:	Display flags
+ *
+ * This function configure horizontal offset
+ */
+static void xlnx_stc_hori_off(void __iomem *base,
+			      struct xlnx_stc_hori_off *hori_off,
+			      enum display_flags flags)
+{
+	u32 reg;
+
+	/* Calculate and update Generator VBlank Hori field 0 */
+	reg = hori_off->v0blank_hori_start & XSTC_XVXHOX_HSTART_MASK;
+	reg |= (hori_off->v0blank_hori_end << XSTC_XVXHOX_HEND_SHIFT) &
+		XSTC_XVXHOX_HEND_MASK;
+	xlnx_stc_writel(base, XSTC_GVBH_F0, reg);
+
+	/* Calculate and update Generator VSync Hori field 0 */
+	reg = hori_off->v0sync_hori_start & XSTC_XVXHOX_HSTART_MASK;
+	reg |= (hori_off->v0sync_hori_end << XSTC_XVXHOX_HEND_SHIFT) &
+		XSTC_XVXHOX_HEND_MASK;
+	xlnx_stc_writel(base, XSTC_GVSH_F0, reg);
+
+	/* Calculate and update Generator VBlank Hori field 1 */
+	if (flags & DISPLAY_FLAGS_INTERLACED) {
+		reg = hori_off->v1blank_hori_start & XSTC_XVXHOX_HSTART_MASK;
+		reg |= (hori_off->v1blank_hori_end << XSTC_XVXHOX_HEND_SHIFT) &
+			XSTC_XVXHOX_HEND_MASK;
+		xlnx_stc_writel(base, XSTC_GVBH_F1, reg);
+	}
+
+	/* Calculate and update Generator VBlank Hori field 1 */
+	if (flags & DISPLAY_FLAGS_INTERLACED) {
+		reg = hori_off->v1sync_hori_start & XSTC_XVXHOX_HSTART_MASK;
+		reg |= (hori_off->v1sync_hori_end << XSTC_XVXHOX_HEND_SHIFT) &
+			XSTC_XVXHOX_HEND_MASK;
+		xlnx_stc_writel(base, XSTC_GVSH_F1, reg);
+	}
+}
+
+/**
+ * xlnx_stc_src - Configure timing source
+ * @base:	Base address of SDI Tx subsystem
+ *
+ * This function configure timing source
+ */
+static void xlnx_stc_src(void __iomem *base)
+{
+	u32 reg;
+
+	reg = xlnx_stc_readl(base, XSTC_CTL);
+	reg |= XSTC_CTL_VCSS;
+	reg |= XSTC_CTL_VASS;
+	reg |= XSTC_CTL_VBSS;
+	reg |= XSTC_CTL_VSSS;
+	reg |= XSTC_CTL_VFSS;
+	reg |= XSTC_CTL_VTSS;
+	reg |= XSTC_CTL_HBSS;
+	reg |= XSTC_CTL_HSSS;
+	reg |= XSTC_CTL_HFSS;
+	reg |= XSTC_CTL_HTSS;
+	xlnx_stc_writel(base, XSTC_CTL, reg);
+}
+
+/**
+ * xlnx_stc_sig - Generates timing signal
+ * @base:	Base address of SDI Tx subsystem
+ * @vm:		video mode
+ *
+ * This function generated the timing for given vide mode
+ */
+void xlnx_stc_sig(void __iomem *base, struct videomode *vm)
+{
+	u32 reg;
+	u32 htotal, hactive, hsync_start, hbackporch_start;
+	u32 vtotal, vactive, vsync_start, vbackporch_start;
+	struct xlnx_stc_hori_off hori_off;
+	struct xlnx_stc_polarity polarity;
+
+	reg = xlnx_stc_readl(base, XSTC_CTL);
+	xlnx_stc_writel(base, XSTC_CTL, reg & ~XSTC_CTL_RU);
+
+	htotal = vm->hactive + vm->hfront_porch + vm->hsync_len +
+		 vm->hback_porch;
+	vtotal = vm->vactive + vm->vfront_porch + vm->vsync_len +
+		 vm->vback_porch;
+	hactive = vm->hactive;
+	vactive = vm->vactive;
+	hsync_start = vm->hactive + vm->hfront_porch;
+	vsync_start = vm->vactive + vm->vfront_porch;
+	hbackporch_start = hsync_start + vm->hsync_len;
+	vbackporch_start = vsync_start + vm->vsync_len;
+
+	DRM_DEBUG_DRIVER("ha: %d, va: %d\n", hactive, vactive);
+	DRM_DEBUG_DRIVER("hs: %d, hb: %d\n", hsync_start, hbackporch_start);
+	DRM_DEBUG_DRIVER("vs: %d, vb: %d\n", vsync_start, vbackporch_start);
+	DRM_DEBUG_DRIVER("ht: %d, vt: %d\n", htotal, vtotal);
+
+	reg = htotal & XSTC_GHFRAME_HSIZE;
+	xlnx_stc_writel(base, XSTC_GHSIZE, reg);
+	reg = vtotal & XSTC_GVFRAME_HSIZE_F1;
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED) {
+		if (vm->pixelclock == 148500000)
+			reg |= (reg + 2) <<
+				XSTC_GV1_BPSTART_SHIFT;
+		else
+			reg |= (reg + 1) <<
+				XSTC_GV1_BPSTART_SHIFT;
+	} else {
+		reg |= reg << XSTC_GV1_BPSTART_SHIFT;
+	}
+	xlnx_stc_writel(base, XSTC_GVSIZE, reg);
+	reg = hactive & XSTC_GA_ACTSIZE_MASK;
+	reg |= (vactive & XSTC_GA_ACTSIZE_MASK) << 16;
+	xlnx_stc_writel(base, XSTC_GASIZE, reg);
+
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED) {
+		if (vactive == 243)
+			reg = ((vactive + 1) & XSTC_GA_ACTSIZE_MASK) << 16;
+		else
+			reg = (vactive & XSTC_GA_ACTSIZE_MASK) << 16;
+		xlnx_stc_writel(base, XSTC_GASIZE_F1, reg);
+	}
+
+	reg = hsync_start & XSTC_GH1_SYNCSTART_MASK;
+	reg |= (hbackporch_start << XSTC_GH1_BPSTART_SHIFT) &
+	       XSTC_GH1_BPSTART_MASK;
+	xlnx_stc_writel(base, XSTC_GHSYNC, reg);
+	reg = vsync_start & XSTC_GV1_SYNCSTART_MASK;
+	reg |= (vbackporch_start << XSTC_GV1_BPSTART_SHIFT) &
+	       XSTC_GV1_BPSTART_MASK;
+
+	/*
+	 * Fix the Vsync_vstart and vsync_vend of Field 0
+	 * for all interlaced modes including 3GB.
+	 */
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED)
+		reg = ((((reg & XSTC_GV1_BPSTART_MASK) >>
+			XSTC_GV1_BPSTART_SHIFT) - 1) <<
+			XSTC_GV1_BPSTART_SHIFT) |
+			((reg & XSTC_GV1_SYNCSTART_MASK) - 1);
+
+	xlnx_stc_writel(base, XSTC_GVSYNC_F0, reg);
+
+	/*
+	 * Fix the Vsync_vstart and vsync_vend of Field 1
+	 * for interlaced and 3GB modes.
+	 */
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED) {
+		if (vm->pixelclock == 148500000)
+			/* Revert and increase by 1 for 3GB mode */
+			reg = ((((reg & XSTC_GV1_BPSTART_MASK) >>
+				XSTC_GV1_BPSTART_SHIFT) + 2) <<
+				XSTC_GV1_BPSTART_SHIFT) |
+				((reg & XSTC_GV1_SYNCSTART_MASK) + 2);
+		else
+			/* Only revert the reduction */
+			reg = ((((reg & XSTC_GV1_BPSTART_MASK) >>
+				XSTC_GV1_BPSTART_SHIFT) + 1) <<
+				XSTC_GV1_BPSTART_SHIFT) |
+				((reg & XSTC_GV1_SYNCSTART_MASK) + 1);
+	}
+
+	hori_off.v0blank_hori_start = hactive;
+	hori_off.v0blank_hori_end = hactive;
+	hori_off.v0sync_hori_start = hsync_start;
+	hori_off.v0sync_hori_end = hsync_start;
+	hori_off.v1blank_hori_start = hactive;
+	hori_off.v1blank_hori_end = hactive;
+
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED) {
+		hori_off.v1sync_hori_start = hsync_start - (htotal / 2);
+		hori_off.v1sync_hori_end = hsync_start - (htotal / 2);
+		xlnx_stc_writel(base, XSTC_GVSYNC_F1, reg);
+		reg = xlnx_stc_readl(base, XSTC_GENC)
+				     | XSTC_GENC_INTERL;
+		xlnx_stc_writel(base, XSTC_GENC, reg);
+	} else {
+		hori_off.v1sync_hori_start = hsync_start;
+		hori_off.v1sync_hori_end = hsync_start;
+		reg = xlnx_stc_readl(base, XSTC_GENC)
+				     & ~XSTC_GENC_INTERL;
+		xlnx_stc_writel(base, XSTC_GENC, reg);
+	}
+
+	xlnx_stc_hori_off(base, &hori_off, vm->flags);
+	/* set up polarity */
+	memset(&polarity, 0x0, sizeof(polarity));
+	polarity.hsync = !!(vm->flags & DISPLAY_FLAGS_HSYNC_LOW);
+	polarity.vsync = !!(vm->flags & DISPLAY_FLAGS_VSYNC_LOW);
+	polarity.hblank = !!(vm->flags & DISPLAY_FLAGS_HSYNC_LOW);
+	polarity.vblank = !!(vm->flags & DISPLAY_FLAGS_VSYNC_LOW);
+	polarity.field_id = !!(vm->flags & DISPLAY_FLAGS_INTERLACED);
+	xlnx_stc_polarity(base, &polarity);
+
+	xlnx_stc_src(base);
+
+	reg = xlnx_stc_readl(base, XSTC_CTL);
+	xlnx_stc_writel(base, XSTC_CTL, reg | XSTC_CTL_RU);
+}
diff --git a/drivers/gpu/drm/xlnx/xlnx_sdi_timing.h b/drivers/gpu/drm/xlnx/xlnx_sdi_timing.h
new file mode 100644
index 000000000..e7950a44d
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_sdi_timing.h
@@ -0,0 +1,20 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Xilinx FPGA SDI Tx timing controller driver
+ *
+ * Copyright (c) 2017 Xilinx Pvt., Ltd
+ *
+ * Contacts: Saurabh Sengar <saurabhs@xilinx.com>
+ */
+
+#ifndef _XLNX_SDI_TIMING_H_
+#define _XLNX_SDI_TIMING_H_
+
+struct videomode;
+
+void xlnx_stc_enable(void __iomem *base);
+void xlnx_stc_disable(void __iomem *base);
+void xlnx_stc_reset(void __iomem *base);
+void xlnx_stc_sig(void __iomem *base, struct videomode *vm);
+
+#endif /* _XLNX_SDI_TIMING_H_ */
diff --git a/drivers/gpu/drm/xlnx/xlnx_vtc.c b/drivers/gpu/drm/xlnx/xlnx_vtc.c
new file mode 100644
index 000000000..a901a0e54
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/xlnx_vtc.c
@@ -0,0 +1,444 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Video Timing Controller support for Xilinx DRM KMS
+ *
+ * Copyright (C) 2013 - 2018 Xilinx, Inc.
+ *
+ * Author: Hyun Woo Kwon <hyunk@xilinx.com>
+ *	   Saurabh Sengar <saurabhs@xilinx.com>
+ *	   Vishal Sagar <vishal.sagar@xilinx.com>
+ *
+ * This driver adds support to control the Xilinx Video Timing
+ * Controller connected to the CRTC.
+ */
+
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <video/videomode.h>
+#include "xlnx_bridge.h"
+
+/* register offsets */
+#define XVTC_CTL		0x000
+#define XVTC_VER		0x010
+#define XVTC_GASIZE		0x060
+#define XVTC_GENC		0x068
+#define XVTC_GPOL		0x06c
+#define XVTC_GHSIZE		0x070
+#define XVTC_GVSIZE		0x074
+#define XVTC_GHSYNC		0x078
+#define XVTC_GVBHOFF_F0		0x07c
+#define XVTC_GVSYNC_F0		0x080
+#define XVTC_GVSHOFF_F0		0x084
+#define XVTC_GVBHOFF_F1		0x088
+#define XVTC_GVSYNC_F1		0x08C
+#define XVTC_GVSHOFF_F1		0x090
+#define XVTC_GASIZE_F1		0x094
+
+/* vtc control register bits */
+#define XVTC_CTL_SWRESET	BIT(31)
+#define XVTC_CTL_FIPSS		BIT(26)
+#define XVTC_CTL_ACPSS		BIT(25)
+#define XVTC_CTL_AVPSS		BIT(24)
+#define XVTC_CTL_HSPSS		BIT(23)
+#define XVTC_CTL_VSPSS		BIT(22)
+#define XVTC_CTL_HBPSS		BIT(21)
+#define XVTC_CTL_VBPSS		BIT(20)
+#define XVTC_CTL_VCSS		BIT(18)
+#define XVTC_CTL_VASS		BIT(17)
+#define XVTC_CTL_VBSS		BIT(16)
+#define XVTC_CTL_VSSS		BIT(15)
+#define XVTC_CTL_VFSS		BIT(14)
+#define XVTC_CTL_VTSS		BIT(13)
+#define XVTC_CTL_HBSS		BIT(11)
+#define XVTC_CTL_HSSS		BIT(10)
+#define XVTC_CTL_HFSS		BIT(9)
+#define XVTC_CTL_HTSS		BIT(8)
+#define XVTC_CTL_GE		BIT(2)
+#define XVTC_CTL_RU		BIT(1)
+
+/* vtc generator polarity register bits */
+#define XVTC_GPOL_FIP		BIT(6)
+#define XVTC_GPOL_ACP		BIT(5)
+#define XVTC_GPOL_AVP		BIT(4)
+#define XVTC_GPOL_HSP		BIT(3)
+#define XVTC_GPOL_VSP		BIT(2)
+#define XVTC_GPOL_HBP		BIT(1)
+#define XVTC_GPOL_VBP		BIT(0)
+
+/* vtc generator horizontal 1 */
+#define XVTC_GH1_BPSTART_MASK	GENMASK(28, 16)
+#define XVTC_GH1_BPSTART_SHIFT	16
+#define XVTC_GH1_SYNCSTART_MASK GENMASK(12, 0)
+/* vtc generator vertical 1 (field 0) */
+#define XVTC_GV1_BPSTART_MASK	GENMASK(28, 16)
+#define XVTC_GV1_BPSTART_SHIFT	16
+#define XVTC_GV1_SYNCSTART_MASK	GENMASK(12, 0)
+/* vtc generator/detector vblank/vsync horizontal offset registers */
+#define XVTC_XVXHOX_HEND_MASK	GENMASK(28, 16)
+#define XVTC_XVXHOX_HEND_SHIFT	16
+#define XVTC_XVXHOX_HSTART_MASK	GENMASK(12, 0)
+
+#define XVTC_GHFRAME_HSIZE	GENMASK(12, 0)
+#define XVTC_GVFRAME_HSIZE_F1	GENMASK(12, 0)
+#define XVTC_GA_ACTSIZE_MASK	GENMASK(12, 0)
+
+/* vtc generator encoding register bits */
+#define XVTC_GENC_INTERL	BIT(6)
+
+/**
+ * struct xlnx_vtc - Xilinx VTC object
+ *
+ * @bridge: xilinx bridge structure
+ * @dev: device structure
+ * @base: base addr
+ * @ppc: pixels per clock
+ * @axi_clk: AXI Lite clock
+ * @vid_clk: Video clock
+ */
+struct xlnx_vtc {
+	struct xlnx_bridge bridge;
+	struct device *dev;
+	void __iomem *base;
+	u32 ppc;
+	struct clk *axi_clk;
+	struct clk *vid_clk;
+};
+
+static inline void xlnx_vtc_writel(void __iomem *base, int offset, u32 val)
+{
+	writel(val, base + offset);
+}
+
+static inline u32 xlnx_vtc_readl(void __iomem *base, int offset)
+{
+	return readl(base + offset);
+}
+
+static inline struct xlnx_vtc *bridge_to_vtc(struct xlnx_bridge *bridge)
+{
+	return container_of(bridge, struct xlnx_vtc, bridge);
+}
+
+static void xlnx_vtc_reset(struct xlnx_vtc *vtc)
+{
+	u32 reg;
+
+	xlnx_vtc_writel(vtc->base, XVTC_CTL, XVTC_CTL_SWRESET);
+
+	/* enable register update */
+	reg = xlnx_vtc_readl(vtc->base, XVTC_CTL);
+	xlnx_vtc_writel(vtc->base, XVTC_CTL, reg | XVTC_CTL_RU);
+}
+
+/**
+ * xlnx_vtc_enable - Enable the VTC
+ * @bridge: xilinx bridge structure pointer
+ *
+ * Return:
+ * Zero on success.
+ *
+ * This function enables the VTC
+ */
+static int xlnx_vtc_enable(struct xlnx_bridge *bridge)
+{
+	u32 reg;
+	struct xlnx_vtc *vtc = bridge_to_vtc(bridge);
+
+	/* enable generator */
+	reg = xlnx_vtc_readl(vtc->base, XVTC_CTL);
+	xlnx_vtc_writel(vtc->base, XVTC_CTL, reg | XVTC_CTL_GE);
+	dev_dbg(vtc->dev, "enabled\n");
+	return 0;
+}
+
+/**
+ * xlnx_vtc_disable - Disable the VTC
+ * @bridge: xilinx bridge structure pointer
+ *
+ * This function disables and resets the VTC.
+ */
+static void xlnx_vtc_disable(struct xlnx_bridge *bridge)
+{
+	u32 reg;
+	struct xlnx_vtc *vtc = bridge_to_vtc(bridge);
+
+	/* disable generator and reset */
+	reg = xlnx_vtc_readl(vtc->base, XVTC_CTL);
+	xlnx_vtc_writel(vtc->base, XVTC_CTL, reg & ~XVTC_CTL_GE);
+	xlnx_vtc_reset(vtc);
+	dev_dbg(vtc->dev, "disabled\n");
+}
+
+/**
+ * xlnx_vtc_set_timing - Configures the VTC
+ * @bridge: xilinx bridge structure pointer
+ * @vm: video mode requested
+ *
+ * Return:
+ * Zero on success.
+ *
+ * This function calculates the timing values from the video mode
+ * structure passed from the CRTC and configures the VTC.
+ */
+static int xlnx_vtc_set_timing(struct xlnx_bridge *bridge,
+			       struct videomode *vm)
+{
+	u32 reg;
+	u32 htotal, hactive, hsync_start, hbackporch_start;
+	u32 vtotal, vactive, vsync_start, vbackporch_start;
+	struct xlnx_vtc *vtc = bridge_to_vtc(bridge);
+
+	reg = xlnx_vtc_readl(vtc->base, XVTC_CTL);
+	xlnx_vtc_writel(vtc->base, XVTC_CTL, reg & ~XVTC_CTL_RU);
+
+	vm->hactive /= vtc->ppc;
+	vm->hfront_porch /= vtc->ppc;
+	vm->hback_porch /= vtc->ppc;
+	vm->hsync_len /= vtc->ppc;
+
+	htotal = vm->hactive + vm->hfront_porch + vm->hsync_len +
+		 vm->hback_porch;
+	vtotal = vm->vactive + vm->vfront_porch + vm->vsync_len +
+		 vm->vback_porch;
+
+	hactive = vm->hactive;
+	vactive = vm->vactive;
+
+	hsync_start = vm->hactive + vm->hfront_porch;
+	vsync_start = vm->vactive + vm->vfront_porch;
+
+	hbackporch_start = hsync_start + vm->hsync_len;
+	vbackporch_start = vsync_start + vm->vsync_len;
+
+	dev_dbg(vtc->dev, "ha: %d, va: %d\n", hactive, vactive);
+	dev_dbg(vtc->dev, "ht: %d, vt: %d\n", htotal, vtotal);
+	dev_dbg(vtc->dev, "hs: %d, hb: %d\n", hsync_start, hbackporch_start);
+	dev_dbg(vtc->dev, "vs: %d, vb: %d\n", vsync_start, vbackporch_start);
+
+	reg = htotal & XVTC_GHFRAME_HSIZE;
+	xlnx_vtc_writel(vtc->base, XVTC_GHSIZE, reg);
+
+	reg = vtotal & XVTC_GVFRAME_HSIZE_F1;
+	reg |= reg << XVTC_GV1_BPSTART_SHIFT;
+	xlnx_vtc_writel(vtc->base, XVTC_GVSIZE, reg);
+
+	reg = hactive & XVTC_GA_ACTSIZE_MASK;
+	reg |= (vactive & XVTC_GA_ACTSIZE_MASK) << 16;
+	xlnx_vtc_writel(vtc->base, XVTC_GASIZE, reg);
+
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED)
+		xlnx_vtc_writel(vtc->base, XVTC_GASIZE_F1, reg);
+
+	reg = hsync_start & XVTC_GH1_SYNCSTART_MASK;
+	reg |= (hbackporch_start << XVTC_GH1_BPSTART_SHIFT) &
+	       XVTC_GH1_BPSTART_MASK;
+	xlnx_vtc_writel(vtc->base, XVTC_GHSYNC, reg);
+
+	reg = vsync_start & XVTC_GV1_SYNCSTART_MASK;
+	reg |= (vbackporch_start << XVTC_GV1_BPSTART_SHIFT) &
+	       XVTC_GV1_BPSTART_MASK;
+	xlnx_vtc_writel(vtc->base, XVTC_GVSYNC_F0, reg);
+
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED) {
+		xlnx_vtc_writel(vtc->base, XVTC_GVSYNC_F1, reg);
+		reg = xlnx_vtc_readl(vtc->base, XVTC_GENC) | XVTC_GENC_INTERL;
+		xlnx_vtc_writel(vtc->base, XVTC_GENC, reg);
+	} else {
+		reg = xlnx_vtc_readl(vtc->base, XVTC_GENC) & ~XVTC_GENC_INTERL;
+		xlnx_vtc_writel(vtc->base, XVTC_GENC, reg);
+	}
+
+	/* configure horizontal offset */
+	/* Calculate and update Generator VBlank Hori field 0 */
+	reg = hactive & XVTC_XVXHOX_HSTART_MASK;
+	reg |= (hactive << XVTC_XVXHOX_HEND_SHIFT) &
+		XVTC_XVXHOX_HEND_MASK;
+	xlnx_vtc_writel(vtc->base, XVTC_GVBHOFF_F0, reg);
+
+	/* Calculate and update Generator VSync Hori field 0 */
+	reg = hsync_start & XVTC_XVXHOX_HSTART_MASK;
+	reg |= (hsync_start << XVTC_XVXHOX_HEND_SHIFT) &
+		XVTC_XVXHOX_HEND_MASK;
+	xlnx_vtc_writel(vtc->base, XVTC_GVSHOFF_F0, reg);
+
+	/* Calculate and update Generator VBlank Hori field 1 */
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED) {
+		reg = hactive & XVTC_XVXHOX_HSTART_MASK;
+		reg |= (hactive << XVTC_XVXHOX_HEND_SHIFT) &
+			XVTC_XVXHOX_HEND_MASK;
+		xlnx_vtc_writel(vtc->base, XVTC_GVBHOFF_F1, reg);
+	}
+
+	/* Calculate and update Generator VBlank Hori field 1 */
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED) {
+		reg =  (hsync_start - (htotal / 2)) & XVTC_XVXHOX_HSTART_MASK;
+		reg |= ((hsync_start - (htotal / 2)) <<
+			XVTC_XVXHOX_HEND_SHIFT) & XVTC_XVXHOX_HEND_MASK;
+	} else {
+		reg =  hsync_start & XVTC_XVXHOX_HSTART_MASK;
+		reg |= (hsync_start << XVTC_XVXHOX_HEND_SHIFT) &
+			XVTC_XVXHOX_HEND_MASK;
+	}
+
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED)
+		xlnx_vtc_writel(vtc->base, XVTC_GVSHOFF_F1, reg);
+
+	/* configure polarity of signals */
+	reg = 0;
+	reg |= XVTC_GPOL_ACP;
+	reg |= XVTC_GPOL_AVP;
+	if (vm->flags & DISPLAY_FLAGS_INTERLACED)
+		reg |= XVTC_GPOL_FIP;
+	if (vm->flags & DISPLAY_FLAGS_VSYNC_HIGH) {
+		reg |= XVTC_GPOL_VBP;
+		reg |= XVTC_GPOL_VSP;
+	}
+	if (vm->flags & DISPLAY_FLAGS_HSYNC_HIGH) {
+		reg |= XVTC_GPOL_HBP;
+		reg |= XVTC_GPOL_HSP;
+	}
+	xlnx_vtc_writel(vtc->base, XVTC_GPOL, reg);
+
+	/* configure timing source */
+	reg = xlnx_vtc_readl(vtc->base, XVTC_CTL);
+	reg |= XVTC_CTL_VCSS;
+	reg |= XVTC_CTL_VASS;
+	reg |= XVTC_CTL_VBSS;
+	reg |= XVTC_CTL_VSSS;
+	reg |= XVTC_CTL_VFSS;
+	reg |= XVTC_CTL_VTSS;
+	reg |= XVTC_CTL_HBSS;
+	reg |= XVTC_CTL_HSSS;
+	reg |= XVTC_CTL_HFSS;
+	reg |= XVTC_CTL_HTSS;
+	xlnx_vtc_writel(vtc->base, XVTC_CTL, reg);
+
+	reg = xlnx_vtc_readl(vtc->base, XVTC_CTL);
+	xlnx_vtc_writel(vtc->base, XVTC_CTL, reg | XVTC_CTL_RU);
+	dev_dbg(vtc->dev, "set timing done\n");
+
+	return 0;
+}
+
+static int xlnx_vtc_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct xlnx_vtc *vtc;
+	struct resource *res;
+	int ret;
+
+	vtc = devm_kzalloc(dev, sizeof(*vtc), GFP_KERNEL);
+	if (!vtc)
+		return -ENOMEM;
+
+	vtc->dev = dev;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(dev, "failed to get resource for device\n");
+		return -EFAULT;
+	}
+
+	vtc->base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(vtc->base)) {
+		dev_err(dev, "failed to remap io region\n");
+		return PTR_ERR(vtc->base);
+	}
+
+	platform_set_drvdata(pdev, vtc);
+
+	ret = of_property_read_u32(dev->of_node, "xlnx,pixels-per-clock",
+				   &vtc->ppc);
+	if (ret || (vtc->ppc != 1 && vtc->ppc != 2 && vtc->ppc != 4)) {
+		dev_err(dev, "failed to get ppc\n");
+		return ret;
+	}
+	dev_info(dev, "vtc ppc = %d\n", vtc->ppc);
+
+	vtc->axi_clk = devm_clk_get(vtc->dev, "s_axi_aclk");
+	if (IS_ERR(vtc->axi_clk)) {
+		ret = PTR_ERR(vtc->axi_clk);
+		dev_err(dev, "failed to get axi lite clk %d\n", ret);
+		return ret;
+	}
+
+	vtc->vid_clk = devm_clk_get(vtc->dev, "clk");
+	if (IS_ERR(vtc->vid_clk)) {
+		ret = PTR_ERR(vtc->vid_clk);
+		dev_err(dev, "failed to get video clk %d\n", ret);
+		return ret;
+	}
+
+	ret = clk_prepare_enable(vtc->axi_clk);
+	if (ret) {
+		dev_err(vtc->dev, "unable to enable axilite clk %d\n", ret);
+		return ret;
+	}
+
+	ret = clk_prepare_enable(vtc->vid_clk);
+	if (ret) {
+		dev_err(vtc->dev, "unable to enable video clk %d\n", ret);
+		goto err_axi_clk;
+	}
+
+	xlnx_vtc_reset(vtc);
+
+	vtc->bridge.enable = &xlnx_vtc_enable;
+	vtc->bridge.disable = &xlnx_vtc_disable;
+	vtc->bridge.set_timing = &xlnx_vtc_set_timing;
+	vtc->bridge.of_node = dev->of_node;
+	ret = xlnx_bridge_register(&vtc->bridge);
+	if (ret) {
+		dev_err(dev, "Bridge registration failed\n");
+		goto err_vid_clk;
+	}
+
+	dev_info(dev, "Xilinx VTC IP version : 0x%08x\n",
+		 xlnx_vtc_readl(vtc->base, XVTC_VER));
+	dev_info(dev, "Xilinx VTC DRM Bridge driver probed\n");
+	return 0;
+
+err_vid_clk:
+	clk_disable_unprepare(vtc->vid_clk);
+err_axi_clk:
+	clk_disable_unprepare(vtc->axi_clk);
+	return ret;
+}
+
+static void xlnx_vtc_remove(struct platform_device *pdev)
+{
+	struct xlnx_vtc *vtc = platform_get_drvdata(pdev);
+
+	xlnx_bridge_unregister(&vtc->bridge);
+	clk_disable_unprepare(vtc->vid_clk);
+	clk_disable_unprepare(vtc->axi_clk);
+}
+
+static const struct of_device_id xlnx_vtc_of_match[] = {
+	{ .compatible = "xlnx,bridge-v-tc-6.1" },
+	{ /* end of table */ },
+};
+
+MODULE_DEVICE_TABLE(of, xlnx_vtc_of_match);
+
+static struct platform_driver xlnx_vtc_bridge_driver = {
+	.probe = xlnx_vtc_probe,
+	.remove = xlnx_vtc_remove,
+	.driver = {
+		.name = "xlnx,bridge-vtc",
+		.of_match_table = xlnx_vtc_of_match,
+	},
+};
+
+module_platform_driver(xlnx_vtc_bridge_driver);
+
+MODULE_AUTHOR("Vishal Sagar");
+MODULE_DESCRIPTION("Xilinx VTC Bridge Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpu/drm/xlnx/zynqmp_disp.c b/drivers/gpu/drm/xlnx/zynqmp_disp.c
index e4e0e299e..a3b536329 100644
--- a/drivers/gpu/drm/xlnx/zynqmp_disp.c
+++ b/drivers/gpu/drm/xlnx/zynqmp_disp.c
@@ -143,7 +143,6 @@ struct zynqmp_disp_layer {
  * @dpsub: Display subsystem
  * @blend: Register I/O base address for the blender
  * @avbuf: Register I/O base address for the audio/video buffer manager
- * @audio: Registers I/O base address for the audio mixer
  * @layers: Layers (planes)
  */
 struct zynqmp_disp {
@@ -152,7 +151,6 @@ struct zynqmp_disp {
 
 	void __iomem *blend;
 	void __iomem *avbuf;
-	void __iomem *audio;
 
 	struct zynqmp_disp_layer layers[ZYNQMP_DPSUB_NUM_LAYERS];
 };
@@ -299,6 +297,31 @@ static const struct zynqmp_disp_format avbuf_vid_fmts[] = {
 		.buf_fmt	= ZYNQMP_DISP_AV_BUF_FMT_NL_VID_YV16CI_420,
 		.swap		= true,
 		.sf		= scaling_factors_888,
+	}, {
+		.drm_fmt	= DRM_FORMAT_XV15,
+		.buf_fmt	= ZYNQMP_DISP_AV_BUF_FMT_NL_VID_YV16CI_420_10,
+		.swap		= false,
+		.sf		= scaling_factors_101010,
+	}, {
+		.drm_fmt	= DRM_FORMAT_XV20,
+		.buf_fmt	= ZYNQMP_DISP_AV_BUF_FMT_NL_VID_YV16CI_10,
+		.swap		= false,
+		.sf		= scaling_factors_101010,
+	}, {
+		.drm_fmt	= DRM_FORMAT_Y8,
+		.buf_fmt	= ZYNQMP_DISP_AV_BUF_FMT_NL_VID_MONO,
+		.swap		= false,
+		.sf		= scaling_factors_888,
+	}, {
+		.drm_fmt	= DRM_FORMAT_Y10_LE32,
+		.buf_fmt	= ZYNQMP_DISP_AV_BUF_FMT_NL_VID_YONLY_10,
+		.swap		= false,
+		.sf		= scaling_factors_101010,
+	}, {
+		.drm_fmt	= DRM_FORMAT_X403,
+		.buf_fmt	= ZYNQMP_DISP_AV_BUF_FMT_NL_VID_YV24_10,
+		.swap		= false,
+		.sf		= scaling_factors_101010,
 	},
 };
 
@@ -689,6 +712,16 @@ static const u32 csc_sdtv_to_rgb_offsets[] = {
 	0x0, 0x1800, 0x1800
 };
 
+static const u16 csc_sdtv_to_rgb_yonly_matrix[] = {
+	0x0, 0x0, 0x1000,
+	0x0, 0x0, 0x1000,
+	0x0, 0x0, 0x1000,
+};
+
+static const u32 csc_sdtv_to_rgb_yonly_offsets[] = {
+	0x1800, 0x1800, 0x0
+};
+
 /**
  * zynqmp_disp_blend_set_output_format - Set the output format of the blender
  * @disp: Display controller
@@ -838,7 +871,11 @@ static void zynqmp_disp_blend_layer_enable(struct zynqmp_disp *disp,
 				ZYNQMP_DISP_V_BLEND_LAYER_CONTROL(layer->id),
 				val);
 
-	if (layer->drm_fmt->is_yuv) {
+	if (layer->drm_fmt->format == DRM_FORMAT_Y8 ||
+	    layer->drm_fmt->format == DRM_FORMAT_Y10_LE32) {
+		coeffs = csc_sdtv_to_rgb_yonly_matrix;
+		offsets = csc_sdtv_to_rgb_yonly_offsets;
+	} else if (layer->drm_fmt->is_yuv) {
 		coeffs = csc_sdtv_to_rgb_matrix;
 		offsets = csc_sdtv_to_rgb_offsets;
 	} else {
@@ -865,42 +902,6 @@ static void zynqmp_disp_blend_layer_disable(struct zynqmp_disp *disp,
 					csc_zero_offsets);
 }
 
-/* -----------------------------------------------------------------------------
- * Audio Mixer
- */
-
-static void zynqmp_disp_audio_write(struct zynqmp_disp *disp, int reg, u32 val)
-{
-	writel(val, disp->audio + reg);
-}
-
-/**
- * zynqmp_disp_audio_enable - Enable the audio mixer
- * @disp: Display controller
- *
- * Enable the audio mixer by de-asserting the soft reset. The audio state is set to
- * default values by the reset, set the default mixer volume explicitly.
- */
-static void zynqmp_disp_audio_enable(struct zynqmp_disp *disp)
-{
-	/* Clear the audio soft reset register as it's an non-reset flop. */
-	zynqmp_disp_audio_write(disp, ZYNQMP_DISP_AUD_SOFT_RESET, 0);
-	zynqmp_disp_audio_write(disp, ZYNQMP_DISP_AUD_MIXER_VOLUME,
-				ZYNQMP_DISP_AUD_MIXER_VOLUME_NO_SCALE);
-}
-
-/**
- * zynqmp_disp_audio_disable - Disable the audio mixer
- * @disp: Display controller
- *
- * Disable the audio mixer by asserting its soft reset.
- */
-static void zynqmp_disp_audio_disable(struct zynqmp_disp *disp)
-{
-	zynqmp_disp_audio_write(disp, ZYNQMP_DISP_AUD_SOFT_RESET,
-				ZYNQMP_DISP_AUD_SOFT_RESET_AUD_SRST);
-}
-
 /* -----------------------------------------------------------------------------
  * ZynqMP Display Layer & DRM Plane
  */
@@ -1154,16 +1155,18 @@ int zynqmp_disp_layer_update(struct zynqmp_disp_layer *layer,
 		return 0;
 
 	for (i = 0; i < info->num_planes; i++) {
-		unsigned int width = state->crtc_w / (i ? info->hsub : 1);
-		unsigned int height = state->crtc_h / (i ? info->vsub : 1);
 		struct zynqmp_disp_layer_dma *dma = &layer->dmas[i];
 		struct dma_async_tx_descriptor *desc;
+		unsigned int width, height;
 		dma_addr_t dma_addr;
 
+		width = drm_format_info_plane_width(info, state->crtc_w, i);
+		height = drm_format_info_plane_height(info, state->crtc_h, i);
+
 		dma_addr = drm_fb_dma_get_gem_addr(state->fb, state, i);
 
 		dma->xt.numf = height;
-		dma->sgl.size = width * info->cpp[i];
+		dma->sgl.size = drm_format_info_min_pitch(info, i, width);
 		dma->sgl.icg = state->fb->pitches[i] - dma->sgl.size;
 		dma->xt.src_start = dma_addr;
 		dma->xt.frame_size = 1;
@@ -1341,8 +1344,6 @@ void zynqmp_disp_enable(struct zynqmp_disp *disp)
 					     disp->dpsub->vid_clk_from_ps);
 	zynqmp_disp_avbuf_enable_channels(disp);
 	zynqmp_disp_avbuf_enable_audio(disp);
-
-	zynqmp_disp_audio_enable(disp);
 }
 
 /**
@@ -1351,8 +1352,6 @@ void zynqmp_disp_enable(struct zynqmp_disp *disp)
  */
 void zynqmp_disp_disable(struct zynqmp_disp *disp)
 {
-	zynqmp_disp_audio_disable(disp);
-
 	zynqmp_disp_avbuf_disable_audio(disp);
 	zynqmp_disp_avbuf_disable_channels(disp);
 	zynqmp_disp_avbuf_disable(disp);
@@ -1421,12 +1420,6 @@ int zynqmp_disp_probe(struct zynqmp_dpsub *dpsub)
 		goto error;
 	}
 
-	disp->audio = devm_platform_ioremap_resource_byname(pdev, "aud");
-	if (IS_ERR(disp->audio)) {
-		ret = PTR_ERR(disp->audio);
-		goto error;
-	}
-
 	ret = zynqmp_disp_create_layers(disp);
 	if (ret)
 		goto error;
diff --git a/drivers/gpu/drm/xlnx/zynqmp_disp.h b/drivers/gpu/drm/xlnx/zynqmp_disp.h
index fa545533c..026e97375 100644
--- a/drivers/gpu/drm/xlnx/zynqmp_disp.h
+++ b/drivers/gpu/drm/xlnx/zynqmp_disp.h
@@ -19,7 +19,7 @@
  * resolutions under a 300Mhz pixel rate would work. Pick 4096x4096.
  */
 #define ZYNQMP_DISP_MAX_WIDTH				4096
-#define ZYNQMP_DISP_MAX_HEIGHT				4096
+#define ZYNQMP_DISP_MAX_HEIGHT				8192
 
 /* The DPDMA is limited to 44 bit addressing. */
 #define ZYNQMP_DISP_MAX_DMA_BIT				44
diff --git a/drivers/gpu/drm/xlnx/zynqmp_disp_regs.h b/drivers/gpu/drm/xlnx/zynqmp_disp_regs.h
index fa3935384..9a4ff094e 100644
--- a/drivers/gpu/drm/xlnx/zynqmp_disp_regs.h
+++ b/drivers/gpu/drm/xlnx/zynqmp_disp_regs.h
@@ -177,12 +177,7 @@
 #define ZYNQMP_DISP_AUD_MIXER_VOLUME			0x0
 #define ZYNQMP_DISP_AUD_MIXER_VOLUME_NO_SCALE		0x20002000
 #define ZYNQMP_DISP_AUD_MIXER_META_DATA			0x4
-#define ZYNQMP_DISP_AUD_CH_STATUS0			0x8
-#define ZYNQMP_DISP_AUD_CH_STATUS1			0xc
-#define ZYNQMP_DISP_AUD_CH_STATUS2			0x10
-#define ZYNQMP_DISP_AUD_CH_STATUS3			0x14
-#define ZYNQMP_DISP_AUD_CH_STATUS4			0x18
-#define ZYNQMP_DISP_AUD_CH_STATUS5			0x1c
+#define ZYNQMP_DISP_AUD_CH_STATUS(x)			(0x8 + ((x) * 4))
 #define ZYNQMP_DISP_AUD_CH_A_DATA0			0x20
 #define ZYNQMP_DISP_AUD_CH_A_DATA1			0x24
 #define ZYNQMP_DISP_AUD_CH_A_DATA2			0x28
diff --git a/drivers/gpu/drm/xlnx/zynqmp_dp.c b/drivers/gpu/drm/xlnx/zynqmp_dp.c
index 129beac4c..8b72460cb 100644
--- a/drivers/gpu/drm/xlnx/zynqmp_dp.c
+++ b/drivers/gpu/drm/xlnx/zynqmp_dp.c
@@ -18,7 +18,9 @@
 #include <drm/drm_modes.h>
 #include <drm/drm_of.h>
 
+#include <linux/bitfield.h>
 #include <linux/clk.h>
+#include <linux/debugfs.h>
 #include <linux/delay.h>
 #include <linux/device.h>
 #include <linux/io.h>
@@ -51,6 +53,7 @@ MODULE_PARM_DESC(power_on_delay_ms, "DP power on delay in msec (default: 4)");
 #define ZYNQMP_DP_LANE_COUNT_SET			0x4
 #define ZYNQMP_DP_ENHANCED_FRAME_EN			0x8
 #define ZYNQMP_DP_TRAINING_PATTERN_SET			0xc
+#define ZYNQMP_DP_LINK_QUAL_PATTERN_SET			0x10
 #define ZYNQMP_DP_SCRAMBLING_DISABLE			0x14
 #define ZYNQMP_DP_DOWNSPREAD_CTL			0x18
 #define ZYNQMP_DP_SOFTWARE_RESET			0x1c
@@ -64,6 +67,9 @@ MODULE_PARM_DESC(power_on_delay_ms, "DP power on delay in msec (default: 4)");
 							 ZYNQMP_DP_SOFTWARE_RESET_STREAM3 | \
 							 ZYNQMP_DP_SOFTWARE_RESET_STREAM4 | \
 							 ZYNQMP_DP_SOFTWARE_RESET_AUX)
+#define ZYNQMP_DP_COMP_PATTERN_80BIT_1			0x20
+#define ZYNQMP_DP_COMP_PATTERN_80BIT_2			0x24
+#define ZYNQMP_DP_COMP_PATTERN_80BIT_3			0x28
 
 /* Core enable registers */
 #define ZYNQMP_DP_TRANSMITTER_ENABLE			0x80
@@ -207,6 +213,7 @@ MODULE_PARM_DESC(power_on_delay_ms, "DP power on delay in msec (default: 4)");
 #define ZYNQMP_DP_TX_PHY_POWER_DOWN_LANE_2		BIT(2)
 #define ZYNQMP_DP_TX_PHY_POWER_DOWN_LANE_3		BIT(3)
 #define ZYNQMP_DP_TX_PHY_POWER_DOWN_ALL			0xf
+#define ZYNQMP_DP_TRANSMIT_PRBS7			0x230
 #define ZYNQMP_DP_PHY_PRECURSOR_LANE_0			0x23c
 #define ZYNQMP_DP_PHY_PRECURSOR_LANE_1			0x240
 #define ZYNQMP_DP_PHY_PRECURSOR_LANE_2			0x244
@@ -274,31 +281,109 @@ struct zynqmp_dp_config {
 	u8 bpp;
 };
 
+/**
+ * enum test_pattern - Test patterns for test testing
+ * @TEST_VIDEO: Use regular video input
+ * @TEST_SYMBOL_ERROR: Symbol error measurement pattern
+ * @TEST_PRBS7: Output of the PRBS7 (x^7 + x^6 + 1) polynomial
+ * @TEST_80BIT_CUSTOM: A custom 80-bit pattern
+ * @TEST_CP2520: HBR2 compliance eye pattern
+ * @TEST_TPS1: Link training symbol pattern TPS1 (/D10.2/)
+ * @TEST_TPS2: Link training symbol pattern TPS2
+ * @TEST_TPS3: Link training symbol pattern TPS3 (for HBR2)
+ */
+enum test_pattern {
+	TEST_VIDEO,
+	TEST_TPS1,
+	TEST_TPS2,
+	TEST_TPS3,
+	TEST_SYMBOL_ERROR,
+	TEST_PRBS7,
+	TEST_80BIT_CUSTOM,
+	TEST_CP2520,
+};
+
+static const char *const test_pattern_str[] = {
+	[TEST_VIDEO] = "video",
+	[TEST_TPS1] = "tps1",
+	[TEST_TPS2] = "tps2",
+	[TEST_TPS3] = "tps3",
+	[TEST_SYMBOL_ERROR] = "symbol-error",
+	[TEST_PRBS7] = "prbs7",
+	[TEST_80BIT_CUSTOM] = "80bit-custom",
+	[TEST_CP2520] = "cp2520",
+};
+
+/**
+ * struct zynqmp_dp_test - Configuration for test mode
+ * @pattern: The test pattern
+ * @enhanced: Use enhanced framing
+ * @downspread: Use SSC
+ * @active: Whether test mode is active
+ * @custom: Custom pattern for %TEST_80BIT_CUSTOM
+ * @train_set: Voltage/preemphasis settings
+ * @bw_code: Bandwidth code for the link
+ * @link_cnt: Number of lanes
+ */
+struct zynqmp_dp_test {
+	enum test_pattern pattern;
+	bool enhanced, downspread, active;
+	u8 custom[10];
+	u8 train_set[ZYNQMP_DP_MAX_LANES];
+	u8 bw_code;
+	u8 link_cnt;
+};
+
+/**
+ * struct zynqmp_dp_train_set_priv - Private data for train_set debugfs files
+ * @dp: DisplayPort IP core structure
+ * @lane: The lane for this file
+ */
+struct zynqmp_dp_train_set_priv {
+	struct zynqmp_dp *dp;
+	int lane;
+};
+
 /**
  * struct zynqmp_dp - Xilinx DisplayPort core
  * @dev: device structure
  * @dpsub: Display subsystem
  * @iomem: device I/O memory for register access
  * @reset: reset controller
+ * @lock: Mutex protecting this struct and register access (but not AUX)
  * @irq: irq
  * @bridge: DRM bridge for the DP encoder
  * @next_bridge: The downstream bridge
+ * @test: Configuration for test mode
  * @config: IP core configuration from DTS
  * @aux: aux channel
+ * @aux_done: Completed when we get an AUX reply or timeout
+ * @ignore_aux_errors: If set, AUX errors are suppressed
  * @phy: PHY handles for DP lanes
  * @num_lanes: number of enabled phy lanes
  * @hpd_work: hot plug detection worker
+ * @hpd_irq_work: hot plug detection IRQ worker
+ * @ignore_hpd: If set, HPD events and IRQs are ignored
  * @status: connection status
  * @enabled: flag to indicate if the device is enabled
  * @dpcd: DP configuration data from currently connected sink device
  * @link_config: common link configuration between IP core and sink device
  * @mode: current mode between IP core and sink device
  * @train_set: set of training data
+ * @debugfs_train_set: Debugfs private data for @train_set
+ *
+ * @lock covers the link configuration in this struct and the device's
+ * registers. It does not cover @aux or @ignore_aux_errors. It is not strictly
+ * required for any of the members which are only modified at probe/remove time
+ * (e.g. @dev).
  */
 struct zynqmp_dp {
 	struct drm_dp_aux aux;
 	struct drm_bridge bridge;
 	struct work_struct hpd_work;
+	struct work_struct hpd_irq_work;
+	struct completion aux_done;
+	struct mutex lock;
 
 	struct drm_bridge *next_bridge;
 	struct device *dev;
@@ -310,9 +395,13 @@ struct zynqmp_dp {
 	enum drm_connector_status status;
 	int irq;
 	bool enabled;
+	bool ignore_aux_errors;
+	bool ignore_hpd;
 
+	struct zynqmp_dp_train_set_priv debugfs_train_set[ZYNQMP_DP_MAX_LANES];
 	struct zynqmp_dp_mode mode;
 	struct zynqmp_dp_link_config link_config;
+	struct zynqmp_dp_test test;
 	struct zynqmp_dp_config config;
 	u8 dpcd[DP_RECEIVER_CAP_SIZE];
 	u8 train_set[ZYNQMP_DP_MAX_LANES];
@@ -383,7 +472,7 @@ static int zynqmp_dp_reset(struct zynqmp_dp *dp, bool assert)
  * Return: 0 if the phy instances are initialized correctly, or the error code
  * returned from the callee functions.
  */
-static int zynqmp_dp_phy_init(struct zynqmp_dp *dp)
+int zynqmp_dp_phy_init(struct zynqmp_dp *dp)
 {
 	int ret;
 	int i;
@@ -419,7 +508,7 @@ static int zynqmp_dp_phy_init(struct zynqmp_dp *dp)
  *
  * Exit the phy.
  */
-static void zynqmp_dp_phy_exit(struct zynqmp_dp *dp)
+void zynqmp_dp_phy_exit(struct zynqmp_dp *dp)
 {
 	unsigned int i;
 	int ret;
@@ -626,6 +715,7 @@ static void zynqmp_dp_adjust_train(struct zynqmp_dp *dp,
 /**
  * zynqmp_dp_update_vs_emph - Update the training values
  * @dp: DisplayPort IP core structure
+ * @train_set: A set of training values
  *
  * Update the training values based on the request from sink. The mapped values
  * are predefined, and values(vs, pe, pc) are from the device manual.
@@ -633,12 +723,12 @@ static void zynqmp_dp_adjust_train(struct zynqmp_dp *dp,
  * Return: 0 if vs and emph are updated successfully, or the error code returned
  * by drm_dp_dpcd_write().
  */
-static int zynqmp_dp_update_vs_emph(struct zynqmp_dp *dp)
+static int zynqmp_dp_update_vs_emph(struct zynqmp_dp *dp, u8 *train_set)
 {
 	unsigned int i;
 	int ret;
 
-	ret = drm_dp_dpcd_write(&dp->aux, DP_TRAINING_LANE0_SET, dp->train_set,
+	ret = drm_dp_dpcd_write(&dp->aux, DP_TRAINING_LANE0_SET, train_set,
 				dp->mode.lane_cnt);
 	if (ret < 0)
 		return ret;
@@ -646,7 +736,7 @@ static int zynqmp_dp_update_vs_emph(struct zynqmp_dp *dp)
 	for (i = 0; i < dp->mode.lane_cnt; i++) {
 		u32 reg = ZYNQMP_DP_SUB_TX_PHY_PRECURSOR_LANE_0 + i * 4;
 		union phy_configure_opts opts = { 0 };
-		u8 train = dp->train_set[i];
+		u8 train = train_set[i];
 
 		opts.dp.voltage[0] = (train & DP_TRAIN_VOLTAGE_SWING_MASK)
 				   >> DP_TRAIN_VOLTAGE_SWING_SHIFT;
@@ -690,7 +780,7 @@ static int zynqmp_dp_link_train_cr(struct zynqmp_dp *dp)
 	 * So, This loop should exit before 512 iterations
 	 */
 	for (max_tries = 0; max_tries < 512; max_tries++) {
-		ret = zynqmp_dp_update_vs_emph(dp);
+		ret = zynqmp_dp_update_vs_emph(dp, dp->train_set);
 		if (ret)
 			return ret;
 
@@ -755,7 +845,7 @@ static int zynqmp_dp_link_train_ce(struct zynqmp_dp *dp)
 		return ret;
 
 	for (tries = 0; tries < DP_MAX_TRAINING_TRIES; tries++) {
-		ret = zynqmp_dp_update_vs_emph(dp);
+		ret = zynqmp_dp_update_vs_emph(dp, dp->train_set);
 		if (ret)
 			return ret;
 
@@ -778,28 +868,29 @@ static int zynqmp_dp_link_train_ce(struct zynqmp_dp *dp)
 }
 
 /**
- * zynqmp_dp_train - Train the link
+ * zynqmp_dp_setup() - Set up major link parameters
  * @dp: DisplayPort IP core structure
+ * @bw_code: The link bandwidth as a multiple of 270 MHz
+ * @lane_cnt: The number of lanes to use
+ * @enhanced: Use enhanced framing
+ * @downspread: Enable spread-spectrum clocking
  *
- * Return: 0 if all trains are done successfully, or corresponding error code.
+ * Return: 0 on success, or -errno on failure
  */
-static int zynqmp_dp_train(struct zynqmp_dp *dp)
+static int zynqmp_dp_setup(struct zynqmp_dp *dp, u8 bw_code, u8 lane_cnt,
+			   bool enhanced, bool downspread)
 {
 	u32 reg;
-	u8 bw_code = dp->mode.bw_code;
-	u8 lane_cnt = dp->mode.lane_cnt;
 	u8 aux_lane_cnt = lane_cnt;
-	bool enhanced;
 	int ret;
 
 	zynqmp_dp_write(dp, ZYNQMP_DP_LANE_COUNT_SET, lane_cnt);
-	enhanced = drm_dp_enhanced_frame_cap(dp->dpcd);
 	if (enhanced) {
 		zynqmp_dp_write(dp, ZYNQMP_DP_ENHANCED_FRAME_EN, 1);
 		aux_lane_cnt |= DP_LANE_COUNT_ENHANCED_FRAME_EN;
 	}
 
-	if (dp->dpcd[3] & 0x1) {
+	if (downspread) {
 		zynqmp_dp_write(dp, ZYNQMP_DP_DOWNSPREAD_CTL, 1);
 		drm_dp_dpcd_writeb(&dp->aux, DP_DOWNSPREAD_CTRL,
 				   DP_SPREAD_AMP_0_5);
@@ -842,8 +933,24 @@ static int zynqmp_dp_train(struct zynqmp_dp *dp)
 	}
 
 	zynqmp_dp_write(dp, ZYNQMP_DP_PHY_CLOCK_SELECT, reg);
-	ret = zynqmp_dp_phy_ready(dp);
-	if (ret < 0)
+	return zynqmp_dp_phy_ready(dp);
+}
+
+/**
+ * zynqmp_dp_train - Train the link
+ * @dp: DisplayPort IP core structure
+ *
+ * Return: 0 if all trains are done successfully, or corresponding error code.
+ */
+static int zynqmp_dp_train(struct zynqmp_dp *dp)
+{
+	int ret;
+
+	ret = zynqmp_dp_setup(dp, dp->mode.bw_code, dp->mode.lane_cnt,
+			      drm_dp_enhanced_frame_cap(dp->dpcd),
+			      dp->dpcd[DP_MAX_DOWNSPREAD] &
+			      DP_MAX_DOWNSPREAD_0_5);
+	if (ret)
 		return ret;
 
 	zynqmp_dp_write(dp, ZYNQMP_DP_SCRAMBLING_DISABLE, 1);
@@ -934,12 +1041,15 @@ static int zynqmp_dp_aux_cmd_submit(struct zynqmp_dp *dp, u32 cmd, u16 addr,
 				    u8 *buf, u8 bytes, u8 *reply)
 {
 	bool is_read = (cmd & AUX_READ_BIT) ? true : false;
+	unsigned long time_left;
 	u32 reg, i;
 
 	reg = zynqmp_dp_read(dp, ZYNQMP_DP_INTERRUPT_SIGNAL_STATE);
 	if (reg & ZYNQMP_DP_INTERRUPT_SIGNAL_STATE_REQUEST)
 		return -EBUSY;
 
+	reinit_completion(&dp->aux_done);
+
 	zynqmp_dp_write(dp, ZYNQMP_DP_AUX_ADDRESS, addr);
 	if (!is_read)
 		for (i = 0; i < bytes; i++)
@@ -954,17 +1064,14 @@ static int zynqmp_dp_aux_cmd_submit(struct zynqmp_dp *dp, u32 cmd, u16 addr,
 	zynqmp_dp_write(dp, ZYNQMP_DP_AUX_COMMAND, reg);
 
 	/* Wait for reply to be delivered upto 2ms */
-	for (i = 0; ; i++) {
-		reg = zynqmp_dp_read(dp, ZYNQMP_DP_INTERRUPT_SIGNAL_STATE);
-		if (reg & ZYNQMP_DP_INTERRUPT_SIGNAL_STATE_REPLY)
-			break;
+	time_left = wait_for_completion_timeout(&dp->aux_done,
+						msecs_to_jiffies(2));
+	if (!time_left)
+		return -ETIMEDOUT;
 
-		if (reg & ZYNQMP_DP_INTERRUPT_SIGNAL_STATE_REPLY_TIMEOUT ||
-		    i == 2)
-			return -ETIMEDOUT;
-
-		usleep_range(1000, 1100);
-	}
+	reg = zynqmp_dp_read(dp, ZYNQMP_DP_INTERRUPT_SIGNAL_STATE);
+	if (reg & ZYNQMP_DP_INTERRUPT_SIGNAL_STATE_REPLY_TIMEOUT)
+		return -ETIMEDOUT;
 
 	reg = zynqmp_dp_read(dp, ZYNQMP_DP_AUX_REPLY_CODE);
 	if (reply)
@@ -1006,6 +1113,8 @@ zynqmp_dp_aux_transfer(struct drm_dp_aux *aux, struct drm_dp_aux_msg *msg)
 
 		if (dp->status == connector_status_disconnected) {
 			dev_dbg(dp->dev, "no connected aux device\n");
+			if (dp->ignore_aux_errors)
+				goto fake_response;
 			return -ENODEV;
 		}
 
@@ -1014,7 +1123,13 @@ zynqmp_dp_aux_transfer(struct drm_dp_aux *aux, struct drm_dp_aux_msg *msg)
 
 	dev_dbg(dp->dev, "failed to do aux transfer (%d)\n", ret);
 
-	return ret;
+	if (!dp->ignore_aux_errors)
+		return ret;
+
+fake_response:
+	msg->reply = DP_AUX_NATIVE_REPLY_ACK;
+	memset(msg->buffer, 0, msg->size);
+	return msg->size;
 }
 
 /**
@@ -1048,12 +1163,11 @@ static int zynqmp_dp_aux_init(struct zynqmp_dp *dp)
 			(w << ZYNQMP_DP_AUX_CLK_DIVIDER_AUX_FILTER_SHIFT) |
 			(rate / (1000 * 1000)));
 
-	dp->aux.name = "ZynqMP DP AUX";
-	dp->aux.dev = dp->dev;
-	dp->aux.drm_dev = dp->bridge.dev;
-	dp->aux.transfer = zynqmp_dp_aux_transfer;
+	zynqmp_dp_write(dp, ZYNQMP_DP_INT_EN, ZYNQMP_DP_INT_REPLY_RECEIVED |
+			ZYNQMP_DP_INT_REPLY_TIMEOUT);
+	zynqmp_dp_write(dp, ZYNQMP_DP_TRANSMITTER_ENABLE, 1);
 
-	return drm_dp_aux_register(&dp->aux);
+	return 0;
 }
 
 /**
@@ -1065,6 +1179,9 @@ static int zynqmp_dp_aux_init(struct zynqmp_dp *dp)
 static void zynqmp_dp_aux_cleanup(struct zynqmp_dp *dp)
 {
 	drm_dp_aux_unregister(&dp->aux);
+
+	zynqmp_dp_write(dp, ZYNQMP_DP_INT_DS, ZYNQMP_DP_INT_REPLY_RECEIVED |
+					      ZYNQMP_DP_INT_REPLY_TIMEOUT);
 }
 
 /* -----------------------------------------------------------------------------
@@ -1221,7 +1338,6 @@ static void zynqmp_dp_encoder_mode_set_stream(struct zynqmp_dp *dp,
 {
 	u8 lane_cnt = dp->mode.lane_cnt;
 	u32 reg, wpl;
-	unsigned int rate;
 
 	zynqmp_dp_write(dp, ZYNQMP_DP_MAIN_STREAM_HTOTAL, mode->htotal);
 	zynqmp_dp_write(dp, ZYNQMP_DP_MAIN_STREAM_VTOTAL, mode->vtotal);
@@ -1246,18 +1362,8 @@ static void zynqmp_dp_encoder_mode_set_stream(struct zynqmp_dp *dp,
 		reg = drm_dp_bw_code_to_link_rate(dp->mode.bw_code);
 		zynqmp_dp_write(dp, ZYNQMP_DP_MAIN_STREAM_N_VID, reg);
 		zynqmp_dp_write(dp, ZYNQMP_DP_MAIN_STREAM_M_VID, mode->clock);
-		rate = zynqmp_dpsub_get_audio_clk_rate(dp->dpsub);
-		if (rate) {
-			dev_dbg(dp->dev, "Audio rate: %d\n", rate / 512);
-			zynqmp_dp_write(dp, ZYNQMP_DP_TX_N_AUD, reg);
-			zynqmp_dp_write(dp, ZYNQMP_DP_TX_M_AUD, rate / 1000);
-		}
 	}
 
-	/* Only 2 channel audio is supported now */
-	if (zynqmp_dpsub_audio_enabled(dp->dpsub))
-		zynqmp_dp_write(dp, ZYNQMP_DP_TX_AUDIO_CHANNELS, 1);
-
 	zynqmp_dp_write(dp, ZYNQMP_DP_USER_PIX_WIDTH, 1);
 
 	/* Translate to the native 16 bit datapath based on IP core spec */
@@ -1266,6 +1372,44 @@ static void zynqmp_dp_encoder_mode_set_stream(struct zynqmp_dp *dp,
 	zynqmp_dp_write(dp, ZYNQMP_DP_USER_DATA_COUNT_PER_LANE, reg);
 }
 
+/* -----------------------------------------------------------------------------
+ * Audio
+ */
+
+void zynqmp_dp_audio_set_channels(struct zynqmp_dp *dp,
+				  unsigned int num_channels)
+{
+	zynqmp_dp_write(dp, ZYNQMP_DP_TX_AUDIO_CHANNELS, num_channels - 1);
+}
+
+void zynqmp_dp_audio_enable(struct zynqmp_dp *dp)
+{
+	zynqmp_dp_write(dp, ZYNQMP_DP_TX_AUDIO_CONTROL, 1);
+}
+
+void zynqmp_dp_audio_disable(struct zynqmp_dp *dp)
+{
+	zynqmp_dp_write(dp, ZYNQMP_DP_TX_AUDIO_CONTROL, 0);
+}
+
+void zynqmp_dp_audio_write_n_m(struct zynqmp_dp *dp)
+{
+	unsigned int rate;
+	u32 link_rate;
+
+	if (!(dp->config.misc0 & ZYNQMP_DP_MAIN_STREAM_MISC0_SYNC_LOCK))
+		return;
+
+	link_rate = drm_dp_bw_code_to_link_rate(dp->mode.bw_code);
+
+	rate = clk_get_rate(dp->dpsub->aud_clk);
+
+	dev_dbg(dp->dev, "Audio rate: %d\n", rate / 512);
+
+	zynqmp_dp_write(dp, ZYNQMP_DP_TX_N_AUD, link_rate);
+	zynqmp_dp_write(dp, ZYNQMP_DP_TX_M_AUD, rate / 1000);
+}
+
 /* -----------------------------------------------------------------------------
  * DISP Configuration
  */
@@ -1346,6 +1490,17 @@ static int zynqmp_dp_bridge_attach(struct drm_bridge *bridge,
 		return ret;
 	}
 
+	dp->aux.name = "ZynqMP DP AUX";
+	dp->aux.dev = dp->dev;
+	dp->aux.drm_dev = dp->bridge.dev;
+	dp->aux.transfer = zynqmp_dp_aux_transfer;
+
+	ret = drm_dp_aux_register(&dp->aux);
+	if (ret) {
+		dev_err(dp->dev, "failed to register DP aux\n");
+		return ret;
+	}
+
 	if (dp->next_bridge) {
 		ret = drm_bridge_attach(bridge->encoder, dp->next_bridge,
 					bridge, flags);
@@ -1386,8 +1541,10 @@ zynqmp_dp_bridge_mode_valid(struct drm_bridge *bridge,
 	}
 
 	/* Check with link rate and lane count */
+	mutex_lock(&dp->lock);
 	rate = zynqmp_dp_max_rate(dp->link_config.max_rate,
 				  dp->link_config.max_lanes, dp->config.bpp);
+	mutex_unlock(&dp->lock);
 	if (mode->clock > rate) {
 		dev_dbg(dp->dev, "filtered mode %s for high pixel rate\n",
 			mode->name);
@@ -1414,6 +1571,7 @@ static void zynqmp_dp_bridge_atomic_enable(struct drm_bridge *bridge,
 
 	pm_runtime_get_sync(dp->dev);
 
+	mutex_lock(&dp->lock);
 	zynqmp_dp_disp_enable(dp, old_bridge_state);
 
 	/*
@@ -1452,9 +1610,15 @@ static void zynqmp_dp_bridge_atomic_enable(struct drm_bridge *bridge,
 
 	/* Enable the encoder */
 	dp->enabled = true;
+
+	/* Initialize and register the AUX adapter. */
+	if (zynqmp_dp_aux_init(dp)) {
+		dev_err(dp->dev, "failed to initialize DP aux\n");
+		return;
+	}
+
 	zynqmp_dp_update_misc(dp);
-	if (zynqmp_dpsub_audio_enabled(dp->dpsub))
-		zynqmp_dp_write(dp, ZYNQMP_DP_TX_AUDIO_CONTROL, 1);
+
 	zynqmp_dp_write(dp, ZYNQMP_DP_TX_PHY_POWER_DOWN, 0);
 	if (dp->status == connector_status_connected) {
 		for (i = 0; i < 3; i++) {
@@ -1474,6 +1638,7 @@ static void zynqmp_dp_bridge_atomic_enable(struct drm_bridge *bridge,
 	zynqmp_dp_write(dp, ZYNQMP_DP_SOFTWARE_RESET,
 			ZYNQMP_DP_SOFTWARE_RESET_ALL);
 	zynqmp_dp_write(dp, ZYNQMP_DP_MAIN_STREAM_ENABLE, 1);
+	mutex_unlock(&dp->lock);
 }
 
 static void zynqmp_dp_bridge_atomic_disable(struct drm_bridge *bridge,
@@ -1481,16 +1646,16 @@ static void zynqmp_dp_bridge_atomic_disable(struct drm_bridge *bridge,
 {
 	struct zynqmp_dp *dp = bridge_to_dp(bridge);
 
+	mutex_lock(&dp->lock);
 	dp->enabled = false;
 	cancel_work(&dp->hpd_work);
 	zynqmp_dp_write(dp, ZYNQMP_DP_MAIN_STREAM_ENABLE, 0);
 	drm_dp_dpcd_writeb(&dp->aux, DP_SET_POWER, DP_SET_POWER_D3);
 	zynqmp_dp_write(dp, ZYNQMP_DP_TX_PHY_POWER_DOWN,
 			ZYNQMP_DP_TX_PHY_POWER_DOWN_ALL);
-	if (zynqmp_dpsub_audio_enabled(dp->dpsub))
-		zynqmp_dp_write(dp, ZYNQMP_DP_TX_AUDIO_CONTROL, 0);
 
 	zynqmp_dp_disp_disable(dp, old_bridge_state);
+	mutex_unlock(&dp->lock);
 
 	pm_runtime_put_sync(dp->dev);
 }
@@ -1526,13 +1691,14 @@ static int zynqmp_dp_bridge_atomic_check(struct drm_bridge *bridge,
 	return 0;
 }
 
-static enum drm_connector_status zynqmp_dp_bridge_detect(struct drm_bridge *bridge)
+static enum drm_connector_status __zynqmp_dp_bridge_detect(struct zynqmp_dp *dp)
 {
-	struct zynqmp_dp *dp = bridge_to_dp(bridge);
 	struct zynqmp_dp_link_config *link_config = &dp->link_config;
 	u32 state, i;
 	int ret;
 
+	lockdep_assert_held(&dp->lock);
+
 	/*
 	 * This is from heuristic. It takes some delay (ex, 100 ~ 500 msec) to
 	 * get the HPD signal with some monitors.
@@ -1568,6 +1734,18 @@ static enum drm_connector_status zynqmp_dp_bridge_detect(struct drm_bridge *brid
 	return connector_status_disconnected;
 }
 
+static enum drm_connector_status zynqmp_dp_bridge_detect(struct drm_bridge *bridge)
+{
+	struct zynqmp_dp *dp = bridge_to_dp(bridge);
+	enum drm_connector_status ret;
+
+	mutex_lock(&dp->lock);
+	ret = __zynqmp_dp_bridge_detect(dp);
+	mutex_unlock(&dp->lock);
+
+	return ret;
+}
+
 static const struct drm_edid *zynqmp_dp_bridge_edid_read(struct drm_bridge *bridge,
 							 struct drm_connector *connector)
 {
@@ -1605,6 +1783,582 @@ zynqmp_dp_bridge_get_input_bus_fmts(struct drm_bridge *bridge,
 		return zynqmp_dp_bridge_default_bus_fmts(num_input_fmts);
 }
 
+/* -----------------------------------------------------------------------------
+ * debugfs
+ */
+
+/**
+ * zynqmp_dp_set_test_pattern() - Configure the link for a test pattern
+ * @dp: DisplayPort IP core structure
+ * @pattern: The test pattern to configure
+ * @custom: The custom pattern to use if @pattern is %TEST_80BIT_CUSTOM
+ *
+ * Return: 0 on success, or negative errno on (DPCD) failure
+ */
+static int zynqmp_dp_set_test_pattern(struct zynqmp_dp *dp,
+				      enum test_pattern pattern,
+				      u8 *const custom)
+{
+	bool scramble = false;
+	u32 train_pattern = 0;
+	u32 link_pattern = 0;
+	u8 dpcd_train = 0;
+	u8 dpcd_link = 0;
+	int ret;
+
+	switch (pattern) {
+	case TEST_TPS1:
+		train_pattern = 1;
+		break;
+	case TEST_TPS2:
+		train_pattern = 2;
+		break;
+	case TEST_TPS3:
+		train_pattern = 3;
+		break;
+	case TEST_SYMBOL_ERROR:
+		scramble = true;
+		link_pattern = DP_PHY_TEST_PATTERN_ERROR_COUNT;
+		break;
+	case TEST_PRBS7:
+		/* We use a dedicated register to enable PRBS7 */
+		dpcd_link = DP_LINK_QUAL_PATTERN_ERROR_RATE;
+		break;
+	case TEST_80BIT_CUSTOM: {
+		const u8 *p = custom;
+
+		link_pattern = DP_LINK_QUAL_PATTERN_80BIT_CUSTOM;
+
+		zynqmp_dp_write(dp, ZYNQMP_DP_COMP_PATTERN_80BIT_1,
+				(p[3] << 24) | (p[2] << 16) | (p[1] << 8) | p[0]);
+		zynqmp_dp_write(dp, ZYNQMP_DP_COMP_PATTERN_80BIT_2,
+				(p[7] << 24) | (p[6] << 16) | (p[5] << 8) | p[4]);
+		zynqmp_dp_write(dp, ZYNQMP_DP_COMP_PATTERN_80BIT_3,
+				(p[9] << 8) | p[8]);
+		break;
+	}
+	case TEST_CP2520:
+		link_pattern = DP_LINK_QUAL_PATTERN_CP2520_PAT_1;
+		break;
+	default:
+		WARN_ON_ONCE(1);
+		fallthrough;
+	case TEST_VIDEO:
+		scramble = true;
+	}
+
+	zynqmp_dp_write(dp, ZYNQMP_DP_SCRAMBLING_DISABLE, !scramble);
+	zynqmp_dp_write(dp, ZYNQMP_DP_TRAINING_PATTERN_SET, train_pattern);
+	zynqmp_dp_write(dp, ZYNQMP_DP_LINK_QUAL_PATTERN_SET, link_pattern);
+	zynqmp_dp_write(dp, ZYNQMP_DP_TRANSMIT_PRBS7, pattern == TEST_PRBS7);
+
+	dpcd_link = dpcd_link ?: link_pattern;
+	dpcd_train = train_pattern;
+	if (!scramble)
+		dpcd_train |= DP_LINK_SCRAMBLING_DISABLE;
+
+	if (dp->dpcd[DP_DPCD_REV] < 0x12) {
+		if (pattern == TEST_CP2520)
+			dev_warn(dp->dev,
+				"can't set sink link quality pattern to CP2520 for DPCD < r1.2; error counters will be invalid\n");
+		else
+			dpcd_train |= FIELD_PREP(DP_LINK_QUAL_PATTERN_11_MASK,
+						 dpcd_link);
+	} else {
+		u8 dpcd_link_lane[ZYNQMP_DP_MAX_LANES];
+
+		memset(dpcd_link_lane, dpcd_link, ZYNQMP_DP_MAX_LANES);
+		ret = drm_dp_dpcd_write(&dp->aux, DP_LINK_QUAL_LANE0_SET,
+					dpcd_link_lane, ZYNQMP_DP_MAX_LANES);
+		if (ret < 0)
+			return ret;
+	}
+
+	ret = drm_dp_dpcd_writeb(&dp->aux, DP_TRAINING_PATTERN_SET, dpcd_train);
+	return ret < 0 ? ret : 0;
+}
+
+static int zynqmp_dp_test_setup(struct zynqmp_dp *dp)
+{
+	return zynqmp_dp_setup(dp, dp->test.bw_code, dp->test.link_cnt,
+			       dp->test.enhanced, dp->test.downspread);
+}
+
+static ssize_t zynqmp_dp_pattern_read(struct file *file, char __user *user_buf,
+				      size_t count, loff_t *ppos)
+{
+	struct dentry *dentry = file->f_path.dentry;
+	struct zynqmp_dp *dp = file->private_data;
+	char buf[16];
+	ssize_t ret;
+
+	ret = debugfs_file_get(dentry);
+	if (unlikely(ret))
+		return ret;
+
+	mutex_lock(&dp->lock);
+	ret = snprintf(buf, sizeof(buf), "%s\n",
+		       test_pattern_str[dp->test.pattern]);
+	mutex_unlock(&dp->lock);
+
+	debugfs_file_put(dentry);
+	return simple_read_from_buffer(user_buf, count, ppos, buf, ret);
+}
+
+static ssize_t zynqmp_dp_pattern_write(struct file *file,
+				       const char __user *user_buf,
+				       size_t count, loff_t *ppos)
+{
+	struct dentry *dentry = file->f_path.dentry;
+	struct zynqmp_dp *dp = file->private_data;
+	char buf[16];
+	ssize_t ret;
+	int pattern;
+
+	ret = debugfs_file_get(dentry);
+	if (unlikely(ret))
+		return ret;
+
+	ret = simple_write_to_buffer(buf, sizeof(buf) - 1, ppos, user_buf,
+				     count);
+	if (ret < 0)
+		goto out;
+	buf[ret] = '\0';
+
+	pattern = sysfs_match_string(test_pattern_str, buf);
+	if (pattern < 0) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	mutex_lock(&dp->lock);
+	dp->test.pattern = pattern;
+	if (dp->test.active)
+		ret = zynqmp_dp_set_test_pattern(dp, dp->test.pattern,
+						 dp->test.custom) ?: ret;
+	mutex_unlock(&dp->lock);
+
+out:
+	debugfs_file_put(dentry);
+	return ret;
+}
+
+static const struct file_operations fops_zynqmp_dp_pattern = {
+	.read = zynqmp_dp_pattern_read,
+	.write = zynqmp_dp_pattern_write,
+	.open = simple_open,
+	.llseek = noop_llseek,
+};
+
+static int zynqmp_dp_enhanced_get(void *data, u64 *val)
+{
+	struct zynqmp_dp *dp = data;
+
+	mutex_lock(&dp->lock);
+	*val = dp->test.enhanced;
+	mutex_unlock(&dp->lock);
+	return 0;
+}
+
+static int zynqmp_dp_enhanced_set(void *data, u64 val)
+{
+	struct zynqmp_dp *dp = data;
+	int ret = 0;
+
+	mutex_lock(&dp->lock);
+	dp->test.enhanced = val;
+	if (dp->test.active)
+		ret = zynqmp_dp_test_setup(dp);
+	mutex_unlock(&dp->lock);
+
+	return ret;
+}
+
+DEFINE_DEBUGFS_ATTRIBUTE(fops_zynqmp_dp_enhanced, zynqmp_dp_enhanced_get,
+			 zynqmp_dp_enhanced_set, "%llu\n");
+
+static int zynqmp_dp_downspread_get(void *data, u64 *val)
+{
+	struct zynqmp_dp *dp = data;
+
+	mutex_lock(&dp->lock);
+	*val = dp->test.downspread;
+	mutex_unlock(&dp->lock);
+	return 0;
+}
+
+static int zynqmp_dp_downspread_set(void *data, u64 val)
+{
+	struct zynqmp_dp *dp = data;
+	int ret = 0;
+
+	mutex_lock(&dp->lock);
+	dp->test.downspread = val;
+	if (dp->test.active)
+		ret = zynqmp_dp_test_setup(dp);
+	mutex_unlock(&dp->lock);
+
+	return ret;
+}
+
+DEFINE_DEBUGFS_ATTRIBUTE(fops_zynqmp_dp_downspread, zynqmp_dp_downspread_get,
+			 zynqmp_dp_downspread_set, "%llu\n");
+
+static int zynqmp_dp_active_get(void *data, u64 *val)
+{
+	struct zynqmp_dp *dp = data;
+
+	mutex_lock(&dp->lock);
+	*val = dp->test.active;
+	mutex_unlock(&dp->lock);
+	return 0;
+}
+
+static int zynqmp_dp_active_set(void *data, u64 val)
+{
+	struct zynqmp_dp *dp = data;
+	int ret = 0;
+
+	mutex_lock(&dp->lock);
+	if (val) {
+		if (val < 2) {
+			ret = zynqmp_dp_test_setup(dp);
+			if (ret)
+				goto out;
+		}
+
+		ret = zynqmp_dp_set_test_pattern(dp, dp->test.pattern,
+						 dp->test.custom);
+		if (ret)
+			goto out;
+
+		ret = zynqmp_dp_update_vs_emph(dp, dp->test.train_set);
+		if (ret)
+			goto out;
+
+		dp->test.active = true;
+	} else {
+		int err;
+
+		dp->test.active = false;
+		err = zynqmp_dp_set_test_pattern(dp, TEST_VIDEO, NULL);
+		if (err)
+			dev_warn(dp->dev, "could not clear test pattern: %d\n",
+				 err);
+		zynqmp_dp_train_loop(dp);
+	}
+out:
+	mutex_unlock(&dp->lock);
+
+	return ret;
+}
+
+DEFINE_DEBUGFS_ATTRIBUTE(fops_zynqmp_dp_active, zynqmp_dp_active_get,
+			 zynqmp_dp_active_set, "%llu\n");
+
+static ssize_t zynqmp_dp_custom_read(struct file *file, char __user *user_buf,
+				     size_t count, loff_t *ppos)
+{
+	struct dentry *dentry = file->f_path.dentry;
+	struct zynqmp_dp *dp = file->private_data;
+	ssize_t ret;
+
+	ret = debugfs_file_get(dentry);
+	if (unlikely(ret))
+		return ret;
+
+	mutex_lock(&dp->lock);
+	ret = simple_read_from_buffer(user_buf, count, ppos, &dp->test.custom,
+				      sizeof(dp->test.custom));
+	mutex_unlock(&dp->lock);
+
+	debugfs_file_put(dentry);
+	return ret;
+}
+
+static ssize_t zynqmp_dp_custom_write(struct file *file,
+				      const char __user *user_buf,
+				      size_t count, loff_t *ppos)
+{
+	struct dentry *dentry = file->f_path.dentry;
+	struct zynqmp_dp *dp = file->private_data;
+	ssize_t ret;
+	char buf[sizeof(dp->test.custom)];
+
+	ret = debugfs_file_get(dentry);
+	if (unlikely(ret))
+		return ret;
+
+	ret = simple_write_to_buffer(buf, sizeof(buf), ppos, user_buf, count);
+	if (ret < 0)
+		goto out;
+
+	mutex_lock(&dp->lock);
+	memcpy(dp->test.custom, buf, ret);
+	if (dp->test.active)
+		ret = zynqmp_dp_set_test_pattern(dp, dp->test.pattern,
+						 dp->test.custom) ?: ret;
+	mutex_unlock(&dp->lock);
+
+out:
+	debugfs_file_put(dentry);
+	return ret;
+}
+
+static const struct file_operations fops_zynqmp_dp_custom = {
+	.read = zynqmp_dp_custom_read,
+	.write = zynqmp_dp_custom_write,
+	.open = simple_open,
+	.llseek = noop_llseek,
+};
+
+static int zynqmp_dp_swing_get(void *data, u64 *val)
+{
+	struct zynqmp_dp_train_set_priv *priv = data;
+	struct zynqmp_dp *dp = priv->dp;
+
+	mutex_lock(&dp->lock);
+	*val = dp->test.train_set[priv->lane] & DP_TRAIN_VOLTAGE_SWING_MASK;
+	mutex_unlock(&dp->lock);
+	return 0;
+}
+
+static int zynqmp_dp_swing_set(void *data, u64 val)
+{
+	struct zynqmp_dp_train_set_priv *priv = data;
+	struct zynqmp_dp *dp = priv->dp;
+	u8 *train_set = &dp->test.train_set[priv->lane];
+	int ret = 0;
+
+	if (val > 3)
+		return -EINVAL;
+
+	mutex_lock(&dp->lock);
+	*train_set &= ~(DP_TRAIN_MAX_SWING_REACHED |
+			DP_TRAIN_VOLTAGE_SWING_MASK);
+	*train_set |= val;
+	if (val == 3)
+		*train_set |= DP_TRAIN_MAX_SWING_REACHED;
+
+	if (dp->test.active)
+		ret = zynqmp_dp_update_vs_emph(dp, dp->test.train_set);
+	mutex_unlock(&dp->lock);
+
+	return ret;
+}
+
+DEFINE_DEBUGFS_ATTRIBUTE(fops_zynqmp_dp_swing, zynqmp_dp_swing_get,
+			 zynqmp_dp_swing_set, "%llu\n");
+
+static int zynqmp_dp_preemphasis_get(void *data, u64 *val)
+{
+	struct zynqmp_dp_train_set_priv *priv = data;
+	struct zynqmp_dp *dp = priv->dp;
+
+	mutex_lock(&dp->lock);
+	*val = FIELD_GET(DP_TRAIN_PRE_EMPHASIS_MASK,
+			 dp->test.train_set[priv->lane]);
+	mutex_unlock(&dp->lock);
+	return 0;
+}
+
+static int zynqmp_dp_preemphasis_set(void *data, u64 val)
+{
+	struct zynqmp_dp_train_set_priv *priv = data;
+	struct zynqmp_dp *dp = priv->dp;
+	u8 *train_set = &dp->test.train_set[priv->lane];
+	int ret = 0;
+
+	if (val > 2)
+		return -EINVAL;
+
+	mutex_lock(&dp->lock);
+	*train_set &= ~(DP_TRAIN_MAX_PRE_EMPHASIS_REACHED |
+			DP_TRAIN_PRE_EMPHASIS_MASK);
+	*train_set |= val;
+	if (val == 2)
+		*train_set |= DP_TRAIN_MAX_PRE_EMPHASIS_REACHED;
+
+	if (dp->test.active)
+		ret = zynqmp_dp_update_vs_emph(dp, dp->test.train_set);
+	mutex_unlock(&dp->lock);
+
+	return ret;
+}
+
+DEFINE_DEBUGFS_ATTRIBUTE(fops_zynqmp_dp_preemphasis, zynqmp_dp_preemphasis_get,
+			 zynqmp_dp_preemphasis_set, "%llu\n");
+
+static int zynqmp_dp_lanes_get(void *data, u64 *val)
+{
+	struct zynqmp_dp *dp = data;
+
+	mutex_lock(&dp->lock);
+	*val = dp->test.link_cnt;
+	mutex_unlock(&dp->lock);
+	return 0;
+}
+
+static int zynqmp_dp_lanes_set(void *data, u64 val)
+{
+	struct zynqmp_dp *dp = data;
+	int ret = 0;
+
+	if (val > ZYNQMP_DP_MAX_LANES)
+		return -EINVAL;
+
+	mutex_lock(&dp->lock);
+	if (val > dp->num_lanes) {
+		ret = -EINVAL;
+	} else {
+		dp->test.link_cnt = val;
+		if (dp->test.active)
+			ret = zynqmp_dp_test_setup(dp);
+	}
+	mutex_unlock(&dp->lock);
+
+	return ret;
+}
+
+DEFINE_DEBUGFS_ATTRIBUTE(fops_zynqmp_dp_lanes, zynqmp_dp_lanes_get,
+			 zynqmp_dp_lanes_set, "%llu\n");
+
+static int zynqmp_dp_rate_get(void *data, u64 *val)
+{
+	struct zynqmp_dp *dp = data;
+
+	mutex_lock(&dp->lock);
+	*val = drm_dp_bw_code_to_link_rate(dp->test.bw_code) * 10000ULL;
+	mutex_unlock(&dp->lock);
+	return 0;
+}
+
+static int zynqmp_dp_rate_set(void *data, u64 val)
+{
+	struct zynqmp_dp *dp = data;
+	int link_rate;
+	int ret = 0;
+	u8 bw_code;
+
+	if (do_div(val, 10000))
+		return -EINVAL;
+
+	bw_code = drm_dp_link_rate_to_bw_code(val);
+	link_rate = drm_dp_bw_code_to_link_rate(bw_code);
+	if (val != link_rate)
+		return -EINVAL;
+
+	if (bw_code != DP_LINK_BW_1_62 && bw_code != DP_LINK_BW_2_7 &&
+	    bw_code != DP_LINK_BW_5_4)
+		return -EINVAL;
+
+	mutex_lock(&dp->lock);
+	dp->test.bw_code = bw_code;
+	if (dp->test.active)
+		ret = zynqmp_dp_test_setup(dp);
+	mutex_unlock(&dp->lock);
+
+	return ret;
+}
+
+DEFINE_DEBUGFS_ATTRIBUTE(fops_zynqmp_dp_rate, zynqmp_dp_rate_get,
+			 zynqmp_dp_rate_set, "%llu\n");
+
+static int zynqmp_dp_ignore_aux_errors_get(void *data, u64 *val)
+{
+	struct zynqmp_dp *dp = data;
+
+	mutex_lock(&dp->aux.hw_mutex);
+	*val = dp->ignore_aux_errors;
+	mutex_unlock(&dp->aux.hw_mutex);
+	return 0;
+}
+
+static int zynqmp_dp_ignore_aux_errors_set(void *data, u64 val)
+{
+	struct zynqmp_dp *dp = data;
+
+	if (val != !!val)
+		return -EINVAL;
+
+	mutex_lock(&dp->aux.hw_mutex);
+	dp->ignore_aux_errors = val;
+	mutex_unlock(&dp->aux.hw_mutex);
+	return 0;
+}
+
+DEFINE_DEBUGFS_ATTRIBUTE(fops_zynqmp_dp_ignore_aux_errors,
+			 zynqmp_dp_ignore_aux_errors_get,
+			 zynqmp_dp_ignore_aux_errors_set, "%llu\n");
+
+static int zynqmp_dp_ignore_hpd_get(void *data, u64 *val)
+{
+	struct zynqmp_dp *dp = data;
+
+	mutex_lock(&dp->lock);
+	*val = dp->ignore_hpd;
+	mutex_unlock(&dp->lock);
+	return 0;
+}
+
+static int zynqmp_dp_ignore_hpd_set(void *data, u64 val)
+{
+	struct zynqmp_dp *dp = data;
+
+	if (val != !!val)
+		return -EINVAL;
+
+	mutex_lock(&dp->lock);
+	dp->ignore_hpd = val;
+	mutex_lock(&dp->lock);
+	return 0;
+}
+
+DEFINE_DEBUGFS_ATTRIBUTE(fops_zynqmp_dp_ignore_hpd, zynqmp_dp_ignore_hpd_get,
+			 zynqmp_dp_ignore_hpd_set, "%llu\n");
+
+static void zynqmp_dp_bridge_debugfs_init(struct drm_bridge *bridge,
+					  struct dentry *root)
+{
+	struct zynqmp_dp *dp = bridge_to_dp(bridge);
+	struct dentry *test;
+	int i;
+
+	dp->test.bw_code = DP_LINK_BW_5_4;
+	dp->test.link_cnt = dp->num_lanes;
+
+	test = debugfs_create_dir("test", root);
+#define CREATE_FILE(name) \
+	debugfs_create_file(#name, 0600, test, dp, &fops_zynqmp_dp_##name)
+	CREATE_FILE(pattern);
+	CREATE_FILE(enhanced);
+	CREATE_FILE(downspread);
+	CREATE_FILE(active);
+	CREATE_FILE(custom);
+	CREATE_FILE(rate);
+	CREATE_FILE(lanes);
+	CREATE_FILE(ignore_aux_errors);
+	CREATE_FILE(ignore_hpd);
+
+	for (i = 0; i < dp->num_lanes; i++) {
+		static const char fmt[] = "lane%d_preemphasis";
+		char name[sizeof(fmt)];
+
+		dp->debugfs_train_set[i].dp = dp;
+		dp->debugfs_train_set[i].lane = i;
+
+		snprintf(name, sizeof(name), fmt, i);
+		debugfs_create_file(name, 0600, test,
+				    &dp->debugfs_train_set[i],
+				    &fops_zynqmp_dp_preemphasis);
+
+		snprintf(name, sizeof(name), "lane%d_swing", i);
+		debugfs_create_file(name, 0600, test,
+				    &dp->debugfs_train_set[i],
+				    &fops_zynqmp_dp_swing);
+	}
+}
+
 static const struct drm_bridge_funcs zynqmp_dp_bridge_funcs = {
 	.attach = zynqmp_dp_bridge_attach,
 	.detach = zynqmp_dp_bridge_detach,
@@ -1618,6 +2372,7 @@ static const struct drm_bridge_funcs zynqmp_dp_bridge_funcs = {
 	.detect = zynqmp_dp_bridge_detect,
 	.edid_read = zynqmp_dp_bridge_edid_read,
 	.atomic_get_input_bus_fmts = zynqmp_dp_bridge_get_input_bus_fmts,
+	.debugfs_init = zynqmp_dp_bridge_debugfs_init,
 };
 
 /* -----------------------------------------------------------------------------
@@ -1651,10 +2406,46 @@ static void zynqmp_dp_hpd_work_func(struct work_struct *work)
 	struct zynqmp_dp *dp = container_of(work, struct zynqmp_dp, hpd_work);
 	enum drm_connector_status status;
 
-	status = zynqmp_dp_bridge_detect(&dp->bridge);
+	mutex_lock(&dp->lock);
+	if (dp->ignore_hpd) {
+		mutex_unlock(&dp->lock);
+		return;
+	}
+
+	status = __zynqmp_dp_bridge_detect(dp);
+	mutex_unlock(&dp->lock);
+
 	drm_bridge_hpd_notify(&dp->bridge, status);
 }
 
+static void zynqmp_dp_hpd_irq_work_func(struct work_struct *work)
+{
+	struct zynqmp_dp *dp = container_of(work, struct zynqmp_dp,
+					    hpd_irq_work);
+	u8 status[DP_LINK_STATUS_SIZE + 2];
+	int err;
+
+	mutex_lock(&dp->lock);
+	if (dp->ignore_hpd) {
+		mutex_unlock(&dp->lock);
+		return;
+	}
+
+	err = drm_dp_dpcd_read(&dp->aux, DP_SINK_COUNT, status,
+			       DP_LINK_STATUS_SIZE + 2);
+	if (err < 0) {
+		dev_dbg_ratelimited(dp->dev,
+				    "could not read sink status: %d\n", err);
+	} else {
+		if (status[4] & DP_LINK_STATUS_UPDATED ||
+		    !drm_dp_clock_recovery_ok(&status[2], dp->mode.lane_cnt) ||
+		    !drm_dp_channel_eq_ok(&status[2], dp->mode.lane_cnt)) {
+			zynqmp_dp_train_loop(dp);
+		}
+	}
+	mutex_unlock(&dp->lock);
+}
+
 static irqreturn_t zynqmp_dp_irq_handler(int irq, void *data)
 {
 	struct zynqmp_dp *dp = (struct zynqmp_dp *)data;
@@ -1686,23 +2477,15 @@ static irqreturn_t zynqmp_dp_irq_handler(int irq, void *data)
 	if (status & ZYNQMP_DP_INT_HPD_EVENT)
 		schedule_work(&dp->hpd_work);
 
-	if (status & ZYNQMP_DP_INT_HPD_IRQ) {
-		int ret;
-		u8 status[DP_LINK_STATUS_SIZE + 2];
+	if (status & ZYNQMP_DP_INT_HPD_IRQ)
+		schedule_work(&dp->hpd_irq_work);
 
-		ret = drm_dp_dpcd_read(&dp->aux, DP_SINK_COUNT, status,
-				       DP_LINK_STATUS_SIZE + 2);
-		if (ret < 0)
-			goto handled;
+	if (status & ZYNQMP_DP_INTERRUPT_SIGNAL_STATE_REPLY)
+		complete(&dp->aux_done);
 
-		if (status[4] & DP_LINK_STATUS_UPDATED ||
-		    !drm_dp_clock_recovery_ok(&status[2], dp->mode.lane_cnt) ||
-		    !drm_dp_channel_eq_ok(&status[2], dp->mode.lane_cnt)) {
-			zynqmp_dp_train_loop(dp);
-		}
-	}
+	if (status & ZYNQMP_DP_INTERRUPT_SIGNAL_STATE_REPLY_TIMEOUT)
+		complete(&dp->aux_done);
 
-handled:
 	return IRQ_HANDLED;
 }
 
@@ -1725,8 +2508,11 @@ int zynqmp_dp_probe(struct zynqmp_dpsub *dpsub)
 	dp->dev = &pdev->dev;
 	dp->dpsub = dpsub;
 	dp->status = connector_status_disconnected;
+	mutex_init(&dp->lock);
+	init_completion(&dp->aux_done);
 
 	INIT_WORK(&dp->hpd_work, zynqmp_dp_hpd_work_func);
+	INIT_WORK(&dp->hpd_irq_work, zynqmp_dp_hpd_irq_work_func);
 
 	/* Acquire all resources (IOMEM, IRQ and PHYs). */
 	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "dp");
@@ -1802,9 +2588,8 @@ int zynqmp_dp_probe(struct zynqmp_dpsub *dpsub)
 	 * Now that the hardware is initialized and won't generate spurious
 	 * interrupts, request the IRQ.
 	 */
-	ret = devm_request_threaded_irq(dp->dev, dp->irq, NULL,
-					zynqmp_dp_irq_handler, IRQF_ONESHOT,
-					dev_name(dp->dev), dp);
+	ret = devm_request_irq(dp->dev, dp->irq, zynqmp_dp_irq_handler,
+			       IRQF_SHARED, dev_name(dp->dev), dp);
 	if (ret < 0)
 		goto err_phy_exit;
 
@@ -1829,8 +2614,9 @@ void zynqmp_dp_remove(struct zynqmp_dpsub *dpsub)
 	struct zynqmp_dp *dp = dpsub->dp;
 
 	zynqmp_dp_write(dp, ZYNQMP_DP_INT_DS, ZYNQMP_DP_INT_ALL);
-	disable_irq(dp->irq);
+	devm_free_irq(dp->dev, dp->irq, dp);
 
+	cancel_work_sync(&dp->hpd_irq_work);
 	cancel_work_sync(&dp->hpd_work);
 
 	zynqmp_dp_write(dp, ZYNQMP_DP_TRANSMITTER_ENABLE, 0);
@@ -1838,4 +2624,5 @@ void zynqmp_dp_remove(struct zynqmp_dpsub *dpsub)
 
 	zynqmp_dp_phy_exit(dp);
 	zynqmp_dp_reset(dp, true);
+	mutex_destroy(&dp->lock);
 }
diff --git a/drivers/gpu/drm/xlnx/zynqmp_dp.h b/drivers/gpu/drm/xlnx/zynqmp_dp.h
index f077d7fbd..d1ce80528 100644
--- a/drivers/gpu/drm/xlnx/zynqmp_dp.h
+++ b/drivers/gpu/drm/xlnx/zynqmp_dp.h
@@ -22,4 +22,14 @@ void zynqmp_dp_disable_vblank(struct zynqmp_dp *dp);
 int zynqmp_dp_probe(struct zynqmp_dpsub *dpsub);
 void zynqmp_dp_remove(struct zynqmp_dpsub *dpsub);
 
+void zynqmp_dp_audio_set_channels(struct zynqmp_dp *dp,
+				  unsigned int num_channels);
+void zynqmp_dp_audio_enable(struct zynqmp_dp *dp);
+void zynqmp_dp_audio_disable(struct zynqmp_dp *dp);
+
+void zynqmp_dp_audio_write_n_m(struct zynqmp_dp *dp);
+
+int zynqmp_dp_phy_init(struct zynqmp_dp *dp);
+void zynqmp_dp_phy_exit(struct zynqmp_dp *dp);
+
 #endif /* _ZYNQMP_DP_H_ */
diff --git a/drivers/gpu/drm/xlnx/zynqmp_dp_audio.c b/drivers/gpu/drm/xlnx/zynqmp_dp_audio.c
new file mode 100644
index 000000000..fa5f0ace6
--- /dev/null
+++ b/drivers/gpu/drm/xlnx/zynqmp_dp_audio.c
@@ -0,0 +1,447 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * ZynqMP DisplayPort Subsystem Driver - Audio support
+ *
+ * Copyright (C) 2015 - 2024 Xilinx, Inc.
+ *
+ * Authors:
+ * - Hyun Woo Kwon <hyun.kwon@xilinx.com>
+ * - Tomi Valkeinen <tomi.valkeinen@ideasonboard.com>
+ */
+
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/mutex.h>
+#include <linux/pm_runtime.h>
+
+#include <sound/asoundef.h>
+#include <sound/core.h>
+#include <sound/dmaengine_pcm.h>
+#include <sound/initval.h>
+#include <sound/pcm.h>
+#include <sound/soc.h>
+#include <sound/tlv.h>
+
+#include "zynqmp_disp_regs.h"
+#include "zynqmp_dp.h"
+#include "zynqmp_dpsub.h"
+
+#define ZYNQMP_DISP_AUD_SMPL_RATE_TO_CLK 512
+#define ZYNQMP_NUM_PCMS 2
+
+struct zynqmp_dpsub_audio {
+	void __iomem *base;
+
+	struct snd_soc_card card;
+
+	const char *dai_name;
+	const char *link_names[ZYNQMP_NUM_PCMS];
+	const char *pcm_names[ZYNQMP_NUM_PCMS];
+
+	struct snd_soc_dai_driver dai_driver;
+	struct snd_dmaengine_pcm_config pcm_configs[2];
+
+	struct snd_soc_dai_link links[ZYNQMP_NUM_PCMS];
+
+	struct {
+		struct snd_soc_dai_link_component cpu;
+		struct snd_soc_dai_link_component codec;
+		struct snd_soc_dai_link_component platform;
+	} components[ZYNQMP_NUM_PCMS];
+
+	/*
+	 * Protects:
+	 * - enabled_streams
+	 * - volumes
+	 * - current_rate
+	 */
+	struct mutex enable_lock;
+
+	u32 enabled_streams;
+	u32 current_rate;
+
+	u16 volumes[2];
+};
+
+static const struct snd_pcm_hardware zynqmp_dp_pcm_hw = {
+	.info = SNDRV_PCM_INFO_MMAP |
+		SNDRV_PCM_INFO_MMAP_VALID |
+		SNDRV_PCM_INFO_INTERLEAVED |
+		SNDRV_PCM_INFO_PAUSE |
+		SNDRV_PCM_INFO_RESUME |
+		SNDRV_PCM_INFO_NO_PERIOD_WAKEUP,
+
+	.buffer_bytes_max       = 128 * 1024,
+	.period_bytes_min       = 256,
+	.period_bytes_max       = 1024 * 1024,
+	.periods_min            = 2,
+	.periods_max            = 256,
+};
+
+static int zynqmp_dp_startup(struct snd_pcm_substream *substream)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+
+	snd_pcm_hw_constraint_step(runtime, 0, SNDRV_PCM_HW_PARAM_PERIOD_BYTES,
+				   256);
+
+	return 0;
+}
+
+static const struct snd_soc_ops zynqmp_dp_ops = {
+	.startup = zynqmp_dp_startup,
+};
+
+static void zynqmp_dp_audio_write(struct zynqmp_dpsub_audio *audio, int reg,
+				  u32 val)
+{
+	writel(val, audio->base + reg);
+}
+
+static int dp_dai_hw_params(struct snd_pcm_substream *substream,
+			    struct snd_pcm_hw_params *params,
+			    struct snd_soc_dai *socdai)
+{
+	struct snd_soc_pcm_runtime *rtd = snd_soc_substream_to_rtd(substream);
+	struct zynqmp_dpsub *dpsub =
+		snd_soc_dai_get_drvdata(snd_soc_rtd_to_cpu(rtd, 0));
+	struct zynqmp_dpsub_audio *audio = dpsub->audio;
+	int ret;
+	u32 sample_rate;
+	struct snd_aes_iec958 iec = { 0 };
+	unsigned long rate;
+
+	sample_rate = params_rate(params);
+
+	if (sample_rate != 48000 && sample_rate != 44100)
+		return -EINVAL;
+
+	guard(mutex)(&audio->enable_lock);
+
+	if (audio->enabled_streams && audio->current_rate != sample_rate) {
+		dev_err(dpsub->dev,
+			"Can't change rate while playback enabled\n");
+		return -EINVAL;
+	}
+
+	if (audio->enabled_streams > 0) {
+		/* Nothing to do */
+		audio->enabled_streams++;
+		return 0;
+	}
+
+	audio->current_rate = sample_rate;
+
+	/* Note: clock rate can only be changed if the clock is disabled */
+	ret = clk_set_rate(dpsub->aud_clk,
+			   sample_rate * ZYNQMP_DISP_AUD_SMPL_RATE_TO_CLK);
+	if (ret) {
+		dev_err(dpsub->dev, "can't set aud_clk to %u err:%d\n",
+			sample_rate * ZYNQMP_DISP_AUD_SMPL_RATE_TO_CLK, ret);
+		return ret;
+	}
+
+	clk_prepare_enable(dpsub->aud_clk);
+
+	rate = clk_get_rate(dpsub->aud_clk);
+
+	/* Ignore some offset +- 10 */
+	if (abs(sample_rate * ZYNQMP_DISP_AUD_SMPL_RATE_TO_CLK - rate) > 10) {
+		dev_err(dpsub->dev, "aud_clk offset is higher: %ld\n",
+			sample_rate * ZYNQMP_DISP_AUD_SMPL_RATE_TO_CLK - rate);
+		clk_disable_unprepare(dpsub->aud_clk);
+		return -EINVAL;
+	}
+
+	pm_runtime_get_sync(dpsub->dev);
+
+	zynqmp_dp_audio_write(audio, ZYNQMP_DISP_AUD_MIXER_VOLUME,
+			      audio->volumes[0] | (audio->volumes[1] << 16));
+
+	/* Clear the audio soft reset register as it's an non-reset flop. */
+	zynqmp_dp_audio_write(audio, ZYNQMP_DISP_AUD_SOFT_RESET, 0);
+
+	/* Only 2 channel audio is supported now */
+	zynqmp_dp_audio_set_channels(dpsub->dp, 2);
+
+	zynqmp_dp_audio_write_n_m(dpsub->dp);
+
+	/* Channel status */
+
+	if (sample_rate == 48000)
+		iec.status[3] = IEC958_AES3_CON_FS_48000;
+	else
+		iec.status[3] = IEC958_AES3_CON_FS_44100;
+
+	for (unsigned int i = 0; i < AES_IEC958_STATUS_SIZE / 4; ++i) {
+		u32 v;
+
+		v = (iec.status[(i * 4) + 0] << 0) |
+		    (iec.status[(i * 4) + 1] << 8) |
+		    (iec.status[(i * 4) + 2] << 16) |
+		    (iec.status[(i * 4) + 3] << 24);
+
+		zynqmp_dp_audio_write(audio, ZYNQMP_DISP_AUD_CH_STATUS(i), v);
+	}
+
+	zynqmp_dp_audio_enable(dpsub->dp);
+
+	audio->enabled_streams++;
+
+	return 0;
+}
+
+static int dp_dai_hw_free(struct snd_pcm_substream *substream,
+			  struct snd_soc_dai *socdai)
+{
+	struct snd_soc_pcm_runtime *rtd = snd_soc_substream_to_rtd(substream);
+	struct zynqmp_dpsub *dpsub =
+		snd_soc_dai_get_drvdata(snd_soc_rtd_to_cpu(rtd, 0));
+	struct zynqmp_dpsub_audio *audio = dpsub->audio;
+
+	guard(mutex)(&audio->enable_lock);
+
+	/* Nothing to do */
+	if (audio->enabled_streams > 1) {
+		audio->enabled_streams--;
+		return 0;
+	}
+
+	pm_runtime_put(dpsub->dev);
+
+	zynqmp_dp_audio_disable(dpsub->dp);
+
+	/*
+	 * Reset doesn't work. If we assert reset between audio stop and start,
+	 * the audio won't start anymore. Probably we are missing writing
+	 * some audio related registers. A/B buf?
+	 */
+	/*
+	zynqmp_disp_audio_write(audio, ZYNQMP_DISP_AUD_SOFT_RESET,
+				ZYNQMP_DISP_AUD_SOFT_RESET_AUD_SRST);
+	*/
+
+	clk_disable_unprepare(dpsub->aud_clk);
+
+	audio->current_rate = 0;
+	audio->enabled_streams--;
+
+	return 0;
+}
+
+static const struct snd_soc_dai_ops zynqmp_dp_dai_ops = {
+	.hw_params	= dp_dai_hw_params,
+	.hw_free	= dp_dai_hw_free,
+};
+
+/*
+ * Min = 10 * log10(0x1 / 0x2000) = -39.13
+ * Max = 10 * log10(0xffffff / 0x2000) = 9.03
+ */
+static const DECLARE_TLV_DB_RANGE(zynqmp_dp_tlv,
+	0x0, 0x0, TLV_DB_SCALE_ITEM(TLV_DB_GAIN_MUTE, -3913, 1),
+	0x1, 0x2000, TLV_DB_LINEAR_ITEM(-3913, 0),
+	0x2000, 0xffff, TLV_DB_LINEAR_ITEM(0, 903),
+);
+
+static const struct snd_kcontrol_new zynqmp_dp_snd_controls[] = {
+	SOC_SINGLE_TLV("Input0 Playback Volume", 0,
+		       0, 0xffff, 0, zynqmp_dp_tlv),
+	SOC_SINGLE_TLV("Input1 Playback Volume", 1,
+		       0, 0xffff, 0, zynqmp_dp_tlv),
+};
+
+/*
+ * Note: these read & write functions only support two "registers", 0 and 1,
+ * for volume 0 and 1. In other words, these are not real register read/write
+ * functions.
+ *
+ * This is done to support caching the volume value for the case where the
+ * hardware is not enabled, and also to support locking as volumes 0 and 1
+ * are in the same register.
+ */
+static unsigned int zynqmp_dp_dai_read(struct snd_soc_component *component,
+				       unsigned int reg)
+{
+	struct zynqmp_dpsub *dpsub = dev_get_drvdata(component->dev);
+	struct zynqmp_dpsub_audio *audio = dpsub->audio;
+
+	return audio->volumes[reg];
+}
+
+static int zynqmp_dp_dai_write(struct snd_soc_component *component,
+			       unsigned int reg, unsigned int val)
+{
+	struct zynqmp_dpsub *dpsub = dev_get_drvdata(component->dev);
+	struct zynqmp_dpsub_audio *audio = dpsub->audio;
+
+	guard(mutex)(&audio->enable_lock);
+
+	audio->volumes[reg] = val;
+
+	if (audio->enabled_streams)
+		zynqmp_dp_audio_write(audio, ZYNQMP_DISP_AUD_MIXER_VOLUME,
+				      audio->volumes[0] |
+				      (audio->volumes[1] << 16));
+
+	return 0;
+}
+
+static const struct snd_soc_component_driver zynqmp_dp_component_driver = {
+	.idle_bias_on		= 1,
+	.use_pmdown_time	= 1,
+	.endianness		= 1,
+	.controls		= zynqmp_dp_snd_controls,
+	.num_controls		= ARRAY_SIZE(zynqmp_dp_snd_controls),
+	.read			= zynqmp_dp_dai_read,
+	.write			= zynqmp_dp_dai_write,
+};
+
+int zynqmp_audio_init(struct zynqmp_dpsub *dpsub)
+{
+	struct platform_device *pdev = to_platform_device(dpsub->dev);
+	struct device *dev = dpsub->dev;
+	struct zynqmp_dpsub_audio *audio;
+	struct snd_soc_card *card;
+	void *dev_data;
+	int ret;
+
+	if (!dpsub->aud_clk)
+		return 0;
+
+	audio = devm_kzalloc(dev, sizeof(*audio), GFP_KERNEL);
+	if (!audio)
+		return -ENOMEM;
+
+	dpsub->audio = audio;
+
+	mutex_init(&audio->enable_lock);
+
+	/* 0x2000 is the zero level, no change */
+	audio->volumes[0] = 0x2000;
+	audio->volumes[1] = 0x2000;
+
+	audio->dai_name = devm_kasprintf(dev, GFP_KERNEL,
+					 "%s-dai", dev_name(dev));
+
+	for (unsigned int i = 0; i < ZYNQMP_NUM_PCMS; ++i) {
+		audio->link_names[i] = devm_kasprintf(dev, GFP_KERNEL,
+						      "%s-dp-%u", dev_name(dev), i);
+		audio->pcm_names[i] = devm_kasprintf(dev, GFP_KERNEL,
+						     "%s-pcm-%u", dev_name(dev), i);
+	}
+
+	audio->base = devm_platform_ioremap_resource_byname(pdev, "aud");
+	if (IS_ERR(audio->base))
+		return PTR_ERR(audio->base);
+
+	/* Create CPU DAI */
+
+	audio->dai_driver = (struct snd_soc_dai_driver) {
+		.name		= audio->dai_name,
+		.ops		= &zynqmp_dp_dai_ops,
+		.playback	= {
+			.channels_min	= 2,
+			.channels_max	= 2,
+			.rates		= SNDRV_PCM_RATE_44100 | SNDRV_PCM_RATE_48000,
+			.formats	= SNDRV_PCM_FMTBIT_S16_LE,
+		},
+	};
+
+	ret = devm_snd_soc_register_component(dev, &zynqmp_dp_component_driver,
+					      &audio->dai_driver, 1);
+	if (ret) {
+		dev_err(dev, "Failed to register CPU DAI\n");
+		return ret;
+	}
+
+	/* Create PCMs */
+
+	for (unsigned int i = 0; i < ZYNQMP_NUM_PCMS; ++i) {
+		struct snd_dmaengine_pcm_config *pcm_config =
+			&audio->pcm_configs[i];
+
+		*pcm_config = (struct snd_dmaengine_pcm_config){
+			.name = audio->pcm_names[i],
+			.pcm_hardware = &zynqmp_dp_pcm_hw,
+			.prealloc_buffer_size = 64 * 1024,
+			.chan_names[SNDRV_PCM_STREAM_PLAYBACK] =
+				i == 0 ? "aud0" : "aud1",
+		};
+
+		ret = devm_snd_dmaengine_pcm_register(dev, pcm_config, 0);
+		if (ret) {
+			dev_err(dev, "Failed to register PCM %u\n", i);
+			return ret;
+		}
+	}
+
+	/* Create card */
+
+	card = &audio->card;
+	card->name = "DisplayPort";
+	card->long_name = "DisplayPort Monitor";
+	card->driver_name = "zynqmp_dpsub";
+	card->dev = dev;
+	card->owner = THIS_MODULE;
+	card->num_links = ZYNQMP_NUM_PCMS;
+	card->dai_link = audio->links;
+
+	for (unsigned int i = 0; i < ZYNQMP_NUM_PCMS; ++i) {
+		struct snd_soc_dai_link *link = &card->dai_link[i];
+
+		link->ops = &zynqmp_dp_ops;
+
+		link->name = audio->link_names[i];
+		link->stream_name = audio->link_names[i];
+
+		link->cpus = &audio->components[i].cpu;
+		link->num_cpus = 1;
+		link->cpus[0].dai_name = audio->dai_name;
+
+		link->codecs = &audio->components[i].codec;
+		link->num_codecs = 1;
+		link->codecs[0].name = "snd-soc-dummy";
+		link->codecs[0].dai_name = "snd-soc-dummy-dai";
+
+		link->platforms = &audio->components[i].platform;
+		link->num_platforms = 1;
+		link->platforms[0].name = audio->pcm_names[i];
+	}
+
+	/*
+	 * HACK: devm_snd_soc_register_card() overwrites current drvdata
+	 * so we need to hack it back.
+	 */
+	dev_data = dev_get_drvdata(dev);
+	ret = devm_snd_soc_register_card(dev, card);
+	dev_set_drvdata(dev, dev_data);
+	if (ret) {
+		/*
+		 * As older dtbs may not have the audio channel dmas defined,
+		 * instead of returning an error here we'll continue and just
+		 * mark the audio as disabled.
+		 */
+		dev_err(dev, "Failed to register sound card, disabling audio support\n");
+
+		devm_kfree(dev, audio);
+		dpsub->audio = NULL;
+
+		return 0;
+	}
+
+	return 0;
+}
+
+void zynqmp_audio_uninit(struct zynqmp_dpsub *dpsub)
+{
+	struct zynqmp_dpsub_audio *audio = dpsub->audio;
+
+	if (!audio)
+		return;
+
+	if (!dpsub->aud_clk)
+		return;
+
+	mutex_destroy(&audio->enable_lock);
+}
diff --git a/drivers/gpu/drm/xlnx/zynqmp_dpsub.c b/drivers/gpu/drm/xlnx/zynqmp_dpsub.c
index a25b22238..d6f45bf3e 100644
--- a/drivers/gpu/drm/xlnx/zynqmp_dpsub.c
+++ b/drivers/gpu/drm/xlnx/zynqmp_dpsub.c
@@ -39,16 +39,22 @@ static int __maybe_unused zynqmp_dpsub_suspend(struct device *dev)
 	if (!dpsub->drm)
 		return 0;
 
+	zynqmp_dp_phy_exit(dpsub->dp);
 	return drm_mode_config_helper_suspend(&dpsub->drm->dev);
 }
 
 static int __maybe_unused zynqmp_dpsub_resume(struct device *dev)
 {
 	struct zynqmp_dpsub *dpsub = dev_get_drvdata(dev);
+	int ret;
 
 	if (!dpsub->drm)
 		return 0;
 
+	ret = zynqmp_dp_phy_init(dpsub->dp);
+	if (ret)
+		return ret;
+
 	return drm_mode_config_helper_resume(&dpsub->drm->dev);
 }
 
@@ -56,36 +62,6 @@ static const struct dev_pm_ops zynqmp_dpsub_pm_ops = {
 	SET_SYSTEM_SLEEP_PM_OPS(zynqmp_dpsub_suspend, zynqmp_dpsub_resume)
 };
 
-/* -----------------------------------------------------------------------------
- * DPSUB Configuration
- */
-
-/**
- * zynqmp_dpsub_audio_enabled - If the audio is enabled
- * @dpsub: DisplayPort subsystem
- *
- * Return if the audio is enabled depending on the audio clock.
- *
- * Return: true if audio is enabled, or false.
- */
-bool zynqmp_dpsub_audio_enabled(struct zynqmp_dpsub *dpsub)
-{
-	return !!dpsub->aud_clk;
-}
-
-/**
- * zynqmp_dpsub_get_audio_clk_rate - Get the current audio clock rate
- * @dpsub: DisplayPort subsystem
- *
- * Return: the current audio clock rate.
- */
-unsigned int zynqmp_dpsub_get_audio_clk_rate(struct zynqmp_dpsub *dpsub)
-{
-	if (zynqmp_dpsub_audio_enabled(dpsub))
-		return 0;
-	return clk_get_rate(dpsub->aud_clk);
-}
-
 /* -----------------------------------------------------------------------------
  * Probe & Remove
  */
@@ -266,10 +242,17 @@ static int zynqmp_dpsub_probe(struct platform_device *pdev)
 			goto err_disp;
 	}
 
+	ret = zynqmp_audio_init(dpsub);
+	if (ret)
+		goto err_drm_cleanup;
+
 	dev_info(&pdev->dev, "ZynqMP DisplayPort Subsystem driver probed");
 
 	return 0;
 
+err_drm_cleanup:
+	if (dpsub->drm)
+		zynqmp_dpsub_drm_cleanup(dpsub);
 err_disp:
 	drm_bridge_remove(dpsub->bridge);
 	zynqmp_disp_remove(dpsub);
@@ -289,6 +272,8 @@ static void zynqmp_dpsub_remove(struct platform_device *pdev)
 {
 	struct zynqmp_dpsub *dpsub = platform_get_drvdata(pdev);
 
+	zynqmp_audio_uninit(dpsub);
+
 	if (dpsub->drm)
 		zynqmp_dpsub_drm_cleanup(dpsub);
 
diff --git a/drivers/gpu/drm/xlnx/zynqmp_dpsub.h b/drivers/gpu/drm/xlnx/zynqmp_dpsub.h
index b18554467..d771b8b19 100644
--- a/drivers/gpu/drm/xlnx/zynqmp_dpsub.h
+++ b/drivers/gpu/drm/xlnx/zynqmp_dpsub.h
@@ -12,6 +12,8 @@
 #ifndef _ZYNQMP_DPSUB_H_
 #define _ZYNQMP_DPSUB_H_
 
+#include <linux/types.h>
+
 struct clk;
 struct device;
 struct drm_bridge;
@@ -39,6 +41,8 @@ enum zynqmp_dpsub_format {
 	ZYNQMP_DPSUB_FORMAT_YONLY,
 };
 
+struct zynqmp_dpsub_audio;
+
 /**
  * struct zynqmp_dpsub - ZynqMP DisplayPort Subsystem
  * @dev: The physical device
@@ -56,6 +60,7 @@ enum zynqmp_dpsub_format {
  * @layers: Video and graphics layers
  * @dp: The DisplayPort controller
  * @dma_align: DMA alignment constraint (must be a power of 2)
+ * @audio: DP audio data
  */
 struct zynqmp_dpsub {
 	struct device *dev;
@@ -77,10 +82,17 @@ struct zynqmp_dpsub {
 	struct zynqmp_dp *dp;
 
 	unsigned int dma_align;
+
+	struct zynqmp_dpsub_audio *audio;
 };
 
-bool zynqmp_dpsub_audio_enabled(struct zynqmp_dpsub *dpsub);
-unsigned int zynqmp_dpsub_get_audio_clk_rate(struct zynqmp_dpsub *dpsub);
+#ifdef CONFIG_DRM_ZYNQMP_DPSUB_AUDIO
+int zynqmp_audio_init(struct zynqmp_dpsub *dpsub);
+void zynqmp_audio_uninit(struct zynqmp_dpsub *dpsub);
+#else
+static inline int zynqmp_audio_init(struct zynqmp_dpsub *dpsub) { return 0; }
+static inline void zynqmp_audio_uninit(struct zynqmp_dpsub *dpsub) { }
+#endif
 
 void zynqmp_dpsub_release(struct zynqmp_dpsub *dpsub);
 
diff --git a/drivers/gpu/drm/xlnx/zynqmp_kms.c b/drivers/gpu/drm/xlnx/zynqmp_kms.c
index 1565a7dd4..20eac03e8 100644
--- a/drivers/gpu/drm/xlnx/zynqmp_kms.c
+++ b/drivers/gpu/drm/xlnx/zynqmp_kms.c
@@ -11,6 +11,7 @@
 
 #include <drm/drm_atomic.h>
 #include <drm/drm_atomic_helper.h>
+#include <drm/drm_atomic_uapi.h>
 #include <drm/drm_blend.h>
 #include <drm/drm_bridge.h>
 #include <drm/drm_bridge_connector.h>
@@ -129,14 +130,95 @@ static void zynqmp_dpsub_plane_atomic_update(struct drm_plane *plane,
 	zynqmp_disp_layer_enable(layer);
 }
 
+static int
+zynqmp_dpsub_plane_atomic_update_plane(struct drm_plane *plane,
+				       struct drm_crtc *crtc,
+				       struct drm_framebuffer *fb,
+				       int crtc_x, int crtc_y,
+				       unsigned int crtc_w, unsigned int crtc_h,
+				       u32 src_x, u32 src_y,
+				       u32 src_w, u32 src_h,
+				       struct drm_modeset_acquire_ctx *ctx)
+{
+	struct drm_atomic_state *state;
+	struct drm_plane_state *plane_state;
+	int ret;
+
+	state = drm_atomic_state_alloc(plane->dev);
+	if (!state)
+		return -ENOMEM;
+
+	state->acquire_ctx = ctx;
+	plane_state = drm_atomic_get_plane_state(state, plane);
+	if (IS_ERR(plane_state)) {
+		ret = PTR_ERR(plane_state);
+		goto fail;
+	}
+
+	ret = drm_atomic_set_crtc_for_plane(plane_state, crtc);
+	if (ret)
+		goto fail;
+
+	drm_atomic_set_fb_for_plane(plane_state, fb);
+	plane_state->crtc_x = crtc_x;
+	plane_state->crtc_y = crtc_y;
+	plane_state->crtc_w = crtc_w;
+	plane_state->crtc_h = crtc_h;
+	plane_state->src_x = src_x;
+	plane_state->src_y = src_y;
+	plane_state->src_w = src_w;
+	plane_state->src_h = src_h;
+
+	if (plane == crtc->cursor)
+		state->legacy_cursor_update = true;
+
+	/* Do async-update if possible */
+	state->async_update = !drm_atomic_helper_async_check(plane->dev, state);
+	ret = drm_atomic_commit(state);
+fail:
+	drm_atomic_state_put(state);
+	return ret;
+}
+
+static int
+zynqmp_dpsub_plane_atomic_async_check(struct drm_plane *plane,
+				      struct drm_atomic_state *state)
+{
+	return 0;
+}
+
+static void
+zynqmp_dpsub_plane_atomic_async_update(struct drm_plane *plane,
+				       struct drm_atomic_state *state)
+{
+	struct drm_plane_state *new_state = drm_atomic_get_new_plane_state(state, plane);
+
+	/* Update the current state with new configurations */
+	swap(plane->state->fb, new_state->fb);
+	plane->state->crtc = new_state->crtc;
+	plane->state->crtc_x = new_state->crtc_x;
+	plane->state->crtc_y = new_state->crtc_y;
+	plane->state->crtc_w = new_state->crtc_w;
+	plane->state->crtc_h = new_state->crtc_h;
+	plane->state->src_x = new_state->src_x;
+	plane->state->src_y = new_state->src_y;
+	plane->state->src_w = new_state->src_w;
+	plane->state->src_h = new_state->src_h;
+	plane->state->state = new_state->state;
+
+	zynqmp_dpsub_plane_atomic_update(plane, state);
+}
+
 static const struct drm_plane_helper_funcs zynqmp_dpsub_plane_helper_funcs = {
 	.atomic_check		= zynqmp_dpsub_plane_atomic_check,
 	.atomic_update		= zynqmp_dpsub_plane_atomic_update,
 	.atomic_disable		= zynqmp_dpsub_plane_atomic_disable,
+	.atomic_async_check	= zynqmp_dpsub_plane_atomic_async_check,
+	.atomic_async_update	= zynqmp_dpsub_plane_atomic_async_update,
 };
 
 static const struct drm_plane_funcs zynqmp_dpsub_plane_funcs = {
-	.update_plane		= drm_atomic_helper_update_plane,
+	.update_plane		= zynqmp_dpsub_plane_atomic_update_plane,
 	.disable_plane		= drm_atomic_helper_disable_plane,
 	.destroy		= drm_plane_cleanup,
 	.reset			= drm_atomic_helper_plane_reset,
@@ -523,7 +605,7 @@ int zynqmp_dpsub_drm_init(struct zynqmp_dpsub *dpsub)
 		goto err_poll_fini;
 
 	/* Initialize fbdev generic emulation. */
-	drm_fbdev_dma_setup(drm, 24);
+	drm_fbdev_dma_setup(drm, 16);
 
 	return 0;
 
diff --git a/include/drm/display/drm_dp.h b/include/drm/display/drm_dp.h
index 3bd9f482f..e0f9587ca 100644
--- a/include/drm/display/drm_dp.h
+++ b/include/drm/display/drm_dp.h
@@ -1158,6 +1158,7 @@
 
 /* Extended Receiver Capability: See DP_DPCD_REV for definitions */
 #define DP_DP13_DPCD_REV                    0x2200
+#define DP_DP13_MAX_LINK_RATE               0x2201
 
 #define DP_DPRX_FEATURE_ENUMERATION_LIST    0x2210  /* DP 1.3 */
 # define DP_GTC_CAP					(1 << 0)  /* DP 1.3 */
diff --git a/include/drm/display/drm_hdmi_helper.h b/include/drm/display/drm_hdmi_helper.h
index 57e3b18c1..9b516b65b 100644
--- a/include/drm/display/drm_hdmi_helper.h
+++ b/include/drm/display/drm_hdmi_helper.h
@@ -21,6 +21,10 @@ int
 drm_hdmi_infoframe_set_hdr_metadata(struct hdmi_drm_infoframe *frame,
 				    const struct drm_connector_state *conn_state);
 
+int
+drm_hdmi_infoframe_set_gen_hdr_metadata(struct hdmi_drm_infoframe *frame,
+					const struct drm_connector_state *conn_state);
+
 void drm_hdmi_avi_infoframe_content_type(struct hdmi_avi_infoframe *frame,
 					 const struct drm_connector_state *conn_state);
 
diff --git a/include/drm/drm_connector.h b/include/drm/drm_connector.h
index 1e2b25e20..b781b70b5 100644
--- a/include/drm/drm_connector.h
+++ b/include/drm/drm_connector.h
@@ -1134,6 +1134,12 @@ struct drm_connector_state {
 	 */
 	struct drm_property_blob *hdr_output_metadata;
 
+	/**
+	 * @gen_hdr_output_metadata:
+	 * DRM blob property for Generic HDR output metadata
+	 */
+	struct drm_property_blob *gen_hdr_output_metadata;
+
 	/**
 	 * @hdmi: HDMI-related variable and properties. Filled by
 	 * @drm_atomic_helper_connector_hdmi_check().
diff --git a/include/drm/drm_edid.h b/include/drm/drm_edid.h
index eaac5e665..f4bd6ebe3 100644
--- a/include/drm/drm_edid.h
+++ b/include/drm/drm_edid.h
@@ -443,6 +443,9 @@ int drm_edid_header_is_valid(const void *edid);
 bool drm_edid_is_valid(struct edid *edid);
 void drm_edid_get_monitor_name(const struct edid *edid, char *name,
 			       int buflen);
+struct drm_display_mode *drm_mode_find_cea(struct drm_device *dev,
+					   int hsize, int vsize, int fresh,
+					   bool interlaced);
 struct drm_display_mode *drm_mode_find_dmt(struct drm_device *dev,
 					   int hsize, int vsize, int fresh,
 					   bool rb);
diff --git a/include/drm/drm_fourcc.h b/include/drm/drm_fourcc.h
index c3f4405d6..27cd857c5 100644
--- a/include/drm/drm_fourcc.h
+++ b/include/drm/drm_fourcc.h
@@ -129,6 +129,25 @@ struct drm_format_info {
 	 */
 	u8 block_h[DRM_FORMAT_MAX_PLANES];
 
+	/**
+	 * @pixels_per_macropixel:
+	 * Number of pixels per macro-pixel (per plane). A macro-pixel is
+	 * composed of multiple pixels, and there can be extra bits between
+	 * pixels. This must be used along with @bytes_per_macropixel, only
+	 * when single pixel size is not byte-aligned. In this case, @cpp
+	 * is not valid and should be 0.
+	 */
+	u8 pixels_per_macropixel[3];
+
+	/**
+	 * @bytes_per_macropixel:
+	 * Number of bytes per macro-pixel (per plane). A macro-pixel is
+	 * composed of multiple pixels. The size of single macro-pixel should
+	 * be byte-aligned. This should be used with @pixels_per_macropixel,
+	 * and @cpp should be 0.
+	 */
+	u8 bytes_per_macropixel[3];
+
 	/** @hsub: Horizontal chroma subsampling factor */
 	u8 hsub;
 	/** @vsub: Vertical chroma subsampling factor */
@@ -321,5 +340,7 @@ unsigned int drm_format_info_block_height(const struct drm_format_info *info,
 unsigned int drm_format_info_bpp(const struct drm_format_info *info, int plane);
 uint64_t drm_format_info_min_pitch(const struct drm_format_info *info,
 				   int plane, unsigned int buffer_width);
+uint64_t drm_format_plane_width_bytes(const struct drm_format_info *info,
+				 int plane, unsigned int width);
 
 #endif /* __DRM_FOURCC_H__ */
diff --git a/include/drm/drm_mode_config.h b/include/drm/drm_mode_config.h
index 271765e2e..87aa1e00d 100644
--- a/include/drm/drm_mode_config.h
+++ b/include/drm/drm_mode_config.h
@@ -869,6 +869,15 @@ struct drm_mode_config {
 	 */
 	struct drm_property *hdr_output_metadata_property;
 
+	/**
+	 * @gen_hdr_output_metadata_property: Connector property containing hdr
+	 * metadata. This will be provided by userspace compositors based
+	 * on HDR content. This is functionally the same as
+	 * hdr_output_metadata_property but it uses a generic, experimental
+	 * structure instead of the existing HDR10 specific structure
+	 */
+	struct drm_property *gen_hdr_output_metadata_property;
+
 	/**
 	 * @content_protection_property: DRM ENUM property for content
 	 * protection. See drm_connector_attach_content_protection_property().
diff --git a/include/dt-bindings/drm/mipi-dsi.h b/include/dt-bindings/drm/mipi-dsi.h
new file mode 100644
index 000000000..c6f37ec66
--- /dev/null
+++ b/include/dt-bindings/drm/mipi-dsi.h
@@ -0,0 +1,11 @@
+#ifndef __DT_BINDINGS_DRM__
+#define __DT_BINDINGS_DRM__
+/*
+ * MIPI DSI pixel formats as defined in the include/drm/drm_mipi_dsi.h"
+ */
+#define MIPI_DSI_FMT_RGB888		0
+#define MIPI_DSI_FMT_RGB666		1
+#define MIPI_DSI_FMT_RGB666_PACKED	2
+#define MIPI_DSI_FMT_RGB565		3
+
+#endif /* _DT_BINDINGS_DRM__ */
diff --git a/include/uapi/drm/drm_fourcc.h b/include/uapi/drm/drm_fourcc.h
index 78abd819f..a7234cce1 100644
--- a/include/uapi/drm/drm_fourcc.h
+++ b/include/uapi/drm/drm_fourcc.h
@@ -241,10 +241,12 @@ extern "C" {
 #define DRM_FORMAT_VYUY		fourcc_code('V', 'Y', 'U', 'Y') /* [31:0] Y1:Cb0:Y0:Cr0 8:8:8:8 little endian */
 
 #define DRM_FORMAT_AYUV		fourcc_code('A', 'Y', 'U', 'V') /* [31:0] A:Y:Cb:Cr 8:8:8:8 little endian */
+#define DRM_FORMAT_AVUY		fourcc_code('A', 'V', 'U', 'Y') /* [31:0] A:Cr:Cb:Y 8:8:8:8 little endian */
 #define DRM_FORMAT_AVUY8888	fourcc_code('A', 'V', 'U', 'Y') /* [31:0] A:Cr:Cb:Y 8:8:8:8 little endian */
 #define DRM_FORMAT_XYUV8888	fourcc_code('X', 'Y', 'U', 'V') /* [31:0] X:Y:Cb:Cr 8:8:8:8 little endian */
 #define DRM_FORMAT_XVUY8888	fourcc_code('X', 'V', 'U', 'Y') /* [31:0] X:Cr:Cb:Y 8:8:8:8 little endian */
 #define DRM_FORMAT_VUY888	fourcc_code('V', 'U', '2', '4') /* [23:0] Cr:Cb:Y 8:8:8 little endian */
+#define DRM_FORMAT_XVUY2101010	fourcc_code('X', 'V', '3', '0') /* [31:0] x:Cr:Cb:Y 2:10:10:10 little endian */
 #define DRM_FORMAT_VUY101010	fourcc_code('V', 'U', '3', '0') /* Y followed by U then V, 10:10:10. Non-linear modifier only */
 
 /*
@@ -290,6 +292,10 @@ extern "C" {
 #define DRM_FORMAT_YUV420_8BIT	fourcc_code('Y', 'U', '0', '8')
 #define DRM_FORMAT_YUV420_10BIT	fourcc_code('Y', 'U', '1', '0')
 
+/* Grey scale */
+#define DRM_FORMAT_Y8		fourcc_code('G', 'R', 'E', 'Y') /* 8  Greyscale	*/
+#define DRM_FORMAT_Y10		fourcc_code('Y', '1', '0', ' ') /* 10 Greyscale */
+
 /*
  * 2 plane RGB + A
  * index 0 = RGB plane, same format as the corresponding non _A8 format has
@@ -304,6 +310,14 @@ extern "C" {
 #define DRM_FORMAT_RGB565_A8	fourcc_code('R', '5', 'A', '8')
 #define DRM_FORMAT_BGR565_A8	fourcc_code('B', '5', 'A', '8')
 
+/*
+ * 2 plane 10 bit per component YCrCb
+ * index 0 = Y plane, [31:0] x:Y2:Y1:Y0 2:10:10:10 little endian
+ * index 1 = Cb:Cr plane, [63:0] x:Cr2:Cb2:Cr1:x:Cb1:Cr0:Cb0 2:10:10:10:2:10:10:10 little endian
+ */
+#define DRM_FORMAT_XV15		fourcc_code('X', 'V', '1', '5') /* 2x2 subsampled Cr:Cb plane 2:10:10:10 */
+#define DRM_FORMAT_XV20		fourcc_code('X', 'V', '2', '0') /* 2x1 subsampled Cr:Cb plane 2:10:10:10 */
+
 /*
  * 2 plane YCbCr
  * index 0 = Y plane, [7:0] Y
@@ -377,6 +391,23 @@ extern "C" {
  */
 #define DRM_FORMAT_Q401		fourcc_code('Q', '4', '0', '1')
 
+/* 3 plane non-subsampled (444) YCbCr
+ * 10 bpc, 30 bits per sample image data in a single contiguous buffer.
+ * index 0: Y plane, [31:0] x:Y2:Y1:Y0 [2:10:10:10] little endian
+ * index 1: Cb plane, [31:0] x:Cb2:Cb1:Cb0 [2:10:10:10] little endian
+ * index 2: Cr plane, [31:0] x:Cr2:Cr1:Cr0 [2:10:10:10] little endian
+ */
+#define DRM_FORMAT_X403		fourcc_code('X', '4', '0', '3') /* non-subsampled Cb:Cr plane, 10 bit per channel */
+
+/*
+ * 3 plane non-subsampled (444) YCbCr
+ * 12 bits per component, 24 bits contains 2 pixels
+ * index 0: Y plane, [23:12] Y1 [11:0] Y0
+ * index 1: Cb plane, [23:12] Cb1 [11:0] Cb0
+ * index 2: Cr plane, [23:12] Cr1 [11:0] Cr0
+ */
+#define DRM_FORMAT_X423 fourcc_code('X', '4', '2', '3')
+
 /*
  * 3 plane YCbCr
  * index 0: Y plane, [7:0] Y
@@ -397,6 +428,10 @@ extern "C" {
 #define DRM_FORMAT_YUV444	fourcc_code('Y', 'U', '2', '4') /* non-subsampled Cb (1) and Cr (2) planes */
 #define DRM_FORMAT_YVU444	fourcc_code('Y', 'V', '2', '4') /* non-subsampled Cr (1) and Cb (2) planes */
 
+/* Greyscale formats */
+
+#define DRM_FORMAT_Y8		fourcc_code('G', 'R', 'E', 'Y')  /* 8-bit Y-only */
+#define DRM_FORMAT_Y10_LE32	fourcc_code('Y', '1', '0', 'P')  /* [31:0] x:Y2:Y1:Y0 2:10:10:10 little endian */
 
 /*
  * Format Modifiers:
diff --git a/include/uapi/drm/drm_mode.h b/include/uapi/drm/drm_mode.h
index c082810c0..a4c1ed486 100644
--- a/include/uapi/drm/drm_mode.h
+++ b/include/uapi/drm/drm_mode.h
@@ -665,6 +665,8 @@ struct drm_mode_fb_cmd {
 
 #define DRM_MODE_FB_INTERLACED	(1<<0) /* for interlaced framebuffers */
 #define DRM_MODE_FB_MODIFIERS	(1<<1) /* enables ->modifier[] */
+#define DRM_MODE_FB_ALTERNATE_TOP	(1<<2) /* for alternate top field */
+#define DRM_MODE_FB_ALTERNATE_BOTTOM	(1<<3) /* for alternate bottom field */
 
 /**
  * struct drm_mode_fb_cmd2 - Frame-buffer metadata.
@@ -857,6 +859,20 @@ struct drm_color_lut {
 	__u16 reserved;
 };
 
+enum drm_hdr_type {
+	/*
+	 * This is for the gen_hdr_output_metadata structure.
+	 * MSB differentiates static (0) or dynamic (1) metadata.
+	 * Other 15 bits represent specific HDR standards.
+	 */
+
+	/* static HDR */
+	DRM_HDR_TYPE_HDR10     = 0x0000,
+
+	/* dynamic HDR */
+	DRM_HDR_TYPE_HDR10P    = 1 << 15 | DRM_HDR_TYPE_HDR10,
+};
+
 /**
  * struct drm_plane_size_hint - Plane size hints
  * @width: The width of the plane in pixel
@@ -956,6 +972,27 @@ struct hdr_output_metadata {
 	};
 };
 
+/**
+ * struct gen_hdr_output_metadata - Generic HDR output metadata
+ *
+ * Generic HDR Metadata Information to be passed from userspace
+ */
+struct gen_hdr_output_metadata {
+	/**
+	 * @metadata_type: HDR type.
+	 */
+	__u16 metadata_type;
+	/**
+	 * @size: size of payload/metadata.
+	 */
+	__u16 size;
+	/**
+	 * @payload: Actual metadata - HDR Metadata Infoframe.
+	 * Currently the largest extended HDR infoframe is 4000 bytes.
+	 */
+	__u8 payload[4000];
+};
+
 /**
  * DRM_MODE_PAGE_FLIP_EVENT
  *
