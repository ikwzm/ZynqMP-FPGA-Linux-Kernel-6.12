diff --git a/Documentation/devicetree/bindings/spi/cdns,qspi-nor.yaml b/Documentation/devicetree/bindings/spi/cdns,qspi-nor.yaml
index d48ecd6cd..b6bc71d19 100644
--- a/Documentation/devicetree/bindings/spi/cdns,qspi-nor.yaml
+++ b/Documentation/devicetree/bindings/spi/cdns,qspi-nor.yaml
@@ -68,6 +68,7 @@ properties:
       - items:
           - enum:
               - amd,pensando-elba-qspi
+              - amd,versal2-ospi
               - intel,lgm-qspi
               - intel,socfpga-qspi
               - mobileye,eyeq5-ospi
diff --git a/Documentation/devicetree/bindings/spi/spi-controller.yaml b/Documentation/devicetree/bindings/spi/spi-controller.yaml
index 093150c0c..22a9d2e37 100644
--- a/Documentation/devicetree/bindings/spi/spi-controller.yaml
+++ b/Documentation/devicetree/bindings/spi/spi-controller.yaml
@@ -188,4 +188,12 @@ examples:
             reg = <2>, <3>;
             stacked-memories = /bits/ 64 <0x10000000 0x10000000>;
         };
+
+        flash@5 {
+            compatible = "jedec,spi-nor";
+            spi-max-frequency = <50000000>;
+            reg = <5>;
+            multi-die;
+        };
+
     };
diff --git a/Documentation/devicetree/bindings/spi/spi-peripheral-props.yaml b/Documentation/devicetree/bindings/spi/spi-peripheral-props.yaml
index 0bb443b8d..f7637a708 100644
--- a/Documentation/devicetree/bindings/spi/spi-peripheral-props.yaml
+++ b/Documentation/devicetree/bindings/spi/spi-peripheral-props.yaml
@@ -118,6 +118,11 @@ properties:
       Only for STM32H7, (Master Inter-Data Idleness) minimum time
       delay in nanoseconds inserted between two consecutive data frames.
 
+  multi-die:
+    $ref: /schemas/types.yaml#/definitions/flag
+    description:
+      The device consists of multiple memory die.
+
 # The controller specific properties go here.
 allOf:
   - $ref: arm,pl022-peripheral-props.yaml#
diff --git a/Documentation/devicetree/bindings/spi/spi-zynqmp-qspi.yaml b/Documentation/devicetree/bindings/spi/spi-zynqmp-qspi.yaml
index e5199b109..32a009972 100644
--- a/Documentation/devicetree/bindings/spi/spi-zynqmp-qspi.yaml
+++ b/Documentation/devicetree/bindings/spi/spi-zynqmp-qspi.yaml
@@ -9,9 +9,6 @@ title: Xilinx Zynq UltraScale+ MPSoC GQSPI controller
 maintainers:
   - Michal Simek <michal.simek@amd.com>
 
-allOf:
-  - $ref: spi-controller.yaml#
-
 properties:
   compatible:
     enum:
@@ -19,6 +16,7 @@ properties:
       - xlnx,zynqmp-qspi-1.0
 
   reg:
+    minItems: 1
     maxItems: 2
 
   interrupts:
@@ -38,6 +36,13 @@ properties:
   power-domains:
     maxItems: 1
 
+  has-io-mode:
+    $ref: /schemas/types.yaml#/definitions/flag
+    description:
+      Describes the controller operating mode.
+      If exists controller will operate in IO
+      mode else DMA mode.
+
 required:
   - compatible
   - reg
@@ -47,6 +52,24 @@ required:
 
 unevaluatedProperties: false
 
+allOf:
+  - $ref: spi-controller.yaml#
+
+  - if:
+      properties:
+        compatible:
+          contains:
+            const: xlnx,zynqmp-qspi-1.0
+    then:
+      properties:
+        reg:
+          minItems: 2
+
+    else:
+      properties:
+        reg:
+          maxItems: 1
+
 examples:
   - |
     #include <dt-bindings/clock/xlnx-zynqmp-clk.h>
@@ -62,5 +85,6 @@ examples:
         interrupt-parent = <&gic>;
         reg = <0x0 0xff0f0000 0x0 0x1000>,
               <0x0 0xc0000000 0x0 0x8000000>;
+        has-io-mode;
       };
     };
diff --git a/Documentation/devicetree/bindings/trivial-devices.yaml b/Documentation/devicetree/bindings/trivial-devices.yaml
index 9bf0fb17a..c3d2866f6 100644
--- a/Documentation/devicetree/bindings/trivial-devices.yaml
+++ b/Documentation/devicetree/bindings/trivial-devices.yaml
@@ -390,6 +390,8 @@ properties:
           - ti,tps53676
             # TI Dual channel DCAP+ multiphase controller TPS53679
           - ti,tps53679
+            # TI Dual channel DCAP+ multiphase controller TPS53681
+          - ti,tps53681
             # TI Dual channel DCAP+ multiphase controller TPS53688
           - ti,tps53688
             # TI DC-DC converters on PMBus
@@ -397,6 +399,7 @@ properties:
           - ti,tps544b25
           - ti,tps544c20
           - ti,tps544c25
+          - ti,tps546b24
           - ti,tps546d24
             # I2C Touch-Screen Controller
           - ti,tsc2003
diff --git a/drivers/spi/spi-cadence-quadspi.c b/drivers/spi/spi-cadence-quadspi.c
index f9463f263..17099e671 100644
--- a/drivers/spi/spi-cadence-quadspi.c
+++ b/drivers/spi/spi-cadence-quadspi.c
@@ -29,9 +29,11 @@
 #include <linux/spi/spi.h>
 #include <linux/spi/spi-mem.h>
 #include <linux/timer.h>
+#include <linux/workqueue.h>
 
 #define CQSPI_NAME			"cadence-qspi"
 #define CQSPI_MAX_CHIPSELECT		4
+#define CQSPI_MIN_CHIPSELECT		1
 
 static_assert(CQSPI_MAX_CHIPSELECT <= SPI_CS_CNT_MAX);
 
@@ -43,7 +45,9 @@ static_assert(CQSPI_MAX_CHIPSELECT <= SPI_CS_CNT_MAX);
 #define CQSPI_SLOW_SRAM		BIT(4)
 #define CQSPI_NEEDS_APB_AHB_HAZARD_WAR	BIT(5)
 #define CQSPI_RD_NO_IRQ			BIT(6)
-#define CQSPI_DISABLE_STIG_MODE		BIT(7)
+#define CQSPI_DMA_SET_MASK		BIT(7)
+#define CQSPI_SUPPORT_DEVICE_RESET	BIT(8)
+#define CQSPI_DISABLE_STIG_MODE		BIT(9)
 
 /* Capabilities */
 #define CQSPI_SUPPORTS_OCTAL		BIT(0)
@@ -66,6 +70,7 @@ struct cqspi_flash_pdata {
 	u32		tsd2d_ns;
 	u32		tchsh_ns;
 	u32		tslch_ns;
+	bool		dtr;
 	u8		cs;
 };
 
@@ -107,11 +112,16 @@ struct cqspi_st {
 	bool			disable_stig_mode;
 
 	const struct cqspi_driver_platdata *ddata;
+	bool			extra_dummy;
+	bool			clk_tuned;
+	struct completion	tuning_complete;
+	struct spi_mem_op	tuning_op;
+	bool			tuning_scheduled;
 };
 
 struct cqspi_driver_platdata {
 	u32 hwcaps_mask;
-	u8 quirks;
+	u16 quirks;
 	int (*indirect_read_dma)(struct cqspi_flash_pdata *f_pdata,
 				 u_char *rxbuf, loff_t from_addr, size_t n_rx);
 	u32 (*get_dma_status)(struct cqspi_st *cqspi);
@@ -126,6 +136,8 @@ struct cqspi_driver_platdata {
 
 /* Runtime_pm autosuspend delay */
 #define CQSPI_AUTOSUSPEND_TIMEOUT		2000
+#define CQSPI_TUNING_TIMEOUT_MS			5000
+#define CQSPI_TUNING_PERIODICITY_MS		300000
 
 #define CQSPI_DUMMY_CLKS_PER_BYTE		8
 #define CQSPI_DUMMY_BYTES_MAX			4
@@ -136,6 +148,7 @@ struct cqspi_driver_platdata {
 /* Register map */
 #define CQSPI_REG_CONFIG			0x00
 #define CQSPI_REG_CONFIG_ENABLE_MASK		BIT(0)
+#define CQSPI_REG_CONFIG_PHY_ENABLE_MASK	BIT(3)
 #define CQSPI_REG_CONFIG_ENB_DIR_ACC_CTRL	BIT(7)
 #define CQSPI_REG_CONFIG_DECODE_MASK		BIT(9)
 #define CQSPI_REG_CONFIG_CHIPSELECT_LSB		10
@@ -146,6 +159,8 @@ struct cqspi_driver_platdata {
 #define CQSPI_REG_CONFIG_IDLE_LSB		31
 #define CQSPI_REG_CONFIG_CHIPSELECT_MASK	0xF
 #define CQSPI_REG_CONFIG_BAUD_MASK		0xF
+#define CQSPI_REG_CONFIG_RESET_PIN_FLD_MASK    BIT(5)
+#define CQSPI_REG_CONFIG_RESET_CFG_FLD_MASK    BIT(6)
 
 #define CQSPI_REG_RD_INSTR			0x04
 #define CQSPI_REG_RD_INSTR_OPCODE_LSB		0
@@ -178,6 +193,7 @@ struct cqspi_driver_platdata {
 #define CQSPI_REG_READCAPTURE_BYPASS_LSB	0
 #define CQSPI_REG_READCAPTURE_DELAY_LSB		1
 #define CQSPI_REG_READCAPTURE_DELAY_MASK	0xF
+#define CQSPI_REG_READCAPTURE_DQS_ENABLE	BIT(8)
 
 #define CQSPI_REG_SIZE				0x14
 #define CQSPI_REG_SIZE_ADDRESS_LSB		0
@@ -207,9 +223,12 @@ struct cqspi_driver_platdata {
 
 #define CQSPI_REG_WR_COMPLETION_CTRL		0x38
 #define CQSPI_REG_WR_DISABLE_AUTO_POLL		BIT(14)
+#define CQSPI_REG_WRCOMPLETION_POLLCNT_MASK	0xFF0000
+#define CQSPI_REG_WRCOMPLETION_POLLCNY_LSB	16
 
 #define CQSPI_REG_IRQSTATUS			0x40
 #define CQSPI_REG_IRQMASK			0x44
+#define CQSPI_REG_VERSAL_ECO			0x48
 
 #define CQSPI_REG_INDIRECTRD			0x60
 #define CQSPI_REG_INDIRECTRD_START_MASK		BIT(0)
@@ -256,6 +275,19 @@ struct cqspi_driver_platdata {
 #define CQSPI_REG_POLLING_STATUS		0xB0
 #define CQSPI_REG_POLLING_STATUS_DUMMY_LSB	16
 
+#define CQSPI_REG_PHY_CONFIG			0xB4
+#define CQSPI_REG_PHY_CONFIG_RESYNC_FLD_MASK	0x80000000
+#define CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK	0x40000000
+#define CQSPI_REG_PHY_CONFIG_TX_DLL_DLY_LSB	16
+
+#define CQSPI_REG_PHY_MASTER_CTRL		0xB8
+#define CQSPI_REG_DLL_LOWER			0xBC
+#define CQSPI_REG_DLL_LOWER_LPBK_LOCK_MASK	0x8000
+#define CQSPI_REG_DLL_LOWER_DLL_LOCK_MASK	0x1
+
+#define CQSPI_REG_DLL_OBSVBLE_UPPER		0xC0
+#define CQSPI_REG_DLL_UPPER_RX_FLD_MASK		0x7F
+
 #define CQSPI_REG_OP_EXT_LOWER			0xE0
 #define CQSPI_REG_OP_EXT_READ_LSB		24
 #define CQSPI_REG_OP_EXT_WRITE_LSB		16
@@ -272,6 +304,7 @@ struct cqspi_driver_platdata {
 #define CQSPI_REG_VERSAL_DMA_DST_I_EN		0x1818
 #define CQSPI_REG_VERSAL_DMA_DST_I_DIS		0x181C
 #define CQSPI_REG_VERSAL_DMA_DST_DONE_MASK	BIT(1)
+#define CQSPI_REG_VERSAL_DMA_DST_ALL_I_DIS_MASK	0xFE
 
 #define CQSPI_REG_VERSAL_DMA_DST_ADDR_MSB	0x1828
 
@@ -300,6 +333,21 @@ struct cqspi_driver_platdata {
 #define CQSPI_DMA_UNALIGN		0x3
 
 #define CQSPI_REG_VERSAL_DMA_VAL		0x602
+#define CQSPI_READ_ID_LEN		6
+#define VERSAL_OSPI_RESET		0xc10402e
+#define SILICON_VER_MASK		0xFF
+#define SILICON_VER_1			0x10
+#define CQSPI_DLL_MODE_MASTER		0
+#define CQSPI_DLL_MODE_BYPASS		1
+#define TAP_GRAN_SEL_MIN_FREQ		120000000
+#define CQSPI_TX_TAP_MASTER		0x1E
+#define CQSPI_MAX_DLL_TAPS		127
+
+#define	CQSPI_SELECT_LOWER_CS		BIT(0)
+
+static unsigned int read_timeout_ms = CQSPI_READ_TIMEOUT_MS;
+module_param(read_timeout_ms, uint, 0644);
+MODULE_PARM_DESC(read_timeout_ms, "Read transfer timeout in msec");
 
 static int cqspi_wait_for_bit(const struct cqspi_driver_platdata *ddata,
 			      void __iomem *reg, const u32 mask, bool clr,
@@ -331,14 +379,6 @@ static bool cqspi_is_idle(struct cqspi_st *cqspi)
 	return reg & (1UL << CQSPI_REG_CONFIG_IDLE_LSB);
 }
 
-static u32 cqspi_get_rd_sram_level(struct cqspi_st *cqspi)
-{
-	u32 reg = readl(cqspi->iobase + CQSPI_REG_SDRAMLEVEL);
-
-	reg >>= CQSPI_REG_SDRAMLEVEL_RD_LSB;
-	return reg & CQSPI_REG_SDRAMLEVEL_RD_MASK;
-}
-
 static u32 cqspi_get_versal_dma_status(struct cqspi_st *cqspi)
 {
 	u32 dma_status;
@@ -553,6 +593,14 @@ static int cqspi_command_read(struct cqspi_flash_pdata *f_pdata,
 
 	reg = opcode << CQSPI_REG_CMDCTRL_OPCODE_LSB;
 
+	if (op->addr.nbytes) {
+		reg |= (0x1 << CQSPI_REG_CMDCTRL_ADDR_EN_LSB);
+		reg |= ((op->addr.nbytes - 1) &
+			CQSPI_REG_CMDCTRL_ADD_BYTES_MASK) <<
+			CQSPI_REG_CMDCTRL_ADD_BYTES_LSB;
+		writel(op->addr.val, reg_base + CQSPI_REG_CMDADDRESS);
+	}
+
 	rdreg = cqspi_calc_rdreg(op);
 	writel(rdreg, reg_base + CQSPI_REG_RD_INSTR);
 
@@ -560,6 +608,9 @@ static int cqspi_command_read(struct cqspi_flash_pdata *f_pdata,
 	if (dummy_clk > CQSPI_DUMMY_CLKS_MAX)
 		return -EOPNOTSUPP;
 
+	if (cqspi->extra_dummy)
+		dummy_clk++;
+
 	if (dummy_clk)
 		reg |= (dummy_clk & CQSPI_REG_CMDCTRL_DUMMY_MASK)
 		     << CQSPI_REG_CMDCTRL_DUMMY_LSB;
@@ -604,6 +655,270 @@ static int cqspi_command_read(struct cqspi_flash_pdata *f_pdata,
 	return 0;
 }
 
+static int cqspi_setdlldelay(struct spi_mem *mem, const struct spi_mem_op *op)
+{
+	struct cqspi_st *cqspi = spi_controller_get_devdata(mem->spi->controller);
+	u8 dummy_incr, dummy_flag = 0, max_tap, count, windowsize, avg_rxtap;
+	u8 min_rxtap = 0, max_rxtap = 0, max_index = 0, min_index = 0, j;
+	struct platform_device *pdev = cqspi->pdev;
+	struct cqspi_flash_pdata *f_pdata;
+	u8 *id = op->data.buf.in;
+	int i, ret;
+	unsigned int reg;
+	bool id_matched, rxtapfound = false;
+	u32 txtap = 0;
+	s8 max_windowsize = -1;
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg &= CQSPI_REG_CONFIG_ENABLE_MASK;
+	if (!reg)
+		return 0;
+
+	f_pdata = &cqspi->f_pdata[spi_get_chipselect(mem->spi, 0)];
+
+	/* Drive DLL reset bit to low */
+	writel(0, cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+
+	/* Set initial delay value */
+	writel(0x4, cqspi->iobase + CQSPI_REG_PHY_MASTER_CTRL);
+
+	/* Set DLL reset bit */
+	writel(CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK,
+	       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+
+	/* Check for loopback lock */
+	ret = cqspi_wait_for_bit(cqspi->ddata, cqspi->iobase + CQSPI_REG_DLL_LOWER,
+				 CQSPI_REG_DLL_LOWER_LPBK_LOCK_MASK, 0, false);
+	if (ret) {
+		dev_err(&pdev->dev,
+			"Loopback lock bit error (%i)\n", ret);
+		return ret;
+	}
+
+	/* Re-synchronize slave DLLs */
+	writel(CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK,
+	       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+	writel(CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK |
+	       CQSPI_REG_PHY_CONFIG_RESYNC_FLD_MASK,
+	       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+
+	txtap = CQSPI_TX_TAP_MASTER <<
+		CQSPI_REG_PHY_CONFIG_TX_DLL_DLY_LSB;
+	max_tap = CQSPI_MAX_DLL_TAPS;
+
+	cqspi->extra_dummy = false;
+	for (dummy_incr = 0; dummy_incr <= 1; dummy_incr++) {
+		if (dummy_incr)
+			cqspi->extra_dummy = true;
+		for (i = 0; i <= max_tap; i++) {
+			writel((txtap | i |
+			       CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK),
+			       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+			writel((CQSPI_REG_PHY_CONFIG_RESYNC_FLD_MASK | txtap |
+			       i | CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK),
+			       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+			ret = cqspi_wait_for_bit(cqspi->ddata, cqspi->iobase +
+						 CQSPI_REG_DLL_LOWER,
+				CQSPI_REG_DLL_LOWER_DLL_LOCK_MASK, 0, false);
+			if (ret)
+				return ret;
+
+			count = 0;
+			do {
+				count += 1;
+				ret = cqspi_command_read(f_pdata, op);
+				if (ret < 0) {
+					dev_err(&pdev->dev,
+						"error %d reading JEDEC ID\n", ret);
+					return ret;
+				}
+
+				id_matched = true;
+				for (j = 0; j < op->data.nbytes; j++) {
+					if (mem->device_id[j] != id[j]) {
+						id_matched = false;
+						break;
+					}
+				}
+			} while (id_matched && (count <= 10));
+
+			if (id_matched && !rxtapfound) {
+				min_rxtap = readl(cqspi->iobase +
+						  CQSPI_REG_DLL_OBSVBLE_UPPER) &
+						  CQSPI_REG_DLL_UPPER_RX_FLD_MASK;
+				max_rxtap = min_rxtap;
+				max_index = i;
+				min_index = i;
+				rxtapfound = true;
+			}
+
+			if (id_matched && rxtapfound) {
+				max_rxtap = readl(cqspi->iobase +
+						  CQSPI_REG_DLL_OBSVBLE_UPPER) &
+						  CQSPI_REG_DLL_UPPER_RX_FLD_MASK;
+				max_index = i;
+			}
+			if ((!id_matched || i == max_tap) && rxtapfound) {
+				windowsize = max_rxtap - min_rxtap + 1;
+				if (windowsize > max_windowsize) {
+					dummy_flag = dummy_incr;
+					max_windowsize = windowsize;
+					avg_rxtap = (max_index + min_index);
+					avg_rxtap /= 2;
+				}
+
+				if (windowsize >= 3)
+					i = max_tap;
+
+				rxtapfound = false;
+			}
+		}
+		if (!dummy_incr) {
+			rxtapfound = false;
+			min_rxtap = 0;
+			max_rxtap = 0;
+		}
+	}
+	if (!dummy_flag)
+		cqspi->extra_dummy = false;
+
+	if (max_windowsize < 3)
+		return -EINVAL;
+
+	writel((txtap | avg_rxtap | CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK),
+	       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+	writel((CQSPI_REG_PHY_CONFIG_RESYNC_FLD_MASK | txtap | avg_rxtap |
+	       CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK),
+	       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+	ret = cqspi_wait_for_bit(cqspi->ddata, cqspi->iobase + CQSPI_REG_DLL_LOWER,
+				 CQSPI_REG_DLL_LOWER_DLL_LOCK_MASK, 0, false);
+	if (ret)
+		return ret;
+
+	cqspi->clk_tuned = true;
+
+	return 0;
+}
+
+static void cqspi_setup_ddrmode(struct cqspi_st *cqspi)
+{
+	u32 reg;
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg &= ~CQSPI_REG_CONFIG_ENABLE_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg |= (CQSPI_REG_CONFIG_PHY_ENABLE_MASK);
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+
+	/* Program POLL_CNT */
+	reg = readl(cqspi->iobase + CQSPI_REG_WR_COMPLETION_CTRL);
+	reg &= ~CQSPI_REG_WRCOMPLETION_POLLCNT_MASK;
+	reg |= (0x3 << CQSPI_REG_WRCOMPLETION_POLLCNY_LSB);
+	writel(reg, cqspi->iobase + CQSPI_REG_WR_COMPLETION_CTRL);
+
+	reg = readl(cqspi->iobase + CQSPI_REG_READCAPTURE);
+	reg |= CQSPI_REG_READCAPTURE_DQS_ENABLE;
+	writel(reg, cqspi->iobase + CQSPI_REG_READCAPTURE);
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg |= CQSPI_REG_CONFIG_ENABLE_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+}
+
+static void cqspi_setup_sdrmode(struct cqspi_st *cqspi)
+{
+	u32 reg;
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg &= ~CQSPI_REG_CONFIG_ENABLE_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+
+	reg &= ~CQSPI_REG_CONFIG_DTR_PROTO;
+	reg &= ~CQSPI_REG_CONFIG_DUAL_OPCODE;
+	reg &= ~CQSPI_REG_CONFIG_PHY_ENABLE_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+
+	/* Program POLL_CNT */
+	reg = readl(cqspi->iobase + CQSPI_REG_WR_COMPLETION_CTRL);
+	reg &= ~CQSPI_REG_WRCOMPLETION_POLLCNT_MASK;
+	reg |= (1 << CQSPI_REG_WRCOMPLETION_POLLCNY_LSB);
+	writel(reg, cqspi->iobase + CQSPI_REG_WR_COMPLETION_CTRL);
+
+	reg = readl(cqspi->iobase + CQSPI_REG_READCAPTURE);
+	reg &= ~CQSPI_REG_READCAPTURE_DQS_ENABLE;
+	reg |= (1 & CQSPI_REG_READCAPTURE_DELAY_MASK)
+		<< CQSPI_REG_READCAPTURE_DELAY_LSB;
+	writel(reg, cqspi->iobase + CQSPI_REG_READCAPTURE);
+
+	writel(CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK,
+	       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg |= CQSPI_REG_CONFIG_ENABLE_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+
+	cqspi->clk_tuned = false;
+	cqspi->extra_dummy = false;
+}
+
+static void cqspi_periodictuning(struct work_struct *work)
+{
+	struct delayed_work *d = to_delayed_work(work);
+	struct spi_mem *mem = container_of(d, struct spi_mem, complete_work);
+	struct cqspi_st *cqspi = spi_controller_get_devdata(mem->spi->controller);
+	u8 buf[CQSPI_READ_ID_LEN];
+	int ret;
+
+	if (!mem->request_completion.done)
+		wait_for_completion(&mem->request_completion);
+
+	reinit_completion(&cqspi->tuning_complete);
+	cqspi->tuning_op.data.buf.in = buf;
+	cqspi->tuning_op.data.nbytes = CQSPI_READ_ID_LEN;
+	ret = cqspi_setdlldelay(mem, &cqspi->tuning_op);
+	complete_all(&cqspi->tuning_complete);
+	if (ret) {
+		dev_err(&cqspi->pdev->dev,
+			"Setting dll delay error (%i)\n", ret);
+	} else {
+		schedule_delayed_work(&mem->complete_work,
+				      msecs_to_jiffies(CQSPI_TUNING_PERIODICITY_MS));
+	}
+}
+
+static int cqspi_setup_edgemode(struct spi_mem *mem,
+				const struct spi_mem_op *op)
+{
+	struct cqspi_st *cqspi = spi_controller_get_devdata(mem->spi->controller);
+	int ret;
+
+	cqspi_setup_ddrmode(cqspi);
+
+	if (cqspi->clk_tuned)
+		return 0;
+	memcpy(&cqspi->tuning_op, op, sizeof(struct spi_mem_op));
+
+	cqspi->f_pdata[spi_get_chipselect(mem->spi, 0)].dtr = true;
+
+	ret = cqspi_setdlldelay(mem, op);
+	if (ret)
+		return ret;
+
+	complete_all(&cqspi->tuning_complete);
+	if (cqspi->tuning_scheduled) {
+		cancel_delayed_work_sync(&mem->complete_work);
+		flush_delayed_work(&mem->complete_work);
+	}
+	INIT_DELAYED_WORK(&mem->complete_work, cqspi_periodictuning);
+	schedule_delayed_work(&mem->complete_work,
+			      msecs_to_jiffies(CQSPI_TUNING_PERIODICITY_MS));
+	cqspi->tuning_scheduled = true;
+
+	return 0;
+}
+
 static int cqspi_command_write(struct cqspi_flash_pdata *f_pdata,
 			       const struct spi_mem_op *op)
 {
@@ -701,6 +1016,9 @@ static int cqspi_read_setup(struct cqspi_flash_pdata *f_pdata,
 	if (dummy_clk > CQSPI_DUMMY_CLKS_MAX)
 		return -EOPNOTSUPP;
 
+	if (cqspi->extra_dummy)
+		dummy_clk++;
+
 	if (dummy_clk)
 		reg |= (dummy_clk & CQSPI_REG_RD_INSTR_DUMMY_MASK)
 		       << CQSPI_REG_RD_INSTR_DUMMY_LSB;
@@ -728,10 +1046,28 @@ static int cqspi_indirect_read_execute(struct cqspi_flash_pdata *f_pdata,
 	unsigned int mod_bytes = n_rx % 4;
 	unsigned int bytes_to_read = 0;
 	u8 *rxbuf_end = rxbuf + n_rx;
+	u8 *rxbuf_start = rxbuf;
 	int ret = 0;
+	u8 extra_bytes = 0;
+	u32 req_bytes;
+	u32 threshold_val;
+	bool is_unaligned_cnt = false;
+
+	if (n_rx % 2)
+		is_unaligned_cnt = true;
 
 	writel(from_addr, reg_base + CQSPI_REG_INDIRECTRDSTARTADDR);
-	writel(remaining, reg_base + CQSPI_REG_INDIRECTRDBYTES);
+	if (f_pdata->dtr && (from_addr % 2) != 0) {
+		mod_bytes += 1;
+		if (!is_unaligned_cnt)
+			extra_bytes = 2;
+	}
+
+	if (f_pdata->dtr && (from_addr % 2) != 0)
+		writel(from_addr - 1, reg_base + CQSPI_REG_INDIRECTRDSTARTADDR);
+
+	req_bytes = remaining + is_unaligned_cnt + extra_bytes;
+	writel(req_bytes, reg_base + CQSPI_REG_INDIRECTRDBYTES);
 
 	/* Clear all interrupts. */
 	writel(CQSPI_IRQ_STATUS_MASK, reg_base + CQSPI_REG_IRQSTATUS);
@@ -749,7 +1085,8 @@ static int cqspi_indirect_read_execute(struct cqspi_flash_pdata *f_pdata,
 	else if (use_irq)
 		writel(CQSPI_IRQ_MASK_RD, reg_base + CQSPI_REG_IRQMASK);
 	else
-		writel(0, reg_base + CQSPI_REG_IRQMASK);
+		writel(CQSPI_REG_IRQ_WATERMARK, reg_base + CQSPI_REG_IRQMASK);
+	threshold_val = readl(reg_base + CQSPI_REG_INDIRECTRDWATERMARK);
 
 	reinit_completion(&cqspi->transfer_complete);
 	writel(CQSPI_REG_INDIRECTRD_START_MASK,
@@ -768,7 +1105,10 @@ static int cqspi_indirect_read_execute(struct cqspi_flash_pdata *f_pdata,
 		if (cqspi->slow_sram)
 			writel(0x0, reg_base + CQSPI_REG_IRQMASK);
 
-		bytes_to_read = cqspi_get_rd_sram_level(cqspi);
+		if (req_bytes > (threshold_val + cqspi->fifo_width))
+			bytes_to_read = threshold_val + cqspi->fifo_width;
+		else
+			bytes_to_read = req_bytes;
 
 		if (ret && bytes_to_read == 0) {
 			dev_err(dev, "Indirect read timeout, no bytes\n");
@@ -777,26 +1117,47 @@ static int cqspi_indirect_read_execute(struct cqspi_flash_pdata *f_pdata,
 
 		while (bytes_to_read != 0) {
 			unsigned int word_remain = round_down(remaining, 4);
+			unsigned int bytes_read = 0;
 
-			bytes_to_read *= cqspi->fifo_width;
 			bytes_to_read = bytes_to_read > remaining ?
 					remaining : bytes_to_read;
 			bytes_to_read = round_down(bytes_to_read, 4);
 			/* Read 4 byte word chunks then single bytes */
 			if (bytes_to_read) {
-				ioread32_rep(ahb_base, rxbuf,
-					     (bytes_to_read / 4));
+				u8 offset = 0;
+
+				if (f_pdata->dtr && ((from_addr % 2) != 0) &&
+				    rxbuf == rxbuf_start) {
+					unsigned int temp = ioread32(ahb_base);
+
+					temp >>= 8;
+					memcpy(rxbuf, &temp, 3);
+					bytes_to_read -= 3;
+					offset = 3;
+					bytes_read += 3;
+				}
+				if (bytes_to_read >= 4) {
+					ioread32_rep(ahb_base, rxbuf + offset,
+						     (bytes_to_read / 4));
+					bytes_read += (bytes_to_read / 4) * 4;
+				}
 			} else if (!word_remain && mod_bytes) {
 				unsigned int temp = ioread32(ahb_base);
 
-				bytes_to_read = mod_bytes;
-				memcpy(rxbuf, &temp, min((unsigned int)
-							 (rxbuf_end - rxbuf),
-							 bytes_to_read));
+				if (f_pdata->dtr && ((from_addr % 2) != 0) &&
+				    rxbuf == rxbuf_start)
+					temp >>= 8;
+
+				bytes_to_read = min(remaining, mod_bytes);
+				bytes_read = min((unsigned int)
+						    (rxbuf_end - rxbuf),
+						     bytes_to_read);
+				memcpy(rxbuf, &temp, bytes_read);
 			}
-			rxbuf += bytes_to_read;
-			remaining -= bytes_to_read;
-			bytes_to_read = cqspi_get_rd_sram_level(cqspi);
+			rxbuf += bytes_read;
+			remaining -= bytes_read;
+			req_bytes -= bytes_read;
+			bytes_to_read -= bytes_read;
 		}
 
 		if (use_irq && remaining > 0) {
@@ -832,6 +1193,25 @@ static int cqspi_indirect_read_execute(struct cqspi_flash_pdata *f_pdata,
 	return ret;
 }
 
+static void cqspi_device_reset(struct cqspi_st *cqspi)
+{
+	u32 reg;
+
+	reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+	reg |= CQSPI_REG_CONFIG_RESET_CFG_FLD_MASK;
+	writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+	/*
+	 * NOTE: Delay timing implementation is derived from
+	 * spi_nor_hw_reset()
+	 */
+	writel(reg & ~CQSPI_REG_CONFIG_RESET_PIN_FLD_MASK, cqspi->iobase + CQSPI_REG_CONFIG);
+	usleep_range(1, 5);
+	writel(reg | CQSPI_REG_CONFIG_RESET_PIN_FLD_MASK, cqspi->iobase + CQSPI_REG_CONFIG);
+	usleep_range(100, 150);
+	writel(reg & ~CQSPI_REG_CONFIG_RESET_PIN_FLD_MASK, cqspi->iobase + CQSPI_REG_CONFIG);
+	usleep_range(1000, 1200);
+}
+
 static void cqspi_controller_enable(struct cqspi_st *cqspi, bool enable)
 {
 	void __iomem *reg_base = cqspi->iobase;
@@ -864,8 +1244,11 @@ static int cqspi_versal_indirect_read_dma(struct cqspi_flash_pdata *f_pdata,
 	bytes_rem = n_rx % 4;
 	bytes_to_dma = (n_rx - bytes_rem);
 
-	if (!bytes_to_dma)
+	if (!bytes_to_dma || (f_pdata->dtr && ((from_addr % 2) != 0))) {
+		bytes_to_dma = 0;
+		bytes_rem = n_rx;
 		goto nondmard;
+	}
 
 	ret = zynqmp_pm_ospi_mux_select(cqspi->pd_dev_id, PM_OSPI_MUX_SEL_DMA);
 	if (ret)
@@ -1046,9 +1429,14 @@ static int cqspi_indirect_write_execute(struct cqspi_flash_pdata *f_pdata,
 	unsigned int remaining = n_tx;
 	unsigned int write_bytes;
 	int ret;
+	u8 unaligned_bytes = 0;
+
+	if (f_pdata->dtr && ((n_tx % 2) != 0))
+		unaligned_bytes = 1;
 
 	writel(to_addr, reg_base + CQSPI_REG_INDIRECTWRSTARTADDR);
-	writel(remaining, reg_base + CQSPI_REG_INDIRECTWRBYTES);
+	writel(remaining + unaligned_bytes,
+	       reg_base + CQSPI_REG_INDIRECTWRBYTES);
 
 	/* Clear all interrupts. */
 	writel(CQSPI_IRQ_STATUS_MASK, reg_base + CQSPI_REG_IRQSTATUS);
@@ -1089,7 +1477,7 @@ static int cqspi_indirect_write_execute(struct cqspi_flash_pdata *f_pdata,
 		if (mod_bytes) {
 			unsigned int temp = 0xFFFFFFFF;
 
-			memcpy(&temp, txbuf, mod_bytes);
+			memcpy(&temp, txbuf, mod_bytes + unaligned_bytes);
 			iowrite32(temp, cqspi->ahb_base);
 			txbuf += mod_bytes;
 		}
@@ -1436,6 +1824,7 @@ static int cqspi_exec_mem_op(struct spi_mem *mem, const struct spi_mem_op *op)
 	int ret;
 	struct cqspi_st *cqspi = spi_controller_get_devdata(mem->spi->controller);
 	struct device *dev = &cqspi->pdev->dev;
+	struct cqspi_flash_pdata *f_pdata;
 
 	ret = pm_runtime_resume_and_get(dev);
 	if (ret) {
@@ -1443,6 +1832,31 @@ static int cqspi_exec_mem_op(struct spi_mem *mem, const struct spi_mem_op *op)
 		return ret;
 	}
 
+	f_pdata = &cqspi->f_pdata[spi_get_chipselect(mem->spi, 0)];
+
+	if (mem->spi->cs_index_mask & CQSPI_SELECT_LOWER_CS)
+		f_pdata->cs = spi_get_chipselect(mem->spi, 0);
+	else
+		f_pdata->cs = spi_get_chipselect(mem->spi, 1);
+
+	if (op->cmd.dtr &&
+	    (!op->addr.nbytes || op->addr.dtr) &&
+	    (!op->data.nbytes || op->data.dtr)) {
+		ret = cqspi_setup_edgemode(mem, op);
+		if (ret)
+			return ret;
+	} else {
+		f_pdata->dtr = false;
+		if (cqspi->clk_tuned)
+			cqspi_setup_sdrmode(cqspi);
+	}
+
+	if (f_pdata->dtr && !cqspi->tuning_complete.done &&
+	    !wait_for_completion_timeout(&cqspi->tuning_complete,
+		msecs_to_jiffies(CQSPI_TUNING_TIMEOUT_MS))) {
+		return -ETIMEDOUT;
+	}
+
 	ret = cqspi_mem_process(mem, op);
 
 	pm_runtime_mark_last_busy(dev);
@@ -1599,6 +2013,22 @@ static void cqspi_controller_init(struct cqspi_st *cqspi)
 	}
 }
 
+static void cqspi_controller_reset_phy(struct cqspi_st *cqspi)
+{
+	u32 reg;
+
+	/* Reset the Delay lines */
+	writel(CQSPI_REG_PHY_CONFIG_RESET_FLD_MASK,
+	       cqspi->iobase + CQSPI_REG_PHY_CONFIG);
+
+	/* Reset PHY */
+	if (cqspi->use_dma_read) {
+		reg = readl(cqspi->iobase + CQSPI_REG_CONFIG);
+		reg &= ~CQSPI_REG_CONFIG_PHY_ENABLE_MASK;
+		writel(reg, cqspi->iobase + CQSPI_REG_CONFIG);
+	}
+}
+
 static void cqspi_controller_detect_fifo_depth(struct cqspi_st *cqspi)
 {
 	struct device *dev = &cqspi->pdev->dev;
@@ -1672,28 +2102,38 @@ static int cqspi_setup_flash(struct cqspi_st *cqspi)
 	struct platform_device *pdev = cqspi->pdev;
 	struct device *dev = &pdev->dev;
 	struct cqspi_flash_pdata *f_pdata;
+	unsigned int cs_num[2] = {0};
 	unsigned int cs;
 	int ret;
 
 	/* Get flash device data */
 	for_each_available_child_of_node_scoped(dev->of_node, np) {
-		ret = of_property_read_u32(np, "reg", &cs);
-		if (ret) {
+		ret = of_property_read_variable_u32_array(np, "reg", &cs_num[0],
+							  CQSPI_MIN_CHIPSELECT,
+							  CQSPI_MAX_CHIPSELECT);
+		if (ret < 0) {
 			dev_err(dev, "Couldn't determine chip select.\n");
 			return ret;
 		}
+		cs = cs_num[0];
+
+		f_pdata = &cqspi->f_pdata[cs];
+		f_pdata->cqspi = cqspi;
+		f_pdata->cs = cs;
 
+		if (ret > CQSPI_MIN_CHIPSELECT) {
+			/* Obtain the maximum CS value between the two CS values */
+			for (int i = CQSPI_MIN_CHIPSELECT; i < ret; i++) {
+				if (cs < cs_num[i])
+					cs = cs_num[i];
+			}
+		}
 		if (cs >= cqspi->num_chipselect) {
 			dev_err(dev, "Chip select %d out of range.\n", cs);
 			return -EINVAL;
 		} else if (cs < max_cs) {
 			max_cs = cs;
 		}
-
-		f_pdata = &cqspi->f_pdata[cs];
-		f_pdata->cqspi = cqspi;
-		f_pdata->cs = cs;
-
 		ret = cqspi_of_get_flash_pdata(pdev, f_pdata, np);
 		if (ret)
 			return ret;
@@ -1810,6 +2250,7 @@ static int cqspi_probe(struct platform_device *pdev)
 	cqspi->ahb_size = resource_size(res_ahb);
 
 	init_completion(&cqspi->transfer_complete);
+	init_completion(&cqspi->tuning_complete);
 
 	/* Obtain IRQ line. */
 	irq = platform_get_irq(pdev, 0);
@@ -1892,11 +2333,13 @@ static int cqspi_probe(struct platform_device *pdev)
 		if (ddata->quirks & CQSPI_DISABLE_STIG_MODE)
 			cqspi->disable_stig_mode = true;
 
-		if (of_device_is_compatible(pdev->dev.of_node,
-					    "xlnx,versal-ospi-1.0")) {
+		if (ddata->quirks & CQSPI_DMA_SET_MASK) {
 			ret = dma_set_mask(&pdev->dev, DMA_BIT_MASK(64));
 			if (ret)
 				goto probe_reset_failed;
+
+			if (cqspi->master_ref_clk_hz >= TAP_GRAN_SEL_MIN_FREQ)
+				writel(0x1, cqspi->iobase + CQSPI_REG_VERSAL_ECO);
 		}
 	}
 
@@ -1911,9 +2354,12 @@ static int cqspi_probe(struct platform_device *pdev)
 	cqspi_controller_enable(cqspi, 0);
 	cqspi_controller_detect_fifo_depth(cqspi);
 	cqspi_controller_init(cqspi);
+	cqspi_controller_reset_phy(cqspi);
 	cqspi_controller_enable(cqspi, 1);
 	cqspi->current_cs = -1;
 	cqspi->sclk = 0;
+	cqspi->extra_dummy = false;
+	cqspi->clk_tuned = false;
 
 	ret = cqspi_setup_flash(cqspi);
 	if (ret) {
@@ -1923,6 +2369,9 @@ static int cqspi_probe(struct platform_device *pdev)
 
 	host->num_chipselect = cqspi->num_chipselect;
 
+	if (ddata->quirks & CQSPI_SUPPORT_DEVICE_RESET)
+		cqspi_device_reset(cqspi);
+
 	if (cqspi->use_direct_mode) {
 		ret = cqspi_request_mmap_dma(cqspi);
 		if (ret == -EPROBE_DEFER)
@@ -1982,6 +2431,17 @@ static void cqspi_remove(struct platform_device *pdev)
 static int cqspi_runtime_suspend(struct device *dev)
 {
 	struct cqspi_st *cqspi = dev_get_drvdata(dev);
+	int ret;
+
+	ret = spi_controller_suspend(cqspi->host);
+	if (ret)
+		return ret;
+
+	if (cqspi->clk_tuned && !cqspi->tuning_complete.done &&
+	    !wait_for_completion_timeout(&cqspi->tuning_complete,
+		msecs_to_jiffies(CQSPI_TUNING_TIMEOUT_MS))) {
+		return -ETIMEDOUT;
+	}
 
 	cqspi_controller_enable(cqspi, 0);
 	clk_disable_unprepare(cqspi->clk);
@@ -2025,6 +2485,22 @@ static int cqspi_resume(struct device *dev)
 		dev_err(dev, "pm_runtime_force_resume failed on resume\n");
 		return ret;
 	}
+	cqspi_controller_enable(cqspi, 0);
+	cqspi_controller_reset_phy(cqspi);
+	cqspi_controller_enable(cqspi, 1);
+	cqspi->extra_dummy = false;
+	cqspi->clk_tuned = false;
+
+	ret = cqspi_setup_flash(cqspi);
+	if (ret) {
+		dev_err(dev, "failed to setup flash parameters %d\n", ret);
+		return ret;
+	}
+
+	ret = zynqmp_pm_ospi_mux_select(cqspi->pd_dev_id,
+					PM_OSPI_MUX_SEL_LINEAR);
+	if (ret)
+		return ret;
 
 	return spi_controller_resume(cqspi->host);
 }
@@ -2060,7 +2536,18 @@ static const struct cqspi_driver_platdata socfpga_qspi = {
 
 static const struct cqspi_driver_platdata versal_ospi = {
 	.hwcaps_mask = CQSPI_SUPPORTS_OCTAL,
-	.quirks = CQSPI_DISABLE_DAC_MODE | CQSPI_SUPPORT_EXTERNAL_DMA,
+	.quirks = CQSPI_DISABLE_DAC_MODE | CQSPI_SUPPORT_EXTERNAL_DMA
+			| CQSPI_DISABLE_STIG_MODE
+			| CQSPI_DMA_SET_MASK,
+	.indirect_read_dma = cqspi_versal_indirect_read_dma,
+	.get_dma_status = cqspi_get_versal_dma_status,
+};
+
+static const struct cqspi_driver_platdata versal2_ospi = {
+	.hwcaps_mask = CQSPI_SUPPORTS_OCTAL,
+	.quirks = CQSPI_DISABLE_DAC_MODE | CQSPI_SUPPORT_EXTERNAL_DMA
+			| CQSPI_DMA_SET_MASK
+			| CQSPI_SUPPORT_DEVICE_RESET,
 	.indirect_read_dma = cqspi_versal_indirect_read_dma,
 	.get_dma_status = cqspi_get_versal_dma_status,
 };
@@ -2117,6 +2604,10 @@ static const struct of_device_id cqspi_dt_ids[] = {
 		.compatible = "mobileye,eyeq5-ospi",
 		.data = &mobileye_eyeq5_ospi,
 	},
+	{
+		.compatible = "amd,versal2-ospi",
+		.data = &versal2_ospi,
+	},
 	{ /* end of table */ }
 };
 
diff --git a/drivers/spi/spi-mem.c b/drivers/spi/spi-mem.c
index 17b8baf74..edc2bf274 100644
--- a/drivers/spi/spi-mem.c
+++ b/drivers/spi/spi-mem.c
@@ -431,6 +431,7 @@ int spi_mem_exec_op(struct spi_mem *mem, const struct spi_mem_op *op)
 		xfers[xferpos].tx_buf = tmpbuf + op->addr.nbytes + 1;
 		xfers[xferpos].len = op->dummy.nbytes;
 		xfers[xferpos].tx_nbits = op->dummy.buswidth;
+		xfers[xferpos].dummy = op->dummy.nbytes * 8;
 		xfers[xferpos].dummy_data = 1;
 		spi_message_add_tail(&xfers[xferpos], &msg);
 		xferpos++;
diff --git a/drivers/spi/spi-xilinx.c b/drivers/spi/spi-xilinx.c
index 779532842..a0268ee65 100644
--- a/drivers/spi/spi-xilinx.c
+++ b/drivers/spi/spi-xilinx.c
@@ -1,6 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0-only
 /*
- * Xilinx SPI controller driver (host mode only)
+ * Xilinx SPI controller driver (master mode only)
  *
  * Author: MontaVista Software, Inc.
  *	source@mvista.com
@@ -16,10 +16,11 @@
 #include <linux/of.h>
 #include <linux/platform_device.h>
 #include <linux/spi/spi.h>
-#include <linux/spi/spi_bitbang.h>
 #include <linux/spi/xilinx_spi.h>
 #include <linux/io.h>
-
+#include <linux/delay.h>
+#include <linux/pm_runtime.h>
+#include <linux/clk.h>
 #define XILINX_SPI_MAX_CS	32
 
 #define XILINX_SPI_NAME "xilinx_spi"
@@ -76,14 +77,49 @@
 #define XIPIF_V123B_RESETR_OFFSET	0x40	/* IPIF reset register */
 #define XIPIF_V123B_RESET_MASK		0x0a	/* the value to write */
 
+/* Number of bits per word */
+#define XSPI_ONE_BITS_PER_WORD 1
+#define XSPI_TWO_BITS_PER_WORD 2
+#define XSPI_FOUR_BITS_PER_WORD 4
+
+/* Number of data lines used to receive */
+#define XSPI_RX_ONE_WIRE	1
+#define XSPI_RX_FOUR_WIRE	4
+
+/* Auto suspend timeout in milliseconds */
+#define SPI_AUTOSUSPEND_TIMEOUT		3000
+
+/* Command used for Dummy read Id */
+#define SPI_READ_ID		0x9F
+
+/**
+ * struct xilinx_spi - This definition define spi driver instance
+ * @regs:		virt. address of the control registers
+ * @irq:		IRQ number
+ * @num_clocks:		Number of clocks
+ * @clks:		Pointer to clocks
+ * @dev:		Pointer to the device
+ * @rx_ptr:		Pointer to the RX buffer
+ * @tx_ptr:		Pointer to the TX buffer
+ * @bytes_per_word:	Number of bytes in a word
+ * @buffer_size:	Buffer size in words
+ * @cs_inactive:	Level of the CS pins when inactive
+ * @read_fn:		For reading data from SPI registers
+ * @write_fn:		For writing data to SPI registers
+ * @bytes_to_transfer:	Number of bytes left to transfer
+ * @bytes_to_receive:	Number of bytes left to receive
+ * @rx_bus_width:	Number of wires used to receive data
+ * @tx_fifo:		For writing data to fifo
+ * @rx_fifo:		For reading data from fifo
+ */
 struct xilinx_spi {
-	/* bitbang has to be first */
-	struct spi_bitbang bitbang;
-	struct completion done;
 	void __iomem	*regs;	/* virt. address of the control registers */
 
 	int		irq;
-	bool force_irq;		/* force irq to setup host inhibit */
+
+	int		num_clocks;
+	struct clk_bulk_data *clks;
+	struct device *dev;
 	u8 *rx_ptr;		/* pointer in the Tx buffer */
 	const u8 *tx_ptr;	/* pointer in the Rx buffer */
 	u8 bytes_per_word;
@@ -91,8 +127,69 @@ struct xilinx_spi {
 	u32 cs_inactive;	/* Level of the CS pins when inactive*/
 	unsigned int (*read_fn)(void __iomem *);
 	void (*write_fn)(u32, void __iomem *);
+	u32 bytes_to_transfer;
+	u32 bytes_to_receive;
+	u32 rx_bus_width;
+	void (*tx_fifo)(struct xilinx_spi *xqspi);
+	void (*rx_fifo)(struct xilinx_spi *xqspi);
 };
 
+/**
+ * XSPI_FIFO_READ - Generate xspi_read_rx_fifo_* functions
+ * @size: bits_per_word that are read from RX FIFO
+ * @type: C type of value argument
+ *
+ * Generates xspi_read_rx_fifo_* functions used to write
+ * data into RX FIFO for different transaction widths.
+ */
+#define XSPI_FIFO_READ(size, type)					\
+static void xspi_read_rx_fifo_##size(struct xilinx_spi *xqspi)		\
+{									\
+	int i;								\
+	int count = (xqspi->bytes_to_receive > xqspi->buffer_size) ?	\
+			xqspi->buffer_size : xqspi->bytes_to_receive;	\
+	u32 data;							\
+	for (i = 0; i < count; i += (size / 8)) {			\
+		data = readl_relaxed(xqspi->regs + XSPI_RXD_OFFSET);	\
+		if (xqspi->rx_ptr)					\
+			((type *)xqspi->rx_ptr)[i] = (type)data;	\
+	}								\
+	xqspi->bytes_to_receive -= count;				\
+	if (xqspi->rx_ptr)						\
+		xqspi->rx_ptr += count;					\
+}
+
+/**
+ * XSPI_FIFO_WRITE - Generate xspi_fill_tx_fifo_* functions
+ * @size: bits_per_word that are written into TX FIFO
+ * @type: C type of value argument
+ *
+ * Generates xspi_fill_tx_fifo_* functions used to write
+ * data into TX FIFO for different transaction widths.
+ */
+#define XSPI_FIFO_WRITE(size, type)					\
+static void xspi_fill_tx_fifo_##size(struct xilinx_spi *xqspi)		\
+{									\
+	int i;								\
+	int count = (xqspi->bytes_to_transfer > xqspi->buffer_size) ?	\
+			xqspi->buffer_size : xqspi->bytes_to_transfer;	\
+	u32 data = 0;							\
+	for (i = 0; i < count; i += (size / 8)) {			\
+		if (xqspi->tx_ptr)					\
+			data = *(type *)&xqspi->tx_ptr[i];		\
+		writel_relaxed(data, (xqspi->regs + XSPI_TXD_OFFSET));	\
+	}								\
+	xqspi->bytes_to_transfer -= count;				\
+	if (xqspi->tx_ptr)						\
+		xqspi->tx_ptr += count;					\
+}
+
+XSPI_FIFO_READ(8, u8)
+XSPI_FIFO_READ(16, u16)
+XSPI_FIFO_READ(32, u32)
+XSPI_FIFO_WRITE(8, u8)
+XSPI_FIFO_WRITE(16, u16)
+XSPI_FIFO_WRITE(32, u32)
 static void xspi_write32(u32 val, void __iomem *addr)
 {
 	iowrite32(val, addr);
@@ -113,53 +210,15 @@ static unsigned int xspi_read32_be(void __iomem *addr)
 	return ioread32be(addr);
 }
 
-static void xilinx_spi_tx(struct xilinx_spi *xspi)
-{
-	u32 data = 0;
-
-	if (!xspi->tx_ptr) {
-		xspi->write_fn(0, xspi->regs + XSPI_TXD_OFFSET);
-		return;
-	}
-
-	switch (xspi->bytes_per_word) {
-	case 1:
-		data = *(u8 *)(xspi->tx_ptr);
-		break;
-	case 2:
-		data = *(u16 *)(xspi->tx_ptr);
-		break;
-	case 4:
-		data = *(u32 *)(xspi->tx_ptr);
-		break;
-	}
-
-	xspi->write_fn(data, xspi->regs + XSPI_TXD_OFFSET);
-	xspi->tx_ptr += xspi->bytes_per_word;
-}
-
-static void xilinx_spi_rx(struct xilinx_spi *xspi)
-{
-	u32 data = xspi->read_fn(xspi->regs + XSPI_RXD_OFFSET);
-
-	if (!xspi->rx_ptr)
-		return;
-
-	switch (xspi->bytes_per_word) {
-	case 1:
-		*(u8 *)(xspi->rx_ptr) = data;
-		break;
-	case 2:
-		*(u16 *)(xspi->rx_ptr) = data;
-		break;
-	case 4:
-		*(u32 *)(xspi->rx_ptr) = data;
-		break;
-	}
-
-	xspi->rx_ptr += xspi->bytes_per_word;
-}
-
+/**
+ * xspi_init_hw - Initialize the hardware
+ * @xspi:	Pointer to the zynqmp_qspi structure
+ *
+ * This function performs the following actions
+ *	- Disable and clear all the interrupts
+ *	- Enable manual slave select
+ *	- Enable the SPI controller
+ */
 static void xspi_init_hw(struct xilinx_spi *xspi)
 {
 	void __iomem *regs_base = xspi->regs;
@@ -174,58 +233,116 @@ static void xspi_init_hw(struct xilinx_spi *xspi)
 			regs_base + XIPIF_V123B_IIER_OFFSET);
 	/* Disable the global IPIF interrupt */
 	xspi->write_fn(0, regs_base + XIPIF_V123B_DGIER_OFFSET);
-	/* Deselect the Target on the SPI bus */
+	/* Deselect the slave on the SPI bus */
 	xspi->write_fn(0xffff, regs_base + XSPI_SSR_OFFSET);
-	/* Disable the transmitter, enable Manual Target Select Assertion,
-	 * put SPI controller into host mode, and enable it */
+	/* Disable the transmitter, enable Manual Slave Select Assertion,
+	 * put SPI controller into master mode, and enable it
+	 */
 	xspi->write_fn(XSPI_CR_MANUAL_SSELECT |	XSPI_CR_MASTER_MODE |
 		XSPI_CR_ENABLE | XSPI_CR_TXFIFO_RESET |	XSPI_CR_RXFIFO_RESET,
 		regs_base + XSPI_CR_OFFSET);
 }
 
-static void xilinx_spi_chipselect(struct spi_device *spi, int is_on)
+/**
+ * xspi_chipselect -	Select or deselect the chip select line
+ * @qspi:	Pointer to the spi_device structure
+ * @is_high:	Select(0) or deselect (1) the chip select line
+ *
+ */
+static void xspi_chipselect(struct spi_device *qspi, bool is_high)
 {
-	struct xilinx_spi *xspi = spi_controller_get_devdata(spi->controller);
-	u16 cr;
+	struct xilinx_spi *xqspi = spi_controller_get_devdata(qspi->controller);
 	u32 cs;
 
-	if (is_on == BITBANG_CS_INACTIVE) {
-		/* Deselect the target on the SPI bus */
-		xspi->write_fn(xspi->cs_inactive, xspi->regs + XSPI_SSR_OFFSET);
-		return;
+	if (is_high) {
+		/* Deselect the slave */
+		xqspi->write_fn(xqspi->cs_inactive,
+			xqspi->regs + XSPI_SSR_OFFSET);
+	} else {
+		cs = xqspi->cs_inactive;
+		cs ^= BIT(spi_get_chipselect(qspi, 0));
+		/* Activate the chip select */
+		xqspi->write_fn(cs, xqspi->regs + XSPI_SSR_OFFSET);
 	}
+}
 
-	/* Set the SPI clock phase and polarity */
-	cr = xspi->read_fn(xspi->regs + XSPI_CR_OFFSET)	& ~XSPI_CR_MODE_MASK;
-	if (spi->mode & SPI_CPHA)
-		cr |= XSPI_CR_CPHA;
-	if (spi->mode & SPI_CPOL)
-		cr |= XSPI_CR_CPOL;
-	if (spi->mode & SPI_LSB_FIRST)
-		cr |= XSPI_CR_LSB_FIRST;
-	if (spi->mode & SPI_LOOP)
-		cr |= XSPI_CR_LOOP;
-	xspi->write_fn(cr, xspi->regs + XSPI_CR_OFFSET);
-
-	/* We do not check spi->max_speed_hz here as the SPI clock
-	 * frequency is not software programmable (the IP block design
-	 * parameter)
-	 */
-
-	cs = xspi->cs_inactive;
-	cs ^= BIT(spi_get_chipselect(spi, 0));
+/**
+ * xilinx_spi_startup_block - Perform a dummy read as a
+ * work around for the startup block issue in the spi controller.
+ * @xspi:	Pointer to the xilinx_spi structure
+ * @cs_num:	chip select number.
+ *
+ * Perform a dummy read if startup block is enabled in the
+ * spi controller.
+ *
+ * Return:	None
+ */
+static void xilinx_spi_startup_block(struct xilinx_spi *xspi, u32 cs_num)
+{
+	void __iomem *regs_base = xspi->regs;
+	u32 chip_sel, config_reg, status_reg;
 
 	/* Activate the chip select */
-	xspi->write_fn(cs, xspi->regs + XSPI_SSR_OFFSET);
+	chip_sel = xspi->cs_inactive;
+	chip_sel ^= BIT(cs_num);
+	xspi->write_fn(chip_sel, regs_base + XSPI_SSR_OFFSET);
+
+	/* Write ReadId to the TXD register */
+	xspi->write_fn(SPI_READ_ID, regs_base + XSPI_TXD_OFFSET);
+	xspi->write_fn(0x0, regs_base + XSPI_TXD_OFFSET);
+	xspi->write_fn(0x0, regs_base + XSPI_TXD_OFFSET);
+
+	config_reg = xspi->read_fn(regs_base + XSPI_CR_OFFSET);
+	/* Enable master transaction  */
+	config_reg &= ~XSPI_CR_TRANS_INHIBIT;
+	xspi->write_fn(config_reg, regs_base + XSPI_CR_OFFSET);
+
+	status_reg = xspi->read_fn(regs_base + XSPI_SR_OFFSET);
+	while ((status_reg & XSPI_SR_TX_EMPTY_MASK) == 0)
+		status_reg = xspi->read_fn(regs_base + XSPI_SR_OFFSET);
+
+	/* Disable master transaction */
+	config_reg |= XSPI_CR_TRANS_INHIBIT;
+	xspi->write_fn(config_reg, regs_base + XSPI_CR_OFFSET);
+
+	/* Read the RXD Register */
+	status_reg = xspi->read_fn(regs_base + XSPI_SR_OFFSET);
+	while ((status_reg & XSPI_SR_RX_EMPTY_MASK) == 0) {
+		xspi->read_fn(regs_base + XSPI_RXD_OFFSET);
+		status_reg = xspi->read_fn(regs_base + XSPI_SR_OFFSET);
+	}
+
+	xspi_init_hw(xspi);
 }
 
-/* spi_bitbang requires custom setup_transfer() to be defined if there is a
- * custom txrx_bufs().
+/**
+ * xilinx_spi_setup_transfer - Configure SPI controller for specified
+ *			 transfer
+ * @spi:	Pointer to the spi_device structure
+ * @t:	Pointer to the spi_transfer structure which provides
+ *		information about next transfer setup parameters
+ *
+ * Sets the operational mode of QSPI controller for the next QSPI
+ * transfer.
+ *
+ * Return:	0 always
  */
 static int xilinx_spi_setup_transfer(struct spi_device *spi,
 		struct spi_transfer *t)
 {
 	struct xilinx_spi *xspi = spi_controller_get_devdata(spi->controller);
+	u32 config_reg;
+
+	config_reg = xspi->read_fn(xspi->regs + XSPI_CR_OFFSET);
+	/* Set the QSPI clock phase and clock polarity */
+	config_reg &= ~(XSPI_CR_CPHA | XSPI_CR_CPOL);
+	if (spi->mode & SPI_CPHA)
+		config_reg |= XSPI_CR_CPHA;
+	if (spi->mode & SPI_CPOL)
+		config_reg |= XSPI_CR_CPOL;
+	if (spi->mode & SPI_LSB_FIRST)
+		config_reg |= XSPI_CR_LSB_FIRST;
+	xspi->write_fn(config_reg, xspi->regs + XSPI_CR_OFFSET);
 
 	if (spi->mode & SPI_CS_HIGH)
 		xspi->cs_inactive &= ~BIT(spi_get_chipselect(spi, 0));
@@ -235,218 +352,361 @@ static int xilinx_spi_setup_transfer(struct spi_device *spi,
 	return 0;
 }
 
-static int xilinx_spi_txrx_bufs(struct spi_device *spi, struct spi_transfer *t)
+/**
+ * xspi_setup -	Configure the SPI controller
+ * @qspi:	Pointer to the spi_device structure
+ *
+ * Sets the operational mode of QSPI controller for the next QSPI
+ * transfer.
+ *
+ * Return:	0 on success; error value otherwise.
+ */
+static int xspi_setup(struct spi_device *qspi)
 {
-	struct xilinx_spi *xspi = spi_controller_get_devdata(spi->controller);
-	int remaining_words;	/* the number of words left to transfer */
-	bool use_irq = false;
-	u16 cr = 0;
-
-	/* We get here with transmitter inhibited */
-
-	xspi->tx_ptr = t->tx_buf;
-	xspi->rx_ptr = t->rx_buf;
-	remaining_words = t->len / xspi->bytes_per_word;
-
-	if (xspi->irq >= 0 &&
-	    (xspi->force_irq || remaining_words > xspi->buffer_size)) {
-		u32 isr;
-		use_irq = true;
-		/* Inhibit irq to avoid spurious irqs on tx_empty*/
-		cr = xspi->read_fn(xspi->regs + XSPI_CR_OFFSET);
-		xspi->write_fn(cr | XSPI_CR_TRANS_INHIBIT,
-			       xspi->regs + XSPI_CR_OFFSET);
-		/* ACK old irqs (if any) */
-		isr = xspi->read_fn(xspi->regs + XIPIF_V123B_IISR_OFFSET);
-		if (isr)
-			xspi->write_fn(isr,
-				       xspi->regs + XIPIF_V123B_IISR_OFFSET);
-		/* Enable the global IPIF interrupt */
-		xspi->write_fn(XIPIF_V123B_GINTR_ENABLE,
-				xspi->regs + XIPIF_V123B_DGIER_OFFSET);
-		reinit_completion(&xspi->done);
+	int ret;
+	struct xilinx_spi *xqspi = spi_controller_get_devdata(qspi->controller);
+
+	if (qspi->controller->busy)
+		return -EBUSY;
+
+	ret = pm_runtime_get_sync(xqspi->dev);
+	if (ret < 0)
+		return ret;
+
+	ret = xilinx_spi_setup_transfer(qspi, NULL);
+	pm_runtime_put_sync(xqspi->dev);
+
+	return ret;
+}
+
+/**
+ * xspi_start_transfer - Initiates the SPI transfer
+ * @ctlr:	Pointer to the spi_ controller structure which provides
+ *		information about the controller.
+ * @qspi:	Pointer to the spi_device structure
+ * @transfer:	Pointer to the spi_transfer structure which provide information
+ *		about next transfer parameters
+ *
+ * This function fills the TX FIFO, starts the SPI transfer, and waits for the
+ * transfer to be completed.
+ *
+ * Return:	Number of bytes transferred in the last transfer
+ */
+
+static int xspi_start_transfer(struct spi_controller *ctlr,
+			       struct spi_device *qspi,
+			       struct spi_transfer *transfer)
+{
+	struct xilinx_spi *xqspi = spi_controller_get_devdata(ctlr);
+	u32 cr;
+
+	xqspi->tx_ptr = transfer->tx_buf;
+	xqspi->rx_ptr = transfer->rx_buf;
+
+	if (transfer->dummy) {
+		xqspi->bytes_to_transfer = (transfer->len - (transfer->dummy / 8))
+							+ ((transfer->dummy / 8) *
+							xqspi->rx_bus_width);
+		xqspi->bytes_to_receive = (transfer->len - (transfer->dummy / 8))
+							+ ((transfer->dummy / 8) *
+							xqspi->rx_bus_width);
+	} else {
+		xqspi->bytes_to_transfer = transfer->len;
+		xqspi->bytes_to_receive = transfer->len;
 	}
 
-	while (remaining_words) {
-		int n_words, tx_words, rx_words;
-		u32 sr;
-		int stalled;
-
-		n_words = min(remaining_words, xspi->buffer_size);
-
-		tx_words = n_words;
-		while (tx_words--)
-			xilinx_spi_tx(xspi);
-
-		/* Start the transfer by not inhibiting the transmitter any
-		 * longer
-		 */
-
-		if (use_irq) {
-			xspi->write_fn(cr, xspi->regs + XSPI_CR_OFFSET);
-			wait_for_completion(&xspi->done);
-			/* A transmit has just completed. Process received data
-			 * and check for more data to transmit. Always inhibit
-			 * the transmitter while the Isr refills the transmit
-			 * register/FIFO, or make sure it is stopped if we're
-			 * done.
-			 */
-			xspi->write_fn(cr | XSPI_CR_TRANS_INHIBIT,
-				       xspi->regs + XSPI_CR_OFFSET);
-			sr = XSPI_SR_TX_EMPTY_MASK;
-		} else
-			sr = xspi->read_fn(xspi->regs + XSPI_SR_OFFSET);
-
-		/* Read out all the data from the Rx FIFO */
-		rx_words = n_words;
-		stalled = 10;
-		while (rx_words) {
-			if (rx_words == n_words && !(stalled--) &&
-			    !(sr & XSPI_SR_TX_EMPTY_MASK) &&
-			    (sr & XSPI_SR_RX_EMPTY_MASK)) {
-				dev_err(&spi->dev,
-					"Detected stall. Check C_SPI_MODE and C_SPI_MEMORY\n");
-				xspi_init_hw(xspi);
-				return -EIO;
-			}
+	xilinx_spi_setup_transfer(qspi, transfer);
+	cr = xqspi->read_fn(xqspi->regs + XSPI_CR_OFFSET);
+	/* Enable master transaction inhibit */
+	cr |= XSPI_CR_TRANS_INHIBIT;
+	xqspi->write_fn(cr, xqspi->regs + XSPI_CR_OFFSET);
+	xqspi->tx_fifo(xqspi);
+	/* Disable master transaction inhibit */
+	cr &= ~XSPI_CR_TRANS_INHIBIT;
+	xqspi->write_fn(cr, xqspi->regs + XSPI_CR_OFFSET);
+	xqspi->write_fn(XIPIF_V123B_GINTR_ENABLE,
+			xqspi->regs + XIPIF_V123B_DGIER_OFFSET);
+
+	return transfer->len;
+}
 
-			if ((sr & XSPI_SR_TX_EMPTY_MASK) && (rx_words > 1)) {
-				xilinx_spi_rx(xspi);
-				rx_words--;
-				continue;
-			}
+/**
+ * xspi_prepare_transfer_hardware -	Prepares hardware for transfer.
+ * @ctlr:	Pointer to the spi_controller structure which provides
+ *		information about the controller.
+ *
+ * This function enables SPI master controller.
+ *
+ * Return:	0 on success; error value otherwise
+ */
+static int xspi_prepare_transfer_hardware(struct spi_controller *ctlr)
+{
+	struct xilinx_spi *xqspi = spi_controller_get_devdata(ctlr);
 
-			sr = xspi->read_fn(xspi->regs + XSPI_SR_OFFSET);
-			if (!(sr & XSPI_SR_RX_EMPTY_MASK)) {
-				xilinx_spi_rx(xspi);
-				rx_words--;
-			}
-		}
+	u32 cr;
+	int ret;
+
+	ret = pm_runtime_get_sync(xqspi->dev);
+	if (ret < 0)
+		return ret;
+
+	cr = xqspi->read_fn(xqspi->regs + XSPI_CR_OFFSET);
+	cr |= XSPI_CR_ENABLE;
+	xqspi->write_fn(cr, xqspi->regs + XSPI_CR_OFFSET);
+
+	return 0;
+}
+
+/**
+ * xspi_unprepare_transfer_hardware -	Relaxes hardware after transfer
+ * @ctlr:	Pointer to the spi_controller structure which provides
+ *		information about the controller.
+ *
+ * This function disables the SPI master controller.
+ *
+ * Return:	Always 0
+ */
+static int xspi_unprepare_transfer_hardware(struct spi_controller *ctlr)
+{
+	struct xilinx_spi *xqspi = spi_controller_get_devdata(ctlr);
+	u32 cr;
 
-		remaining_words -= n_words;
+	cr = xqspi->read_fn(xqspi->regs + XSPI_CR_OFFSET);
+	cr &= ~XSPI_CR_ENABLE;
+	xqspi->write_fn(cr, xqspi->regs + XSPI_CR_OFFSET);
+
+	pm_runtime_put_sync(xqspi->dev);
+
+	return 0;
+}
+
+/**
+ * xilinx_spi_runtime_resume - Runtime resume method for the SPI driver
+ * @dev:	Address of the platform_device structure
+ *
+ * This function enables the clocks
+ *
+ * Return:	0 on success and error value on error
+ */
+static int __maybe_unused xilinx_spi_runtime_resume(struct device *dev)
+{
+	struct spi_controller *ctlr = dev_get_drvdata(dev);
+	struct xilinx_spi *xspi = spi_controller_get_devdata(ctlr);
+	int ret;
+
+	ret = clk_bulk_prepare_enable(xspi->num_clocks, xspi->clks);
+	if (ret) {
+		dev_err(dev, "Can not enable clocks\n");
+		return ret;
 	}
 
-	if (use_irq) {
-		xspi->write_fn(0, xspi->regs + XIPIF_V123B_DGIER_OFFSET);
-		xspi->write_fn(cr, xspi->regs + XSPI_CR_OFFSET);
+	return 0;
+}
+
+/**
+ * xilinx_spi_runtime_suspend - Runtime suspend method for the SPI driver
+ * @dev:	Address of the platform_device structure
+ *
+ * This function disables the clocks
+ *
+ * Return:	Always 0
+ */
+static int __maybe_unused xilinx_spi_runtime_suspend(struct device *dev)
+{
+	struct spi_controller *ctlr = dev_get_drvdata(dev);
+	struct xilinx_spi *xspi = spi_controller_get_devdata(ctlr);
+
+	clk_bulk_disable_unprepare(xspi->num_clocks, xspi->clks);
+
+	return 0;
+}
+
+/**
+ * xilinx_spi_resume - Resume method for the SPI driver
+ * @dev:	Address of the platform_device structure
+ *
+ * The function starts the SPI driver queue and initializes the SPI
+ * controller
+ *
+ * Return:	0 on success; error value otherwise
+ */
+static int __maybe_unused xilinx_spi_resume(struct device *dev)
+{
+	struct spi_controller *ctlr = dev_get_drvdata(dev);
+	struct xilinx_spi *xspi = spi_controller_get_devdata(ctlr);
+	int ret = 0;
+
+	if (!pm_runtime_suspended(dev)) {
+		ret = xilinx_spi_runtime_resume(dev);
+		if (ret < 0)
+			return ret;
 	}
 
-	return t->len;
+	ret = spi_controller_resume(ctlr);
+	if (ret < 0)
+		clk_bulk_disable_unprepare(xspi->num_clocks, xspi->clks);
+
+	return ret;
 }
 
+/**
+ * xilinx_spi_suspend - Suspend method for the SPI driver
+ * @dev:	Address of the platform_device structure
+ *
+ * This function stops the SPI driver queue and disables the SPI controller
+ *
+ * Return:	Always 0
+ */
+static int __maybe_unused xilinx_spi_suspend(struct device *dev)
+{
+	struct spi_controller *ctlr = dev_get_drvdata(dev);
+	int ret = 0;
+
+	ret = spi_controller_suspend(ctlr);
+	if (ret)
+		return ret;
+
+	if (!pm_runtime_suspended(dev))
+		xilinx_spi_runtime_suspend(dev);
 
-/* This driver supports single host mode only. Hence Tx FIFO Empty
+	xspi_unprepare_transfer_hardware(ctlr);
+
+	return ret;
+}
+
+static const struct dev_pm_ops xilinx_spi_dev_pm_ops = {
+	SET_RUNTIME_PM_OPS(xilinx_spi_runtime_suspend,
+			   xilinx_spi_runtime_resume, NULL)
+	SET_SYSTEM_SLEEP_PM_OPS(xilinx_spi_suspend, xilinx_spi_resume)
+};
+
+/* This driver supports single master mode only. Hence Tx FIFO Empty
  * is the only interrupt we care about.
- * Receive FIFO Overrun, Transmit FIFO Underrun, Mode Fault, and Target Mode
+ * Receive FIFO Overrun, Transmit FIFO Underrun, Mode Fault, and Slave Mode
  * Fault are not to happen.
  */
 static irqreturn_t xilinx_spi_irq(int irq, void *dev_id)
 {
-	struct xilinx_spi *xspi = dev_id;
+	struct spi_controller *ctlr = dev_id;
+	struct xilinx_spi *xspi = spi_controller_get_devdata(dev_id);
 	u32 ipif_isr;
+	u32 cr;
+	irqreturn_t status = IRQ_NONE;
 
 	/* Get the IPIF interrupts, and clear them immediately */
 	ipif_isr = xspi->read_fn(xspi->regs + XIPIF_V123B_IISR_OFFSET);
 	xspi->write_fn(ipif_isr, xspi->regs + XIPIF_V123B_IISR_OFFSET);
 
-	if (ipif_isr & XSPI_INTR_TX_EMPTY) {	/* Transmission completed */
-		complete(&xspi->done);
-		return IRQ_HANDLED;
-	}
-
-	return IRQ_NONE;
-}
+	cr = xspi->read_fn(xspi->regs + XSPI_CR_OFFSET);
+	/* Enable master transaction inhibit */
+	cr |= XSPI_CR_TRANS_INHIBIT;
+	xspi->write_fn(cr, xspi->regs + XSPI_CR_OFFSET);
 
-static int xilinx_spi_find_buffer_size(struct xilinx_spi *xspi)
-{
-	u8 sr;
-	int n_words = 0;
+	if (ipif_isr & XSPI_INTR_TX_EMPTY)  {
+		/* Transmission completed */
+		xspi->rx_fifo(xspi);
+		if (xspi->bytes_to_transfer) {
+			/* There is more data to send */
+			xspi->tx_fifo(xspi);
+		}
+		status = IRQ_HANDLED;
+	}
 
-	/*
-	 * Before the buffer_size detection we reset the core
-	 * to make sure we start with a clean state.
-	 */
-	xspi->write_fn(XIPIF_V123B_RESET_MASK,
-		xspi->regs + XIPIF_V123B_RESETR_OFFSET);
+	if (!xspi->bytes_to_receive && !xspi->bytes_to_transfer) {
+		/* Disable the interrupts here. */
+		xspi->write_fn(0x0, xspi->regs + XIPIF_V123B_DGIER_OFFSET);
+		spi_finalize_current_transfer(ctlr);
+	}
 
-	/* Fill the Tx FIFO with as many words as possible */
-	do {
-		xspi->write_fn(0, xspi->regs + XSPI_TXD_OFFSET);
-		sr = xspi->read_fn(xspi->regs + XSPI_SR_OFFSET);
-		n_words++;
-	} while (!(sr & XSPI_SR_TX_FULL_MASK));
+	/* Disable master transaction inhibit */
+	cr &= ~XSPI_CR_TRANS_INHIBIT;
+	xspi->write_fn(cr, xspi->regs + XSPI_CR_OFFSET);
 
-	return n_words;
+	return status;
 }
-
-static const struct of_device_id xilinx_spi_of_match[] = {
-	{ .compatible = "xlnx,axi-quad-spi-1.00.a", },
-	{ .compatible = "xlnx,xps-spi-2.00.a", },
-	{ .compatible = "xlnx,xps-spi-2.00.b", },
-	{}
-};
-MODULE_DEVICE_TABLE(of, xilinx_spi_of_match);
-
 static int xilinx_spi_probe(struct platform_device *pdev)
 {
 	struct xilinx_spi *xspi;
-	struct xspi_platform_data *pdata;
 	struct resource *res;
-	int ret, num_cs = 0, bits_per_word;
-	struct spi_controller *host;
-	bool force_irq = false;
-	u32 tmp;
-	u8 i;
-
-	pdata = dev_get_platdata(&pdev->dev);
-	if (pdata) {
-		num_cs = pdata->num_chipselect;
-		bits_per_word = pdata->bits_per_word;
-		force_irq = pdata->force_irq;
-	} else {
-		of_property_read_u32(pdev->dev.of_node, "xlnx,num-ss-bits",
-					  &num_cs);
-		ret = of_property_read_u32(pdev->dev.of_node,
-					   "xlnx,num-transfer-bits",
-					   &bits_per_word);
-		if (ret)
-			bits_per_word = 8;
-	}
-
-	if (!num_cs) {
-		dev_err(&pdev->dev,
-			"Missing target select configuration data\n");
-		return -EINVAL;
-	}
+	int ret;
+	u32 num_cs = 0, bits_per_word = 8;
+	u32 cs_num;
+	struct spi_controller *ctlr;
+	struct device_node *nc;
+	u32 tmp, rx_bus_width, fifo_size;
+	bool startup_block;
+
+	if (of_property_read_u32(pdev->dev.of_node, "num-cs", &num_cs))
+		dev_info(&pdev->dev,
+			 "Missing num-cs optional property, assuming default as <1>\n");
+	if (!num_cs)
+		num_cs = 1;
 
 	if (num_cs > XILINX_SPI_MAX_CS) {
-		dev_err(&pdev->dev, "Invalid number of spi targets\n");
+		dev_err(&pdev->dev, "Invalid number of spi slaves\n");
 		return -EINVAL;
 	}
 
-	host = devm_spi_alloc_host(&pdev->dev, sizeof(struct xilinx_spi));
-	if (!host)
+	startup_block = of_property_read_bool(pdev->dev.of_node,
+					      "xlnx,startup-block");
+	ctlr = spi_alloc_master(&pdev->dev, sizeof(struct xilinx_spi));
+	if (!ctlr)
 		return -ENODEV;
 
-	/* the spi->mode bits understood by this driver: */
-	host->mode_bits = SPI_CPOL | SPI_CPHA | SPI_LSB_FIRST | SPI_LOOP |
-			  SPI_CS_HIGH;
+	xspi = spi_controller_get_devdata(ctlr);
+	ctlr->dev.of_node = pdev->dev.of_node;
+	platform_set_drvdata(pdev, ctlr);
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	xspi->regs = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(xspi->regs)) {
+		ret = PTR_ERR(xspi->regs);
+		goto put_controller;
+	}
+	ret = of_property_read_u32(pdev->dev.of_node, "fifo-size",
+				   &fifo_size);
+	if (ret < 0) {
+		dev_err(&pdev->dev,
+			"Missing fifo size\n");
+		return -EINVAL;
+	}
+	if (of_property_read_u32(pdev->dev.of_node, "bits-per-word",
+				 &bits_per_word))
+		dev_info(&pdev->dev,
+			 "Missing bits-per-word optional property, assuming default as <8>\n");
+
+	xspi->rx_bus_width = XSPI_ONE_BITS_PER_WORD;
+	for_each_available_child_of_node(pdev->dev.of_node, nc) {
+		if (startup_block) {
+			ret = of_property_read_u32(nc, "reg",
+						   &cs_num);
+			if (ret < 0) {
+				of_node_put(nc);
+				return -EINVAL;
+			}
+		}
+		ret = of_property_read_u32(nc, "spi-rx-bus-width",
+					   &rx_bus_width);
+		if (!ret) {
+			xspi->rx_bus_width = rx_bus_width;
+			of_node_put(nc);
+			break;
+		}
+	}
+
+	ret = devm_clk_bulk_get_all(&pdev->dev, &xspi->clks);
+	if (ret < 0)
+		return ret;
 
-	xspi = spi_controller_get_devdata(host);
-	xspi->cs_inactive = 0xffffffff;
-	xspi->bitbang.ctlr = host;
-	xspi->bitbang.chipselect = xilinx_spi_chipselect;
-	xspi->bitbang.setup_transfer = xilinx_spi_setup_transfer;
-	xspi->bitbang.txrx_bufs = xilinx_spi_txrx_bufs;
-	init_completion(&xspi->done);
+	xspi->num_clocks = ret;
 
-	xspi->regs = devm_platform_get_and_ioremap_resource(pdev, 0, &res);
-	if (IS_ERR(xspi->regs))
-		return PTR_ERR(xspi->regs);
+	pm_runtime_set_autosuspend_delay(&pdev->dev, SPI_AUTOSUSPEND_TIMEOUT);
+	pm_runtime_use_autosuspend(&pdev->dev);
+	pm_runtime_enable(&pdev->dev);
+	ret = pm_runtime_get_sync(&pdev->dev);
+	if (ret < 0)
+		goto runtime_disable;
 
-	host->bus_num = pdev->id;
-	host->num_chipselect = num_cs;
-	host->dev.of_node = pdev->dev.of_node;
+	xspi->dev = &pdev->dev;
 
 	/*
 	 * Detect endianess on the IP via loop bit in CR. Detection
@@ -466,68 +726,127 @@ static int xilinx_spi_probe(struct platform_device *pdev)
 		xspi->write_fn = xspi_write32_be;
 	}
 
-	host->bits_per_word_mask = SPI_BPW_MASK(bits_per_word);
-	xspi->bytes_per_word = bits_per_word / 8;
-	xspi->buffer_size = xilinx_spi_find_buffer_size(xspi);
-
+	xspi->buffer_size = fifo_size;
 	xspi->irq = platform_get_irq(pdev, 0);
 	if (xspi->irq < 0 && xspi->irq != -ENXIO) {
-		return xspi->irq;
+		ret = xspi->irq;
+		goto clk_unprepare_all;
 	} else if (xspi->irq >= 0) {
 		/* Register for SPI Interrupt */
 		ret = devm_request_irq(&pdev->dev, xspi->irq, xilinx_spi_irq, 0,
-				dev_name(&pdev->dev), xspi);
+				       dev_name(&pdev->dev), ctlr);
 		if (ret)
-			return ret;
-
-		xspi->force_irq = force_irq;
+			goto clk_unprepare_all;
 	}
 
 	/* SPI controller initializations */
 	xspi_init_hw(xspi);
 
-	ret = spi_bitbang_start(&xspi->bitbang);
-	if (ret) {
-		dev_err(&pdev->dev, "spi_bitbang_start FAILED\n");
-		return ret;
+	pm_runtime_put(&pdev->dev);
+
+	ctlr->bus_num = pdev->id;
+	ctlr->num_chipselect = num_cs;
+	ctlr->setup = xspi_setup;
+	ctlr->set_cs = xspi_chipselect;
+	ctlr->transfer_one = xspi_start_transfer;
+	ctlr->prepare_transfer_hardware = xspi_prepare_transfer_hardware;
+	ctlr->unprepare_transfer_hardware = xspi_unprepare_transfer_hardware;
+	ctlr->bits_per_word_mask = SPI_BPW_MASK(bits_per_word);
+	ctlr->mode_bits = SPI_CPOL | SPI_CPHA | SPI_CS_HIGH;
+
+	xspi->bytes_per_word = bits_per_word / 8;
+	xspi->tx_fifo = xspi_fill_tx_fifo_8;
+	xspi->rx_fifo = xspi_read_rx_fifo_8;
+	if (xspi->rx_bus_width == XSPI_RX_ONE_WIRE) {
+		if (xspi->bytes_per_word == XSPI_TWO_BITS_PER_WORD) {
+			xspi->tx_fifo = xspi_fill_tx_fifo_16;
+			xspi->rx_fifo = xspi_read_rx_fifo_16;
+		} else if (xspi->bytes_per_word == XSPI_FOUR_BITS_PER_WORD) {
+			xspi->tx_fifo = xspi_fill_tx_fifo_32;
+			xspi->rx_fifo = xspi_read_rx_fifo_32;
+		}
+	} else if (xspi->rx_bus_width == XSPI_RX_FOUR_WIRE) {
+		ctlr->mode_bits |= SPI_TX_QUAD | SPI_RX_QUAD;
+	} else {
+		dev_err(&pdev->dev, "Dual Mode not supported\n");
+		goto clk_unprepare_all;
 	}
+	xspi->cs_inactive = 0xffffffff;
 
-	dev_info(&pdev->dev, "at %pR, irq=%d\n", res, xspi->irq);
+	/*
+	 * This is the work around for the startup block issue in
+	 * the spi controller. SPI clock is passing through STARTUP
+	 * block to FLASH. STARTUP block don't provide clock as soon
+	 * as QSPI provides command. So first command fails.
+	 */
+	if (startup_block)
+		xilinx_spi_startup_block(xspi, cs_num);
 
-	if (pdata) {
-		for (i = 0; i < pdata->num_devices; i++)
-			spi_new_device(host, pdata->devices + i);
+	ret = spi_register_controller(ctlr);
+	if (ret) {
+		dev_err(&pdev->dev, "spi_register_controller failed\n");
+		goto clk_unprepare_all;
 	}
 
-	platform_set_drvdata(pdev, host);
-	return 0;
+	return ret;
+
+clk_unprepare_all:
+	pm_runtime_put_sync(&pdev->dev);
+runtime_disable:
+	pm_runtime_disable(&pdev->dev);
+	pm_runtime_set_suspended(&pdev->dev);
+put_controller:
+	spi_controller_put(ctlr);
+
+	return ret;
 }
 
+/**
+ * xilinx_spi_remove -	Remove method for the SPI driver
+ * @pdev:	Pointer to the platform_device structure
+ *
+ * This function is called if a device is physically removed from the system or
+ * if the driver module is being unloaded. It frees all resources allocated to
+ * the device.
+ *
+ * Return:	0 Always
+ */
 static void xilinx_spi_remove(struct platform_device *pdev)
 {
-	struct spi_controller *host = platform_get_drvdata(pdev);
-	struct xilinx_spi *xspi = spi_controller_get_devdata(host);
+	struct spi_controller *ctlr = platform_get_drvdata(pdev);
+	struct xilinx_spi *xspi = spi_controller_get_devdata(ctlr);
 	void __iomem *regs_base = xspi->regs;
 
-	spi_bitbang_stop(&xspi->bitbang);
-
 	/* Disable all the interrupts just in case */
 	xspi->write_fn(0, regs_base + XIPIF_V123B_IIER_OFFSET);
 	/* Disable the global IPIF interrupt */
 	xspi->write_fn(0, regs_base + XIPIF_V123B_DGIER_OFFSET);
 
-	spi_controller_put(xspi->bitbang.ctlr);
+	pm_runtime_disable(&pdev->dev);
+
+	clk_bulk_disable_unprepare(xspi->num_clocks, xspi->clks);
+
+	spi_unregister_controller(ctlr);
 }
 
 /* work with hotplug and coldplug */
 MODULE_ALIAS("platform:" XILINX_SPI_NAME);
 
+static const struct of_device_id xilinx_spi_of_match[] = {
+	{ .compatible = "xlnx,axi-quad-spi-1.00.a", },
+	{ .compatible = "xlnx,xps-spi-2.00.a", },
+	{ .compatible = "xlnx,xps-spi-2.00.b", },
+	{}
+};
+MODULE_DEVICE_TABLE(of, xilinx_spi_of_match);
+
 static struct platform_driver xilinx_spi_driver = {
 	.probe = xilinx_spi_probe,
 	.remove_new = xilinx_spi_remove,
 	.driver = {
 		.name = XILINX_SPI_NAME,
 		.of_match_table = xilinx_spi_of_match,
+		.pm = &xilinx_spi_dev_pm_ops,
 	},
 };
 module_platform_driver(xilinx_spi_driver);
diff --git a/drivers/spi/spi-zynq-qspi.c b/drivers/spi/spi-zynq-qspi.c
index de4c18247..68168e024 100644
--- a/drivers/spi/spi-zynq-qspi.c
+++ b/drivers/spi/spi-zynq-qspi.c
@@ -16,6 +16,7 @@
 #include <linux/spi/spi.h>
 #include <linux/workqueue.h>
 #include <linux/spi/spi-mem.h>
+#include <linux/mtd/spi-nor.h>
 
 /* Register offset definitions */
 #define ZYNQ_QSPI_CONFIG_OFFSET		0x00 /* Configuration  Register, RW */
@@ -53,6 +54,8 @@
 #define ZYNQ_QSPI_CONFIG_FWIDTH_MASK	GENMASK(7, 6) /* FIFO width */
 #define ZYNQ_QSPI_CONFIG_MSTREN_MASK	BIT(0) /* Master Mode */
 
+#define ZYNQ_QSPI_CS0_MASK		BIT(0)
+#define ZYNQ_QSPI_CS1_MASK		BIT(1)
 /*
  * QSPI Configuration Register - Baud rate and target select
  *
@@ -117,8 +120,11 @@
 /* Maximum number of chip selects */
 #define ZYNQ_QSPI_MAX_NUM_CS		2
 
+/* Maximum address width */
+#define ZYNQ_QSPI_MAX_ADDR_WIDTH	3
 /**
  * struct zynq_qspi - Defines qspi driver instance
+ * @ctlr:		Pointer to the spi controller information
  * @dev:		Pointer to the this device's information
  * @regs:		Virtual address of the QSPI controller registers
  * @refclk:		Pointer to the peripheral clock
@@ -128,9 +134,13 @@
  * @rxbuf:		Pointer to the RX buffer
  * @tx_bytes:		Number of bytes left to transfer
  * @rx_bytes:		Number of bytes left to receive
+ * @flags:		Flag to indicate connection mode of flashes
  * @data_completion:	completion structure
+ * @is_stripe:		Flag to indicate if data needs to be split between flashes
+ *			(Used in dual parallel configuration)
  */
 struct zynq_qspi {
+	struct spi_controller *ctlr;
 	struct device *dev;
 	void __iomem *regs;
 	struct clk *refclk;
@@ -140,9 +150,39 @@ struct zynq_qspi {
 	u8 *rxbuf;
 	int tx_bytes;
 	int rx_bytes;
+	u32 flags;
+#define	ZYNQ_QSPI_MEM_CONFIG		BIT(0)
+#define	ZYNQ_QSPI_IS_PARALLEL		BIT(1)
+#define	ZYNQ_QSPI_IS_STACKED		BIT(2)
+	bool is_stripe;
 	struct completion data_completion;
 };
 
+/**
+ * zynq_qspi_update_stripe - For Zynq QSPI controller data stripe capabilities
+ * @op: Pointer to mem ops
+ * Return:      Status of the data stripe
+ *
+ * Returns true if data stripe need to be enabled, else returns false
+ */
+static bool zynq_qspi_update_stripe(const struct spi_mem_op *op)
+{
+	if (op->cmd.opcode ==  SPINOR_OP_BE_4K ||
+	    op->cmd.opcode ==  SPINOR_OP_BE_32K ||
+	    op->cmd.opcode ==  SPINOR_OP_CHIP_ERASE ||
+	    op->cmd.opcode ==  SPINOR_OP_SE ||
+	    op->cmd.opcode ==  SPINOR_OP_BE_32K_4B ||
+	    op->cmd.opcode ==  SPINOR_OP_SE_4B ||
+	    op->cmd.opcode == SPINOR_OP_BE_4K_4B ||
+	    op->cmd.opcode ==  SPINOR_OP_WRSR ||
+	    op->cmd.opcode ==  SPINOR_OP_WREAR ||
+	    op->cmd.opcode ==  SPINOR_OP_BRWR ||
+	    (op->cmd.opcode ==  SPINOR_OP_WRSR2 && !op->addr.nbytes))
+		return false;
+
+	return true;
+}
+
 /*
  * Inline functions for the QSPI controller read/write
  */
@@ -228,12 +268,6 @@ static bool zynq_qspi_supports_op(struct spi_mem *mem,
 	if (!spi_mem_default_supports_op(mem, op))
 		return false;
 
-	/*
-	 * The number of address bytes should be equal to or less than 3 bytes.
-	 */
-	if (op->addr.nbytes > 3)
-		return false;
-
 	return true;
 }
 
@@ -244,12 +278,16 @@ static bool zynq_qspi_supports_op(struct spi_mem *mem,
  */
 static void zynq_qspi_rxfifo_op(struct zynq_qspi *xqspi, unsigned int size)
 {
+	unsigned int xsize;
 	u32 data;
 
 	data = zynq_qspi_read(xqspi, ZYNQ_QSPI_RXD_OFFSET);
 
 	if (xqspi->rxbuf) {
-		memcpy(xqspi->rxbuf, ((u8 *)&data) + 4 - size, size);
+		xsize = size;
+		if (xqspi->is_stripe && (size % 2))
+			xsize++;
+		memcpy(xqspi->rxbuf, ((u8 *)&data) + 4 - xsize, size);
 		xqspi->rxbuf += size;
 	}
 
@@ -268,6 +306,7 @@ static void zynq_qspi_txfifo_op(struct zynq_qspi *xqspi, unsigned int size)
 	static const unsigned int offset[4] = {
 		ZYNQ_QSPI_TXD_00_01_OFFSET, ZYNQ_QSPI_TXD_00_10_OFFSET,
 		ZYNQ_QSPI_TXD_00_11_OFFSET, ZYNQ_QSPI_TXD_00_00_OFFSET };
+	unsigned int xsize;
 	u32 data;
 
 	if (xqspi->txbuf) {
@@ -279,7 +318,10 @@ static void zynq_qspi_txfifo_op(struct zynq_qspi *xqspi, unsigned int size)
 	}
 
 	xqspi->tx_bytes -= size;
-	zynq_qspi_write(xqspi, offset[size - 1], data);
+	xsize = size;
+	if (xqspi->is_stripe && (size % 2))
+		xsize++;
+	zynq_qspi_write(xqspi, offset[xsize - 1], data);
 }
 
 /**
@@ -292,14 +334,20 @@ static void zynq_qspi_chipselect(struct spi_device *spi, bool assert)
 	struct spi_controller *ctlr = spi->controller;
 	struct zynq_qspi *xqspi = spi_controller_get_devdata(ctlr);
 	u32 config_reg;
+	u8 idx = 0;
 
 	/* Select the lower (CS0) or upper (CS1) memory */
 	if (ctlr->num_chipselect > 1) {
 		config_reg = zynq_qspi_read(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET);
-		if (!spi_get_chipselect(spi, 0))
-			config_reg &= ~ZYNQ_QSPI_LCFG_U_PAGE;
-		else
-			config_reg |= ZYNQ_QSPI_LCFG_U_PAGE;
+		if (!(xqspi->flags & ZYNQ_QSPI_IS_PARALLEL)) {
+			if (spi->cs_index_mask & ZYNQ_QSPI_CS1_MASK)
+				idx = 1;
+
+			if (!spi_get_chipselect(spi, idx))
+				config_reg &= ~ZYNQ_QSPI_LCFG_U_PAGE;
+			else
+				config_reg |= ZYNQ_QSPI_LCFG_U_PAGE;
+		}
 
 		zynq_qspi_write(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET, config_reg);
 	}
@@ -334,7 +382,17 @@ static void zynq_qspi_chipselect(struct spi_device *spi, bool assert)
 static int zynq_qspi_config_op(struct zynq_qspi *xqspi, struct spi_device *spi)
 {
 	u32 config_reg, baud_rate_val = 0;
-
+	u32 lqspi_cfg_reg = 0;
+
+	lqspi_cfg_reg = zynq_qspi_read(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET);
+	/* In dual parallel enable two memories on separate buses */
+	if ((spi->cs_index_mask & ZYNQ_QSPI_CS0_MASK) &&
+	    (spi->cs_index_mask & ZYNQ_QSPI_CS1_MASK)) {
+		lqspi_cfg_reg |= ZYNQ_QSPI_LCFG_SEP_BUS;
+		xqspi->flags |= ZYNQ_QSPI_IS_PARALLEL;
+	}
+	lqspi_cfg_reg |= ((1 << ZYNQ_QSPI_LCFG_DUMMY_SHIFT) | ZYNQ_QSPI_FAST_READ_QOUT_CODE);
+	zynq_qspi_write(xqspi, ZYNQ_QSPI_LINEAR_CFG_OFFSET, lqspi_cfg_reg);
 	/*
 	 * Set the clock frequency
 	 * The baud rate divisor is not a direct mapping to the value written
@@ -352,8 +410,6 @@ static int zynq_qspi_config_op(struct zynq_qspi *xqspi, struct spi_device *spi)
 	config_reg = zynq_qspi_read(xqspi, ZYNQ_QSPI_CONFIG_OFFSET);
 
 	/* Set the QSPI clock phase and clock polarity */
-	config_reg &= (~ZYNQ_QSPI_CONFIG_CPHA_MASK) &
-		      (~ZYNQ_QSPI_CONFIG_CPOL_MASK);
 	if (spi->mode & SPI_CPHA)
 		config_reg |= ZYNQ_QSPI_CONFIG_CPHA_MASK;
 	if (spi->mode & SPI_CPOL)
@@ -535,6 +591,7 @@ static int zynq_qspi_exec_mem_op(struct spi_mem *mem,
 				 const struct spi_mem_op *op)
 {
 	struct zynq_qspi *xqspi = spi_controller_get_devdata(mem->spi->controller);
+	u8 opaddr[ZYNQ_QSPI_MAX_ADDR_WIDTH];
 	int err = 0, i;
 	u8 *tmpbuf;
 
@@ -542,8 +599,11 @@ static int zynq_qspi_exec_mem_op(struct spi_mem *mem,
 		op->cmd.opcode, op->cmd.buswidth, op->addr.buswidth,
 		op->dummy.buswidth, op->data.buswidth);
 
-	zynq_qspi_chipselect(mem->spi, true);
+	if (op->addr.nbytes > ZYNQ_QSPI_MAX_ADDR_WIDTH)
+		return -EINVAL;
+
 	zynq_qspi_config_op(xqspi, mem->spi);
+	zynq_qspi_chipselect(mem->spi, true);
 
 	if (op->cmd.opcode) {
 		reinit_completion(&xqspi->data_completion);
@@ -560,6 +620,7 @@ static int zynq_qspi_exec_mem_op(struct spi_mem *mem,
 	}
 
 	if (op->addr.nbytes) {
+		xqspi->txbuf = opaddr;
 		for (i = 0; i < op->addr.nbytes; i++) {
 			xqspi->txbuf[i] = op->addr.val >>
 					(8 * (op->addr.nbytes - i - 1));
@@ -599,6 +660,8 @@ static int zynq_qspi_exec_mem_op(struct spi_mem *mem,
 	}
 
 	if (op->data.nbytes) {
+		if (xqspi->flags & ZYNQ_QSPI_IS_PARALLEL)
+			xqspi->is_stripe = zynq_qspi_update_stripe(op);
 		reinit_completion(&xqspi->data_completion);
 		if (op->data.dir == SPI_MEM_DATA_OUT) {
 			xqspi->txbuf = (u8 *)op->data.buf.out;
@@ -619,6 +682,9 @@ static int zynq_qspi_exec_mem_op(struct spi_mem *mem,
 							       msecs_to_jiffies(1000)))
 			err = -ETIMEDOUT;
 	}
+	if (xqspi->is_stripe)
+		xqspi->is_stripe = false;
+
 	zynq_qspi_chipselect(mem->spi, false);
 
 	return err;
@@ -652,6 +718,7 @@ static int zynq_qspi_probe(struct platform_device *pdev)
 
 	xqspi = spi_controller_get_devdata(ctlr);
 	xqspi->dev = dev;
+	xqspi->ctlr = ctlr;
 	platform_set_drvdata(pdev, xqspi);
 	xqspi->regs = devm_platform_ioremap_resource(pdev, 0);
 	if (IS_ERR(xqspi->regs)) {
@@ -712,12 +779,13 @@ static int zynq_qspi_probe(struct platform_device *pdev)
 		ctlr->num_chipselect = num_cs;
 	}
 
-	ctlr->mode_bits =  SPI_RX_DUAL | SPI_RX_QUAD |
+	ctlr->mode_bits =  SPI_CPOL | SPI_CPHA | SPI_RX_DUAL | SPI_RX_QUAD |
 			    SPI_TX_DUAL | SPI_TX_QUAD;
 	ctlr->mem_ops = &zynq_qspi_mem_ops;
 	ctlr->setup = zynq_qspi_setup_op;
 	ctlr->max_speed_hz = clk_get_rate(xqspi->refclk) / 2;
 	ctlr->dev.of_node = np;
+	ctlr->flags |= SPI_CONTROLLER_MULTI_CS | SPI_CONTROLLER_NO_4B;
 
 	/* QSPI controller initializations */
 	zynq_qspi_init_hw(xqspi, ctlr->num_chipselect);
diff --git a/drivers/spi/spi-zynqmp-gqspi.c b/drivers/spi/spi-zynqmp-gqspi.c
index b9df39e06..d9d3f21f3 100644
--- a/drivers/spi/spi-zynqmp-gqspi.c
+++ b/drivers/spi/spi-zynqmp-gqspi.c
@@ -21,6 +21,7 @@
 #include <linux/spinlock.h>
 #include <linux/workqueue.h>
 #include <linux/spi/spi-mem.h>
+#include <linux/mtd/spi-nor.h>
 
 /* Generic QSPI register offsets */
 #define GQSPI_CONFIG_OFST		0x00000100
@@ -154,6 +155,9 @@
 #define GQSPI_FREQ_100MHZ	100000000
 #define GQSPI_FREQ_150MHZ	150000000
 
+#define GQSPI_SELECT_LOWER_CS  BIT(0)
+#define GQSPI_SELECT_UPPER_CS  BIT(1)
+
 #define SPI_AUTOSUSPEND_TIMEOUT		3000
 enum mode_type {GQSPI_MODE_IO, GQSPI_MODE_DMA};
 
@@ -183,10 +187,12 @@ struct qspi_platform_data {
  * @dma_addr:		DMA address after mapping the kernel buffer
  * @genfifoentry:	Used for storing the genfifoentry instruction.
  * @mode:		Defines the mode in which QSPI is operating
+* @io_mode:		Defines the operating mode, either IO or dma
  * @data_completion:	completion structure
  * @op_lock:		Operational lock
  * @speed_hz:          Current SPI bus clock speed in hz
  * @has_tapdelay:	Used for tapdelay register available in qspi
+ * @is_parallel:		Used for multi CS support
  */
 struct zynqmp_qspi {
 	struct spi_controller *ctlr;
@@ -208,9 +214,57 @@ struct zynqmp_qspi {
 	struct completion data_completion;
 	struct mutex op_lock;
 	u32 speed_hz;
+	bool io_mode;
 	bool has_tapdelay;
+	bool is_parallel;
 };
 
+/**
+ * zynqmp_gqspi_update_stripe - For GQSPI controller data stripe capabilities
+ * @op:	Pointer to mem ops
+ * Return:      Status of the data stripe
+ *
+ * Returns true if data stripe need to be enabled, else returns false
+ */
+static bool zynqmp_gqspi_update_stripe(const struct spi_mem_op *op)
+{
+	if (op->cmd.opcode ==  SPINOR_OP_BE_4K ||
+	    op->cmd.opcode ==  SPINOR_OP_BE_32K ||
+	    op->cmd.opcode ==  SPINOR_OP_CHIP_ERASE ||
+	    op->cmd.opcode ==  SPINOR_OP_SE ||
+	    op->cmd.opcode ==  SPINOR_OP_BE_32K_4B ||
+	    op->cmd.opcode ==  SPINOR_OP_SE_4B ||
+	    op->cmd.opcode == SPINOR_OP_BE_4K_4B ||
+	    op->cmd.opcode ==  SPINOR_OP_WRSR ||
+	    op->cmd.opcode ==  SPINOR_OP_BRWR ||
+	    (op->cmd.opcode ==  SPINOR_OP_WRSR2 && !op->addr.nbytes))
+		return false;
+
+	return true;
+}
+
+/**
+ * zynqmp_get_addr_buswidth - Get address buswidth
+ * @op:	The memory operation to execute
+ *
+ * This function gets address busswith
+ *
+ * Return:	buswidth
+ */
+static u8 zynqmp_get_addr_buswidth(const struct spi_mem_op *op)
+{
+	if (op->cmd.opcode == SPINOR_OP_BE_4K ||
+	    op->cmd.opcode == SPINOR_OP_BE_32K ||
+	    op->cmd.opcode == SPINOR_OP_CHIP_ERASE ||
+	    op->cmd.opcode == SPINOR_OP_SE ||
+	    op->cmd.opcode == SPINOR_OP_BE_4K_4B ||
+	    op->cmd.opcode == SPINOR_OP_BE_32K_4B ||
+	    op->cmd.opcode == SPINOR_OP_SE_4B)
+		return op->cmd.buswidth;
+
+	return op->addr.buswidth;
+}
+
 /**
  * zynqmp_gqspi_read - For GQSPI controller read operation
  * @xqspi:	Pointer to the zynqmp_qspi structure
@@ -429,10 +483,11 @@ static void zynqmp_qspi_init_hw(struct zynqmp_qspi *xqspi)
 	zynqmp_gqspi_selecttarget(xqspi,
 				  GQSPI_SELECT_FLASH_CS_LOWER,
 				  GQSPI_SELECT_FLASH_BUS_LOWER);
-	/* Initialize DMA */
-	zynqmp_gqspi_write(xqspi,
-			   GQSPI_QSPIDMA_DST_CTRL_OFST,
-			   GQSPI_QSPIDMA_DST_CTRL_RESET_VAL);
+	if (!xqspi->io_mode)
+		/* Initialize DMA */
+		zynqmp_gqspi_write(xqspi,
+				   GQSPI_QSPIDMA_DST_CTRL_OFST,
+				   GQSPI_QSPIDMA_DST_CTRL_RESET_VAL);
 
 	/* Enable the GQSPI */
 	zynqmp_gqspi_write(xqspi, GQSPI_EN_OFST, GQSPI_EN_MASK);
@@ -465,15 +520,24 @@ static void zynqmp_qspi_chipselect(struct spi_device *qspi, bool is_high)
 
 	genfifoentry |= GQSPI_GENFIFO_MODE_SPI;
 
+	if ((qspi->cs_index_mask & GQSPI_SELECT_LOWER_CS) &&
+	    (qspi->cs_index_mask & GQSPI_SELECT_UPPER_CS)) {
+		zynqmp_gqspi_selecttarget(xqspi,
+					  GQSPI_SELECT_FLASH_CS_BOTH,
+					  GQSPI_SELECT_FLASH_BUS_BOTH);
+		if (!xqspi->is_parallel)
+			xqspi->is_parallel = true;
+	} else if (qspi->cs_index_mask & GQSPI_SELECT_UPPER_CS) {
+		zynqmp_gqspi_selecttarget(xqspi,
+					  GQSPI_SELECT_FLASH_CS_UPPER,
+					  GQSPI_SELECT_FLASH_BUS_LOWER);
+	} else if (qspi->cs_index_mask & GQSPI_SELECT_LOWER_CS) {
+		zynqmp_gqspi_selecttarget(xqspi,
+					  GQSPI_SELECT_FLASH_CS_LOWER,
+					  GQSPI_SELECT_FLASH_BUS_LOWER);
+	}
+	genfifoentry |= xqspi->genfifobus;
 	if (!is_high) {
-		if (!spi_get_chipselect(qspi, 0)) {
-			xqspi->genfifobus = GQSPI_GENFIFO_BUS_LOWER;
-			xqspi->genfifocs = GQSPI_GENFIFO_CS_LOWER;
-		} else {
-			xqspi->genfifobus = GQSPI_GENFIFO_BUS_UPPER;
-			xqspi->genfifocs = GQSPI_GENFIFO_CS_UPPER;
-		}
-		genfifoentry |= xqspi->genfifobus;
 		genfifoentry |= xqspi->genfifocs;
 		genfifoentry |= GQSPI_GENFIFO_CS_SETUP;
 	} else {
@@ -724,6 +788,12 @@ static void zynqmp_qspi_fillgenfifo(struct zynqmp_qspi *xqspi, u8 nbits,
 		if (imm_data != 0) {
 			genfifoentry &= ~GQSPI_GENFIFO_EXP;
 			genfifoentry &= ~GQSPI_GENFIFO_IMM_DATA_MASK;
+			if (imm_data % 4 != 0) {
+				if (((imm_data + 4 - (imm_data % 4)) & 0xFF) == 0x00)
+					imm_data = 0xFF;
+				else
+					imm_data = imm_data + 4 - (imm_data % 4);
+			}
 			genfifoentry |= (u8)(imm_data & 0xFF);
 			zynqmp_gqspi_write(xqspi, GQSPI_GEN_FIFO_OFST,
 					   genfifoentry);
@@ -813,28 +883,34 @@ static irqreturn_t zynqmp_qspi_irq(int irq, void *dev_id)
 		zynqmp_gqspi_write(xqspi, GQSPI_QSPIDMA_DST_I_STS_OFST,
 				   dma_status);
 	}
-
-	if (mask & GQSPI_ISR_TXNOT_FULL_MASK) {
-		zynqmp_qspi_filltxfifo(xqspi, GQSPI_TX_FIFO_FILL);
-		ret = IRQ_HANDLED;
-	}
-
 	if (dma_status & GQSPI_QSPIDMA_DST_I_STS_DONE_MASK) {
 		zynqmp_process_dma_irq(xqspi);
 		ret = IRQ_HANDLED;
-	} else if (!(mask & GQSPI_IER_RXEMPTY_MASK) &&
-			(mask & GQSPI_IER_GENFIFOEMPTY_MASK)) {
+	} else if ((mask & GQSPI_IER_RXNEMPTY_MASK)) {
+		zynqmp_qspi_readrxfifo(xqspi, GQSPI_RX_FIFO_FILL);
+		ret = IRQ_HANDLED;
+	}
+	if (!(mask & GQSPI_IER_RXEMPTY_MASK) &&
+	    (mask & GQSPI_IER_GENFIFOEMPTY_MASK)) {
 		zynqmp_qspi_readrxfifo(xqspi, GQSPI_RX_FIFO_FILL);
 		ret = IRQ_HANDLED;
 	}
 
 	if (xqspi->bytes_to_receive == 0 && xqspi->bytes_to_transfer == 0 &&
 	    ((status & GQSPI_IRQ_MASK) == GQSPI_IRQ_MASK)) {
-		zynqmp_gqspi_write(xqspi, GQSPI_IDR_OFST, GQSPI_ISR_IDR_MASK);
-		complete(&xqspi->data_completion);
+		goto transfer_complete;
+	}
+	if (mask & GQSPI_ISR_TXNOT_FULL_MASK) {
+		zynqmp_qspi_filltxfifo(xqspi, GQSPI_TX_FIFO_FILL);
 		ret = IRQ_HANDLED;
 	}
+
 	return ret;
+
+transfer_complete:
+	zynqmp_gqspi_write(xqspi, GQSPI_IDR_OFST, GQSPI_ISR_IDR_MASK);
+	complete(&xqspi->data_completion);
+	return IRQ_HANDLED;
 }
 
 /**
@@ -849,8 +925,9 @@ static int zynqmp_qspi_setuprxdma(struct zynqmp_qspi *xqspi)
 	dma_addr_t addr;
 	u64 dma_align =  (u64)(uintptr_t)xqspi->rxbuf;
 
-	if (xqspi->bytes_to_receive < 8 ||
-	    ((dma_align & GQSPI_DMA_UNALIGN) != 0x0)) {
+	if ((xqspi->bytes_to_receive < 8 || xqspi->io_mode) ||
+	    ((dma_align & GQSPI_DMA_UNALIGN) != 0x0) ||
+	    is_vmalloc_addr(xqspi->rxbuf)) {
 		/* Setting to IO mode */
 		config_reg = zynqmp_gqspi_read(xqspi, GQSPI_CONFIG_OFST);
 		config_reg &= ~GQSPI_CFG_MODE_EN_MASK;
@@ -978,11 +1055,26 @@ static int __maybe_unused zynqmp_qspi_resume(struct device *dev)
 {
 	struct zynqmp_qspi *xqspi = dev_get_drvdata(dev);
 	struct spi_controller *ctlr = xqspi->ctlr;
+	int ret = 0;
 
-	zynqmp_gqspi_write(xqspi, GQSPI_EN_OFST, GQSPI_EN_MASK);
+	ret = clk_enable(xqspi->pclk);
+	if (ret) {
+		dev_err(dev, "Cannot enable APB clock.\n");
+		return ret;
+	}
 
+	ret = clk_enable(xqspi->refclk);
+	if (ret) {
+		dev_err(dev, "Cannot enable device clock.\n");
+		clk_disable(xqspi->pclk);
+		return ret;
+	}
+
+	zynqmp_qspi_init_hw(xqspi);
 	spi_controller_resume(ctlr);
 
+	clk_disable(xqspi->refclk);
+	clk_disable(xqspi->pclk);
 	return 0;
 }
 
@@ -998,8 +1090,8 @@ static int __maybe_unused zynqmp_runtime_suspend(struct device *dev)
 {
 	struct zynqmp_qspi *xqspi = dev_get_drvdata(dev);
 
-	clk_disable_unprepare(xqspi->refclk);
-	clk_disable_unprepare(xqspi->pclk);
+	clk_disable(xqspi->refclk);
+	clk_disable(xqspi->pclk);
 
 	return 0;
 }
@@ -1017,16 +1109,16 @@ static int __maybe_unused zynqmp_runtime_resume(struct device *dev)
 	struct zynqmp_qspi *xqspi = dev_get_drvdata(dev);
 	int ret;
 
-	ret = clk_prepare_enable(xqspi->pclk);
+	ret = clk_enable(xqspi->pclk);
 	if (ret) {
 		dev_err(dev, "Cannot enable APB clock.\n");
 		return ret;
 	}
 
-	ret = clk_prepare_enable(xqspi->refclk);
+	ret = clk_enable(xqspi->refclk);
 	if (ret) {
 		dev_err(dev, "Cannot enable device clock.\n");
-		clk_disable_unprepare(xqspi->pclk);
+		clk_disable(xqspi->pclk);
 		return ret;
 	}
 
@@ -1064,8 +1156,11 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 	unsigned long timeout;
 	int err = 0, i;
 	u32 genfifoentry = 0;
+	u32 speed_hz = xqspi->speed_hz;
 	u16 opcode = op->cmd.opcode;
+	unsigned long long ms;
 	u64 opaddr;
+	u8 addrbuswidth = zynqmp_get_addr_buswidth(op);
 
 	dev_dbg(xqspi->dev, "cmd:%#x mode:%d.%d.%d.%d\n",
 		op->cmd.opcode, op->cmd.buswidth, op->addr.buswidth,
@@ -1083,7 +1178,8 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 		xqspi->rxbuf = NULL;
 		xqspi->bytes_to_transfer = op->cmd.nbytes;
 		xqspi->bytes_to_receive = 0;
-		zynqmp_qspi_write_op(xqspi, op->cmd.buswidth, genfifoentry);
+		/* Opcode always gets transmitted on single line */
+		zynqmp_qspi_write_op(xqspi, 0x1, genfifoentry);
 		zynqmp_gqspi_write(xqspi, GQSPI_CONFIG_OFST,
 				   zynqmp_gqspi_read(xqspi, GQSPI_CONFIG_OFST) |
 				   GQSPI_CFG_START_GEN_FIFO_MASK);
@@ -1110,7 +1206,7 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 		xqspi->rxbuf = NULL;
 		xqspi->bytes_to_transfer = op->addr.nbytes;
 		xqspi->bytes_to_receive = 0;
-		zynqmp_qspi_write_op(xqspi, op->addr.buswidth, genfifoentry);
+		zynqmp_qspi_write_op(xqspi, addrbuswidth, genfifoentry);
 		zynqmp_gqspi_write(xqspi, GQSPI_CONFIG_OFST,
 				   zynqmp_gqspi_read(xqspi,
 						     GQSPI_CONFIG_OFST) |
@@ -1149,12 +1245,22 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 	}
 
 	if (op->data.nbytes) {
+		if (xqspi->is_parallel && zynqmp_gqspi_update_stripe(op))
+			genfifoentry |= GQSPI_GENFIFO_STRIPE;
 		reinit_completion(&xqspi->data_completion);
 		if (op->data.dir == SPI_MEM_DATA_OUT) {
 			xqspi->txbuf = (u8 *)op->data.buf.out;
 			xqspi->rxbuf = NULL;
 			xqspi->bytes_to_transfer = op->data.nbytes;
 			xqspi->bytes_to_receive = 0;
+			if ((genfifoentry & GQSPI_GENFIFO_STRIPE) &&
+			    (xqspi->bytes_to_transfer % 2)) {
+				u32 data_len = xqspi->bytes_to_transfer;
+
+				xqspi->bytes_to_transfer = roundup(xqspi->bytes_to_transfer, 4);
+				for (; data_len < xqspi->bytes_to_transfer; data_len++)
+					*(((u8 *)xqspi->txbuf) + data_len) = 0xFF;
+			}
 			zynqmp_qspi_write_op(xqspi, op->data.buswidth,
 					     genfifoentry);
 			zynqmp_gqspi_write(xqspi, GQSPI_CONFIG_OFST,
@@ -1190,10 +1296,31 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 						   GQSPI_IER_RXEMPTY_MASK);
 			}
 		}
-		timeout = zynqmp_qspi_timeout(xqspi, op->data.buswidth,
-					      op->data.nbytes);
-		if (!wait_for_completion_timeout(&xqspi->data_completion, timeout))
+
+		if (speed_hz)
+			speed_hz = 100000;
+
+		/*
+		 * For each byte we wait for 8 cycles of the SPI clock.
+		 * Since speed is defined in Hz and we want milliseconds,
+		 * use respective multiplier, but before the division,
+		 * otherwise we may get 0 for short transfers.
+		 */
+		ms = 8LL * MSEC_PER_SEC * op->data.nbytes;
+		do_div(ms, speed_hz);
+
+		/*
+		 * Increase it twice and add 10000 ms tolerance, use
+		 * predefined maximum in case of overflow.
+		 */
+		ms += ms + 10000;
+		if (ms > UINT_MAX)
+			ms = UINT_MAX;
+
+		if (!wait_for_completion_timeout
+		    (&xqspi->data_completion, msecs_to_jiffies(ms)))
 			err = -ETIMEDOUT;
+
 	}
 
 return_err:
@@ -1204,9 +1331,20 @@ static int zynqmp_qspi_exec_op(struct spi_mem *mem,
 	return err;
 }
 
+static int __maybe_unused zynqmp_runtime_idle(struct device *dev)
+{
+	struct zynqmp_qspi *xqspi = dev_get_drvdata(dev);
+	u32 value;
+
+	value = zynqmp_gqspi_read(xqspi, GQSPI_EN_OFST);
+	if (value)
+		return -EBUSY;
+
+	return 0;
+}
 static const struct dev_pm_ops zynqmp_qspi_dev_pm_ops = {
 	SET_RUNTIME_PM_OPS(zynqmp_runtime_suspend,
-			   zynqmp_runtime_resume, NULL)
+			   zynqmp_runtime_resume, zynqmp_runtime_idle)
 	SET_SYSTEM_SLEEP_PM_OPS(zynqmp_qspi_suspend, zynqmp_qspi_resume)
 };
 
@@ -1288,6 +1426,8 @@ static int zynqmp_qspi_probe(struct platform_device *pdev)
 	pm_runtime_set_active(&pdev->dev);
 	pm_runtime_enable(&pdev->dev);
 
+	if (of_property_read_bool(pdev->dev.of_node, "has-io-mode"))
+		xqspi->io_mode = true;
 	ret = pm_runtime_get_sync(&pdev->dev);
 	if (ret < 0) {
 		dev_err(&pdev->dev, "Failed to pm_runtime_get_sync: %d\n", ret);
@@ -1337,6 +1477,7 @@ static int zynqmp_qspi_probe(struct platform_device *pdev)
 	ctlr->bits_per_word_mask = SPI_BPW_MASK(8);
 	ctlr->dev.of_node = np;
 	ctlr->auto_runtime_pm = true;
+	ctlr->flags |= SPI_CONTROLLER_MULTI_CS;
 
 	ret = devm_spi_register_controller(&pdev->dev, ctlr);
 	if (ret) {
diff --git a/drivers/spi/spi.c b/drivers/spi/spi.c
index 0f3e6e2c2..2d1479ccb 100644
--- a/drivers/spi/spi.c
+++ b/drivers/spi/spi.c
@@ -2487,6 +2487,9 @@ static int of_spi_parse_dt(struct spi_controller *ctlr, struct spi_device *spi,
 	of_spi_parse_dt_cs_delay(nc, &spi->cs_hold, "spi-cs-hold-delay-ns");
 	of_spi_parse_dt_cs_delay(nc, &spi->cs_inactive, "spi-cs-inactive-delay-ns");
 
+	/* Multi die flash */
+	if (of_property_read_bool(nc, "multi-die"))
+		spi->multi_die = true;
 	return 0;
 }
 
diff --git a/include/linux/spi/spi-mem.h b/include/linux/spi/spi-mem.h
index f866d5c8e..a1a08f458 100644
--- a/include/linux/spi/spi-mem.h
+++ b/include/linux/spi/spi-mem.h
@@ -55,6 +55,8 @@
 
 #define SPI_MEM_OP_NO_DATA	{ }
 
+#define SPI_MEM_DEV_MAX_ID_LEN		6
+
 /**
  * enum spi_mem_data_dir - describes the direction of a SPI memory data
  *			   transfer from the controller perspective
@@ -201,6 +203,9 @@ struct spi_mem {
 	struct spi_device *spi;
 	void *drvpriv;
 	const char *name;
+	u8 device_id[SPI_MEM_DEV_MAX_ID_LEN];
+	struct delayed_work	complete_work;
+	struct completion	request_completion;
 };
 
 /**
diff --git a/include/linux/spi/spi.h b/include/linux/spi/spi.h
index 4b9566316..e4c372e22 100644
--- a/include/linux/spi/spi.h
+++ b/include/linux/spi/spi.h
@@ -164,6 +164,7 @@ extern void spi_transfer_cs_change_delay_exec(struct spi_message *msg,
  *	(optional, NULL when not using a GPIO line)
  * @word_delay: delay to be inserted between consecutive
  *	words of a transfer
+ * @multi_die: Flash device with multiple dies.
  * @cs_setup: delay to be introduced by the controller after CS is asserted
  * @cs_hold: delay to be introduced by the controller before CS is deasserted
  * @cs_inactive: delay to be introduced by the controller after CS is
@@ -218,6 +219,7 @@ struct spi_device {
 	const char		*driver_override;
 	struct gpio_desc	*cs_gpiod[SPI_CS_CNT_MAX];	/* Chip select gpio desc */
 	struct spi_delay	word_delay; /* Inter-word delay */
+	bool			multi_die;	/* flash with multiple dies*/
 	/* CS delays */
 	struct spi_delay	cs_setup;
 	struct spi_delay	cs_hold;
@@ -598,6 +600,7 @@ struct spi_controller {
 	 * assert/de-assert more than one chip select at once.
 	 */
 #define SPI_CONTROLLER_MULTI_CS		BIT(7)
+#define	SPI_CONTROLLER_NO_4B		BIT(8)	/* No 4-byte mode support */
 
 	/* Flag indicating if the allocation of this struct is devres-managed */
 	bool			devm_allocated;
@@ -973,6 +976,7 @@ struct spi_res {
  * @len: size of rx and tx buffers (in bytes)
  * @speed_hz: Select a speed other than the device default for this
  *      transfer. If 0 the default (from @spi_device) is used.
+ * @dummy_data: indicates transfer is dummy bytes transfer.
  * @bits_per_word: select a bits_per_word other than the device default
  *      for this transfer. If 0 the default (from @spi_device) is used.
  * @dummy_data: indicates transfer is dummy bytes transfer.
@@ -1110,6 +1114,7 @@ struct spi_transfer {
 	struct spi_delay	cs_change_delay;
 	struct spi_delay	word_delay;
 	u32		speed_hz;
+	u32		dummy;
 
 	u32		effective_speed_hz;
 
